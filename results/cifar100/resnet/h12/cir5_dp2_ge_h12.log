==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=16, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=64, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=64, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule2(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.349 | Acc: 0.000,0.781,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.406 | Acc: 1.414,1.488,1.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.212 | Acc: 1.429,1.296,1.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.141 | Acc: 1.614,1.178,1.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.100 | Acc: 1.746,1.167,1.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.068 | Acc: 1.717,1.245,1.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.045 | Acc: 1.659,1.227,1.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.015 | Acc: 1.751,1.280,1.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.997 | Acc: 1.723,1.300,1.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.981 | Acc: 1.800,1.334,1.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.961 | Acc: 1.835,1.337,1.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.941 | Acc: 1.845,1.372,1.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.921 | Acc: 1.883,1.417,1.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.905 | Acc: 1.889,1.476,1.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.890 | Acc: 1.879,1.546,1.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.869 | Acc: 1.910,1.651,1.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.853 | Acc: 1.981,1.733,1.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.837 | Acc: 1.991,1.796,1.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.820 | Acc: 2.047,1.883,1.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.807 | Acc: 2.083,1.940,1.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.522 | Acc: 2.344,4.688,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.707 | Acc: 2.530,3.795,0.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.708 | Acc: 2.782,3.373,1.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.693 | Acc: 2.830,3.394,1.025,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 13.631 | Acc: 2.344,4.688,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.491 | Acc: 3.237,3.646,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.476 | Acc: 3.068,3.258,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.447 | Acc: 3.215,3.407,1.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.439 | Acc: 3.221,3.559,1.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.424 | Acc: 3.210,3.713,1.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.401 | Acc: 3.202,3.816,1.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.386 | Acc: 3.186,3.890,1.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.368 | Acc: 3.159,3.979,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.354 | Acc: 3.172,4.096,1.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.341 | Acc: 3.191,4.155,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.330 | Acc: 3.192,4.239,1.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.313 | Acc: 3.213,4.263,1.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.301 | Acc: 3.230,4.304,1.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.290 | Acc: 3.217,4.384,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.276 | Acc: 3.257,4.451,1.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.265 | Acc: 3.259,4.515,1.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.249 | Acc: 3.320,4.655,1.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.237 | Acc: 3.328,4.729,1.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.227 | Acc: 3.346,4.772,1.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.064 | Acc: 7.812,3.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.361 | Acc: 3.869,3.274,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.389 | Acc: 3.716,3.639,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.376 | Acc: 3.548,3.740,2.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 13.071 | Acc: 4.688,3.906,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.890 | Acc: 5.060,7.850,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.927 | Acc: 4.573,6.993,1.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.904 | Acc: 4.278,7.018,2.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.912 | Acc: 3.993,6.829,2.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.905 | Acc: 3.991,6.861,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.899 | Acc: 3.919,6.779,2.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.894 | Acc: 3.934,6.859,2.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.887 | Acc: 3.848,6.934,2.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.874 | Acc: 3.915,6.928,2.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.868 | Acc: 3.957,7.027,2.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.859 | Acc: 4.002,7.003,2.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.850 | Acc: 4.026,7.005,2.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.844 | Acc: 4.005,7.031,2.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.832 | Acc: 4.054,7.070,2.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.823 | Acc: 4.002,7.096,2.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.805 | Acc: 4.047,7.119,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.788 | Acc: 4.133,7.180,2.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.769 | Acc: 4.214,7.291,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.752 | Acc: 4.230,7.298,2.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.333 | Acc: 5.469,10.156,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.513 | Acc: 4.539,8.482,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.533 | Acc: 4.916,8.479,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.532 | Acc: 4.854,8.402,2.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 12.533 | Acc: 3.125,7.031,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.393 | Acc: 4.576,7.626,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.385 | Acc: 4.897,8.098,3.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.352 | Acc: 4.880,8.363,4.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.316 | Acc: 5.073,8.574,4.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.329 | Acc: 5.097,8.501,4.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.306 | Acc: 5.236,8.581,4.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.308 | Acc: 5.319,8.561,4.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.303 | Acc: 5.347,8.662,4.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.289 | Acc: 5.417,8.697,4.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.276 | Acc: 5.465,8.761,4.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.252 | Acc: 5.557,8.848,4.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.233 | Acc: 5.666,8.898,4.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.223 | Acc: 5.702,8.881,4.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.211 | Acc: 5.772,8.950,4.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.203 | Acc: 5.843,8.955,4.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.195 | Acc: 5.924,8.937,4.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.185 | Acc: 5.964,8.988,4.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.170 | Acc: 6.064,9.079,4.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.159 | Acc: 6.078,9.129,4.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.092 | Acc: 7.812,8.594,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.260 | Acc: 5.952,9.003,5.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.292 | Acc: 5.716,8.632,4.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.291 | Acc: 5.610,8.453,4.969,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 11.517 | Acc: 8.594,17.188,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.815 | Acc: 7.850,10.789,6.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.828 | Acc: 7.470,10.385,5.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.829 | Acc: 7.544,10.412,5.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.834 | Acc: 7.407,10.446,5.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.843 | Acc: 7.294,10.295,5.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.846 | Acc: 7.147,10.427,5.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.838 | Acc: 7.214,10.694,5.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.844 | Acc: 7.264,10.739,5.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.837 | Acc: 7.295,10.838,5.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.830 | Acc: 7.280,10.809,5.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.828 | Acc: 7.307,10.945,6.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.816 | Acc: 7.372,10.908,6.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.807 | Acc: 7.396,10.923,6.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.801 | Acc: 7.393,10.968,6.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.792 | Acc: 7.369,10.987,6.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.777 | Acc: 7.528,11.125,6.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.766 | Acc: 7.554,11.141,6.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.764 | Acc: 7.523,11.150,6.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.755 | Acc: 7.538,11.124,6.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.563 | Acc: 7.031,14.062,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.785 | Acc: 6.957,9.673,6.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.775 | Acc: 7.622,9.889,6.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.793 | Acc: 7.492,9.695,6.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 11.603 | Acc: 9.375,10.938,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.553 | Acc: 7.850,11.198,7.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.533 | Acc: 8.022,11.357,6.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.532 | Acc: 8.389,11.539,7.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.533 | Acc: 8.314,11.603,7.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.543 | Acc: 8.277,11.610,7.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.527 | Acc: 8.348,11.654,7.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.506 | Acc: 8.300,11.796,7.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.498 | Acc: 8.424,11.903,7.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.490 | Acc: 8.391,11.904,7.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.488 | Acc: 8.399,11.995,7.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.474 | Acc: 8.389,12.002,7.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.461 | Acc: 8.464,12.069,7.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.452 | Acc: 8.501,12.147,7.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.444 | Acc: 8.438,12.233,7.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.432 | Acc: 8.493,12.313,7.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.424 | Acc: 8.538,12.388,7.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.418 | Acc: 8.557,12.404,8.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.413 | Acc: 8.583,12.504,8.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.406 | Acc: 8.592,12.566,8.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.719 | Acc: 6.250,12.500,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.652 | Acc: 7.292,11.012,8.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.648 | Acc: 7.222,10.995,8.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.641 | Acc: 7.262,11.181,8.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 11.103 | Acc: 9.375,16.406,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.181 | Acc: 8.966,14.397,11.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.143 | Acc: 9.299,14.596,11.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.149 | Acc: 9.477,14.857,10.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.135 | Acc: 9.597,14.641,10.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.105 | Acc: 9.800,14.604,10.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.101 | Acc: 9.543,14.540,10.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.089 | Acc: 9.480,14.545,10.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.089 | Acc: 9.394,14.407,10.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.081 | Acc: 9.384,14.477,10.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.071 | Acc: 9.398,14.630,10.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.061 | Acc: 9.516,14.752,10.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.059 | Acc: 9.531,14.727,10.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.052 | Acc: 9.411,14.745,10.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.048 | Acc: 9.372,14.841,10.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.041 | Acc: 9.354,14.948,11.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.037 | Acc: 9.356,15.007,11.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.033 | Acc: 9.290,14.970,11.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.026 | Acc: 9.319,15.030,11.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.018 | Acc: 9.338,15.026,11.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.158 | Acc: 10.156,10.156,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.373 | Acc: 8.743,12.016,7.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.349 | Acc: 8.880,12.500,7.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.361 | Acc: 8.876,12.231,7.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 10.554 | Acc: 10.938,18.750,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.843 | Acc: 10.045,17.113,12.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.809 | Acc: 9.756,16.482,12.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.731 | Acc: 10.297,16.983,12.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.711 | Acc: 9.934,16.956,13.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.716 | Acc: 9.955,16.940,13.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.719 | Acc: 10.014,16.729,13.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.713 | Acc: 9.912,16.700,13.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.707 | Acc: 9.797,16.605,13.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.703 | Acc: 9.772,16.605,13.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.694 | Acc: 9.783,16.783,13.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.684 | Acc: 9.803,16.845,13.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.673 | Acc: 9.903,16.944,13.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.664 | Acc: 9.971,17.059,13.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.647 | Acc: 10.023,17.137,13.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.639 | Acc: 9.998,17.211,14.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.629 | Acc: 10.000,17.287,14.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.615 | Acc: 10.033,17.368,14.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.595 | Acc: 10.102,17.473,14.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.585 | Acc: 10.150,17.501,14.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.158 | Acc: 7.031,17.188,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.043 | Acc: 6.845,16.034,15.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.065 | Acc: 6.841,16.597,15.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.075 | Acc: 6.814,16.329,15.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 10.488 | Acc: 14.062,19.531,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.417 | Acc: 11.012,18.155,17.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.420 | Acc: 11.204,17.912,16.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.366 | Acc: 11.232,18.353,16.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.344 | Acc: 10.976,18.239,16.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.296 | Acc: 11.084,18.603,17.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.282 | Acc: 11.163,18.685,17.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.274 | Acc: 11.176,18.833,17.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.262 | Acc: 11.287,18.828,17.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.248 | Acc: 11.460,19.061,17.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.243 | Acc: 11.466,18.979,17.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.227 | Acc: 11.531,19.082,17.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.210 | Acc: 11.566,19.259,17.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.198 | Acc: 11.593,19.334,17.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.186 | Acc: 11.688,19.442,18.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.172 | Acc: 11.734,19.529,18.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.155 | Acc: 11.806,19.655,18.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.147 | Acc: 11.852,19.719,18.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.142 | Acc: 11.831,19.730,18.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.134 | Acc: 11.844,19.726,18.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.355 | Acc: 3.125,13.281,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.714 | Acc: 4.985,9.747,12.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.774 | Acc: 4.421,9.242,12.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.783 | Acc: 4.380,9.298,12.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 10.125 | Acc: 11.719,24.219,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.916 | Acc: 13.281,20.089,20.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.884 | Acc: 12.862,20.694,20.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.899 | Acc: 12.372,20.633,20.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.876 | Acc: 12.529,20.689,21.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.890 | Acc: 12.338,20.637,20.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.862 | Acc: 12.455,21.003,21.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.867 | Acc: 12.373,20.745,21.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.841 | Acc: 12.607,20.938,21.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.822 | Acc: 12.634,21.094,21.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.805 | Acc: 12.784,21.269,21.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.788 | Acc: 12.854,21.384,21.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.773 | Acc: 12.892,21.518,21.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.769 | Acc: 12.910,21.555,21.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.759 | Acc: 13.012,21.533,21.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.744 | Acc: 13.058,21.608,22.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.733 | Acc: 13.087,21.663,22.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.723 | Acc: 13.194,21.673,22.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.716 | Acc: 13.197,21.745,22.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.702 | Acc: 13.271,21.791,22.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.191 | Acc: 5.469,16.406,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.193 | Acc: 7.106,17.783,18.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.135 | Acc: 6.669,17.454,18.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.168 | Acc: 6.737,17.059,19.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 9.691 | Acc: 12.500,19.531,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.489 | Acc: 13.616,22.619,23.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.448 | Acc: 13.796,22.942,24.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.443 | Acc: 13.922,23.335,24.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.410 | Acc: 14.207,23.659,24.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.387 | Acc: 14.434,23.546,24.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.361 | Acc: 14.805,23.689,25.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.366 | Acc: 14.755,23.681,25.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.370 | Acc: 14.960,23.700,25.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.358 | Acc: 15.133,23.645,25.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.358 | Acc: 15.073,23.601,25.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.351 | Acc: 15.155,23.657,25.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.332 | Acc: 15.285,23.846,25.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.330 | Acc: 15.326,23.803,25.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.327 | Acc: 15.314,23.768,25.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.317 | Acc: 15.412,23.889,25.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.308 | Acc: 15.537,24.024,25.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.294 | Acc: 15.646,24.072,25.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.288 | Acc: 15.727,24.134,25.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.277 | Acc: 15.754,24.213,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.012 | Acc: 17.188,14.844,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.004 | Acc: 12.798,19.085,23.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.993 | Acc: 12.671,18.902,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.012 | Acc: 12.756,18.532,22.349,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 8.536 | Acc: 24.219,32.812,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.830 | Acc: 19.345,26.897,29.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.826 | Acc: 18.636,25.991,28.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.868 | Acc: 18.353,25.858,28.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.889 | Acc: 18.142,26.061,28.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.891 | Acc: 18.123,26.052,28.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.914 | Acc: 18.066,25.872,28.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.932 | Acc: 17.969,25.892,28.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.937 | Acc: 17.833,25.713,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.939 | Acc: 17.900,25.717,27.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.945 | Acc: 17.883,25.731,28.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.943 | Acc: 17.838,25.767,28.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.926 | Acc: 17.943,25.917,28.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.930 | Acc: 17.834,25.844,28.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.925 | Acc: 17.819,25.829,28.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.914 | Acc: 17.948,25.911,28.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.902 | Acc: 17.986,25.942,28.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.903 | Acc: 17.992,25.864,28.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.891 | Acc: 18.051,25.920,28.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.882 | Acc: 18.108,25.976,28.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.714 | Acc: 13.281,22.656,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.276 | Acc: 12.984,18.564,22.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.214 | Acc: 12.710,18.540,22.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.200 | Acc: 12.500,18.327,22.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 8.797 | Acc: 17.188,25.000,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.794 | Acc: 18.862,25.893,29.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.698 | Acc: 19.779,26.753,31.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.654 | Acc: 20.095,27.357,31.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.663 | Acc: 19.936,27.093,31.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.634 | Acc: 20.042,27.475,31.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.635 | Acc: 19.751,27.583,31.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.641 | Acc: 19.664,27.394,31.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.633 | Acc: 19.648,27.397,31.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.615 | Acc: 19.738,27.426,31.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.599 | Acc: 19.850,27.659,31.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.594 | Acc: 19.874,27.803,31.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.585 | Acc: 20.005,27.885,31.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.568 | Acc: 20.061,27.999,31.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.559 | Acc: 20.073,28.028,31.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.557 | Acc: 20.105,28.042,31.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.551 | Acc: 20.142,28.140,31.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.548 | Acc: 20.182,28.143,31.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.539 | Acc: 20.226,28.186,31.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.536 | Acc: 20.269,28.201,31.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.899 | Acc: 20.312,35.938,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.532 | Acc: 15.699,23.214,27.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.463 | Acc: 15.816,23.228,27.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.454 | Acc: 15.382,23.502,27.139,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 8.818 | Acc: 17.969,25.781,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.306 | Acc: 22.061,29.799,33.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.280 | Acc: 22.294,29.535,33.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.242 | Acc: 22.054,29.739,33.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.254 | Acc: 21.962,29.909,34.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.247 | Acc: 21.976,29.997,34.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.264 | Acc: 21.798,29.933,33.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.258 | Acc: 21.709,29.937,34.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.266 | Acc: 21.628,29.969,33.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.262 | Acc: 21.573,29.791,33.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.261 | Acc: 21.653,29.851,33.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.246 | Acc: 21.709,30.027,33.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.239 | Acc: 21.813,30.031,33.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.237 | Acc: 21.848,30.101,33.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.227 | Acc: 21.936,30.138,33.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.226 | Acc: 21.942,30.147,33.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.225 | Acc: 21.938,30.111,33.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.223 | Acc: 22.063,30.123,34.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.221 | Acc: 22.031,30.112,34.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.216 | Acc: 22.045,30.126,34.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.266 | Acc: 22.656,32.812,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.973 | Acc: 19.420,25.484,30.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.938 | Acc: 19.341,25.362,29.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.925 | Acc: 19.019,25.474,29.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.687 | Acc: 21.094,31.250,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.943 | Acc: 23.810,31.473,36.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.960 | Acc: 23.571,31.974,37.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.981 | Acc: 23.348,31.826,36.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.962 | Acc: 23.245,32.282,36.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.966 | Acc: 23.105,32.317,36.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.987 | Acc: 23.121,32.044,36.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.982 | Acc: 23.122,32.081,36.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.966 | Acc: 23.423,32.225,36.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.972 | Acc: 23.386,32.208,36.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.975 | Acc: 23.356,32.109,36.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.975 | Acc: 23.466,32.109,36.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.977 | Acc: 23.421,31.986,36.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.966 | Acc: 23.467,32.040,36.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.958 | Acc: 23.602,32.140,36.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.957 | Acc: 23.650,32.179,36.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.954 | Acc: 23.722,32.219,36.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.952 | Acc: 23.738,32.205,36.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.943 | Acc: 23.773,32.245,36.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.940 | Acc: 23.770,32.247,36.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.777 | Acc: 29.688,24.219,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.070 | Acc: 21.949,24.256,27.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.105 | Acc: 22.618,23.609,28.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.133 | Acc: 22.503,23.770,27.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 8.495 | Acc: 26.562,26.562,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.799 | Acc: 24.740,32.031,36.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.813 | Acc: 24.276,32.374,37.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.805 | Acc: 24.552,32.800,37.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.787 | Acc: 24.932,33.218,37.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.754 | Acc: 25.093,33.501,37.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.738 | Acc: 24.890,33.523,37.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.754 | Acc: 24.756,33.389,37.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.753 | Acc: 24.806,33.303,37.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.740 | Acc: 24.905,33.525,37.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.738 | Acc: 24.891,33.500,37.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.728 | Acc: 25.014,33.583,37.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.734 | Acc: 25.036,33.496,37.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.725 | Acc: 25.114,33.564,37.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.708 | Acc: 25.281,33.752,37.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.727 | Acc: 25.267,33.638,37.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.725 | Acc: 25.265,33.667,37.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.721 | Acc: 25.318,33.660,37.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.720 | Acc: 25.268,33.711,37.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.714 | Acc: 25.244,33.731,37.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.341 | Acc: 21.094,19.531,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.642 | Acc: 16.815,21.317,28.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.622 | Acc: 17.473,21.189,29.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.612 | Acc: 17.777,21.401,28.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.906 | Acc: 32.031,42.188,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.542 | Acc: 25.930,35.231,40.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.494 | Acc: 25.819,35.156,40.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.499 | Acc: 26.204,35.156,40.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.463 | Acc: 26.640,35.581,40.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.482 | Acc: 26.307,35.504,40.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.478 | Acc: 26.246,35.479,40.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.494 | Acc: 26.263,35.322,40.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.497 | Acc: 26.499,35.428,40.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.496 | Acc: 26.528,35.458,40.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.503 | Acc: 26.551,35.491,40.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.509 | Acc: 26.669,35.460,40.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.506 | Acc: 26.692,35.406,40.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.509 | Acc: 26.625,35.321,40.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.509 | Acc: 26.560,35.254,39.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.506 | Acc: 26.617,35.307,39.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.502 | Acc: 26.687,35.353,40.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.495 | Acc: 26.707,35.436,40.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.491 | Acc: 26.729,35.448,40.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.481 | Acc: 26.817,35.507,40.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.326 | Acc: 25.000,29.688,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.546 | Acc: 21.131,25.707,35.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.557 | Acc: 20.694,24.924,34.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.576 | Acc: 21.004,25.115,34.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 7.987 | Acc: 21.875,25.781,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.392 | Acc: 26.153,37.128,41.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.390 | Acc: 25.896,36.833,41.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.364 | Acc: 26.486,37.026,41.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.336 | Acc: 27.054,37.288,41.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.347 | Acc: 27.189,36.989,40.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.346 | Acc: 27.253,36.667,40.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.326 | Acc: 27.366,36.774,41.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.319 | Acc: 27.417,36.957,41.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.315 | Acc: 27.521,37.008,41.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.304 | Acc: 27.593,37.127,41.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.320 | Acc: 27.471,36.945,41.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.317 | Acc: 27.600,36.913,41.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.313 | Acc: 27.631,36.868,41.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.320 | Acc: 27.658,36.816,41.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.320 | Acc: 27.632,36.820,41.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.311 | Acc: 27.702,36.979,41.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.307 | Acc: 27.729,37.010,41.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.305 | Acc: 27.705,36.976,41.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.301 | Acc: 27.764,36.977,41.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.055 | Acc: 25.781,26.562,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.353 | Acc: 22.991,26.711,34.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.344 | Acc: 23.952,27.248,34.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.346 | Acc: 23.873,27.293,34.234,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.651 | Acc: 28.906,41.406,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.051 | Acc: 27.827,38.765,44.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.090 | Acc: 27.896,38.529,44.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.133 | Acc: 28.163,38.076,43.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.131 | Acc: 28.617,38.108,43.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.096 | Acc: 28.628,38.204,43.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.110 | Acc: 28.506,38.197,43.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.093 | Acc: 28.773,38.403,43.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.072 | Acc: 28.833,38.728,43.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.081 | Acc: 28.794,38.644,43.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.081 | Acc: 28.770,38.542,43.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.072 | Acc: 28.772,38.606,43.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.058 | Acc: 28.897,38.703,43.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.066 | Acc: 28.840,38.637,43.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.069 | Acc: 28.842,38.643,43.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.068 | Acc: 28.808,38.678,43.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.081 | Acc: 28.819,38.658,43.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.081 | Acc: 28.803,38.680,43.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.087 | Acc: 28.802,38.679,43.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.083 | Acc: 28.845,38.722,43.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.145 | Acc: 26.562,32.812,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.161 | Acc: 24.777,32.961,38.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.242 | Acc: 23.990,32.107,37.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.230 | Acc: 24.142,32.082,36.860,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.686 | Acc: 27.344,42.969,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.034 | Acc: 28.646,40.179,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.947 | Acc: 29.764,39.806,44.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.894 | Acc: 30.200,40.330,45.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.943 | Acc: 29.851,39.892,45.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.935 | Acc: 29.827,39.929,45.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.951 | Acc: 29.552,39.682,45.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.953 | Acc: 29.599,39.689,44.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.953 | Acc: 29.518,39.621,45.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.948 | Acc: 29.700,39.688,45.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.927 | Acc: 29.789,39.984,45.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.927 | Acc: 29.666,39.967,45.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.931 | Acc: 29.571,39.818,45.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.934 | Acc: 29.592,39.877,45.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.936 | Acc: 29.568,39.799,45.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.928 | Acc: 29.662,39.924,45.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.934 | Acc: 29.639,39.793,45.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.936 | Acc: 29.660,39.764,45.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.936 | Acc: 29.739,39.787,45.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.936 | Acc: 29.741,39.844,45.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.168 | Acc: 22.656,32.031,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.310 | Acc: 19.940,31.957,38.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.283 | Acc: 20.008,31.288,38.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.294 | Acc: 19.839,31.084,38.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.840 | Acc: 27.344,43.750,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.863 | Acc: 29.390,40.216,45.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.911 | Acc: 29.287,39.977,45.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.891 | Acc: 29.841,40.036,45.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.836 | Acc: 30.122,40.760,46.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.824 | Acc: 30.244,40.857,46.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.814 | Acc: 30.210,41.025,46.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.814 | Acc: 30.258,41.135,46.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.802 | Acc: 30.493,41.261,46.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.784 | Acc: 30.508,41.329,46.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.784 | Acc: 30.500,41.247,46.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.787 | Acc: 30.557,41.240,46.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.776 | Acc: 30.534,41.315,46.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.779 | Acc: 30.538,41.239,46.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.779 | Acc: 30.638,41.326,46.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.768 | Acc: 30.749,41.531,46.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.767 | Acc: 30.734,41.594,46.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.757 | Acc: 30.819,41.651,46.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.753 | Acc: 30.809,41.649,46.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.754 | Acc: 30.758,41.617,46.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.019 | Acc: 25.781,37.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.509 | Acc: 19.494,31.138,36.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.542 | Acc: 18.845,30.583,35.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.540 | Acc: 19.057,30.917,36.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.554 | Acc: 29.688,42.969,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.572 | Acc: 31.882,42.746,48.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.609 | Acc: 31.364,42.073,48.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.605 | Acc: 31.416,41.842,47.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.603 | Acc: 31.462,42.323,48.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.633 | Acc: 31.265,42.489,48.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.620 | Acc: 31.192,42.620,47.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.625 | Acc: 31.117,42.664,47.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.624 | Acc: 31.100,42.639,47.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.611 | Acc: 31.306,42.731,47.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.612 | Acc: 31.479,42.681,47.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.612 | Acc: 31.529,42.654,47.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.627 | Acc: 31.425,42.577,47.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.635 | Acc: 31.427,42.514,47.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.637 | Acc: 31.403,42.463,47.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.643 | Acc: 31.372,42.367,47.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.642 | Acc: 31.418,42.438,47.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.641 | Acc: 31.415,42.414,47.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.637 | Acc: 31.393,42.428,47.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.637 | Acc: 31.379,42.436,47.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.036 | Acc: 23.438,37.500,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.367 | Acc: 22.359,33.147,35.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.352 | Acc: 22.066,32.241,36.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.336 | Acc: 22.080,31.685,36.322,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 7.036 | Acc: 27.344,35.156,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.529 | Acc: 31.213,43.750,47.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.489 | Acc: 32.012,44.169,48.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.449 | Acc: 32.262,44.416,49.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.435 | Acc: 32.253,44.541,49.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.481 | Acc: 32.101,44.160,49.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.478 | Acc: 32.070,44.073,49.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.522 | Acc: 31.688,43.589,48.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.530 | Acc: 31.658,43.517,48.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.526 | Acc: 31.794,43.534,48.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.517 | Acc: 32.012,43.567,48.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.522 | Acc: 31.823,43.411,48.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.517 | Acc: 31.850,43.400,48.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.523 | Acc: 31.750,43.460,48.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.514 | Acc: 31.770,43.508,48.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.509 | Acc: 31.847,43.592,48.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.517 | Acc: 31.912,43.594,48.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.521 | Acc: 31.862,43.569,48.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.521 | Acc: 31.908,43.635,48.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.524 | Acc: 31.873,43.621,48.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.349 | Acc: 32.812,38.281,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.595 | Acc: 27.381,38.765,41.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.623 | Acc: 26.486,37.729,41.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.645 | Acc: 26.101,37.538,40.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 6.179 | Acc: 32.812,48.438,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.335 | Acc: 32.738,45.387,49.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.342 | Acc: 32.317,44.931,49.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.336 | Acc: 32.428,44.711,49.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.340 | Acc: 32.514,44.830,50.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.383 | Acc: 32.085,44.810,49.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.386 | Acc: 32.141,44.893,49.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.376 | Acc: 32.292,45.130,49.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.370 | Acc: 32.405,45.317,49.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.385 | Acc: 32.290,45.166,49.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.398 | Acc: 32.109,45.106,49.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.380 | Acc: 32.187,45.203,49.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.387 | Acc: 32.096,45.147,49.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.389 | Acc: 32.136,45.079,49.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.395 | Acc: 32.087,45.046,49.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.383 | Acc: 32.166,45.157,49.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.383 | Acc: 32.189,45.108,49.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.385 | Acc: 32.189,45.083,49.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.377 | Acc: 32.254,45.228,49.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.379 | Acc: 32.228,45.189,49.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.440 | Acc: 30.469,42.188,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.832 | Acc: 22.210,37.500,42.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.845 | Acc: 22.428,37.976,42.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.843 | Acc: 22.503,37.705,42.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.310 | Acc: 30.469,41.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.209 | Acc: 32.701,46.577,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.222 | Acc: 32.832,46.627,52.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.206 | Acc: 32.889,46.568,52.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.236 | Acc: 32.774,46.267,51.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.248 | Acc: 32.712,46.117,51.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.259 | Acc: 32.503,46.036,51.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.261 | Acc: 32.685,45.988,51.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.266 | Acc: 32.851,46.006,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.276 | Acc: 32.877,45.848,51.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.296 | Acc: 32.719,45.744,51.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.296 | Acc: 32.696,45.769,51.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.294 | Acc: 32.657,45.802,51.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.304 | Acc: 32.696,45.573,50.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.306 | Acc: 32.724,45.577,50.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.310 | Acc: 32.646,45.559,50.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.317 | Acc: 32.754,45.534,50.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.312 | Acc: 32.758,45.539,50.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.311 | Acc: 32.832,45.611,50.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.311 | Acc: 32.849,45.604,50.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.426 | Acc: 30.469,38.281,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.317 | Acc: 27.939,40.625,43.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.385 | Acc: 27.306,39.177,43.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.363 | Acc: 27.088,39.293,43.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 6.040 | Acc: 39.844,53.125,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.057 | Acc: 34.375,48.884,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.074 | Acc: 34.470,47.961,53.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.125 | Acc: 34.234,47.451,52.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.175 | Acc: 33.854,47.116,52.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.147 | Acc: 33.965,47.076,52.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.129 | Acc: 34.104,47.366,52.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.152 | Acc: 33.943,47.063,52.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.158 | Acc: 33.929,46.909,52.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.177 | Acc: 33.758,46.750,52.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.188 | Acc: 33.749,46.630,52.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.198 | Acc: 33.643,46.539,51.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.207 | Acc: 33.688,46.441,51.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.221 | Acc: 33.522,46.324,51.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.217 | Acc: 33.452,46.408,51.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.210 | Acc: 33.557,46.499,51.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.202 | Acc: 33.606,46.622,51.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.207 | Acc: 33.566,46.616,51.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.206 | Acc: 33.561,46.607,51.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.208 | Acc: 33.553,46.598,51.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.284 | Acc: 30.469,39.062,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.181 | Acc: 28.311,39.286,45.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.209 | Acc: 27.858,38.777,45.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.212 | Acc: 27.664,38.384,45.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 6.027 | Acc: 33.594,53.125,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.046 | Acc: 34.933,48.772,54.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.120 | Acc: 33.956,48.114,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.101 | Acc: 34.221,48.015,53.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.081 | Acc: 33.970,47.975,53.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.082 | Acc: 33.864,47.927,53.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.081 | Acc: 33.678,47.934,53.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.087 | Acc: 33.616,47.662,53.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.078 | Acc: 33.705,47.666,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.069 | Acc: 33.758,47.756,53.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.084 | Acc: 33.866,47.652,53.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.101 | Acc: 33.760,47.490,53.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.106 | Acc: 33.817,47.549,52.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.112 | Acc: 33.794,47.557,52.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.111 | Acc: 33.813,47.573,52.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.116 | Acc: 33.840,47.547,52.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.120 | Acc: 33.767,47.556,52.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.128 | Acc: 33.745,47.427,52.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.125 | Acc: 33.758,47.442,52.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.113 | Acc: 33.745,47.492,52.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.925 | Acc: 25.000,38.281,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.670 | Acc: 24.554,37.909,42.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.802 | Acc: 23.647,37.348,41.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.821 | Acc: 23.194,36.860,41.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 6.271 | Acc: 28.906,44.531,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.830 | Acc: 35.342,50.223,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.900 | Acc: 35.023,49.333,54.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.922 | Acc: 34.721,49.360,54.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.956 | Acc: 34.587,49.151,53.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.972 | Acc: 34.360,49.018,54.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.011 | Acc: 33.968,48.747,53.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.002 | Acc: 34.297,48.726,53.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.017 | Acc: 34.079,48.491,53.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.014 | Acc: 33.999,48.377,53.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.025 | Acc: 34.006,48.317,53.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.030 | Acc: 34.064,48.211,53.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.028 | Acc: 34.099,48.243,53.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.027 | Acc: 34.025,48.366,53.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.021 | Acc: 34.080,48.351,53.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.021 | Acc: 34.105,48.409,53.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.017 | Acc: 34.178,48.433,53.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.020 | Acc: 34.116,48.527,53.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.023 | Acc: 34.068,48.485,53.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.029 | Acc: 34.090,48.419,53.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.717 | Acc: 29.688,40.625,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.297 | Acc: 26.488,41.369,45.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.375 | Acc: 26.048,39.863,44.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.413 | Acc: 25.589,39.178,43.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 5.344 | Acc: 42.188,53.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.945 | Acc: 34.747,48.549,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.862 | Acc: 35.099,49.562,55.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.861 | Acc: 34.836,49.718,55.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.855 | Acc: 34.992,49.788,55.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.891 | Acc: 34.839,49.520,55.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.903 | Acc: 34.569,49.219,55.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.947 | Acc: 34.386,49.180,54.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.954 | Acc: 34.448,49.180,54.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.941 | Acc: 34.466,49.262,54.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.957 | Acc: 34.394,49.145,54.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.949 | Acc: 34.495,49.212,54.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.950 | Acc: 34.501,49.258,54.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.949 | Acc: 34.546,49.294,54.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.949 | Acc: 34.453,49.341,54.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.944 | Acc: 34.539,49.512,54.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.943 | Acc: 34.506,49.523,54.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.940 | Acc: 34.512,49.539,54.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.946 | Acc: 34.438,49.455,54.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.958 | Acc: 34.359,49.311,54.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.508 | Acc: 24.219,40.625,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.291 | Acc: 24.293,41.257,46.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.294 | Acc: 24.371,41.444,46.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.250 | Acc: 24.334,41.650,46.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.607 | Acc: 34.375,52.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.749 | Acc: 35.305,50.818,56.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.754 | Acc: 35.575,50.896,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.786 | Acc: 35.669,50.231,56.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.825 | Acc: 35.619,50.347,55.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.842 | Acc: 35.589,50.309,55.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.845 | Acc: 35.460,50.220,55.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.849 | Acc: 35.395,50.321,55.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.851 | Acc: 35.394,50.257,55.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.847 | Acc: 35.264,50.138,55.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.847 | Acc: 35.218,50.198,55.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.862 | Acc: 35.040,50.064,55.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.871 | Acc: 34.955,49.942,54.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.883 | Acc: 34.917,49.943,54.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.880 | Acc: 35.039,50.061,54.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.873 | Acc: 34.993,50.112,54.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.879 | Acc: 34.983,50.034,54.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.877 | Acc: 35.046,50.149,54.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.882 | Acc: 35.026,50.119,54.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.881 | Acc: 35.035,50.107,54.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.410 | Acc: 22.656,37.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.693 | Acc: 20.908,39.323,47.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.747 | Acc: 20.522,39.024,46.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.745 | Acc: 20.594,39.062,45.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 5.453 | Acc: 37.500,58.594,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.733 | Acc: 34.859,51.302,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.852 | Acc: 34.204,50.553,56.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.796 | Acc: 34.759,50.692,56.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.777 | Acc: 34.925,50.598,56.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.795 | Acc: 34.623,50.549,56.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.786 | Acc: 34.846,50.652,56.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.796 | Acc: 34.674,50.543,56.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.831 | Acc: 34.540,50.194,56.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.828 | Acc: 34.785,50.350,56.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.823 | Acc: 34.795,50.350,56.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.825 | Acc: 34.714,50.403,55.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.829 | Acc: 34.719,50.357,55.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.836 | Acc: 34.632,50.326,55.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.830 | Acc: 34.789,50.275,55.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.828 | Acc: 34.775,50.314,55.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.820 | Acc: 34.869,50.321,55.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.820 | Acc: 34.948,50.318,55.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.821 | Acc: 34.948,50.286,55.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.828 | Acc: 34.920,50.182,55.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.133 | Acc: 26.562,42.188,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.198 | Acc: 26.414,41.481,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.323 | Acc: 25.038,40.282,47.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.344 | Acc: 24.859,40.254,46.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.609 | Acc: 32.812,54.688,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.744 | Acc: 34.896,51.860,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.717 | Acc: 34.470,51.867,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.723 | Acc: 35.003,51.639,56.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.724 | Acc: 35.127,51.620,56.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.736 | Acc: 34.994,51.354,56.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.736 | Acc: 35.092,50.975,56.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.735 | Acc: 35.228,50.986,56.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.734 | Acc: 35.229,50.946,56.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.754 | Acc: 35.156,50.811,56.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.765 | Acc: 35.051,50.707,56.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.764 | Acc: 35.142,50.739,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.769 | Acc: 35.156,50.869,56.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.766 | Acc: 35.216,50.871,56.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.770 | Acc: 35.226,50.865,56.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.775 | Acc: 35.164,50.880,56.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.775 | Acc: 35.098,50.842,56.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.779 | Acc: 35.067,50.804,55.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.772 | Acc: 35.126,50.892,56.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.771 | Acc: 35.152,50.908,56.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.750 | Acc: 20.312,36.719,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.884 | Acc: 21.726,36.868,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.923 | Acc: 21.894,36.966,43.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.895 | Acc: 21.619,36.949,43.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.053 | Acc: 39.844,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.561 | Acc: 36.682,51.786,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.637 | Acc: 35.995,52.058,58.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.654 | Acc: 35.592,51.985,57.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.653 | Acc: 35.677,51.987,57.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.677 | Acc: 35.775,51.849,57.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.664 | Acc: 35.783,51.853,57.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.656 | Acc: 35.877,51.812,57.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.635 | Acc: 35.981,51.985,57.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.640 | Acc: 35.946,51.960,57.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.644 | Acc: 35.926,51.978,57.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.647 | Acc: 35.909,51.902,57.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.657 | Acc: 35.853,51.773,57.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.657 | Acc: 35.929,51.844,57.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.673 | Acc: 35.876,51.790,57.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.671 | Acc: 35.818,51.825,57.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.681 | Acc: 35.714,51.774,56.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.694 | Acc: 35.688,51.650,56.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.694 | Acc: 35.691,51.617,56.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.699 | Acc: 35.732,51.556,56.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.526 | Acc: 34.375,39.062,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.643 | Acc: 24.256,39.918,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.714 | Acc: 23.133,38.681,44.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.718 | Acc: 22.695,38.794,44.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.360 | Acc: 33.594,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.614 | Acc: 35.826,53.757,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.616 | Acc: 35.480,52.725,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.600 | Acc: 35.387,52.497,57.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.595 | Acc: 35.513,52.459,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.604 | Acc: 35.520,52.483,57.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.646 | Acc: 35.511,52.221,57.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.637 | Acc: 35.572,52.272,57.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.648 | Acc: 35.641,52.038,57.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.664 | Acc: 35.566,51.830,57.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.651 | Acc: 35.809,51.959,57.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.646 | Acc: 35.941,52.075,57.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.650 | Acc: 35.840,52.029,57.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.659 | Acc: 35.788,51.919,56.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.663 | Acc: 35.771,51.927,56.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.657 | Acc: 35.852,51.926,56.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.661 | Acc: 35.791,51.957,56.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.658 | Acc: 35.770,51.957,56.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.665 | Acc: 35.736,51.922,56.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.670 | Acc: 35.712,51.884,56.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.506 | Acc: 28.125,44.531,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.630 | Acc: 24.442,40.997,47.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.737 | Acc: 23.171,39.920,46.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.715 | Acc: 23.105,40.254,46.363,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.584 | Acc: 35.156,48.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.637 | Acc: 36.235,50.074,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.560 | Acc: 35.518,51.277,58.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.568 | Acc: 36.091,51.447,58.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.565 | Acc: 36.082,51.919,58.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.596 | Acc: 35.814,51.918,57.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.589 | Acc: 36.002,52.053,57.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.582 | Acc: 36.242,52.333,57.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.572 | Acc: 36.272,52.252,58.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.583 | Acc: 36.266,52.167,57.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.570 | Acc: 36.392,52.344,57.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.579 | Acc: 36.164,52.224,57.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.587 | Acc: 36.158,52.133,57.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.590 | Acc: 36.003,52.161,57.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.596 | Acc: 35.879,52.043,57.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.594 | Acc: 35.979,52.118,57.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.595 | Acc: 35.989,52.188,57.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.590 | Acc: 36.089,52.316,57.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.586 | Acc: 36.182,52.404,57.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.590 | Acc: 36.204,52.522,57.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.330 | Acc: 33.594,50.781,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.400 | Acc: 31.473,46.168,51.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.484 | Acc: 30.926,45.389,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.470 | Acc: 31.007,45.479,51.140,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 6.292 | Acc: 35.938,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.550 | Acc: 36.682,53.013,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.584 | Acc: 36.242,51.810,57.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.541 | Acc: 36.399,52.446,57.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.559 | Acc: 36.179,52.537,57.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.560 | Acc: 36.061,52.614,57.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.547 | Acc: 35.925,52.725,58.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.553 | Acc: 36.070,52.754,58.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.564 | Acc: 36.030,52.664,57.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.572 | Acc: 35.972,52.581,57.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.579 | Acc: 36.035,52.507,57.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.582 | Acc: 35.938,52.478,57.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.585 | Acc: 36.022,52.454,57.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.600 | Acc: 35.914,52.284,57.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.601 | Acc: 35.949,52.285,57.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.602 | Acc: 35.880,52.271,57.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.597 | Acc: 35.942,52.383,57.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.593 | Acc: 35.972,52.481,57.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.592 | Acc: 35.981,52.487,57.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.595 | Acc: 35.935,52.479,57.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.699 | Acc: 28.906,50.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.961 | Acc: 25.521,44.010,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.026 | Acc: 25.057,42.607,50.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.008 | Acc: 24.923,43.033,50.333,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.015 | Acc: 37.500,60.156,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.386 | Acc: 36.942,55.580,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.388 | Acc: 36.986,54.707,60.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.405 | Acc: 37.090,54.188,60.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.405 | Acc: 36.970,54.147,60.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.417 | Acc: 37.067,54.030,60.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.441 | Acc: 36.906,53.945,59.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.437 | Acc: 36.874,54.078,60.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.448 | Acc: 36.651,53.848,59.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.447 | Acc: 36.654,53.829,59.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.470 | Acc: 36.680,53.619,59.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.469 | Acc: 36.641,53.595,59.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.481 | Acc: 36.660,53.582,59.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.488 | Acc: 36.581,53.487,59.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.494 | Acc: 36.663,53.359,58.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.504 | Acc: 36.550,53.289,58.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.507 | Acc: 36.488,53.295,58.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.510 | Acc: 36.497,53.283,58.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.513 | Acc: 36.437,53.246,58.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.516 | Acc: 36.436,53.207,58.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.484 | Acc: 17.969,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.068 | Acc: 24.442,44.159,49.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.113 | Acc: 24.219,43.388,49.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.109 | Acc: 24.654,43.122,49.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.622 | Acc: 32.031,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.521 | Acc: 35.938,52.418,60.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.539 | Acc: 36.414,53.182,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.482 | Acc: 36.501,53.317,59.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.490 | Acc: 36.198,53.154,59.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.521 | Acc: 36.084,53.140,59.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.512 | Acc: 36.286,53.138,59.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.496 | Acc: 36.508,53.324,59.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.498 | Acc: 36.583,53.406,59.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.489 | Acc: 36.749,53.475,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.466 | Acc: 36.909,53.584,59.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.473 | Acc: 36.842,53.514,59.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.473 | Acc: 36.816,53.459,59.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.483 | Acc: 36.737,53.466,58.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.486 | Acc: 36.744,53.411,58.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.494 | Acc: 36.620,53.343,58.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.487 | Acc: 36.646,53.412,58.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.483 | Acc: 36.703,53.405,58.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.488 | Acc: 36.721,53.437,58.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.488 | Acc: 36.655,53.418,58.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.592 | Acc: 28.906,38.281,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.709 | Acc: 29.725,44.643,51.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.826 | Acc: 28.296,43.121,50.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.824 | Acc: 28.048,43.148,50.615,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 4.672 | Acc: 44.531,63.281,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.275 | Acc: 37.760,54.390,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.306 | Acc: 37.576,54.992,60.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.320 | Acc: 37.410,55.046,60.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.311 | Acc: 37.413,54.803,60.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.354 | Acc: 37.206,54.324,60.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.358 | Acc: 37.229,54.119,60.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.349 | Acc: 37.317,54.217,60.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.365 | Acc: 37.160,54.202,60.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.391 | Acc: 36.904,54.023,60.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.400 | Acc: 36.886,53.957,59.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.401 | Acc: 37.083,53.970,59.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.407 | Acc: 37.127,53.978,59.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.411 | Acc: 37.090,54.032,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.410 | Acc: 37.094,54.042,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.411 | Acc: 37.155,54.104,59.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.419 | Acc: 37.042,54.140,59.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.430 | Acc: 37.019,54.028,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.427 | Acc: 37.048,53.988,59.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.436 | Acc: 36.965,53.962,59.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.955 | Acc: 28.906,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.610 | Acc: 27.939,45.908,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.669 | Acc: 26.944,44.931,53.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.643 | Acc: 27.408,45.479,53.023,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.289 | Acc: 39.062,53.906,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.158 | Acc: 38.318,56.696,62.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.197 | Acc: 38.720,56.079,62.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.253 | Acc: 37.897,55.699,61.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.291 | Acc: 37.741,55.343,61.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.289 | Acc: 37.887,55.631,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.301 | Acc: 37.771,55.217,60.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.300 | Acc: 37.871,55.297,61.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.313 | Acc: 37.801,55.187,60.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.329 | Acc: 37.703,55.136,60.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.344 | Acc: 37.465,54.866,60.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.353 | Acc: 37.401,54.832,60.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.357 | Acc: 37.267,54.756,60.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.366 | Acc: 37.114,54.622,60.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.370 | Acc: 37.089,54.510,60.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.378 | Acc: 37.098,54.464,60.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.385 | Acc: 37.169,54.422,60.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.385 | Acc: 37.182,54.447,60.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.393 | Acc: 37.178,54.289,59.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.394 | Acc: 37.190,54.269,59.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.793 | Acc: 27.344,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.020 | Acc: 26.302,44.531,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.085 | Acc: 25.610,43.274,51.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.050 | Acc: 25.538,43.161,52.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.988 | Acc: 33.594,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.331 | Acc: 37.686,55.506,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.254 | Acc: 37.862,56.021,61.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.279 | Acc: 37.654,56.071,61.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.268 | Acc: 37.558,56.009,61.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.317 | Acc: 37.454,55.732,61.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.317 | Acc: 37.390,55.591,60.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.312 | Acc: 37.533,55.552,60.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.310 | Acc: 37.558,55.590,60.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.314 | Acc: 37.530,55.348,60.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.322 | Acc: 37.597,55.278,60.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.340 | Acc: 37.419,55.013,60.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.342 | Acc: 37.406,54.982,60.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.344 | Acc: 37.347,54.939,60.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.341 | Acc: 37.453,54.960,60.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.339 | Acc: 37.453,55.028,60.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.346 | Acc: 37.415,54.967,60.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.348 | Acc: 37.392,54.972,60.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.352 | Acc: 37.416,54.990,60.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.355 | Acc: 37.482,54.927,60.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.296 | Acc: 25.000,46.875,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.529 | Acc: 25.856,40.811,47.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.657 | Acc: 25.114,39.444,46.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.684 | Acc: 24.577,39.524,46.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 4.930 | Acc: 42.969,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.242 | Acc: 37.426,56.250,63.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.271 | Acc: 37.805,55.564,61.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.294 | Acc: 38.102,55.302,61.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.296 | Acc: 38.059,55.208,60.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.284 | Acc: 37.802,55.353,61.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.277 | Acc: 37.991,55.359,61.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.283 | Acc: 37.844,55.291,61.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.289 | Acc: 37.830,55.313,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.278 | Acc: 37.970,55.460,61.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.280 | Acc: 37.970,55.383,61.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.304 | Acc: 37.797,55.158,60.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.303 | Acc: 37.753,55.057,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.307 | Acc: 37.781,55.047,60.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.317 | Acc: 37.725,55.016,60.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.329 | Acc: 37.645,54.895,60.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.325 | Acc: 37.622,54.897,60.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.322 | Acc: 37.649,54.951,60.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.323 | Acc: 37.569,54.919,60.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.326 | Acc: 37.590,54.934,60.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.190 | Acc: 29.688,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.192 | Acc: 32.701,48.661,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.270 | Acc: 32.184,47.752,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.274 | Acc: 31.954,47.874,52.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 5.277 | Acc: 34.375,53.906,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.197 | Acc: 36.421,56.101,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.161 | Acc: 37.271,56.155,62.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.169 | Acc: 37.564,56.071,62.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.231 | Acc: 37.452,55.334,61.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.229 | Acc: 37.655,55.260,61.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.264 | Acc: 37.649,55.139,61.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.260 | Acc: 37.594,55.391,61.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.267 | Acc: 37.650,55.309,61.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.270 | Acc: 37.591,55.249,61.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.277 | Acc: 37.469,55.166,61.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.285 | Acc: 37.468,55.165,61.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.294 | Acc: 37.390,55.125,60.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.287 | Acc: 37.533,55.244,61.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.287 | Acc: 37.606,55.255,60.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.284 | Acc: 37.555,55.266,60.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.284 | Acc: 37.556,55.313,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.289 | Acc: 37.621,55.334,60.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.292 | Acc: 37.703,55.324,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.298 | Acc: 37.765,55.299,60.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.255 | Acc: 29.688,42.969,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.254 | Acc: 23.549,39.546,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.371 | Acc: 22.790,38.186,44.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.388 | Acc: 22.285,38.345,44.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 4.903 | Acc: 38.281,54.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.280 | Acc: 37.500,54.501,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.242 | Acc: 38.491,55.850,61.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.250 | Acc: 38.051,55.699,61.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.186 | Acc: 38.108,56.038,62.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.203 | Acc: 38.088,55.972,62.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.199 | Acc: 38.365,55.940,61.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.195 | Acc: 38.442,55.895,61.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.196 | Acc: 38.480,55.939,61.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.210 | Acc: 38.268,55.844,61.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.220 | Acc: 38.308,55.768,61.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.232 | Acc: 38.161,55.688,61.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.228 | Acc: 38.045,55.676,61.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.232 | Acc: 38.063,55.645,61.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.233 | Acc: 38.045,55.722,61.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.242 | Acc: 38.094,55.528,61.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.252 | Acc: 37.970,55.503,61.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.258 | Acc: 37.928,55.457,61.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.254 | Acc: 37.976,55.532,61.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.259 | Acc: 37.974,55.475,61.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.771 | Acc: 30.469,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.521 | Acc: 30.320,45.982,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.662 | Acc: 29.668,44.989,51.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.667 | Acc: 29.406,45.184,51.319,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.631 | Acc: 43.750,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.129 | Acc: 37.612,56.473,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.043 | Acc: 39.062,57.146,63.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.045 | Acc: 39.293,57.300,63.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.066 | Acc: 38.831,57.359,63.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.088 | Acc: 38.830,57.078,63.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.121 | Acc: 38.630,56.799,63.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.132 | Acc: 38.647,56.771,62.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.143 | Acc: 38.650,56.730,62.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.161 | Acc: 38.640,56.479,62.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.163 | Acc: 38.670,56.440,62.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.170 | Acc: 38.642,56.345,62.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.189 | Acc: 38.408,56.172,62.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.191 | Acc: 38.404,56.130,62.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.210 | Acc: 38.292,55.989,61.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.216 | Acc: 38.281,55.975,61.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.221 | Acc: 38.254,56.024,61.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.230 | Acc: 38.206,55.987,61.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.229 | Acc: 38.177,55.975,61.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.239 | Acc: 38.115,55.885,61.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.249 | Acc: 35.156,41.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.301 | Acc: 29.315,40.997,46.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.359 | Acc: 29.021,40.168,45.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.328 | Acc: 28.868,40.638,45.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.991 | Acc: 46.094,58.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.015 | Acc: 39.546,57.106,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.995 | Acc: 39.463,57.565,64.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.050 | Acc: 39.152,57.262,63.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.069 | Acc: 38.966,56.993,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.092 | Acc: 38.877,57.047,62.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.105 | Acc: 38.843,57.005,62.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.112 | Acc: 38.641,56.898,62.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.120 | Acc: 38.597,56.891,62.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.143 | Acc: 38.294,56.656,62.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.166 | Acc: 38.192,56.565,61.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.169 | Acc: 38.193,56.657,62.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.174 | Acc: 38.200,56.639,62.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.184 | Acc: 38.090,56.460,61.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.189 | Acc: 38.042,56.436,61.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.190 | Acc: 38.094,56.439,61.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.192 | Acc: 38.150,56.440,61.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.206 | Acc: 38.057,56.307,61.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.212 | Acc: 38.022,56.200,61.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.212 | Acc: 38.035,56.178,61.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.648 | Acc: 30.469,45.312,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.947 | Acc: 30.766,42.150,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.106 | Acc: 29.211,41.025,49.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.050 | Acc: 28.945,41.765,50.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 5.190 | Acc: 37.500,56.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.105 | Acc: 36.756,56.585,64.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.179 | Acc: 36.947,55.507,63.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.196 | Acc: 37.077,55.635,62.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.195 | Acc: 37.336,55.565,62.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.200 | Acc: 37.755,55.647,62.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.193 | Acc: 37.926,55.817,62.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.161 | Acc: 38.159,56.184,62.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.169 | Acc: 38.174,56.201,62.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.168 | Acc: 38.268,56.241,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.165 | Acc: 38.219,56.405,62.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.166 | Acc: 38.281,56.345,62.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.159 | Acc: 38.391,56.412,62.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.167 | Acc: 38.398,56.292,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.173 | Acc: 38.334,56.155,62.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.177 | Acc: 38.357,56.221,62.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.179 | Acc: 38.354,56.245,62.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.181 | Acc: 38.389,56.248,62.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.178 | Acc: 38.407,56.235,62.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.180 | Acc: 38.359,56.219,62.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.169 | Acc: 28.125,38.281,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.082 | Acc: 28.013,41.220,47.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.141 | Acc: 28.068,40.568,47.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.109 | Acc: 28.291,40.932,47.567,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.277 | Acc: 39.062,57.812,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.153 | Acc: 38.058,57.887,63.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.150 | Acc: 37.424,57.107,63.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.165 | Acc: 37.065,56.596,62.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.153 | Acc: 37.326,56.674,62.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.109 | Acc: 37.956,57.132,62.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.115 | Acc: 37.881,57.076,62.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.130 | Acc: 37.578,56.887,62.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.142 | Acc: 37.646,57.046,62.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.146 | Acc: 37.720,56.919,62.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.141 | Acc: 37.803,56.969,62.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.151 | Acc: 37.825,56.904,62.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.139 | Acc: 38.019,56.905,62.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.145 | Acc: 38.039,56.771,62.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.156 | Acc: 38.137,56.778,62.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.155 | Acc: 38.219,56.777,62.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.156 | Acc: 38.262,56.820,62.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.155 | Acc: 38.293,56.788,62.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.156 | Acc: 38.316,56.785,62.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.156 | Acc: 38.324,56.765,62.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.024 | Acc: 28.125,37.500,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.915 | Acc: 20.238,38.616,47.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.979 | Acc: 20.217,37.614,45.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.962 | Acc: 20.466,38.486,46.235,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 4.639 | Acc: 45.312,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.063 | Acc: 38.132,56.585,63.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.018 | Acc: 38.377,57.393,63.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.023 | Acc: 38.896,57.672,63.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.071 | Acc: 38.262,57.272,63.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.080 | Acc: 38.196,57.194,63.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.094 | Acc: 38.042,56.999,63.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.088 | Acc: 38.392,57.120,62.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.099 | Acc: 38.359,56.915,62.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.103 | Acc: 38.311,56.949,62.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.112 | Acc: 38.316,56.969,62.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.109 | Acc: 38.355,56.939,62.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.117 | Acc: 38.336,56.921,62.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.116 | Acc: 38.257,56.929,62.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.104 | Acc: 38.448,57.065,62.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.124 | Acc: 38.427,56.979,62.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.133 | Acc: 38.371,56.900,62.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.138 | Acc: 38.435,56.843,62.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.144 | Acc: 38.446,56.785,62.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.151 | Acc: 38.417,56.756,62.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.487 | Acc: 32.031,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.597 | Acc: 27.679,47.693,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.705 | Acc: 26.505,46.494,52.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.700 | Acc: 26.460,46.311,52.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 4.884 | Acc: 40.625,55.469,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.010 | Acc: 40.811,57.143,64.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.994 | Acc: 40.320,57.565,64.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.978 | Acc: 39.370,57.800,64.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.002 | Acc: 39.429,57.629,64.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.029 | Acc: 39.387,57.426,64.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.040 | Acc: 39.405,57.212,63.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.060 | Acc: 39.190,57.186,63.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.045 | Acc: 39.291,57.424,64.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.036 | Acc: 39.227,57.394,63.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.046 | Acc: 39.132,57.268,63.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.048 | Acc: 39.172,57.236,63.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.051 | Acc: 39.105,57.197,63.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.076 | Acc: 39.003,56.858,63.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.088 | Acc: 38.974,56.734,63.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.096 | Acc: 38.844,56.759,62.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.095 | Acc: 38.880,56.846,62.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.089 | Acc: 38.907,56.882,63.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.097 | Acc: 38.943,56.776,62.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.097 | Acc: 38.907,56.804,62.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.721 | Acc: 27.344,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.686 | Acc: 28.497,47.470,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.841 | Acc: 27.591,45.636,51.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.861 | Acc: 27.318,45.056,51.575,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.873 | Acc: 39.062,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.990 | Acc: 39.807,56.510,64.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.911 | Acc: 40.149,58.079,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.922 | Acc: 39.844,58.261,65.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.959 | Acc: 39.361,57.706,64.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.993 | Acc: 39.442,57.356,64.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.009 | Acc: 39.205,57.238,64.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.009 | Acc: 39.074,57.253,64.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.009 | Acc: 39.029,57.313,63.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.018 | Acc: 38.929,57.338,63.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.018 | Acc: 39.012,57.369,63.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.032 | Acc: 38.900,57.212,63.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.032 | Acc: 38.920,57.245,63.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.044 | Acc: 38.856,57.169,63.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.045 | Acc: 38.882,57.226,63.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.050 | Acc: 38.907,57.210,63.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.065 | Acc: 38.792,57.060,63.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.071 | Acc: 38.742,57.006,63.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.065 | Acc: 38.768,57.092,63.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.073 | Acc: 38.761,57.058,63.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.637 | Acc: 28.125,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.157 | Acc: 25.930,43.043,49.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.165 | Acc: 25.648,42.950,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.134 | Acc: 26.089,43.251,49.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.854 | Acc: 42.188,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.916 | Acc: 40.551,59.338,63.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.924 | Acc: 39.710,59.127,64.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.958 | Acc: 39.421,58.683,64.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.990 | Acc: 39.246,58.603,64.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.978 | Acc: 39.310,58.663,64.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.019 | Acc: 38.940,58.122,63.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.016 | Acc: 39.140,58.128,63.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.037 | Acc: 39.048,57.890,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.036 | Acc: 39.114,57.890,63.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.035 | Acc: 39.164,57.968,63.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.023 | Acc: 39.225,58.078,63.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.029 | Acc: 39.127,57.936,63.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.032 | Acc: 39.134,57.887,63.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.037 | Acc: 39.043,57.804,63.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.039 | Acc: 39.031,57.789,63.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.044 | Acc: 38.999,57.757,63.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.055 | Acc: 38.891,57.632,63.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.062 | Acc: 38.848,57.568,63.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.069 | Acc: 38.784,57.505,63.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.473 | Acc: 30.469,38.281,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.933 | Acc: 25.818,37.946,44.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.998 | Acc: 25.476,37.481,44.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.981 | Acc: 25.807,37.218,44.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 5.175 | Acc: 36.719,57.812,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.847 | Acc: 40.216,59.747,66.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.857 | Acc: 40.206,59.661,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.890 | Acc: 40.202,59.375,64.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.972 | Acc: 39.998,58.613,64.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.957 | Acc: 39.975,58.431,64.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.977 | Acc: 39.941,58.161,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.973 | Acc: 39.783,58.217,64.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.998 | Acc: 39.514,57.910,64.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.005 | Acc: 39.468,57.942,64.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.022 | Acc: 39.280,57.824,63.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.024 | Acc: 39.239,57.724,63.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.025 | Acc: 39.273,57.709,63.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.030 | Acc: 39.134,57.555,63.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.027 | Acc: 39.104,57.484,63.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.034 | Acc: 39.008,57.410,63.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.034 | Acc: 39.021,57.435,63.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.039 | Acc: 39.010,57.432,63.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.043 | Acc: 38.978,57.384,63.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.042 | Acc: 38.974,57.417,63.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.926 | Acc: 36.719,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.222 | Acc: 32.626,49.442,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.219 | Acc: 32.412,48.171,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.202 | Acc: 32.223,48.591,55.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.700 | Acc: 39.062,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.885 | Acc: 39.769,59.635,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.970 | Acc: 39.920,59.051,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.994 | Acc: 39.703,58.325,64.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.987 | Acc: 39.497,58.275,64.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.997 | Acc: 39.519,58.068,64.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.014 | Acc: 39.327,57.877,63.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.989 | Acc: 39.589,58.051,64.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.001 | Acc: 39.635,57.929,63.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.018 | Acc: 39.252,57.687,63.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.025 | Acc: 39.234,57.502,63.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.049 | Acc: 39.151,57.282,63.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.043 | Acc: 39.072,57.297,63.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.037 | Acc: 39.042,57.429,63.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.037 | Acc: 39.035,57.493,63.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.031 | Acc: 39.029,57.496,63.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.035 | Acc: 39.060,57.457,63.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.034 | Acc: 39.131,57.425,63.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.032 | Acc: 39.108,57.488,63.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.035 | Acc: 39.079,57.472,63.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.649 | Acc: 28.125,42.188,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.920 | Acc: 23.921,41.927,47.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.002 | Acc: 23.114,40.682,46.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.011 | Acc: 23.117,40.689,46.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 5.194 | Acc: 33.594,53.125,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.959 | Acc: 38.653,58.408,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.926 | Acc: 38.872,58.441,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.900 | Acc: 39.062,58.530,65.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.922 | Acc: 38.937,58.748,65.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.911 | Acc: 39.016,58.687,65.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.913 | Acc: 39.217,58.878,64.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.907 | Acc: 39.168,58.860,65.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.920 | Acc: 39.164,58.783,64.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.938 | Acc: 39.227,58.671,64.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.944 | Acc: 39.269,58.594,64.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.943 | Acc: 39.246,58.576,64.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.948 | Acc: 39.312,58.522,64.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.958 | Acc: 39.329,58.426,64.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.967 | Acc: 39.304,58.321,64.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.977 | Acc: 39.236,58.230,64.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.987 | Acc: 39.238,58.195,64.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.991 | Acc: 39.232,58.186,64.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.998 | Acc: 39.223,58.135,64.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.000 | Acc: 39.239,58.079,64.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.560 | Acc: 34.375,55.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.551 | Acc: 29.613,48.586,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.630 | Acc: 28.201,47.085,53.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.637 | Acc: 27.779,46.901,53.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 5.074 | Acc: 42.188,60.156,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.846 | Acc: 39.918,58.817,65.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.870 | Acc: 39.653,58.613,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.851 | Acc: 40.061,59.080,65.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.857 | Acc: 40.095,59.018,65.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.866 | Acc: 39.952,58.864,65.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.872 | Acc: 40.070,58.768,65.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.900 | Acc: 39.844,58.549,64.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.921 | Acc: 39.606,58.506,64.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.954 | Acc: 39.257,58.248,64.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.955 | Acc: 39.393,58.329,64.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.963 | Acc: 39.395,58.283,64.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.975 | Acc: 39.289,58.176,64.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.971 | Acc: 39.305,58.202,64.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.976 | Acc: 39.268,58.260,64.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.982 | Acc: 39.221,58.199,64.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.973 | Acc: 39.350,58.287,64.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.973 | Acc: 39.376,58.209,64.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.980 | Acc: 39.253,58.185,64.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.991 | Acc: 39.112,58.128,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.937 | Acc: 28.125,39.844,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.301 | Acc: 24.293,43.899,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.337 | Acc: 23.552,42.969,51.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.330 | Acc: 23.604,43.199,51.306,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.262 | Acc: 37.500,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.831 | Acc: 39.955,60.268,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 39.768,59.394,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.875 | Acc: 39.908,58.914,64.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.923 | Acc: 39.622,58.816,64.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.891 | Acc: 39.705,59.011,65.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.888 | Acc: 40.005,59.039,65.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.902 | Acc: 39.916,58.754,65.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.908 | Acc: 39.766,58.798,65.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.905 | Acc: 39.904,58.866,65.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.920 | Acc: 39.727,58.815,64.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.913 | Acc: 39.685,58.841,64.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.926 | Acc: 39.711,58.782,64.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.940 | Acc: 39.646,58.543,64.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.935 | Acc: 39.802,58.630,64.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.926 | Acc: 39.963,58.749,64.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.939 | Acc: 39.905,58.650,64.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.944 | Acc: 39.841,58.589,64.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.948 | Acc: 39.762,58.522,64.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.954 | Acc: 39.756,58.481,64.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.346 | Acc: 32.031,52.344,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.748 | Acc: 28.199,46.689,53.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.785 | Acc: 27.096,46.018,53.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.768 | Acc: 26.383,46.158,53.509,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 4.394 | Acc: 46.875,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.839 | Acc: 40.327,59.896,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.905 | Acc: 39.825,59.089,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.894 | Acc: 39.908,59.144,65.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.885 | Acc: 39.709,58.960,65.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.909 | Acc: 39.712,58.919,65.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.912 | Acc: 39.753,59.007,65.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.919 | Acc: 39.628,58.921,65.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.915 | Acc: 39.422,58.875,65.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.915 | Acc: 39.218,58.883,65.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.919 | Acc: 39.144,58.959,65.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.914 | Acc: 39.278,58.944,65.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.918 | Acc: 39.302,58.860,65.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.937 | Acc: 39.212,58.612,64.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.937 | Acc: 39.285,58.744,64.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.948 | Acc: 39.283,58.703,64.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.946 | Acc: 39.320,58.774,64.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.945 | Acc: 39.376,58.782,64.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.948 | Acc: 39.381,58.726,64.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.950 | Acc: 39.356,58.711,64.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.397 | Acc: 41.406,49.219,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.505 | Acc: 30.878,47.359,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.486 | Acc: 30.488,47.180,52.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.479 | Acc: 30.033,47.349,52.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 5.043 | Acc: 35.156,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 39.509,59.821,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.790 | Acc: 40.282,59.661,66.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.825 | Acc: 40.766,59.426,65.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.811 | Acc: 40.345,59.558,66.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.814 | Acc: 40.486,59.723,66.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.841 | Acc: 40.173,59.452,65.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.838 | Acc: 40.481,59.508,65.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.842 | Acc: 40.470,59.443,65.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.853 | Acc: 40.414,59.401,65.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.860 | Acc: 40.368,59.289,65.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.861 | Acc: 40.342,59.318,65.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.870 | Acc: 40.265,59.304,65.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.863 | Acc: 40.365,59.336,65.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.879 | Acc: 40.308,59.228,65.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.888 | Acc: 40.150,59.053,65.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.905 | Acc: 40.002,58.883,64.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.918 | Acc: 39.803,58.798,64.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.923 | Acc: 39.792,58.769,64.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.922 | Acc: 39.735,58.776,64.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.138 | Acc: 25.000,41.406,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.534 | Acc: 21.912,42.448,48.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.567 | Acc: 22.256,42.207,48.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.559 | Acc: 22.490,42.341,48.630,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 4.724 | Acc: 39.844,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.754 | Acc: 40.997,62.351,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.836 | Acc: 40.053,59.680,65.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.812 | Acc: 40.394,59.567,66.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.841 | Acc: 39.873,58.835,65.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.845 | Acc: 39.766,58.880,65.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.849 | Acc: 39.650,58.917,65.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.861 | Acc: 39.772,58.910,65.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.854 | Acc: 39.766,58.987,65.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.852 | Acc: 39.822,59.017,65.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.854 | Acc: 40.023,59.072,65.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.855 | Acc: 39.914,59.124,65.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.860 | Acc: 39.935,59.103,65.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.855 | Acc: 39.922,59.082,65.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.867 | Acc: 39.869,59.011,65.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.877 | Acc: 39.794,58.934,65.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.878 | Acc: 39.839,58.930,65.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.886 | Acc: 39.764,58.823,65.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.887 | Acc: 39.798,58.858,65.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.896 | Acc: 39.706,58.782,64.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.851 | Acc: 38.281,51.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.422 | Acc: 31.473,48.735,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.420 | Acc: 31.307,48.075,52.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.401 | Acc: 31.340,48.258,52.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.566 | Acc: 44.531,57.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.821 | Acc: 40.290,59.263,66.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.782 | Acc: 40.987,59.966,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.791 | Acc: 40.856,59.849,66.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.786 | Acc: 40.548,59.828,66.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.803 | Acc: 40.331,59.878,66.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.827 | Acc: 40.005,59.627,66.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.833 | Acc: 39.871,59.464,66.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.827 | Acc: 39.951,59.584,66.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.844 | Acc: 39.904,59.492,66.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.838 | Acc: 39.972,59.639,66.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.858 | Acc: 39.724,59.432,65.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.867 | Acc: 39.759,59.359,65.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.872 | Acc: 39.757,59.249,65.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.875 | Acc: 39.716,59.294,65.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.885 | Acc: 39.626,59.139,65.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.883 | Acc: 39.678,59.236,65.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.887 | Acc: 39.741,59.231,65.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.884 | Acc: 39.855,59.256,65.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.896 | Acc: 39.739,59.090,65.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.427 | Acc: 23.438,46.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.227 | Acc: 25.558,43.899,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.301 | Acc: 24.428,43.655,50.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.292 | Acc: 23.975,43.174,50.179,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.397 | Acc: 55.469,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.852 | Acc: 41.443,59.152,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.824 | Acc: 40.377,59.280,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.835 | Acc: 39.946,59.170,66.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.838 | Acc: 40.143,59.414,66.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.831 | Acc: 39.960,59.499,66.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.847 | Acc: 39.863,59.517,66.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.838 | Acc: 40.076,59.536,66.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.828 | Acc: 40.217,59.462,66.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.847 | Acc: 40.120,59.366,65.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.858 | Acc: 40.081,59.200,65.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.859 | Acc: 39.946,59.131,65.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.863 | Acc: 39.866,59.125,65.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.864 | Acc: 39.820,59.088,65.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.864 | Acc: 39.905,59.066,65.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.872 | Acc: 39.841,58.918,65.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.870 | Acc: 39.810,58.976,65.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.866 | Acc: 39.823,59.073,65.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.870 | Acc: 39.759,59.066,65.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.870 | Acc: 39.795,59.074,65.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.153 | Acc: 27.344,41.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.293 | Acc: 24.963,42.448,50.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.356 | Acc: 25.305,41.521,50.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.335 | Acc: 25.628,42.021,50.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.822 | Acc: 37.500,65.625,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.780 | Acc: 39.844,61.012,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.783 | Acc: 39.977,60.537,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.785 | Acc: 40.190,60.118,67.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.799 | Acc: 39.796,60.079,67.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.781 | Acc: 40.084,60.125,67.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.802 | Acc: 39.908,59.969,66.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.815 | Acc: 39.777,59.857,66.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.824 | Acc: 39.917,59.773,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.827 | Acc: 39.969,59.729,66.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.839 | Acc: 39.867,59.612,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.845 | Acc: 39.929,59.573,66.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.841 | Acc: 40.019,59.550,66.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.842 | Acc: 40.077,59.504,65.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.848 | Acc: 40.052,59.478,65.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.840 | Acc: 40.129,59.567,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.831 | Acc: 40.253,59.640,65.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.833 | Acc: 40.325,59.650,65.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.835 | Acc: 40.339,59.689,65.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.844 | Acc: 40.301,59.603,65.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.567 | Acc: 31.250,53.125,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.896 | Acc: 28.795,46.912,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.979 | Acc: 28.430,46.837,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.992 | Acc: 28.356,46.414,50.922,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.883 | Acc: 31.250,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.791 | Acc: 38.988,59.115,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.734 | Acc: 39.748,59.318,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.720 | Acc: 40.420,60.131,66.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.704 | Acc: 40.432,60.253,66.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.720 | Acc: 40.300,60.179,66.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.755 | Acc: 40.083,59.801,66.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.770 | Acc: 39.949,59.696,66.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.772 | Acc: 40.067,59.729,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.781 | Acc: 40.051,59.746,66.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.784 | Acc: 39.991,59.713,66.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.800 | Acc: 39.989,59.711,66.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.817 | Acc: 39.967,59.566,66.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.822 | Acc: 39.990,59.561,65.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.826 | Acc: 39.961,59.439,65.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.826 | Acc: 40.012,59.435,65.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.822 | Acc: 39.995,59.521,65.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.821 | Acc: 40.004,59.545,65.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.829 | Acc: 39.995,59.479,65.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.828 | Acc: 40.026,59.490,65.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.692 | Acc: 24.219,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.139 | Acc: 26.265,44.271,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.197 | Acc: 25.114,43.559,50.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.232 | Acc: 24.757,43.545,50.128,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 4.887 | Acc: 42.188,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.630 | Acc: 41.034,61.012,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.750 | Acc: 40.434,60.232,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.753 | Acc: 40.663,59.951,66.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.730 | Acc: 40.876,60.340,67.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.757 | Acc: 40.803,60.234,67.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.770 | Acc: 40.560,60.098,66.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.768 | Acc: 40.559,59.918,66.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.783 | Acc: 40.591,59.797,66.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.795 | Acc: 40.431,59.716,66.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.796 | Acc: 40.512,59.729,66.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.793 | Acc: 40.544,59.718,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.795 | Acc: 40.492,59.725,66.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.799 | Acc: 40.436,59.707,66.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.805 | Acc: 40.336,59.567,66.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.812 | Acc: 40.404,59.526,66.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.811 | Acc: 40.321,59.538,66.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.815 | Acc: 40.307,59.467,65.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.824 | Acc: 40.240,59.401,65.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.831 | Acc: 40.196,59.350,65.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.144 | Acc: 38.281,53.906,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.217 | Acc: 33.743,48.810,55.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.179 | Acc: 33.403,48.114,55.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.197 | Acc: 33.338,48.373,55.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 5.432 | Acc: 30.469,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.774 | Acc: 40.104,59.003,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.761 | Acc: 39.844,59.013,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.762 | Acc: 40.138,59.157,66.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.768 | Acc: 40.181,58.999,66.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.748 | Acc: 40.053,59.476,66.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.750 | Acc: 40.244,59.620,66.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.749 | Acc: 40.337,59.563,66.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.741 | Acc: 40.232,59.787,66.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.751 | Acc: 40.198,59.802,66.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.757 | Acc: 40.213,59.841,66.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.759 | Acc: 40.346,59.916,66.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.770 | Acc: 40.304,59.913,66.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.783 | Acc: 40.167,59.875,66.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.786 | Acc: 40.241,59.912,66.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.787 | Acc: 40.324,59.925,66.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.799 | Acc: 40.279,59.791,66.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.805 | Acc: 40.215,59.785,66.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.807 | Acc: 40.246,59.823,66.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.820 | Acc: 40.182,59.711,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.755 | Acc: 33.594,45.312,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.442 | Acc: 27.009,40.141,50.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.435 | Acc: 26.524,39.787,50.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.446 | Acc: 26.332,40.049,50.628,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.301 | Acc: 42.969,62.500,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.673 | Acc: 40.960,60.193,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 40.663,60.061,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.729 | Acc: 40.740,60.336,67.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.773 | Acc: 40.741,60.002,66.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.784 | Acc: 40.579,59.886,66.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.765 | Acc: 40.987,60.247,66.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.757 | Acc: 40.957,60.201,66.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.762 | Acc: 40.848,60.287,66.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.765 | Acc: 40.832,60.428,66.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.758 | Acc: 40.909,60.483,66.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.763 | Acc: 40.830,60.460,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.774 | Acc: 40.677,60.231,66.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.788 | Acc: 40.715,60.150,66.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.800 | Acc: 40.583,60.067,66.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.803 | Acc: 40.493,60.016,65.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.800 | Acc: 40.511,59.986,66.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.802 | Acc: 40.485,59.923,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.808 | Acc: 40.443,59.890,66.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.805 | Acc: 40.445,59.943,65.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.133 | Acc: 16.406,34.375,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.244 | Acc: 12.537,26.562,40.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.223 | Acc: 11.814,27.115,40.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.214 | Acc: 11.642,26.972,40.727,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.933 | Acc: 34.375,62.500,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 41.443,60.863,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.703 | Acc: 40.892,60.442,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.710 | Acc: 40.676,60.489,66.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.710 | Acc: 40.953,60.639,66.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.699 | Acc: 40.903,60.791,66.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.702 | Acc: 40.741,60.905,66.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.707 | Acc: 40.841,60.816,66.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.727 | Acc: 40.470,60.515,66.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.741 | Acc: 40.513,60.463,66.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.743 | Acc: 40.559,60.452,66.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.749 | Acc: 40.653,60.358,66.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.760 | Acc: 40.512,60.221,66.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.769 | Acc: 40.439,60.105,66.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.776 | Acc: 40.375,60.081,66.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.775 | Acc: 40.428,60.128,66.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.783 | Acc: 40.442,60.064,66.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.775 | Acc: 40.467,60.081,66.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.784 | Acc: 40.443,59.979,66.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.788 | Acc: 40.397,59.978,66.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.921 | Acc: 35.156,42.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.032 | Acc: 28.795,46.838,52.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.065 | Acc: 27.839,45.389,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.009 | Acc: 27.574,45.671,51.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 5.156 | Acc: 38.281,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.816 | Acc: 39.993,59.189,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.812 | Acc: 40.587,59.623,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.779 | Acc: 40.727,60.233,67.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.802 | Acc: 40.500,59.713,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.798 | Acc: 40.656,59.986,67.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.793 | Acc: 40.380,59.924,67.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.765 | Acc: 40.392,60.162,67.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.747 | Acc: 40.518,60.195,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.733 | Acc: 40.547,60.325,67.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.740 | Acc: 40.586,60.319,67.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.751 | Acc: 40.586,60.223,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.756 | Acc: 40.463,60.101,66.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.758 | Acc: 40.412,60.183,66.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.772 | Acc: 40.275,60.006,66.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.770 | Acc: 40.345,60.019,66.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.772 | Acc: 40.343,60.039,66.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.771 | Acc: 40.391,60.007,66.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.761 | Acc: 40.510,60.117,66.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.769 | Acc: 40.447,60.019,66.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.348 | Acc: 28.125,46.875,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.386 | Acc: 26.376,42.783,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.457 | Acc: 25.400,42.264,51.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.463 | Acc: 25.333,42.008,51.434,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.140 | Acc: 44.531,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 42.188,62.240,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 41.349,61.566,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.634 | Acc: 40.971,61.053,68.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.681 | Acc: 40.760,60.571,67.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.720 | Acc: 40.401,60.087,67.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.736 | Acc: 40.199,60.124,66.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.737 | Acc: 40.221,60.295,67.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.756 | Acc: 40.135,60.132,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.746 | Acc: 40.297,60.148,66.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.744 | Acc: 40.493,60.242,66.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.732 | Acc: 40.682,60.361,66.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.746 | Acc: 40.528,60.224,66.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.757 | Acc: 40.520,60.147,66.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.753 | Acc: 40.550,60.212,66.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.749 | Acc: 40.550,60.299,66.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.749 | Acc: 40.593,60.322,66.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.747 | Acc: 40.572,60.376,66.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.759 | Acc: 40.499,60.280,66.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.761 | Acc: 40.488,60.255,66.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.912 | Acc: 34.375,57.812,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.171 | Acc: 33.668,49.777,55.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.205 | Acc: 33.232,48.342,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.206 | Acc: 32.748,48.386,54.752,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.181 | Acc: 45.312,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.586 | Acc: 41.518,61.756,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 41.235,61.395,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 40.689,61.053,67.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.690 | Acc: 40.693,60.899,67.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.705 | Acc: 40.803,60.628,67.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.707 | Acc: 40.728,60.602,67.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.702 | Acc: 40.791,60.472,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.709 | Acc: 40.780,60.239,67.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.715 | Acc: 40.742,60.389,67.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.721 | Acc: 40.703,60.386,67.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.728 | Acc: 40.597,60.308,67.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.730 | Acc: 40.583,60.202,67.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.734 | Acc: 40.622,60.216,67.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.736 | Acc: 40.622,60.190,66.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.734 | Acc: 40.680,60.174,66.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.735 | Acc: 40.713,60.222,66.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.738 | Acc: 40.703,60.191,66.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.747 | Acc: 40.640,60.145,66.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.756 | Acc: 40.572,60.109,66.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.904 | Acc: 33.594,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.839 | Acc: 28.385,48.065,54.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.911 | Acc: 27.839,46.646,52.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.878 | Acc: 27.933,46.427,52.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.543 | Acc: 43.750,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.685 | Acc: 40.811,60.751,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.688 | Acc: 40.701,61.090,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 40.407,60.848,67.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.664 | Acc: 40.635,60.802,67.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.640 | Acc: 40.772,61.270,68.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.655 | Acc: 41.058,61.157,67.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.647 | Acc: 41.185,61.137,67.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.657 | Acc: 41.101,61.069,67.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.653 | Acc: 41.104,61.188,67.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.654 | Acc: 41.173,61.186,67.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.671 | Acc: 41.166,60.934,67.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.677 | Acc: 41.183,60.941,67.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.691 | Acc: 41.119,60.955,67.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.697 | Acc: 41.075,60.843,67.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.701 | Acc: 41.040,60.782,67.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.711 | Acc: 41.005,60.704,67.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.723 | Acc: 40.992,60.628,67.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.721 | Acc: 40.889,60.624,67.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.724 | Acc: 40.853,60.650,66.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.049 | Acc: 29.688,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.729 | Acc: 21.503,42.411,49.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.734 | Acc: 21.189,42.530,49.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.721 | Acc: 21.107,42.264,49.052,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.097 | Acc: 42.969,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 40.439,62.537,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 40.473,61.357,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.613 | Acc: 40.049,61.219,68.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.657 | Acc: 39.969,60.899,68.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.689 | Acc: 40.022,60.651,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.689 | Acc: 40.096,60.660,68.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.682 | Acc: 40.248,60.766,67.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.676 | Acc: 40.450,60.802,67.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.677 | Acc: 40.474,60.773,67.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.696 | Acc: 40.380,60.689,67.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.680 | Acc: 40.600,60.796,67.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.690 | Acc: 40.554,60.675,67.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.696 | Acc: 40.553,60.659,67.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.702 | Acc: 40.525,60.551,67.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.704 | Acc: 40.576,60.517,67.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.716 | Acc: 40.491,60.436,67.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.725 | Acc: 40.417,60.365,67.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.731 | Acc: 40.391,60.345,66.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.731 | Acc: 40.430,60.236,66.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.949 | Acc: 28.906,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.756 | Acc: 27.121,46.577,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.770 | Acc: 26.734,45.560,55.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.782 | Acc: 26.844,45.082,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 4.965 | Acc: 39.844,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 42.039,61.198,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 41.978,60.976,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 40.894,61.027,68.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.606 | Acc: 40.992,60.918,68.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.626 | Acc: 40.733,60.976,69.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.659 | Acc: 40.560,60.660,68.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.680 | Acc: 40.653,60.544,68.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.683 | Acc: 40.659,60.486,67.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.677 | Acc: 40.703,60.536,67.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.701 | Acc: 40.571,60.230,67.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.695 | Acc: 40.674,60.280,67.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.688 | Acc: 40.797,60.348,67.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.694 | Acc: 40.897,60.393,67.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.700 | Acc: 40.853,60.359,67.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.706 | Acc: 40.703,60.348,67.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.716 | Acc: 40.683,60.266,67.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.722 | Acc: 40.648,60.204,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.726 | Acc: 40.606,60.195,67.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.728 | Acc: 40.584,60.162,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.280 | Acc: 38.281,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.466 | Acc: 31.696,48.438,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.502 | Acc: 30.888,48.266,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.517 | Acc: 30.443,48.412,53.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.343 | Acc: 46.094,63.281,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 42.522,61.570,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 42.302,61.242,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.622 | Acc: 41.624,61.117,68.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.602 | Acc: 41.532,61.545,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.623 | Acc: 41.406,61.417,68.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.632 | Acc: 41.284,61.331,68.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.641 | Acc: 40.852,61.159,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.646 | Acc: 40.892,61.166,68.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.678 | Acc: 40.772,60.950,67.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.691 | Acc: 40.718,60.844,67.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.682 | Acc: 40.710,60.757,67.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.691 | Acc: 40.651,60.630,67.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.691 | Acc: 40.646,60.638,67.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.690 | Acc: 40.633,60.651,67.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.690 | Acc: 40.594,60.686,67.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.693 | Acc: 40.637,60.682,67.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.693 | Acc: 40.648,60.651,67.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.696 | Acc: 40.660,60.680,67.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.698 | Acc: 40.609,60.642,67.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.214 | Acc: 30.469,57.812,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.735 | Acc: 26.562,47.842,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.757 | Acc: 25.838,47.008,54.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.780 | Acc: 25.525,46.478,54.355,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.568 | Acc: 48.438,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 42.225,61.235,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 42.226,61.300,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.632 | Acc: 41.291,61.104,68.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.655 | Acc: 41.165,60.928,67.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.665 | Acc: 41.228,60.605,67.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.684 | Acc: 40.890,60.427,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.688 | Acc: 40.658,60.450,67.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.680 | Acc: 40.814,60.632,67.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.676 | Acc: 40.824,60.713,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.682 | Acc: 40.870,60.611,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.678 | Acc: 40.802,60.732,67.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.678 | Acc: 40.709,60.769,67.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.686 | Acc: 40.652,60.704,67.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.680 | Acc: 40.761,60.718,67.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.678 | Acc: 40.776,60.748,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.683 | Acc: 40.735,60.723,67.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.689 | Acc: 40.664,60.718,67.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.693 | Acc: 40.692,60.699,67.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.707 | Acc: 40.545,60.579,67.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.438 | Acc: 32.812,43.750,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.434 | Acc: 25.744,42.299,49.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.469 | Acc: 25.324,41.597,49.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.432 | Acc: 25.026,41.842,49.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 5.058 | Acc: 32.812,58.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 40.625,61.644,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 40.816,61.014,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.625 | Acc: 40.497,61.437,68.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.609 | Acc: 40.866,61.834,68.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.609 | Acc: 40.733,61.719,68.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.607 | Acc: 40.806,61.557,68.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.623 | Acc: 40.786,61.392,68.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.635 | Acc: 40.751,61.321,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.651 | Acc: 40.586,61.045,67.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.656 | Acc: 40.606,60.938,67.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.668 | Acc: 40.484,60.831,67.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.681 | Acc: 40.476,60.675,67.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.678 | Acc: 40.398,60.626,67.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.673 | Acc: 40.475,60.787,67.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.665 | Acc: 40.747,60.860,67.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.666 | Acc: 40.720,60.899,67.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.670 | Acc: 40.643,60.883,67.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.667 | Acc: 40.733,60.851,67.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.674 | Acc: 40.828,60.843,67.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.923 | Acc: 30.469,42.188,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.713 | Acc: 29.725,46.987,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.800 | Acc: 28.944,47.123,54.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.833 | Acc: 28.842,46.542,53.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.694 | Acc: 39.844,53.125,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 40.923,61.421,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.541 | Acc: 41.063,62.024,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 41.214,61.885,69.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.536 | Acc: 40.963,62.008,68.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.560 | Acc: 40.880,61.765,68.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.591 | Acc: 40.560,61.532,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.592 | Acc: 40.813,61.558,68.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.609 | Acc: 40.707,61.442,68.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.618 | Acc: 40.711,61.378,68.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.609 | Acc: 40.858,61.482,68.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.605 | Acc: 41.000,61.542,68.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.618 | Acc: 40.839,61.534,68.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.623 | Acc: 40.867,61.437,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.629 | Acc: 40.828,61.405,68.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.648 | Acc: 40.807,61.197,67.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.650 | Acc: 40.810,61.215,67.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.651 | Acc: 40.776,61.196,67.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.650 | Acc: 40.833,61.299,67.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.654 | Acc: 40.875,61.309,67.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.333 | Acc: 40.625,49.219,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.071 | Acc: 33.557,49.107,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.081 | Acc: 33.289,49.009,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.073 | Acc: 33.133,48.975,56.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.488 | Acc: 42.969,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 41.964,60.826,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 40.892,61.871,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.546 | Acc: 41.214,61.770,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.575 | Acc: 41.040,61.680,68.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.582 | Acc: 41.136,61.649,68.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.590 | Acc: 40.993,61.609,68.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.597 | Acc: 40.974,61.408,68.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.608 | Acc: 40.877,61.209,68.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.618 | Acc: 40.793,61.136,68.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.635 | Acc: 40.792,60.984,67.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.645 | Acc: 40.858,60.906,67.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.649 | Acc: 40.842,60.944,67.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.657 | Acc: 40.772,60.845,67.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.666 | Acc: 40.800,60.793,67.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.672 | Acc: 40.747,60.826,67.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.674 | Acc: 40.820,60.855,67.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.673 | Acc: 40.827,60.908,67.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.670 | Acc: 40.796,60.963,67.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.670 | Acc: 40.795,60.958,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.463 | Acc: 35.156,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.435 | Acc: 31.101,49.702,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.486 | Acc: 30.145,48.685,55.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.546 | Acc: 29.585,47.643,54.252,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 4.715 | Acc: 34.375,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.624 | Acc: 41.220,61.198,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 40.777,61.509,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 40.958,62.013,69.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.598 | Acc: 40.828,61.613,69.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.613 | Acc: 40.749,61.378,68.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.633 | Acc: 40.896,61.222,68.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.638 | Acc: 40.902,61.270,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.649 | Acc: 40.989,61.161,68.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.638 | Acc: 40.996,61.218,68.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.645 | Acc: 40.975,61.132,68.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.642 | Acc: 40.848,61.093,68.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.637 | Acc: 40.849,61.187,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.640 | Acc: 40.754,61.153,68.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.648 | Acc: 40.667,61.051,68.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.657 | Acc: 40.656,60.958,67.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.657 | Acc: 40.610,60.947,67.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.658 | Acc: 40.598,60.887,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.661 | Acc: 40.564,60.814,67.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.661 | Acc: 40.539,60.821,67.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.069 | Acc: 22.656,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.277 | Acc: 22.545,46.391,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.477 | Acc: 21.761,44.836,53.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.523 | Acc: 21.632,44.736,53.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.448 | Acc: 38.281,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 41.146,62.798,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 42.207,62.805,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.524 | Acc: 42.021,61.808,70.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.544 | Acc: 41.725,61.555,69.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.530 | Acc: 41.677,61.889,69.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.529 | Acc: 41.962,62.029,69.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.553 | Acc: 41.611,62.018,69.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.574 | Acc: 41.367,61.816,69.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.580 | Acc: 41.458,61.827,68.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.599 | Acc: 41.282,61.730,68.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.603 | Acc: 41.237,61.715,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.606 | Acc: 41.319,61.751,68.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.612 | Acc: 41.409,61.719,68.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.622 | Acc: 41.295,61.621,68.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.627 | Acc: 41.263,61.503,68.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.633 | Acc: 41.190,61.466,68.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.622 | Acc: 41.347,61.581,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.629 | Acc: 41.322,61.552,68.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.639 | Acc: 41.230,61.477,68.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.239 | Acc: 31.250,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.969 | Acc: 27.679,45.089,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.967 | Acc: 27.591,45.732,52.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.973 | Acc: 27.305,45.991,51.985,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.485 | Acc: 37.500,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.436 | Acc: 43.006,62.723,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.442 | Acc: 42.321,63.034,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.473 | Acc: 42.034,62.820,69.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.495 | Acc: 42.207,62.857,69.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.509 | Acc: 41.847,62.778,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.539 | Acc: 41.632,62.487,69.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.544 | Acc: 41.423,62.334,69.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.541 | Acc: 41.610,62.384,69.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.554 | Acc: 41.510,62.327,69.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.559 | Acc: 41.503,62.197,69.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.583 | Acc: 41.265,61.963,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.583 | Acc: 41.380,61.968,68.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.589 | Acc: 41.403,61.883,68.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.594 | Acc: 41.359,61.769,68.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.603 | Acc: 41.269,61.737,68.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.610 | Acc: 41.243,61.670,68.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.621 | Acc: 41.131,61.531,68.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.622 | Acc: 41.194,61.546,68.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.626 | Acc: 41.131,61.544,68.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.550 | Acc: 29.688,53.125,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.431 | Acc: 31.362,48.214,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.494 | Acc: 29.573,47.370,55.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.486 | Acc: 29.623,48.028,55.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.915 | Acc: 35.156,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 42.746,62.500,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.455 | Acc: 42.149,62.119,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.491 | Acc: 41.931,62.167,70.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.501 | Acc: 42.120,62.259,69.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.517 | Acc: 42.203,62.392,69.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.544 | Acc: 41.890,62.248,69.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.543 | Acc: 41.888,62.223,69.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.546 | Acc: 41.731,62.170,69.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.552 | Acc: 41.842,62.271,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.559 | Acc: 41.838,62.181,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.565 | Acc: 41.749,62.090,68.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.572 | Acc: 41.808,62.023,68.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.579 | Acc: 41.625,61.916,68.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.580 | Acc: 41.606,61.938,68.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.580 | Acc: 41.588,62.017,68.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.584 | Acc: 41.528,61.986,68.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.590 | Acc: 41.475,61.927,68.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.596 | Acc: 41.452,61.831,68.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.609 | Acc: 41.357,61.772,68.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.608 | Acc: 34.375,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.406 | Acc: 30.543,48.177,56.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.480 | Acc: 29.364,46.970,56.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.469 | Acc: 29.124,47.131,55.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.126 | Acc: 43.750,66.406,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.452 | Acc: 42.076,62.872,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 42.149,62.976,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.497 | Acc: 41.381,62.436,69.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.485 | Acc: 41.454,62.413,69.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.508 | Acc: 41.646,62.075,69.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.521 | Acc: 41.697,62.067,69.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.523 | Acc: 41.528,62.057,68.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.531 | Acc: 41.358,62.083,68.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.537 | Acc: 41.333,62.051,68.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.540 | Acc: 41.426,62.010,68.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.550 | Acc: 41.350,61.828,68.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.548 | Acc: 41.286,61.891,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.558 | Acc: 41.167,61.806,68.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.552 | Acc: 41.370,61.794,68.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.557 | Acc: 41.378,61.724,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.569 | Acc: 41.272,61.597,68.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.584 | Acc: 41.205,61.535,68.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.596 | Acc: 41.147,61.448,68.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.599 | Acc: 41.146,61.430,68.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.308 | Acc: 38.281,45.312,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.620 | Acc: 28.274,46.540,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.669 | Acc: 27.915,46.113,55.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.683 | Acc: 27.561,46.568,55.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.312 | Acc: 44.531,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.431 | Acc: 42.894,63.988,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.507 | Acc: 42.207,62.862,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 42.252,62.859,70.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.514 | Acc: 41.889,62.558,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.509 | Acc: 41.692,62.732,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.526 | Acc: 41.471,62.668,69.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.525 | Acc: 41.395,62.683,69.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.541 | Acc: 41.198,62.393,68.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.555 | Acc: 41.052,62.284,68.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.564 | Acc: 41.146,62.111,68.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.572 | Acc: 41.063,61.941,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.577 | Acc: 41.134,61.988,68.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.582 | Acc: 41.092,61.925,68.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.591 | Acc: 41.117,61.827,68.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.588 | Acc: 41.087,61.919,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.599 | Acc: 41.053,61.804,68.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.602 | Acc: 41.008,61.758,68.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.602 | Acc: 40.976,61.714,68.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.609 | Acc: 40.976,61.602,68.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.249 | Acc: 25.781,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.565 | Acc: 28.534,47.061,54.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.611 | Acc: 27.725,46.380,53.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.606 | Acc: 27.741,46.721,54.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.896 | Acc: 40.625,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 40.885,63.132,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 42.511,63.815,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 42.303,63.345,70.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.493 | Acc: 42.178,62.982,69.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.494 | Acc: 42.164,62.833,70.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.527 | Acc: 42.039,62.545,69.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.545 | Acc: 41.539,62.317,69.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.558 | Acc: 41.528,62.223,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.574 | Acc: 41.277,62.120,69.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.577 | Acc: 41.177,62.127,69.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.591 | Acc: 41.003,61.956,68.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.592 | Acc: 40.936,61.907,68.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.593 | Acc: 40.966,61.880,68.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.589 | Acc: 41.050,61.894,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.598 | Acc: 40.988,61.794,68.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.611 | Acc: 40.949,61.638,68.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.606 | Acc: 40.973,61.700,68.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.611 | Acc: 40.947,61.639,68.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.611 | Acc: 40.924,61.610,68.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.066 | Acc: 36.719,55.469,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.297 | Acc: 31.994,50.074,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.315 | Acc: 30.888,49.143,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.293 | Acc: 30.674,49.449,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.329 | Acc: 39.062,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.429 | Acc: 41.071,62.909,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 41.463,62.614,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.457 | Acc: 41.509,62.923,69.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.471 | Acc: 41.705,62.973,69.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.450 | Acc: 41.631,63.096,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.478 | Acc: 41.439,63.017,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.498 | Acc: 41.373,62.788,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.517 | Acc: 41.232,62.631,68.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.506 | Acc: 41.458,62.664,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.505 | Acc: 41.515,62.780,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.511 | Acc: 41.438,62.730,68.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.531 | Acc: 41.218,62.584,68.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.544 | Acc: 41.200,62.458,68.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.545 | Acc: 41.131,62.430,68.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.552 | Acc: 41.149,62.344,68.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.558 | Acc: 41.119,62.300,68.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.571 | Acc: 41.044,62.230,68.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.574 | Acc: 41.002,62.180,68.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.585 | Acc: 40.945,62.094,68.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.138 | Acc: 27.344,45.312,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.035 | Acc: 27.121,45.610,53.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.112 | Acc: 25.705,45.446,52.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.079 | Acc: 24.834,45.364,53.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.756 | Acc: 43.750,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 41.555,62.314,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.410 | Acc: 42.378,62.862,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.463 | Acc: 42.162,62.500,70.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.468 | Acc: 42.091,62.442,70.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.451 | Acc: 42.218,62.701,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.425 | Acc: 42.388,62.978,70.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.438 | Acc: 42.431,62.827,70.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.443 | Acc: 42.241,62.733,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.467 | Acc: 41.989,62.414,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.489 | Acc: 41.989,62.100,69.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.490 | Acc: 41.929,62.253,69.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.492 | Acc: 41.847,62.312,69.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.511 | Acc: 41.828,62.246,69.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.523 | Acc: 41.687,62.191,69.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.528 | Acc: 41.661,62.160,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.544 | Acc: 41.560,61.916,69.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.551 | Acc: 41.532,61.872,69.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.557 | Acc: 41.428,61.849,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.562 | Acc: 41.373,61.772,68.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.746 | Acc: 32.812,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.042 | Acc: 25.409,45.387,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.137 | Acc: 24.809,44.646,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.150 | Acc: 25.179,44.634,52.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.955 | Acc: 35.938,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 40.476,62.872,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 40.987,62.995,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.471 | Acc: 41.176,62.385,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.481 | Acc: 41.233,62.394,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.482 | Acc: 41.074,62.276,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.502 | Acc: 41.200,62.074,69.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.508 | Acc: 41.384,61.985,69.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.509 | Acc: 41.445,61.981,69.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.521 | Acc: 41.376,61.904,69.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.524 | Acc: 41.220,61.905,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.527 | Acc: 41.300,61.941,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.531 | Acc: 41.335,61.978,69.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.535 | Acc: 41.236,61.958,69.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.548 | Acc: 41.184,61.819,69.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.556 | Acc: 41.139,61.763,69.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.558 | Acc: 41.121,61.782,69.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.567 | Acc: 41.108,61.661,68.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.583 | Acc: 41.099,61.563,68.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.591 | Acc: 41.105,61.526,68.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.877 | Acc: 38.281,45.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.039 | Acc: 29.055,44.345,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.993 | Acc: 28.220,44.798,52.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.950 | Acc: 28.343,45.645,52.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.586 | Acc: 41.406,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 40.253,60.789,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 41.025,61.795,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.511 | Acc: 41.406,62.295,70.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.497 | Acc: 41.464,62.394,69.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.509 | Acc: 41.437,62.353,69.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.537 | Acc: 41.361,62.197,69.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.526 | Acc: 41.462,62.389,69.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.539 | Acc: 41.450,62.388,69.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.519 | Acc: 41.661,62.457,69.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.524 | Acc: 41.632,62.387,69.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.526 | Acc: 41.537,62.313,69.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.534 | Acc: 41.393,62.189,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.545 | Acc: 41.307,62.111,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.555 | Acc: 41.198,62.036,68.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.560 | Acc: 41.175,62.020,68.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.561 | Acc: 41.158,62.077,68.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.560 | Acc: 41.237,62.149,68.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.573 | Acc: 41.160,62.015,68.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.575 | Acc: 41.172,61.942,68.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.116 | Acc: 26.562,41.406,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.264 | Acc: 19.308,37.723,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.217 | Acc: 18.807,38.091,49.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.200 | Acc: 18.622,38.064,49.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.445 | Acc: 39.062,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 38.765,62.314,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 39.177,62.405,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.491 | Acc: 40.113,62.846,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.504 | Acc: 40.365,62.558,70.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.503 | Acc: 40.834,62.430,69.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.525 | Acc: 40.935,62.203,69.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.533 | Acc: 40.924,62.278,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.527 | Acc: 40.989,62.335,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.535 | Acc: 41.052,62.232,69.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.536 | Acc: 41.060,62.127,69.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.550 | Acc: 41.070,62.111,69.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.558 | Acc: 41.202,62.011,69.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.559 | Acc: 41.212,62.045,69.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.558 | Acc: 41.228,62.102,69.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.560 | Acc: 41.328,62.035,68.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.564 | Acc: 41.355,62.025,68.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.570 | Acc: 41.402,61.968,68.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.574 | Acc: 41.343,61.922,68.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.580 | Acc: 41.283,61.905,68.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.695 | Acc: 38.281,50.000,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.981 | Acc: 29.204,43.564,50.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.041 | Acc: 28.487,42.511,50.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.029 | Acc: 28.074,42.623,50.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.559 | Acc: 35.156,63.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.379 | Acc: 41.778,63.579,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.441 | Acc: 41.463,62.976,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.467 | Acc: 41.445,62.884,69.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.506 | Acc: 41.252,62.375,69.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.494 | Acc: 41.553,62.353,69.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.495 | Acc: 41.355,62.519,69.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.514 | Acc: 41.240,62.229,69.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.525 | Acc: 41.023,62.471,69.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.534 | Acc: 40.992,62.362,69.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.538 | Acc: 41.107,62.356,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.535 | Acc: 41.194,62.369,69.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.530 | Acc: 41.280,62.276,69.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.535 | Acc: 41.307,62.281,69.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.535 | Acc: 41.381,62.269,69.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.538 | Acc: 41.414,62.204,69.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.534 | Acc: 41.470,62.240,69.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.536 | Acc: 41.502,62.200,69.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.545 | Acc: 41.350,62.065,69.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.549 | Acc: 41.347,62.073,69.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.713 | Acc: 12.500,30.469,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.140 | Acc: 14.807,27.753,40.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.165 | Acc: 14.596,27.439,39.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.188 | Acc: 14.421,27.549,39.498,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.565 | Acc: 43.750,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.432 | Acc: 40.774,63.914,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.411 | Acc: 41.540,64.005,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.415 | Acc: 41.598,63.653,71.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.429 | Acc: 41.464,63.329,71.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.430 | Acc: 41.925,63.281,71.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.451 | Acc: 42.007,63.120,70.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.459 | Acc: 41.982,62.910,70.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.460 | Acc: 41.950,63.010,70.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.475 | Acc: 41.881,62.910,70.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.486 | Acc: 41.861,62.702,70.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.510 | Acc: 41.760,62.496,70.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.520 | Acc: 41.607,62.442,69.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.524 | Acc: 41.574,62.386,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.526 | Acc: 41.562,62.380,69.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.530 | Acc: 41.598,62.324,69.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.530 | Acc: 41.586,62.288,69.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.529 | Acc: 41.608,62.298,69.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.536 | Acc: 41.631,62.253,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.539 | Acc: 41.578,62.299,69.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.426 | Acc: 21.094,37.500,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.798 | Acc: 16.741,39.993,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.846 | Acc: 16.654,39.977,50.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.756 | Acc: 16.726,40.394,50.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.311 | Acc: 41.406,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 40.551,63.504,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 41.921,63.014,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.495 | Acc: 42.047,62.551,70.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.462 | Acc: 42.149,62.876,70.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.466 | Acc: 42.002,62.871,70.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.485 | Acc: 41.742,62.577,70.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.486 | Acc: 41.916,62.755,70.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.509 | Acc: 41.862,62.563,69.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.506 | Acc: 41.933,62.642,69.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.503 | Acc: 41.896,62.749,69.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.513 | Acc: 41.721,62.701,69.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.519 | Acc: 41.717,62.630,69.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.529 | Acc: 41.700,62.563,69.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.533 | Acc: 41.715,62.514,69.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.536 | Acc: 41.705,62.422,69.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.530 | Acc: 41.737,62.527,69.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.530 | Acc: 41.764,62.479,69.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.532 | Acc: 41.763,62.437,69.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.540 | Acc: 41.699,62.328,69.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.878 | Acc: 30.469,49.219,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.756 | Acc: 28.348,47.991,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.817 | Acc: 27.287,47.142,54.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.780 | Acc: 27.164,47.336,54.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.324 | Acc: 43.750,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.414 | Acc: 41.778,63.281,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.422 | Acc: 42.092,63.720,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.410 | Acc: 42.520,63.819,71.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.464 | Acc: 42.303,63.146,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.474 | Acc: 42.342,62.972,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.473 | Acc: 42.175,62.965,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.471 | Acc: 42.021,63.087,69.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.478 | Acc: 42.100,63.019,69.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.478 | Acc: 42.179,62.958,69.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.482 | Acc: 42.191,62.815,69.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.490 | Acc: 42.223,62.666,69.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.498 | Acc: 42.012,62.568,69.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.497 | Acc: 41.927,62.623,69.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.500 | Acc: 41.968,62.617,69.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.495 | Acc: 42.068,62.614,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.506 | Acc: 42.005,62.568,69.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.513 | Acc: 41.963,62.477,69.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.522 | Acc: 41.828,62.435,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.528 | Acc: 41.784,62.432,69.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.107 | Acc: 28.906,46.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.182 | Acc: 22.991,40.327,49.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.237 | Acc: 21.989,40.111,49.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.283 | Acc: 21.875,40.612,48.681,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.607 | Acc: 44.531,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 42.746,61.719,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.474 | Acc: 42.416,62.671,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.449 | Acc: 42.252,63.076,70.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.455 | Acc: 42.274,63.407,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.442 | Acc: 42.157,63.459,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.443 | Acc: 41.968,63.404,70.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.477 | Acc: 41.645,62.916,69.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.484 | Acc: 41.736,62.747,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.492 | Acc: 41.613,62.612,69.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.496 | Acc: 41.601,62.589,69.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.503 | Acc: 41.484,62.518,69.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.495 | Acc: 41.662,62.581,69.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.500 | Acc: 41.700,62.491,69.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.501 | Acc: 41.715,62.503,69.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.502 | Acc: 41.757,62.536,69.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.520 | Acc: 41.608,62.366,69.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.530 | Acc: 41.489,62.225,68.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.533 | Acc: 41.443,62.197,68.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.534 | Acc: 41.406,62.221,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.321 | Acc: 28.906,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.536 | Acc: 28.757,48.847,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.655 | Acc: 27.992,48.056,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.660 | Acc: 27.510,47.836,54.265,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.862 | Acc: 30.469,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 41.443,62.835,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.472 | Acc: 41.597,63.338,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.454 | Acc: 41.483,63.384,70.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.441 | Acc: 41.590,63.021,70.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.437 | Acc: 41.855,63.080,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.449 | Acc: 41.787,62.920,69.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.460 | Acc: 41.694,63.032,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.471 | Acc: 41.591,62.869,69.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.490 | Acc: 41.531,62.573,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.488 | Acc: 41.616,62.702,69.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.509 | Acc: 41.572,62.535,69.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.509 | Acc: 41.666,62.633,69.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.511 | Acc: 41.568,62.581,69.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.510 | Acc: 41.517,62.611,69.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.515 | Acc: 41.552,62.516,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.529 | Acc: 41.477,62.395,69.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.533 | Acc: 41.402,62.305,69.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.533 | Acc: 41.456,62.325,69.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.533 | Acc: 41.527,62.334,69.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.937 | Acc: 25.781,42.188,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.590 | Acc: 20.238,38.765,49.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.753 | Acc: 19.950,38.129,48.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.785 | Acc: 19.608,37.961,48.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.096 | Acc: 42.969,66.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 42.262,64.360,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 42.168,64.539,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.346 | Acc: 42.469,64.357,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.383 | Acc: 42.052,64.120,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.395 | Acc: 42.273,63.962,70.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.412 | Acc: 42.020,63.630,70.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.412 | Acc: 42.110,63.713,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.412 | Acc: 42.192,63.674,70.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 42.105,63.329,70.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.445 | Acc: 42.013,63.141,70.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.447 | Acc: 41.958,63.013,70.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.469 | Acc: 41.880,62.798,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.478 | Acc: 41.837,62.659,69.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.486 | Acc: 41.857,62.647,69.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.480 | Acc: 41.894,62.661,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.492 | Acc: 41.769,62.575,69.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.494 | Acc: 41.686,62.582,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.496 | Acc: 41.690,62.580,69.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.507 | Acc: 41.650,62.479,69.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.890 | Acc: 27.344,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.398 | Acc: 25.298,45.238,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.399 | Acc: 24.695,45.332,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.454 | Acc: 24.347,44.992,53.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.477 | Acc: 44.531,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 42.448,64.769,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.350 | Acc: 43.464,64.215,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.370 | Acc: 42.789,64.037,70.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.400 | Acc: 42.660,63.696,70.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.400 | Acc: 42.644,63.653,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.423 | Acc: 42.323,63.507,70.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.427 | Acc: 42.320,63.409,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.436 | Acc: 42.124,63.427,70.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.442 | Acc: 42.062,63.445,70.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 41.993,63.293,70.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.459 | Acc: 41.954,63.196,69.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.463 | Acc: 41.944,63.054,69.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.473 | Acc: 41.819,62.856,69.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.488 | Acc: 41.840,62.753,69.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.491 | Acc: 41.725,62.749,69.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.498 | Acc: 41.633,62.602,69.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.505 | Acc: 41.523,62.571,69.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.506 | Acc: 41.543,62.628,69.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.509 | Acc: 41.521,62.590,69.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.313 | Acc: 28.125,50.000,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.539 | Acc: 28.943,48.810,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.677 | Acc: 28.125,47.618,54.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.703 | Acc: 28.010,47.080,54.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 3.841 | Acc: 43.750,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.366 | Acc: 42.560,64.360,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 42.321,63.548,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.426 | Acc: 41.675,63.012,70.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.402 | Acc: 41.898,63.436,70.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.412 | Acc: 41.793,63.653,70.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.410 | Acc: 42.084,63.591,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 42.149,63.531,70.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.411 | Acc: 42.056,63.485,70.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.415 | Acc: 41.950,63.506,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.422 | Acc: 41.970,63.503,70.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.427 | Acc: 42.057,63.278,70.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.432 | Acc: 42.100,63.187,70.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.439 | Acc: 42.038,63.135,70.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.453 | Acc: 41.882,63.056,70.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.457 | Acc: 41.894,63.061,69.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.465 | Acc: 41.771,62.975,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.480 | Acc: 41.677,62.818,69.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.486 | Acc: 41.603,62.805,69.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.491 | Acc: 41.661,62.754,69.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.383 | Acc: 28.906,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.180 | Acc: 27.493,42.746,50.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.204 | Acc: 27.039,42.511,50.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.206 | Acc: 26.857,42.136,50.756,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.374 | Acc: 32.031,57.812,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 43.304,64.695,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.295 | Acc: 43.502,65.530,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.314 | Acc: 43.430,64.997,71.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.359 | Acc: 43.065,64.680,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.393 | Acc: 42.466,64.248,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.402 | Acc: 42.284,64.004,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.413 | Acc: 42.293,63.880,70.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.419 | Acc: 42.115,63.597,70.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.419 | Acc: 42.149,63.536,70.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.421 | Acc: 42.129,63.511,70.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.424 | Acc: 42.039,63.599,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.431 | Acc: 42.022,63.528,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.438 | Acc: 41.993,63.431,70.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.442 | Acc: 41.954,63.362,70.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.451 | Acc: 41.931,63.216,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.468 | Acc: 41.754,63.070,69.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.476 | Acc: 41.700,62.990,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.480 | Acc: 41.664,62.894,69.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.490 | Acc: 41.599,62.773,69.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.981 | Acc: 38.281,56.250,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.426 | Acc: 31.436,48.103,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.519 | Acc: 30.755,46.837,54.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.567 | Acc: 30.392,46.824,53.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.782 | Acc: 38.281,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.346 | Acc: 43.229,63.839,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.418 | Acc: 41.845,63.014,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.372 | Acc: 42.098,63.461,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.418 | Acc: 41.667,63.050,71.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.428 | Acc: 41.538,63.088,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.430 | Acc: 41.574,63.062,70.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.440 | Acc: 41.650,63.165,70.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.450 | Acc: 41.756,63.102,70.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.445 | Acc: 41.816,63.104,70.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.444 | Acc: 41.888,63.165,70.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.444 | Acc: 41.799,63.112,70.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.453 | Acc: 41.815,63.009,70.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.464 | Acc: 41.664,62.895,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.471 | Acc: 41.576,62.814,69.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.476 | Acc: 41.614,62.713,69.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.487 | Acc: 41.543,62.614,69.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.488 | Acc: 41.610,62.608,69.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.491 | Acc: 41.575,62.621,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.499 | Acc: 41.509,62.557,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.333 | Acc: 26.562,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.641 | Acc: 25.335,48.921,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.750 | Acc: 24.638,48.152,55.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.735 | Acc: 24.321,48.322,56.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.404 | Acc: 35.156,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.437 | Acc: 41.518,62.835,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 40.949,62.710,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.387 | Acc: 41.714,62.974,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.400 | Acc: 41.416,62.568,70.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.403 | Acc: 41.561,62.717,70.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.416 | Acc: 41.645,62.461,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.423 | Acc: 41.772,62.616,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.419 | Acc: 41.955,62.704,70.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.424 | Acc: 41.976,62.893,70.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.413 | Acc: 42.036,63.005,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.430 | Acc: 42.004,62.917,70.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.439 | Acc: 41.828,62.831,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.444 | Acc: 41.798,62.808,70.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.447 | Acc: 41.804,62.870,70.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.453 | Acc: 41.767,62.783,70.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.466 | Acc: 41.703,62.636,70.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.467 | Acc: 41.670,62.651,70.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.465 | Acc: 41.670,62.747,70.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.471 | Acc: 41.589,62.736,70.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.193 | Acc: 33.594,56.250,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.334 | Acc: 32.143,49.442,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.369 | Acc: 31.669,49.009,57.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.379 | Acc: 31.314,49.283,56.724,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.937 | Acc: 36.719,58.594,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.327 | Acc: 42.188,64.025,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 42.168,63.853,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.332 | Acc: 42.418,64.011,71.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.359 | Acc: 42.274,63.744,71.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 42.257,63.807,71.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.382 | Acc: 42.433,63.720,70.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.424 | Acc: 42.271,63.237,70.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.441 | Acc: 42.246,63.291,70.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.445 | Acc: 42.140,63.139,70.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.447 | Acc: 42.118,63.137,70.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.454 | Acc: 42.060,63.076,70.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.455 | Acc: 41.987,63.109,70.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.454 | Acc: 42.137,63.168,70.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.453 | Acc: 42.232,63.162,70.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.448 | Acc: 42.198,63.172,70.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.451 | Acc: 42.119,63.096,70.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.465 | Acc: 41.965,63.018,69.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.473 | Acc: 41.852,62.967,69.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.483 | Acc: 41.823,62.881,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.007 | Acc: 21.875,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.893 | Acc: 18.378,41.555,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.874 | Acc: 18.598,40.987,50.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.893 | Acc: 18.622,41.150,50.832,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.505 | Acc: 39.844,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.382 | Acc: 41.257,64.435,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.332 | Acc: 41.940,64.672,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.363 | Acc: 41.931,63.819,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 42.255,63.995,71.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.359 | Acc: 42.396,63.869,71.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.384 | Acc: 42.239,63.552,71.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.405 | Acc: 42.420,63.403,70.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.418 | Acc: 42.280,63.388,70.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.405 | Acc: 42.429,63.506,70.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.420 | Acc: 42.277,63.386,70.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.425 | Acc: 42.166,63.352,70.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.433 | Acc: 42.155,63.226,70.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.443 | Acc: 42.125,63.153,70.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.450 | Acc: 42.068,63.089,70.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.451 | Acc: 42.058,63.045,70.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.449 | Acc: 42.102,63.011,70.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.448 | Acc: 42.130,63.025,70.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.454 | Acc: 42.062,62.996,70.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.464 | Acc: 41.978,62.881,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.123 | Acc: 33.594,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.673 | Acc: 30.506,46.838,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.770 | Acc: 29.002,45.617,54.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.744 | Acc: 28.420,45.940,54.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.457 | Acc: 43.750,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.481 | Acc: 41.332,62.835,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.386 | Acc: 41.921,63.815,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 41.726,63.397,71.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.439 | Acc: 41.850,63.551,70.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.462 | Acc: 41.770,63.312,70.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.454 | Acc: 41.561,63.262,70.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.451 | Acc: 41.545,63.259,70.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.454 | Acc: 41.605,63.145,70.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.460 | Acc: 41.717,63.143,70.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.455 | Acc: 41.775,63.281,70.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.453 | Acc: 41.781,63.264,70.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.452 | Acc: 41.847,63.207,70.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.456 | Acc: 41.930,63.197,70.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.454 | Acc: 42.001,63.192,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.455 | Acc: 42.037,63.157,70.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.453 | Acc: 42.100,63.135,70.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.468 | Acc: 42.009,63.004,69.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 42.027,62.950,69.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.467 | Acc: 42.093,62.990,69.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.543 | Acc: 37.500,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.176 | Acc: 32.143,48.028,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.248 | Acc: 31.307,47.599,57.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.242 | Acc: 31.224,48.169,57.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.172 | Acc: 49.219,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.410 | Acc: 40.811,63.095,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 41.444,63.377,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.373 | Acc: 41.944,63.781,72.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.385 | Acc: 42.159,63.445,71.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.404 | Acc: 41.839,63.359,71.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.421 | Acc: 41.884,63.152,70.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.438 | Acc: 41.495,63.076,70.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.421 | Acc: 41.571,63.242,70.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.426 | Acc: 41.682,63.152,70.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.433 | Acc: 41.636,63.130,70.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.454 | Acc: 41.622,63.013,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.450 | Acc: 41.724,63.090,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.451 | Acc: 41.789,63.069,70.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.458 | Acc: 41.734,62.992,70.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.453 | Acc: 41.811,62.972,70.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.457 | Acc: 41.869,62.938,70.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.453 | Acc: 41.965,62.931,70.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.461 | Acc: 41.891,62.903,70.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.458 | Acc: 41.946,62.947,70.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.742 | Acc: 35.156,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.942 | Acc: 33.333,52.158,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.011 | Acc: 32.793,50.896,58.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.980 | Acc: 32.736,51.319,58.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 3.907 | Acc: 48.438,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.215 | Acc: 44.420,64.993,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.320 | Acc: 43.083,64.367,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.342 | Acc: 42.700,64.191,71.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.364 | Acc: 42.622,63.908,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.382 | Acc: 42.721,63.861,70.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.376 | Acc: 42.710,63.895,70.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.395 | Acc: 42.620,63.758,70.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.407 | Acc: 42.362,63.519,70.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.415 | Acc: 42.485,63.493,70.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.413 | Acc: 42.390,63.549,70.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.430 | Acc: 42.205,63.444,70.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.437 | Acc: 42.074,63.304,70.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.432 | Acc: 42.116,63.311,70.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.433 | Acc: 42.115,63.284,70.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 42.112,63.232,70.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.449 | Acc: 42.034,63.157,70.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.455 | Acc: 42.075,63.080,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.461 | Acc: 42.023,62.972,69.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.467 | Acc: 41.933,62.951,69.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.160 | Acc: 26.562,42.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.675 | Acc: 25.521,41.109,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.732 | Acc: 24.981,40.911,49.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.705 | Acc: 24.667,41.470,48.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.894 | Acc: 43.750,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.418 | Acc: 42.113,61.347,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.426 | Acc: 42.149,62.138,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.394 | Acc: 41.944,62.679,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.390 | Acc: 41.831,62.857,70.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.393 | Acc: 42.064,62.941,70.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.378 | Acc: 42.026,62.978,70.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.391 | Acc: 41.872,62.860,70.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.403 | Acc: 41.877,62.767,70.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.389 | Acc: 41.950,62.897,70.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.389 | Acc: 42.005,62.990,70.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.397 | Acc: 41.887,62.981,70.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.390 | Acc: 41.967,63.119,70.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.400 | Acc: 42.050,63.078,70.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.413 | Acc: 42.007,63.056,70.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.424 | Acc: 41.954,62.871,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.440 | Acc: 41.820,62.746,70.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.448 | Acc: 41.780,62.692,69.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.455 | Acc: 41.707,62.647,69.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.459 | Acc: 41.695,62.557,69.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.215 | Acc: 33.594,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.068 | Acc: 26.488,45.982,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.059 | Acc: 26.410,46.113,53.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.041 | Acc: 26.294,46.183,53.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.695 | Acc: 39.844,57.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.306 | Acc: 41.927,63.914,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 41.120,63.872,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.350 | Acc: 41.163,64.024,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.308 | Acc: 41.300,64.554,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.316 | Acc: 41.445,64.488,71.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.318 | Acc: 41.645,64.450,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.345 | Acc: 41.822,64.207,71.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.343 | Acc: 41.921,64.155,71.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.346 | Acc: 42.071,64.244,71.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.351 | Acc: 42.024,64.257,71.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.373 | Acc: 41.947,63.995,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.383 | Acc: 42.009,63.968,70.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.389 | Acc: 42.011,63.841,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.396 | Acc: 41.929,63.815,70.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.401 | Acc: 41.969,63.715,70.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.400 | Acc: 41.949,63.666,70.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.414 | Acc: 41.913,63.554,70.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.425 | Acc: 41.915,63.467,70.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.435 | Acc: 41.898,63.380,70.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.182 | Acc: 27.344,56.250,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.795 | Acc: 26.414,48.772,56.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.768 | Acc: 26.791,48.514,56.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.756 | Acc: 26.383,48.463,56.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 3.712 | Acc: 47.656,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.216 | Acc: 43.266,65.253,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.258 | Acc: 42.873,64.748,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 43.174,64.716,71.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.271 | Acc: 42.882,64.583,71.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.276 | Acc: 42.744,64.325,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.284 | Acc: 42.607,64.411,71.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.306 | Acc: 42.348,64.423,71.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.317 | Acc: 42.183,64.329,71.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.345 | Acc: 42.157,63.955,71.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.366 | Acc: 42.051,63.860,70.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.362 | Acc: 42.078,63.964,70.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.370 | Acc: 42.025,63.959,70.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.379 | Acc: 41.969,63.802,70.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.394 | Acc: 41.951,63.593,70.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.400 | Acc: 41.972,63.491,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.412 | Acc: 41.898,63.430,70.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.422 | Acc: 41.864,63.345,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.425 | Acc: 41.848,63.348,70.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.427 | Acc: 41.923,63.335,70.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.997 | Acc: 33.594,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.705 | Acc: 26.302,46.652,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.772 | Acc: 27.020,46.684,54.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.771 | Acc: 26.985,46.811,53.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.518 | Acc: 35.938,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.385 | Acc: 42.411,65.179,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.393 | Acc: 41.311,63.777,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.427 | Acc: 41.381,63.473,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.415 | Acc: 41.435,63.233,71.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.405 | Acc: 41.615,63.297,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.403 | Acc: 41.723,63.320,71.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.418 | Acc: 41.694,63.220,71.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.428 | Acc: 41.576,63.102,70.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.422 | Acc: 41.726,63.264,70.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.423 | Acc: 41.639,63.250,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.425 | Acc: 41.604,63.327,70.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.426 | Acc: 41.695,63.246,70.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.420 | Acc: 41.849,63.230,70.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.419 | Acc: 41.893,63.234,70.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.417 | Acc: 41.912,63.271,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.425 | Acc: 41.893,63.191,70.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.424 | Acc: 41.897,63.222,70.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.422 | Acc: 41.895,63.299,70.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.424 | Acc: 41.939,63.259,70.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.251 | Acc: 35.938,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.853 | Acc: 26.339,45.573,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.899 | Acc: 25.953,45.541,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.910 | Acc: 25.679,45.620,52.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.007 | Acc: 47.656,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.369 | Acc: 42.188,63.951,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.352 | Acc: 42.207,63.796,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.383 | Acc: 42.034,63.268,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.389 | Acc: 42.139,63.127,70.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.379 | Acc: 42.412,63.382,70.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.383 | Acc: 42.375,63.288,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.392 | Acc: 42.099,63.292,70.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.394 | Acc: 42.149,63.238,70.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.391 | Acc: 42.136,63.368,70.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.398 | Acc: 42.129,63.324,70.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.397 | Acc: 42.124,63.355,70.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.403 | Acc: 42.181,63.385,70.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.419 | Acc: 42.068,63.263,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.426 | Acc: 42.048,63.190,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.426 | Acc: 41.990,63.164,70.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.424 | Acc: 41.981,63.162,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.427 | Acc: 41.935,63.073,70.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.428 | Acc: 41.919,63.058,70.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.432 | Acc: 41.950,63.004,70.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.478 | Acc: 28.906,53.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.739 | Acc: 27.158,48.996,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.807 | Acc: 26.696,48.666,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.871 | Acc: 26.204,47.964,54.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.018 | Acc: 45.312,65.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.299 | Acc: 43.118,63.430,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.317 | Acc: 42.797,64.367,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.344 | Acc: 42.751,63.986,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.330 | Acc: 42.921,64.111,71.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.325 | Acc: 42.814,64.078,71.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.343 | Acc: 42.459,63.862,70.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.373 | Acc: 42.354,63.603,70.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.368 | Acc: 42.362,63.684,70.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.357 | Acc: 42.442,63.838,70.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.376 | Acc: 42.273,63.662,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.381 | Acc: 42.350,63.621,70.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.392 | Acc: 42.320,63.502,70.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.405 | Acc: 42.182,63.386,70.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.416 | Acc: 42.062,63.334,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.427 | Acc: 41.969,63.175,70.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.429 | Acc: 41.983,63.189,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.436 | Acc: 41.929,63.178,70.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.438 | Acc: 41.895,63.156,70.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.443 | Acc: 41.839,63.109,70.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.531 | Acc: 32.812,43.750,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.717 | Acc: 29.167,44.308,53.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.788 | Acc: 28.963,44.322,53.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.830 | Acc: 28.304,44.198,53.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 4.026 | Acc: 46.875,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 40.960,63.839,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.314 | Acc: 41.978,64.901,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.326 | Acc: 42.252,64.895,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.321 | Acc: 42.593,64.940,71.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.326 | Acc: 42.713,64.797,71.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.334 | Acc: 42.665,64.598,71.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.342 | Acc: 42.520,64.362,71.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.356 | Acc: 42.479,64.276,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.359 | Acc: 42.485,64.058,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.363 | Acc: 42.506,64.230,71.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.373 | Acc: 42.389,64.002,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.382 | Acc: 42.343,63.884,70.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.380 | Acc: 42.382,63.925,70.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.389 | Acc: 42.352,63.787,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.400 | Acc: 42.255,63.686,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.398 | Acc: 42.331,63.724,70.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.400 | Acc: 42.263,63.687,70.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.401 | Acc: 42.261,63.658,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.414 | Acc: 42.212,63.554,70.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.787 | Acc: 39.062,50.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.046 | Acc: 29.390,43.564,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.108 | Acc: 29.592,43.731,52.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.077 | Acc: 29.752,44.096,52.715,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.191 | Acc: 42.188,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.408 | Acc: 42.374,64.211,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.384 | Acc: 42.397,64.234,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.385 | Acc: 42.123,63.883,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.367 | Acc: 42.274,63.889,70.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.383 | Acc: 42.234,63.761,70.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.377 | Acc: 42.446,63.940,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.376 | Acc: 42.398,63.863,70.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.380 | Acc: 42.275,63.728,70.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.389 | Acc: 42.287,63.648,70.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.393 | Acc: 42.219,63.654,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.399 | Acc: 42.163,63.568,70.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.394 | Acc: 42.314,63.638,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.411 | Acc: 42.065,63.455,70.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.418 | Acc: 41.965,63.337,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.411 | Acc: 41.956,63.458,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.408 | Acc: 42.003,63.461,70.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.404 | Acc: 42.009,63.526,70.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.410 | Acc: 42.006,63.437,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.407 | Acc: 42.019,63.445,70.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.259 | Acc: 32.031,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.781 | Acc: 29.055,47.210,53.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.883 | Acc: 28.030,46.951,53.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.950 | Acc: 27.843,46.773,53.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.474 | Acc: 42.969,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 41.257,63.765,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.312 | Acc: 42.511,64.291,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.287 | Acc: 42.713,64.549,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.280 | Acc: 42.448,64.593,71.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.268 | Acc: 42.845,64.735,71.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.310 | Acc: 42.381,64.456,71.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 42.149,64.262,71.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.333 | Acc: 42.251,64.261,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.346 | Acc: 42.244,64.062,71.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.353 | Acc: 42.257,64.039,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.354 | Acc: 42.244,63.921,71.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.363 | Acc: 42.207,63.891,71.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.367 | Acc: 42.188,63.877,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.369 | Acc: 42.204,63.910,71.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.384 | Acc: 42.076,63.720,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.392 | Acc: 42.061,63.583,70.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.397 | Acc: 42.029,63.554,70.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.400 | Acc: 42.099,63.526,70.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.402 | Acc: 42.165,63.509,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.543 | Acc: 32.031,42.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.714 | Acc: 32.106,46.354,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.765 | Acc: 30.850,46.322,53.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.764 | Acc: 30.238,46.593,53.356,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.396 | Acc: 46.094,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.304 | Acc: 42.448,65.551,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.398 | Acc: 41.845,63.453,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 41.970,63.665,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.375 | Acc: 41.879,63.821,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.380 | Acc: 41.901,63.823,70.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.371 | Acc: 41.981,63.914,71.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.383 | Acc: 41.766,63.664,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.364 | Acc: 41.945,63.922,71.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.372 | Acc: 42.036,63.838,71.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.383 | Acc: 41.892,63.783,70.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.385 | Acc: 41.958,63.684,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.385 | Acc: 42.106,63.706,70.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.380 | Acc: 42.146,63.796,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.387 | Acc: 42.035,63.668,70.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.392 | Acc: 42.094,63.624,70.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.391 | Acc: 42.175,63.610,70.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.401 | Acc: 42.100,63.568,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.404 | Acc: 42.107,63.498,70.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.401 | Acc: 42.124,63.587,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.620 | Acc: 37.500,52.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.018 | Acc: 31.994,51.749,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.052 | Acc: 31.326,50.667,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.043 | Acc: 31.506,50.730,58.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.116 | Acc: 46.094,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.221 | Acc: 41.592,65.625,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.198 | Acc: 42.588,65.930,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 43.199,65.856,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.196 | Acc: 43.142,65.210,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.211 | Acc: 43.100,65.091,72.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.256 | Acc: 42.833,64.702,72.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.289 | Acc: 42.453,64.245,71.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.310 | Acc: 42.285,64.160,71.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.323 | Acc: 42.222,64.088,71.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.318 | Acc: 42.226,64.113,71.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.341 | Acc: 42.011,63.939,71.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.352 | Acc: 41.983,63.800,71.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.357 | Acc: 41.996,63.760,71.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 42.004,63.784,71.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.362 | Acc: 41.993,63.803,70.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.376 | Acc: 41.912,63.700,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.380 | Acc: 41.931,63.664,70.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.384 | Acc: 41.960,63.666,70.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.383 | Acc: 42.062,63.659,70.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.576 | Acc: 31.250,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.361 | Acc: 27.493,44.048,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.362 | Acc: 27.496,43.255,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.381 | Acc: 27.062,43.212,50.820,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 4.589 | Acc: 37.500,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 41.741,64.658,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 41.711,64.196,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 41.790,64.178,71.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.306 | Acc: 42.120,64.024,71.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.324 | Acc: 41.847,63.730,71.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.322 | Acc: 42.033,63.817,71.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.312 | Acc: 42.154,63.990,71.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.317 | Acc: 42.333,63.999,71.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.334 | Acc: 42.170,63.834,71.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.325 | Acc: 42.304,63.950,71.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.342 | Acc: 42.297,63.857,71.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.354 | Acc: 42.171,63.858,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.359 | Acc: 42.214,63.868,71.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.367 | Acc: 42.199,63.754,71.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.379 | Acc: 42.076,63.645,70.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.383 | Acc: 42.071,63.600,70.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.388 | Acc: 42.073,63.659,70.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.398 | Acc: 42.045,63.506,70.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.399 | Acc: 42.017,63.474,70.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.988 | Acc: 39.844,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.158 | Acc: 32.812,50.186,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.183 | Acc: 32.489,49.695,57.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.194 | Acc: 31.890,50.346,57.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 4.717 | Acc: 42.188,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.297 | Acc: 41.629,63.876,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.322 | Acc: 42.283,64.177,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 42.328,63.883,71.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.295 | Acc: 42.872,64.554,71.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.322 | Acc: 42.667,64.318,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.334 | Acc: 42.368,64.127,71.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 42.226,64.018,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.361 | Acc: 42.003,63.820,71.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.357 | Acc: 42.088,63.911,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.365 | Acc: 41.993,63.775,71.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.365 | Acc: 42.074,63.776,70.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.371 | Acc: 42.100,63.641,70.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.366 | Acc: 42.214,63.700,70.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.368 | Acc: 42.299,63.698,70.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.372 | Acc: 42.291,63.735,70.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.376 | Acc: 42.253,63.705,70.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.376 | Acc: 42.277,63.675,70.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.384 | Acc: 42.285,63.608,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.383 | Acc: 42.331,63.591,70.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.168 | Acc: 32.812,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.577 | Acc: 28.237,46.280,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.636 | Acc: 27.706,46.380,56.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.646 | Acc: 27.830,46.388,55.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 3.774 | Acc: 43.750,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 42.411,63.318,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.253 | Acc: 42.092,64.253,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.238 | Acc: 42.674,64.972,72.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.271 | Acc: 42.091,64.429,72.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.301 | Acc: 42.110,64.295,72.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.321 | Acc: 42.007,64.243,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.328 | Acc: 42.071,64.195,71.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.336 | Acc: 42.207,64.160,71.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.350 | Acc: 42.002,64.054,71.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.363 | Acc: 41.908,63.915,71.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.365 | Acc: 41.848,63.981,71.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.359 | Acc: 42.032,63.972,71.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.360 | Acc: 42.152,63.979,71.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.368 | Acc: 42.110,63.926,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.372 | Acc: 42.094,63.902,71.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.380 | Acc: 42.005,63.829,71.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.386 | Acc: 41.954,63.767,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.386 | Acc: 42.081,63.824,70.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.387 | Acc: 42.118,63.784,70.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.279 | Acc: 29.688,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.735 | Acc: 28.274,47.731,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.751 | Acc: 27.763,47.599,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.736 | Acc: 27.561,47.669,54.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.527 | Acc: 32.812,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.398 | Acc: 40.923,62.091,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.275 | Acc: 42.378,63.758,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.280 | Acc: 42.162,64.178,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.270 | Acc: 42.458,64.313,72.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.285 | Acc: 42.334,64.310,72.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.296 | Acc: 42.401,63.979,72.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.320 | Acc: 42.254,63.913,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.316 | Acc: 42.372,64.048,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.332 | Acc: 42.231,63.924,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.341 | Acc: 42.312,63.849,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.345 | Acc: 42.177,63.801,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.344 | Acc: 42.171,63.761,71.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.354 | Acc: 42.104,63.652,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.357 | Acc: 42.029,63.595,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.363 | Acc: 41.982,63.590,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.366 | Acc: 41.988,63.539,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.371 | Acc: 41.913,63.510,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.381 | Acc: 41.848,63.441,70.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.389 | Acc: 41.753,63.328,70.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.301 | Acc: 28.125,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.424 | Acc: 28.832,50.521,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.434 | Acc: 27.782,50.057,57.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.470 | Acc: 27.600,49.936,57.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.006 | Acc: 43.750,64.844,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 41.183,64.583,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.294 | Acc: 41.463,64.539,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.325 | Acc: 41.240,63.781,72.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.309 | Acc: 41.744,63.860,72.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.296 | Acc: 42.420,64.240,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.305 | Acc: 42.123,64.334,72.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.300 | Acc: 42.387,64.334,72.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.307 | Acc: 42.527,64.237,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.311 | Acc: 42.554,64.252,71.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.323 | Acc: 42.491,64.187,71.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.335 | Acc: 42.474,63.967,71.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.353 | Acc: 42.376,63.819,71.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 42.283,63.646,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.371 | Acc: 42.265,63.459,71.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.373 | Acc: 42.406,63.494,71.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.378 | Acc: 42.414,63.483,71.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.378 | Acc: 42.435,63.508,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.381 | Acc: 42.402,63.441,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.384 | Acc: 42.395,63.404,70.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.987 | Acc: 33.594,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.178 | Acc: 32.106,50.484,57.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.292 | Acc: 30.755,49.143,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.277 | Acc: 31.352,49.436,56.865,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.862 | Acc: 39.062,57.031,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.308 | Acc: 41.704,64.807,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.296 | Acc: 41.768,64.329,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 42.495,64.895,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.276 | Acc: 42.593,64.718,71.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.317 | Acc: 42.149,64.356,71.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.306 | Acc: 42.278,64.353,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.315 | Acc: 42.393,64.245,71.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.321 | Acc: 42.251,64.004,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.320 | Acc: 42.248,63.998,71.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.332 | Acc: 42.277,63.930,71.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.343 | Acc: 42.354,63.833,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.345 | Acc: 42.363,63.829,71.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.347 | Acc: 42.394,63.835,71.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.345 | Acc: 42.479,63.846,71.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.339 | Acc: 42.543,63.889,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.344 | Acc: 42.570,63.860,71.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.357 | Acc: 42.490,63.717,71.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.370 | Acc: 42.397,63.604,70.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.368 | Acc: 42.405,63.673,70.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.218 | Acc: 34.375,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.812 | Acc: 27.902,49.740,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.827 | Acc: 27.115,48.552,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.775 | Acc: 27.152,48.694,56.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 4.116 | Acc: 46.094,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.329 | Acc: 41.741,63.951,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.312 | Acc: 42.797,64.405,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 43.186,64.831,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.270 | Acc: 42.843,64.718,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.266 | Acc: 43.015,64.968,72.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.297 | Acc: 42.827,64.553,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.288 | Acc: 42.974,64.750,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 42.886,64.616,72.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.299 | Acc: 42.839,64.744,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.308 | Acc: 42.891,64.712,72.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.318 | Acc: 42.820,64.564,71.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.318 | Acc: 42.884,64.584,71.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.321 | Acc: 42.879,64.547,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 42.813,64.410,71.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.335 | Acc: 42.694,64.306,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.358 | Acc: 42.555,64.053,71.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.356 | Acc: 42.579,64.085,71.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.356 | Acc: 42.545,64.056,71.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.364 | Acc: 42.444,64.011,71.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.858 | Acc: 24.219,49.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.299 | Acc: 25.521,46.838,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.459 | Acc: 24.486,44.931,51.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.453 | Acc: 24.232,44.582,51.114,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 4.234 | Acc: 37.500,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.285 | Acc: 42.894,64.881,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.310 | Acc: 43.197,64.482,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.333 | Acc: 42.879,64.524,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.319 | Acc: 43.027,64.699,71.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.312 | Acc: 42.930,64.550,71.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 42.691,64.405,71.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.324 | Acc: 42.570,64.295,71.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.334 | Acc: 42.561,64.247,71.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.329 | Acc: 42.684,64.300,71.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.336 | Acc: 42.701,64.300,71.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.336 | Acc: 42.767,64.299,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.333 | Acc: 42.829,64.270,71.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.341 | Acc: 42.807,64.215,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.351 | Acc: 42.833,64.138,71.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.352 | Acc: 42.795,64.143,71.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.357 | Acc: 42.725,64.021,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.359 | Acc: 42.774,64.065,70.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.361 | Acc: 42.651,64.045,70.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.364 | Acc: 42.616,63.991,70.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.158 | Acc: 35.156,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.334 | Acc: 33.743,49.033,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.383 | Acc: 33.308,48.552,55.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.394 | Acc: 32.979,48.668,55.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.406 | Acc: 44.531,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 43.155,64.955,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.248 | Acc: 43.083,64.901,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.287 | Acc: 42.700,64.344,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.311 | Acc: 42.448,64.574,72.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.255 | Acc: 42.690,64.913,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.282 | Acc: 42.736,64.566,72.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.286 | Acc: 42.852,64.644,72.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.311 | Acc: 42.784,64.509,71.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.320 | Acc: 42.697,64.399,71.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.325 | Acc: 42.607,64.436,71.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.334 | Acc: 42.502,64.338,71.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.333 | Acc: 42.567,64.325,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.347 | Acc: 42.526,64.251,71.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.345 | Acc: 42.524,64.279,71.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.344 | Acc: 42.478,64.353,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.354 | Acc: 42.368,64.247,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.357 | Acc: 42.405,64.195,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.358 | Acc: 42.376,64.262,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.362 | Acc: 42.347,64.177,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.870 | Acc: 29.688,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.001 | Acc: 25.372,46.466,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.998 | Acc: 25.667,46.399,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.996 | Acc: 25.295,46.414,54.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.334 | Acc: 37.500,63.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 42.820,64.509,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.221 | Acc: 42.683,64.691,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.234 | Acc: 42.546,65.036,72.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.236 | Acc: 42.872,64.931,72.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.276 | Acc: 42.466,64.581,72.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.267 | Acc: 42.659,64.624,72.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.288 | Acc: 42.714,64.484,72.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.274 | Acc: 42.978,64.722,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.281 | Acc: 43.003,64.606,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.279 | Acc: 42.973,64.630,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.296 | Acc: 42.841,64.497,71.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.309 | Acc: 42.748,64.374,71.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.320 | Acc: 42.613,64.236,71.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.326 | Acc: 42.613,64.240,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.331 | Acc: 42.530,64.192,71.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.332 | Acc: 42.523,64.238,71.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.329 | Acc: 42.607,64.273,71.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.331 | Acc: 42.568,64.190,71.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.336 | Acc: 42.645,64.048,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.400 | Acc: 32.812,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.438 | Acc: 31.585,48.363,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.474 | Acc: 30.793,47.885,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.482 | Acc: 30.520,48.463,55.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.108 | Acc: 45.312,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.173 | Acc: 42.001,65.588,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.222 | Acc: 42.092,65.225,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.240 | Acc: 42.405,65.382,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.273 | Acc: 42.467,64.805,72.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.266 | Acc: 42.853,65.068,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.276 | Acc: 42.710,65.160,72.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.280 | Acc: 42.747,64.993,71.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.287 | Acc: 42.746,65.052,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.297 | Acc: 42.667,64.900,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.296 | Acc: 42.806,64.848,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.301 | Acc: 42.640,64.854,71.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.308 | Acc: 42.622,64.824,71.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.323 | Acc: 42.532,64.631,71.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 42.421,64.493,71.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.337 | Acc: 42.400,64.371,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.345 | Acc: 42.397,64.282,70.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.353 | Acc: 42.359,64.248,70.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.358 | Acc: 42.317,64.288,70.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.367 | Acc: 42.286,64.235,70.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.148 | Acc: 35.156,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.610 | Acc: 31.734,46.689,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.558 | Acc: 31.288,46.951,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.513 | Acc: 31.352,47.259,54.265,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.614 | Acc: 33.594,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 43.266,65.327,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.183 | Acc: 43.274,66.101,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.200 | Acc: 42.994,65.932,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.233 | Acc: 42.853,65.403,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.240 | Acc: 42.891,65.114,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.273 | Acc: 42.691,64.618,72.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.281 | Acc: 42.636,64.644,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.310 | Acc: 42.571,64.397,71.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.320 | Acc: 42.602,64.188,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.339 | Acc: 42.335,64.059,71.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.345 | Acc: 42.357,64.034,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.346 | Acc: 42.401,64.062,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.340 | Acc: 42.436,64.179,71.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.334 | Acc: 42.477,64.227,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.338 | Acc: 42.455,64.223,71.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.347 | Acc: 42.346,64.087,71.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.348 | Acc: 42.293,64.088,71.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.355 | Acc: 42.302,63.967,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.355 | Acc: 42.397,63.923,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.972 | Acc: 32.031,59.375,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.203 | Acc: 32.180,50.930,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.324 | Acc: 30.011,49.905,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.347 | Acc: 29.547,49.962,57.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 3.935 | Acc: 49.219,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.190 | Acc: 44.196,64.174,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.251 | Acc: 43.255,63.986,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 43.417,64.152,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.281 | Acc: 43.046,64.265,71.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.278 | Acc: 43.123,64.333,71.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.276 | Acc: 42.859,64.450,71.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.287 | Acc: 42.786,64.378,71.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.303 | Acc: 42.789,64.349,71.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.310 | Acc: 42.787,64.334,71.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.763,64.214,71.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.317 | Acc: 42.753,64.179,71.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.318 | Acc: 42.735,64.179,71.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.314 | Acc: 42.813,64.116,71.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.319 | Acc: 42.838,64.104,71.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.325 | Acc: 42.740,63.998,71.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.331 | Acc: 42.560,63.960,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.340 | Acc: 42.456,63.904,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.345 | Acc: 42.404,63.868,71.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.360 | Acc: 42.249,63.765,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.300 | Acc: 28.125,45.312,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.144 | Acc: 26.786,47.991,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.207 | Acc: 26.658,47.942,53.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.161 | Acc: 26.742,48.233,54.239,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.571 | Acc: 39.844,54.688,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.316 | Acc: 43.229,63.504,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 43.312,63.967,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 43.263,64.421,72.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.283 | Acc: 42.785,64.091,71.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.300 | Acc: 42.946,64.109,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.309 | Acc: 42.969,64.030,71.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.302 | Acc: 42.924,64.195,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 42.828,64.295,72.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.297 | Acc: 42.844,64.321,72.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.290 | Acc: 42.914,64.443,72.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.291 | Acc: 43.064,64.331,71.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.304 | Acc: 42.969,64.150,71.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.314 | Acc: 42.906,64.042,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.314 | Acc: 42.894,64.101,71.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.313 | Acc: 42.906,64.156,71.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.320 | Acc: 42.835,64.136,71.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.330 | Acc: 42.742,64.065,71.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.330 | Acc: 42.731,64.101,71.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.332 | Acc: 42.784,64.114,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.066 | Acc: 34.375,46.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.099 | Acc: 28.571,44.345,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.142 | Acc: 28.659,44.131,51.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.184 | Acc: 28.484,44.070,50.871,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.184 | Acc: 43.750,68.750,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.257 | Acc: 41.518,66.183,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.236 | Acc: 42.378,65.530,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.270 | Acc: 42.277,64.972,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.261 | Acc: 42.544,64.593,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.270 | Acc: 42.590,64.418,72.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 42.730,64.579,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.269 | Acc: 42.553,64.694,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.284 | Acc: 42.386,64.596,72.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.298 | Acc: 42.239,64.468,72.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.302 | Acc: 42.121,64.354,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.305 | Acc: 42.117,64.204,72.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.310 | Acc: 42.213,64.118,71.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.316 | Acc: 42.107,63.961,71.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.320 | Acc: 42.096,63.951,71.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.329 | Acc: 42.102,63.857,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.335 | Acc: 42.105,63.858,71.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.333 | Acc: 42.213,63.849,71.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.330 | Acc: 42.270,63.883,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.331 | Acc: 42.286,63.915,71.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.067 | Acc: 24.219,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.859 | Acc: 21.243,41.964,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.783 | Acc: 21.589,42.454,53.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.748 | Acc: 21.171,43.058,53.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.390 | Acc: 39.062,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 43.601,63.876,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.250 | Acc: 42.969,64.005,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.289 | Acc: 42.661,63.755,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.291 | Acc: 42.602,63.841,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.273 | Acc: 42.876,64.233,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.277 | Acc: 42.898,64.288,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.255 | Acc: 43.224,64.456,72.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.267 | Acc: 43.274,64.368,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.291 | Acc: 43.072,64.067,71.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.293 | Acc: 43.210,64.160,71.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.297 | Acc: 43.071,64.066,71.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.307 | Acc: 42.978,63.884,71.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.305 | Acc: 43.091,63.928,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.314 | Acc: 43.022,63.926,71.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.315 | Acc: 43.005,63.972,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.315 | Acc: 43.003,63.968,71.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.318 | Acc: 43.017,63.962,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.324 | Acc: 42.999,63.937,71.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.327 | Acc: 43.002,63.929,71.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.533 | Acc: 32.031,50.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.666 | Acc: 30.655,47.433,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.734 | Acc: 29.306,47.542,55.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.747 | Acc: 29.290,47.631,55.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.377 | Acc: 39.844,60.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 42.522,64.769,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.264 | Acc: 43.274,64.863,72.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.282 | Acc: 42.751,64.319,72.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.234 | Acc: 42.834,64.882,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.257 | Acc: 42.837,64.782,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.259 | Acc: 42.936,64.605,72.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.267 | Acc: 42.974,64.251,72.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.285 | Acc: 43.003,64.096,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.291 | Acc: 42.874,64.114,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.289 | Acc: 42.712,64.249,71.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.286 | Acc: 42.661,64.384,71.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.293 | Acc: 42.641,64.338,71.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.302 | Acc: 42.559,64.215,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.312 | Acc: 42.482,64.040,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.321 | Acc: 42.390,63.946,71.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.333 | Acc: 42.270,63.834,71.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.341 | Acc: 42.249,63.751,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.335 | Acc: 42.350,63.857,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.337 | Acc: 42.378,63.833,71.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.808 | Acc: 21.094,39.844,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.988 | Acc: 23.103,41.704,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.038 | Acc: 22.790,41.768,48.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.017 | Acc: 23.028,42.252,48.719,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.179 | Acc: 41.406,63.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.203 | Acc: 43.750,65.960,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 42.530,65.225,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.290 | Acc: 42.533,64.908,71.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.292 | Acc: 42.747,64.882,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.310 | Acc: 42.358,64.859,71.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.301 | Acc: 42.297,64.792,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.301 | Acc: 42.420,64.722,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.310 | Acc: 42.474,64.480,71.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.317 | Acc: 42.442,64.291,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.327 | Acc: 42.300,64.234,71.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.327 | Acc: 42.336,64.172,71.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.321 | Acc: 42.414,64.199,71.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.319 | Acc: 42.472,64.191,71.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.320 | Acc: 42.441,64.163,71.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.318 | Acc: 42.499,64.195,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.325 | Acc: 42.472,64.204,71.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.329 | Acc: 42.513,64.182,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 42.460,64.251,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.330 | Acc: 42.417,64.192,71.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.510 | Acc: 29.688,50.000,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.810 | Acc: 26.079,43.229,50.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.875 | Acc: 25.762,42.835,49.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.929 | Acc: 25.410,42.188,49.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.029 | Acc: 42.188,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.234 | Acc: 43.080,65.774,73.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.227 | Acc: 42.988,64.748,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.229 | Acc: 43.007,64.754,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.268 | Acc: 42.785,64.651,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.281 | Acc: 42.845,64.480,71.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.295 | Acc: 42.672,64.418,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.312 | Acc: 42.548,64.351,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.323 | Acc: 42.566,64.412,71.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.339 | Acc: 42.459,64.257,71.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.344 | Acc: 42.444,64.195,71.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.353 | Acc: 42.329,64.059,71.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.347 | Acc: 42.405,64.043,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.339 | Acc: 42.394,64.134,71.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.333 | Acc: 42.507,64.202,71.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.334 | Acc: 42.520,64.182,71.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.340 | Acc: 42.365,64.165,71.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.344 | Acc: 42.330,64.076,71.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.349 | Acc: 42.350,64.039,71.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.350 | Acc: 42.380,64.069,71.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.168 | Acc: 35.938,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.803 | Acc: 29.315,46.391,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.785 | Acc: 29.249,45.808,52.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.782 | Acc: 29.534,45.453,52.305,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 4.186 | Acc: 42.969,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.256 | Acc: 43.118,65.402,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.234 | Acc: 42.797,65.568,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.202 | Acc: 43.366,65.484,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.235 | Acc: 43.056,64.959,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 43.185,64.960,73.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.249 | Acc: 43.240,65.141,72.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.283 | Acc: 42.742,64.556,72.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 42.789,64.664,72.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.287 | Acc: 42.606,64.606,72.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.291 | Acc: 42.677,64.560,71.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.297 | Acc: 42.573,64.607,71.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.311 | Acc: 42.470,64.464,71.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.316 | Acc: 42.502,64.398,71.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.326 | Acc: 42.388,64.232,71.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.331 | Acc: 42.278,64.125,71.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.337 | Acc: 42.299,64.053,71.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.338 | Acc: 42.325,64.060,71.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.336 | Acc: 42.432,64.082,71.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.345 | Acc: 42.391,64.046,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.956 | Acc: 30.469,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.647 | Acc: 26.079,50.149,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.731 | Acc: 25.019,49.143,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.735 | Acc: 24.488,49.219,56.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 5.046 | Acc: 37.500,58.594,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.309 | Acc: 41.220,63.653,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.269 | Acc: 41.940,64.710,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.238 | Acc: 42.828,64.921,72.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.266 | Acc: 42.641,64.776,72.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.259 | Acc: 42.775,64.743,72.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.264 | Acc: 42.969,64.908,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.263 | Acc: 43.080,64.838,72.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.263 | Acc: 43.139,64.853,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.258 | Acc: 43.189,64.900,72.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.274 | Acc: 43.136,64.754,71.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.269 | Acc: 43.234,64.791,71.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.277 | Acc: 43.222,64.633,71.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.283 | Acc: 43.172,64.509,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.296 | Acc: 42.988,64.354,71.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.307 | Acc: 42.865,64.226,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.305 | Acc: 42.879,64.250,71.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.311 | Acc: 42.818,64.191,71.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.315 | Acc: 42.761,64.130,71.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.312 | Acc: 42.743,64.171,71.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.549 | Acc: 32.031,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.864 | Acc: 26.525,47.879,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.894 | Acc: 26.677,47.218,55.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.903 | Acc: 26.473,47.439,55.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 4.149 | Acc: 48.438,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.218 | Acc: 42.597,63.876,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.225 | Acc: 43.007,64.310,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 42.892,63.973,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.235 | Acc: 42.930,64.178,72.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.233 | Acc: 42.930,64.364,72.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 42.827,64.482,72.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.238 | Acc: 42.913,64.528,72.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.239 | Acc: 42.983,64.606,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.249 | Acc: 43.003,64.619,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.248 | Acc: 43.081,64.638,72.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.258 | Acc: 42.976,64.543,72.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.272 | Acc: 42.884,64.435,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.286 | Acc: 42.840,64.338,71.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.293 | Acc: 42.810,64.257,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.304 | Acc: 42.774,64.260,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.312 | Acc: 42.703,64.233,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.314 | Acc: 42.772,64.161,71.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.317 | Acc: 42.778,64.099,71.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.320 | Acc: 42.762,64.030,71.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.691 | Acc: 33.594,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.361 | Acc: 29.688,43.601,48.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.426 | Acc: 29.230,43.236,48.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.422 | Acc: 29.124,43.033,48.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 4.191 | Acc: 43.750,67.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 42.522,64.658,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.258 | Acc: 41.959,64.691,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.255 | Acc: 42.431,64.933,72.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.263 | Acc: 42.380,64.468,72.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.272 | Acc: 42.249,64.511,72.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.264 | Acc: 42.349,64.766,72.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.273 | Acc: 42.326,64.583,72.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.284 | Acc: 42.299,64.397,72.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.275 | Acc: 42.541,64.550,72.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.272 | Acc: 42.615,64.607,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.286 | Acc: 42.477,64.416,71.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.293 | Acc: 42.327,64.370,71.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.296 | Acc: 42.334,64.323,71.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.301 | Acc: 42.238,64.221,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.313 | Acc: 42.203,64.169,71.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.314 | Acc: 42.212,64.114,71.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.316 | Acc: 42.302,64.065,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.317 | Acc: 42.341,64.134,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.318 | Acc: 42.380,64.120,71.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.782 | Acc: 40.625,57.031,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.204 | Acc: 34.784,50.632,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.272 | Acc: 33.803,50.191,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.293 | Acc: 33.978,49.821,57.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 3.983 | Acc: 45.312,71.875,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.156 | Acc: 43.304,64.621,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.142 | Acc: 43.350,65.587,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 43.302,65.446,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.195 | Acc: 42.988,65.220,73.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.198 | Acc: 42.992,65.385,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.205 | Acc: 43.001,65.147,72.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.225 | Acc: 42.753,65.010,72.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.228 | Acc: 42.746,65.014,72.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.237 | Acc: 42.762,64.870,72.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.256 | Acc: 42.732,64.774,72.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.258 | Acc: 42.764,64.798,72.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.264 | Acc: 42.690,64.721,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.272 | Acc: 42.711,64.649,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.274 | Acc: 42.724,64.655,71.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 42.696,64.597,71.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.290 | Acc: 42.669,64.491,71.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.292 | Acc: 42.749,64.534,71.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 42.839,64.569,71.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.292 | Acc: 42.831,64.530,71.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.485 | Acc: 33.594,42.969,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.724 | Acc: 27.195,42.448,49.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.843 | Acc: 26.772,41.406,49.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.782 | Acc: 26.870,41.944,49.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 3.893 | Acc: 42.188,72.656,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.191 | Acc: 42.374,65.885,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.175 | Acc: 42.016,65.511,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.204 | Acc: 42.239,65.126,72.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.229 | Acc: 42.593,64.689,72.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.285 | Acc: 42.110,64.024,72.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.278 | Acc: 42.226,64.288,72.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.298 | Acc: 41.971,64.107,71.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.315 | Acc: 41.945,64.014,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.317 | Acc: 42.144,64.101,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.323 | Acc: 42.118,64.082,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.318 | Acc: 42.237,64.112,71.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.312 | Acc: 42.272,64.153,71.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.303 | Acc: 42.499,64.248,71.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.307 | Acc: 42.599,64.321,71.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.313 | Acc: 42.566,64.306,71.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.318 | Acc: 42.635,64.216,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.319 | Acc: 42.593,64.092,71.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.312 | Acc: 42.683,64.184,71.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.309 | Acc: 42.733,64.220,71.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.311 | Acc: 37.500,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.477 | Acc: 29.948,49.479,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.501 | Acc: 30.088,49.771,56.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.551 | Acc: 29.931,49.513,56.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.247 | Acc: 48.438,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.086 | Acc: 44.606,67.448,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.156 | Acc: 43.598,66.139,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 43.417,65.856,73.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.208 | Acc: 43.239,65.548,73.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.205 | Acc: 43.441,65.354,73.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.230 | Acc: 43.188,65.192,73.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.227 | Acc: 43.285,65.243,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.259 | Acc: 42.983,64.955,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.278 | Acc: 42.775,64.757,72.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.281 | Acc: 42.751,64.766,72.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.286 | Acc: 42.665,64.621,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.289 | Acc: 42.525,64.568,72.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.287 | Acc: 42.481,64.500,72.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.303 | Acc: 42.307,64.474,72.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.304 | Acc: 42.307,64.392,71.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.307 | Acc: 42.316,64.330,71.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.311 | Acc: 42.355,64.266,71.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.317 | Acc: 42.361,64.242,71.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.316 | Acc: 42.382,64.276,71.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.953 | Acc: 28.125,57.812,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.782 | Acc: 27.567,50.223,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.761 | Acc: 27.382,50.095,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.726 | Acc: 27.100,49.782,56.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 4.547 | Acc: 41.406,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.259 | Acc: 43.713,65.327,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 44.131,65.968,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.208 | Acc: 44.198,65.497,73.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.187 | Acc: 43.846,65.606,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.215 | Acc: 43.417,65.393,72.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.217 | Acc: 43.343,65.328,72.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.229 | Acc: 43.257,65.376,72.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.252 | Acc: 42.954,65.072,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.245 | Acc: 43.159,65.206,72.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.246 | Acc: 43.054,65.108,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.258 | Acc: 42.976,64.907,72.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.268 | Acc: 42.930,64.876,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.279 | Acc: 42.837,64.745,71.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.289 | Acc: 42.771,64.602,71.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.295 | Acc: 42.777,64.537,71.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.295 | Acc: 42.835,64.559,71.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.304 | Acc: 42.774,64.505,71.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.308 | Acc: 42.755,64.415,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.311 | Acc: 42.747,64.442,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.181 | Acc: 37.500,54.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.259 | Acc: 33.482,50.000,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.329 | Acc: 33.194,49.162,54.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.390 | Acc: 32.877,48.514,53.791,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 3.701 | Acc: 42.188,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.124 | Acc: 43.564,67.150,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.169 | Acc: 43.750,65.701,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.201 | Acc: 43.135,64.946,73.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.192 | Acc: 43.220,64.853,73.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.193 | Acc: 43.363,64.991,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.223 | Acc: 43.221,64.779,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.238 | Acc: 43.240,64.545,72.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.236 | Acc: 43.105,64.742,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.241 | Acc: 42.969,64.701,72.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.257 | Acc: 42.592,64.568,72.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 42.580,64.444,72.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.276 | Acc: 42.570,64.426,72.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.282 | Acc: 42.601,64.338,72.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.294 | Acc: 42.452,64.224,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.291 | Acc: 42.522,64.210,72.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.302 | Acc: 42.436,64.194,71.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.307 | Acc: 42.368,64.101,71.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.305 | Acc: 42.413,64.184,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.305 | Acc: 42.507,64.169,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.191 | Acc: 34.375,52.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.387 | Acc: 29.799,52.046,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.481 | Acc: 28.354,50.229,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.484 | Acc: 27.741,50.090,56.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 4.065 | Acc: 42.188,71.094,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.260 | Acc: 42.448,64.955,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.212 | Acc: 42.912,65.758,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.197 | Acc: 43.110,65.612,74.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.226 | Acc: 42.718,65.287,73.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.243 | Acc: 42.768,65.099,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.244 | Acc: 42.788,65.115,73.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.256 | Acc: 42.548,65.004,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.257 | Acc: 42.522,64.863,72.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.250 | Acc: 42.757,65.159,72.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.237 | Acc: 42.813,65.236,72.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.243 | Acc: 42.771,65.112,72.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.246 | Acc: 42.807,65.119,72.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.253 | Acc: 42.795,65.026,72.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.257 | Acc: 42.807,64.966,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.269 | Acc: 42.681,64.823,72.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.267 | Acc: 42.672,64.800,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.269 | Acc: 42.712,64.773,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.274 | Acc: 42.674,64.718,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.279 | Acc: 42.598,64.682,72.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.880 | Acc: 35.156,50.781,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.806 | Acc: 29.650,48.251,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.865 | Acc: 28.868,47.237,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.856 | Acc: 28.560,47.810,54.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 3.757 | Acc: 44.531,67.188,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.177 | Acc: 43.936,64.360,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.132 | Acc: 44.188,65.587,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.135 | Acc: 44.134,65.907,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.167 | Acc: 43.547,65.548,72.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.144 | Acc: 43.595,65.702,73.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.164 | Acc: 43.479,65.677,72.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.179 | Acc: 43.329,65.492,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.177 | Acc: 43.439,65.625,72.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.200 | Acc: 43.353,65.448,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.218 | Acc: 43.311,65.229,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.237 | Acc: 43.262,65.059,72.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.250 | Acc: 43.257,64.853,72.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.266 | Acc: 43.068,64.721,71.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.279 | Acc: 43.047,64.596,71.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.282 | Acc: 42.997,64.589,71.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.281 | Acc: 42.988,64.583,71.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 43.008,64.605,71.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.286 | Acc: 42.884,64.573,71.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.295 | Acc: 42.780,64.510,71.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.904 | Acc: 39.062,50.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.285 | Acc: 26.674,46.205,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.340 | Acc: 25.762,45.751,55.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.291 | Acc: 25.922,46.055,55.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.136 | Acc: 46.094,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.222 | Acc: 41.555,66.146,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.249 | Acc: 42.016,65.015,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.239 | Acc: 42.188,65.241,72.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.224 | Acc: 42.207,65.287,72.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.220 | Acc: 42.644,65.153,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.229 | Acc: 42.433,65.102,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.229 | Acc: 42.525,65.016,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.218 | Acc: 42.522,65.048,72.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.223 | Acc: 42.546,65.038,72.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.243 | Acc: 42.397,64.855,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.251 | Acc: 42.393,64.745,72.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.265 | Acc: 42.337,64.652,72.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.271 | Acc: 42.325,64.637,72.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.278 | Acc: 42.385,64.591,72.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.277 | Acc: 42.333,64.605,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.275 | Acc: 42.316,64.659,72.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.275 | Acc: 42.380,64.683,72.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.276 | Acc: 42.361,64.617,71.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.283 | Acc: 42.278,64.604,71.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.475 | Acc: 28.125,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.140 | Acc: 28.199,45.647,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.215 | Acc: 27.420,45.370,51.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.253 | Acc: 26.780,45.248,52.036,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.043 | Acc: 36.719,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.978 | Acc: 44.940,67.076,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.931 | Acc: 45.236,67.912,75.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.878 | Acc: 45.863,68.417,76.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.838 | Acc: 46.036,68.769,77.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.812 | Acc: 46.032,69.044,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.783 | Acc: 46.120,69.499,77.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.770 | Acc: 46.193,69.692,77.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.752 | Acc: 46.205,69.900,78.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.734 | Acc: 46.210,70.166,78.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.733 | Acc: 46.222,70.134,78.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.719 | Acc: 46.394,70.366,78.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.701 | Acc: 46.463,70.523,78.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.688 | Acc: 46.396,70.705,78.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.679 | Acc: 46.386,70.813,78.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.672 | Acc: 46.465,70.899,79.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.663 | Acc: 46.466,71.023,79.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.647 | Acc: 46.655,71.190,79.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.639 | Acc: 46.676,71.195,79.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.634 | Acc: 46.633,71.248,79.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.115 | Acc: 51.562,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 44.978,64.955,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.371 | Acc: 44.245,64.520,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.390 | Acc: 44.352,64.472,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.736 | Acc: 50.000,74.219,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.482 | Acc: 46.949,73.065,82.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.486 | Acc: 46.646,72.790,82.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.451 | Acc: 47.464,73.399,82.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.449 | Acc: 47.338,73.534,82.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.454 | Acc: 47.146,73.523,82.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.444 | Acc: 47.333,73.683,82.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.431 | Acc: 47.424,73.848,82.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.445 | Acc: 47.317,73.471,82.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.450 | Acc: 47.302,73.489,82.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.447 | Acc: 47.341,73.430,82.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.441 | Acc: 47.462,73.360,82.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.434 | Acc: 47.595,73.431,82.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.432 | Acc: 47.543,73.443,82.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.435 | Acc: 47.470,73.410,82.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.434 | Acc: 47.464,73.419,82.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.433 | Acc: 47.418,73.508,82.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.434 | Acc: 47.432,73.495,82.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.433 | Acc: 47.505,73.470,82.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.432 | Acc: 47.539,73.423,82.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.091 | Acc: 54.688,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.321 | Acc: 45.424,65.141,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.364 | Acc: 44.322,64.425,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.375 | Acc: 44.314,64.460,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.381 | Acc: 49.219,71.094,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.405 | Acc: 46.131,72.879,84.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.358 | Acc: 47.942,74.009,84.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.384 | Acc: 47.823,73.566,83.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.368 | Acc: 48.331,73.920,84.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.355 | Acc: 48.646,73.987,83.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.345 | Acc: 48.683,73.999,83.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.356 | Acc: 48.410,73.980,83.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.365 | Acc: 48.122,73.932,83.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.371 | Acc: 47.984,73.912,83.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.366 | Acc: 48.084,74.024,83.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.364 | Acc: 48.045,74.049,83.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.352 | Acc: 48.198,74.267,83.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.355 | Acc: 48.294,74.279,83.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.352 | Acc: 48.268,74.260,83.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.357 | Acc: 48.256,74.214,83.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.357 | Acc: 48.211,74.146,83.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.356 | Acc: 48.298,74.111,83.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.357 | Acc: 48.206,74.104,83.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.357 | Acc: 48.177,74.110,83.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 52.344,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.306 | Acc: 45.424,65.848,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.362 | Acc: 44.074,64.558,70.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.379 | Acc: 44.339,64.395,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.484 | Acc: 41.406,76.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.221 | Acc: 49.665,76.228,85.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.223 | Acc: 48.628,76.391,84.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.244 | Acc: 48.642,75.820,84.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.259 | Acc: 48.418,75.723,84.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.259 | Acc: 48.391,75.588,84.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.282 | Acc: 48.186,75.252,84.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.285 | Acc: 48.105,75.255,84.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.293 | Acc: 48.108,75.311,84.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.298 | Acc: 48.019,75.199,83.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.298 | Acc: 47.994,75.144,83.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.296 | Acc: 48.080,75.127,83.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.294 | Acc: 48.052,75.100,83.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.297 | Acc: 48.069,75.051,83.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.303 | Acc: 48.082,74.983,83.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.300 | Acc: 48.027,74.969,83.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.306 | Acc: 48.038,74.881,83.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.308 | Acc: 48.023,74.814,83.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.309 | Acc: 48.035,74.751,83.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.310 | Acc: 48.058,74.735,83.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.142 | Acc: 51.562,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 45.647,65.439,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.330 | Acc: 44.531,64.958,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 44.595,64.959,70.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.919 | Acc: 54.688,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.152 | Acc: 48.661,76.042,85.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.211 | Acc: 47.885,75.724,84.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.216 | Acc: 47.823,76.114,85.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.208 | Acc: 48.225,76.051,85.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.202 | Acc: 48.546,76.091,85.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.240 | Acc: 48.199,75.697,84.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.236 | Acc: 48.277,75.526,84.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.243 | Acc: 48.248,75.476,85.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.247 | Acc: 48.304,75.384,84.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.244 | Acc: 48.511,75.486,84.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.257 | Acc: 48.522,75.357,84.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.262 | Acc: 48.544,75.276,84.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.261 | Acc: 48.497,75.287,84.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.262 | Acc: 48.432,75.239,84.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.265 | Acc: 48.414,75.140,84.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.270 | Acc: 48.301,75.083,84.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.272 | Acc: 48.227,75.007,84.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.275 | Acc: 48.156,74.978,84.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.275 | Acc: 48.193,74.941,84.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.123 | Acc: 50.000,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.307 | Acc: 45.424,65.551,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.337 | Acc: 44.703,64.558,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.343 | Acc: 44.647,64.793,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 2.914 | Acc: 48.438,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.268 | Acc: 48.624,75.707,85.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.255 | Acc: 48.685,75.343,85.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.274 | Acc: 48.143,75.013,85.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.292 | Acc: 48.129,74.701,85.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.271 | Acc: 48.422,74.954,85.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.257 | Acc: 48.496,75.032,85.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.267 | Acc: 48.249,74.972,85.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.261 | Acc: 48.151,75.039,85.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.267 | Acc: 48.196,74.965,85.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.257 | Acc: 48.243,75.047,85.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.253 | Acc: 48.339,75.124,85.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.256 | Acc: 48.305,75.049,85.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.260 | Acc: 48.363,75.054,85.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.263 | Acc: 48.279,75.036,84.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.260 | Acc: 48.380,75.052,84.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.260 | Acc: 48.435,75.005,84.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.264 | Acc: 48.399,74.922,84.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.257 | Acc: 48.539,75.026,84.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.256 | Acc: 48.565,75.014,84.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.312 | Acc: 49.219,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.346 | Acc: 45.982,65.141,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 44.989,64.215,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.396 | Acc: 44.967,64.165,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.104 | Acc: 50.781,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.227 | Acc: 48.028,76.228,86.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.219 | Acc: 49.143,75.457,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.205 | Acc: 49.513,75.538,85.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.207 | Acc: 49.325,75.125,85.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.199 | Acc: 49.435,75.379,85.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.191 | Acc: 49.458,75.478,85.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.194 | Acc: 49.274,75.493,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.198 | Acc: 49.194,75.442,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.202 | Acc: 48.947,75.371,85.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.206 | Acc: 48.927,75.245,85.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.212 | Acc: 48.897,75.166,85.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.215 | Acc: 48.820,75.045,85.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.218 | Acc: 48.761,75.000,85.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.221 | Acc: 48.732,75.000,85.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.214 | Acc: 48.796,75.208,85.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.216 | Acc: 48.720,75.219,85.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.217 | Acc: 48.683,75.137,85.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.218 | Acc: 48.717,75.123,85.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.221 | Acc: 48.630,75.100,85.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.250 | Acc: 49.219,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 45.164,64.881,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.360 | Acc: 44.341,64.729,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.364 | Acc: 44.582,64.805,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.694 | Acc: 41.406,72.656,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.186 | Acc: 48.326,75.595,86.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.117 | Acc: 49.123,76.658,86.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.165 | Acc: 48.988,76.114,86.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.196 | Acc: 48.573,75.453,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.189 | Acc: 48.724,75.665,85.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.195 | Acc: 48.851,75.671,85.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.201 | Acc: 48.814,75.576,85.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.200 | Acc: 48.612,75.524,85.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.197 | Acc: 48.619,75.475,85.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.195 | Acc: 48.554,75.478,85.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.194 | Acc: 48.604,75.498,85.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.200 | Acc: 48.460,75.415,85.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.194 | Acc: 48.590,75.494,85.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.196 | Acc: 48.518,75.495,85.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.201 | Acc: 48.466,75.483,85.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.192 | Acc: 48.635,75.533,85.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.193 | Acc: 48.602,75.573,85.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.200 | Acc: 48.559,75.485,85.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.203 | Acc: 48.593,75.392,85.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.184 | Acc: 53.125,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.320 | Acc: 45.461,64.993,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.363 | Acc: 44.455,64.272,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.380 | Acc: 44.685,64.255,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.075 | Acc: 54.688,73.438,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.093 | Acc: 50.372,76.414,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.102 | Acc: 50.000,76.143,86.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.125 | Acc: 49.142,75.845,86.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.103 | Acc: 49.257,76.360,86.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.120 | Acc: 49.428,76.346,86.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.135 | Acc: 49.219,76.123,86.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.150 | Acc: 48.947,76.020,86.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.166 | Acc: 48.908,75.907,86.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.156 | Acc: 49.003,75.906,86.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.154 | Acc: 49.153,75.828,86.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.169 | Acc: 48.964,75.658,86.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.179 | Acc: 48.823,75.509,86.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.178 | Acc: 48.758,75.581,86.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.181 | Acc: 48.679,75.606,86.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.193 | Acc: 48.557,75.480,86.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.183 | Acc: 48.678,75.587,86.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.179 | Acc: 48.694,75.564,86.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.182 | Acc: 48.587,75.532,86.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.180 | Acc: 48.542,75.601,86.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 52.344,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.320 | Acc: 45.164,65.290,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.369 | Acc: 44.379,65.034,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 44.531,64.818,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 3.148 | Acc: 55.469,77.344,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.042 | Acc: 50.670,76.860,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.111 | Acc: 49.867,76.200,86.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.090 | Acc: 49.744,76.140,87.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.061 | Acc: 50.010,76.292,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.095 | Acc: 49.489,75.897,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.118 | Acc: 49.283,75.917,86.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.122 | Acc: 49.014,76.020,86.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.141 | Acc: 48.865,75.927,86.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.150 | Acc: 48.796,75.777,86.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.152 | Acc: 48.846,75.805,86.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.149 | Acc: 49.049,75.838,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.156 | Acc: 49.002,75.768,86.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.151 | Acc: 49.144,75.841,86.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.158 | Acc: 49.069,75.748,86.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.168 | Acc: 48.923,75.613,86.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.166 | Acc: 48.958,75.647,86.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.170 | Acc: 48.969,75.614,86.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.174 | Acc: 48.883,75.563,86.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.174 | Acc: 48.911,75.564,86.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.330 | Acc: 51.562,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 45.610,64.769,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.407 | Acc: 44.436,64.177,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.414 | Acc: 44.647,64.408,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.964 | Acc: 51.562,82.031,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.147 | Acc: 49.963,76.376,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.122 | Acc: 49.524,76.486,87.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 49.616,76.716,87.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.114 | Acc: 49.412,76.534,87.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.112 | Acc: 49.590,76.292,87.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.127 | Acc: 49.432,76.194,87.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.115 | Acc: 49.335,76.225,87.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.116 | Acc: 49.321,76.184,87.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.125 | Acc: 49.301,76.191,86.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.124 | Acc: 49.331,76.166,86.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.124 | Acc: 49.318,76.135,86.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.135 | Acc: 49.206,76.115,86.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.131 | Acc: 49.174,76.096,86.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.128 | Acc: 49.158,76.154,86.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.133 | Acc: 49.073,76.054,86.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.137 | Acc: 48.995,76.010,86.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.139 | Acc: 48.948,76.017,86.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.144 | Acc: 48.918,75.933,86.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.153 | Acc: 48.841,75.845,86.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.334 | Acc: 49.219,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.345 | Acc: 45.201,65.774,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.395 | Acc: 44.779,64.863,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.409 | Acc: 44.813,64.511,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 2.718 | Acc: 54.688,79.688,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.095 | Acc: 48.996,76.972,87.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.042 | Acc: 50.210,76.963,87.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.039 | Acc: 50.077,76.870,87.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.053 | Acc: 49.990,76.881,87.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.072 | Acc: 49.466,76.632,87.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.093 | Acc: 49.212,76.343,87.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.105 | Acc: 48.969,76.297,87.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.103 | Acc: 49.049,76.310,87.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.114 | Acc: 48.917,76.170,86.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.126 | Acc: 48.733,76.034,86.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.129 | Acc: 48.805,76.053,86.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.132 | Acc: 48.687,75.937,86.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.130 | Acc: 48.701,75.997,86.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.128 | Acc: 48.727,75.945,86.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.130 | Acc: 48.783,75.859,86.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.130 | Acc: 48.793,75.888,86.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.133 | Acc: 48.843,75.884,86.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.135 | Acc: 48.788,75.898,86.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.137 | Acc: 48.778,75.886,86.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.201 | Acc: 53.906,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.384 | Acc: 45.461,65.104,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.426 | Acc: 44.398,64.825,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.430 | Acc: 44.429,64.703,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 2.887 | Acc: 52.344,78.906,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.018 | Acc: 49.219,76.972,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.024 | Acc: 49.390,76.620,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.061 | Acc: 49.449,76.550,87.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.096 | Acc: 49.016,76.495,87.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.092 | Acc: 49.435,76.640,87.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.090 | Acc: 49.561,76.491,87.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.101 | Acc: 49.396,76.363,87.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.097 | Acc: 49.651,76.456,87.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.099 | Acc: 49.547,76.420,87.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.091 | Acc: 49.635,76.438,87.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.097 | Acc: 49.572,76.269,87.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.095 | Acc: 49.423,76.290,87.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.100 | Acc: 49.434,76.182,87.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.099 | Acc: 49.419,76.215,87.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.098 | Acc: 49.434,76.233,87.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.102 | Acc: 49.409,76.217,87.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.103 | Acc: 49.359,76.214,87.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.107 | Acc: 49.333,76.125,87.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.109 | Acc: 49.235,76.134,87.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 52.344,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.385 | Acc: 44.940,65.104,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.434 | Acc: 44.874,64.577,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.446 | Acc: 44.864,64.395,69.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.995 | Acc: 57.812,78.125,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.069 | Acc: 50.818,75.409,87.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.047 | Acc: 50.248,75.896,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.065 | Acc: 49.513,76.383,87.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.051 | Acc: 49.489,76.707,87.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.049 | Acc: 49.776,76.717,87.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.053 | Acc: 49.748,76.692,87.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.054 | Acc: 49.778,76.779,87.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.059 | Acc: 49.544,76.795,87.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.064 | Acc: 49.452,76.752,87.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.059 | Acc: 49.522,76.714,87.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.067 | Acc: 49.392,76.545,87.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.076 | Acc: 49.355,76.481,87.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.081 | Acc: 49.312,76.467,87.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.084 | Acc: 49.252,76.415,87.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.090 | Acc: 49.188,76.316,87.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.095 | Acc: 49.099,76.273,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.101 | Acc: 49.072,76.237,87.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.100 | Acc: 49.030,76.225,87.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.105 | Acc: 48.940,76.159,87.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.241 | Acc: 46.875,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.342 | Acc: 44.940,65.513,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.405 | Acc: 44.512,64.463,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.435 | Acc: 44.647,64.370,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.310 | Acc: 42.188,76.562,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.118 | Acc: 47.098,75.967,86.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.097 | Acc: 48.438,76.086,86.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 48.450,76.422,87.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.081 | Acc: 48.389,76.611,87.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.089 | Acc: 48.677,76.516,87.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.086 | Acc: 48.851,76.679,87.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.092 | Acc: 48.753,76.723,87.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.084 | Acc: 49.083,76.742,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.085 | Acc: 49.029,76.670,87.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.087 | Acc: 49.024,76.664,87.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.088 | Acc: 48.950,76.577,87.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.096 | Acc: 48.791,76.410,87.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.097 | Acc: 48.889,76.380,87.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.096 | Acc: 48.910,76.373,87.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.096 | Acc: 48.879,76.409,87.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.095 | Acc: 48.966,76.378,87.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.095 | Acc: 48.969,76.340,87.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.094 | Acc: 48.911,76.363,87.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.099 | Acc: 48.887,76.282,87.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 52.344,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.367 | Acc: 45.499,65.030,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.425 | Acc: 44.607,64.444,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 44.711,64.511,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.892 | Acc: 49.219,78.125,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.019 | Acc: 49.330,77.493,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.018 | Acc: 49.886,77.649,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.044 | Acc: 49.501,77.664,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.053 | Acc: 49.267,77.373,87.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.059 | Acc: 49.242,77.205,87.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.056 | Acc: 49.316,77.350,87.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.066 | Acc: 49.091,77.166,87.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.063 | Acc: 49.238,77.125,87.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.061 | Acc: 49.206,77.020,87.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.063 | Acc: 49.277,76.908,87.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.062 | Acc: 49.321,76.810,87.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.063 | Acc: 49.284,76.822,88.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.061 | Acc: 49.267,76.673,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.070 | Acc: 49.238,76.551,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.074 | Acc: 49.125,76.477,87.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.074 | Acc: 49.078,76.446,87.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.074 | Acc: 49.093,76.510,87.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.077 | Acc: 49.093,76.467,87.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.079 | Acc: 49.145,76.460,87.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.304 | Acc: 53.125,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.381 | Acc: 46.131,65.290,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.446 | Acc: 45.103,64.882,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.444 | Acc: 45.056,64.562,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 3.171 | Acc: 48.438,78.906,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.032 | Acc: 50.595,76.897,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.036 | Acc: 49.848,77.134,88.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.053 | Acc: 49.475,76.908,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 49.421,77.373,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.025 | Acc: 49.606,77.599,88.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.020 | Acc: 49.813,77.479,88.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.013 | Acc: 49.922,77.421,88.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.031 | Acc: 49.714,77.140,87.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.038 | Acc: 49.741,77.037,87.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.042 | Acc: 49.642,76.905,87.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.044 | Acc: 49.678,76.955,87.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.049 | Acc: 49.582,76.890,87.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.049 | Acc: 49.521,76.772,87.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.057 | Acc: 49.463,76.626,87.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.064 | Acc: 49.291,76.526,87.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.065 | Acc: 49.238,76.528,87.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.067 | Acc: 49.301,76.512,87.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.067 | Acc: 49.286,76.519,87.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.069 | Acc: 49.217,76.524,87.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.512 | Acc: 46.094,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.391 | Acc: 45.610,64.918,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.459 | Acc: 44.436,64.710,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.488 | Acc: 44.224,64.677,69.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 2.563 | Acc: 55.469,79.688,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.130 | Acc: 48.289,75.744,87.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.064 | Acc: 49.066,76.391,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.058 | Acc: 49.488,76.614,88.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.027 | Acc: 49.904,76.765,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.061 | Acc: 49.304,76.361,87.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.044 | Acc: 49.490,76.588,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.058 | Acc: 49.468,76.524,88.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.053 | Acc: 49.461,76.601,88.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.037 | Acc: 49.512,76.752,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.031 | Acc: 49.506,76.757,88.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.028 | Acc: 49.410,76.813,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.028 | Acc: 49.536,76.841,88.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.036 | Acc: 49.335,76.709,88.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.040 | Acc: 49.330,76.668,88.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.038 | Acc: 49.333,76.695,88.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.037 | Acc: 49.433,76.621,88.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.046 | Acc: 49.317,76.540,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.045 | Acc: 49.297,76.582,88.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.044 | Acc: 49.346,76.569,88.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.422 | Acc: 48.438,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.422 | Acc: 45.982,65.030,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.488 | Acc: 45.046,64.253,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.490 | Acc: 44.800,64.165,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.755 | Acc: 51.562,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.012 | Acc: 48.214,77.493,88.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.030 | Acc: 48.438,76.810,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.046 | Acc: 48.847,76.178,88.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.050 | Acc: 48.900,76.379,88.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.037 | Acc: 48.902,76.524,88.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.031 | Acc: 49.057,76.705,88.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.025 | Acc: 49.208,76.884,88.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.025 | Acc: 49.282,76.815,88.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.040 | Acc: 49.141,76.679,88.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.041 | Acc: 49.071,76.562,88.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.040 | Acc: 49.060,76.534,88.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.043 | Acc: 48.963,76.517,88.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.037 | Acc: 49.039,76.554,88.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.039 | Acc: 49.063,76.507,88.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.040 | Acc: 49.014,76.487,88.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.043 | Acc: 48.973,76.421,88.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.047 | Acc: 48.900,76.407,88.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.045 | Acc: 48.894,76.517,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.050 | Acc: 48.995,76.491,87.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.202 | Acc: 50.781,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.369 | Acc: 45.536,64.993,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 45.008,64.939,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.411 | Acc: 45.364,64.536,70.120,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 2.949 | Acc: 49.219,75.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.984 | Acc: 49.591,77.790,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 49.962,77.630,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.972 | Acc: 49.974,77.561,89.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.973 | Acc: 50.000,77.566,89.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.982 | Acc: 49.729,77.444,89.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.991 | Acc: 49.690,77.253,88.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.000 | Acc: 49.668,77.227,88.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 49.757,77.169,88.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.009 | Acc: 49.672,77.124,88.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.019 | Acc: 49.557,76.978,88.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.027 | Acc: 49.403,76.937,88.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.032 | Acc: 49.303,76.893,88.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.033 | Acc: 49.282,76.874,88.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.032 | Acc: 49.308,76.929,88.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.030 | Acc: 49.351,76.936,88.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.033 | Acc: 49.348,76.850,88.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.029 | Acc: 49.384,76.918,88.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.027 | Acc: 49.310,76.933,88.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.035 | Acc: 49.217,76.911,88.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.229 | Acc: 52.344,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.475 | Acc: 44.048,64.695,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.517 | Acc: 43.693,64.539,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.528 | Acc: 43.916,64.216,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.693 | Acc: 37.500,71.094,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.095 | Acc: 47.768,76.897,88.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.073 | Acc: 48.819,77.058,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.018 | Acc: 49.654,77.446,89.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.011 | Acc: 49.576,77.353,89.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.008 | Acc: 49.660,77.096,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.011 | Acc: 49.722,76.989,89.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.007 | Acc: 49.789,76.900,89.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.003 | Acc: 49.748,76.936,89.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.010 | Acc: 49.689,77.007,88.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.999 | Acc: 49.767,77.099,88.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.002 | Acc: 49.639,77.086,88.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.996 | Acc: 49.799,77.020,88.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.002 | Acc: 49.605,76.982,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.006 | Acc: 49.583,76.907,88.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.010 | Acc: 49.569,76.918,88.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.015 | Acc: 49.555,76.876,88.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.014 | Acc: 49.604,76.938,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.019 | Acc: 49.543,76.861,88.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.024 | Acc: 49.514,76.718,88.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.553 | Acc: 46.875,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 45.461,64.955,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 44.341,63.872,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 44.352,63.934,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.860 | Acc: 52.344,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.066 | Acc: 48.958,76.302,88.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.993 | Acc: 48.914,77.153,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.989 | Acc: 49.078,77.549,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.990 | Acc: 49.016,77.556,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.002 | Acc: 48.933,77.073,88.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.005 | Acc: 49.141,76.969,88.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.997 | Acc: 49.435,77.216,88.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.999 | Acc: 49.345,77.101,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.992 | Acc: 49.400,77.020,88.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.000 | Acc: 49.335,76.932,88.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.991 | Acc: 49.424,77.064,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.990 | Acc: 49.303,77.182,88.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.994 | Acc: 49.279,77.131,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.997 | Acc: 49.380,77.071,88.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.997 | Acc: 49.447,77.069,88.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.003 | Acc: 49.448,77.001,88.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.005 | Acc: 49.315,77.009,88.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.008 | Acc: 49.316,76.954,88.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.013 | Acc: 49.301,76.819,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.264 | Acc: 52.344,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.435 | Acc: 45.275,65.551,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.491 | Acc: 44.226,64.901,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.508 | Acc: 44.339,64.524,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 3.282 | Acc: 43.750,72.656,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 49.479,77.530,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 49.162,76.944,88.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.016 | Acc: 49.142,76.934,88.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.991 | Acc: 49.508,76.997,88.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.978 | Acc: 49.776,77.135,88.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.985 | Acc: 49.742,77.131,88.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.996 | Acc: 49.568,76.840,88.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.995 | Acc: 49.510,76.839,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.986 | Acc: 49.689,77.016,88.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.991 | Acc: 49.592,76.971,88.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.998 | Acc: 49.459,76.859,88.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.999 | Acc: 49.384,76.916,88.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.000 | Acc: 49.252,76.976,88.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.000 | Acc: 49.244,76.988,88.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.995 | Acc: 49.343,77.004,88.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.994 | Acc: 49.404,76.988,88.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.000 | Acc: 49.384,76.906,88.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.007 | Acc: 49.292,76.926,88.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.003 | Acc: 49.309,76.938,88.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.262 | Acc: 43.750,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.415 | Acc: 44.829,65.662,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.496 | Acc: 44.093,64.596,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.519 | Acc: 43.916,64.613,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.715 | Acc: 57.812,85.938,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.046 | Acc: 48.289,76.674,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.027 | Acc: 48.704,76.582,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.005 | Acc: 48.694,77.126,89.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.966 | Acc: 49.055,77.440,89.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.958 | Acc: 49.358,77.437,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.961 | Acc: 49.296,77.408,89.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.956 | Acc: 49.485,77.305,89.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.962 | Acc: 49.389,77.310,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.971 | Acc: 49.331,77.180,89.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.968 | Acc: 49.499,77.134,89.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.970 | Acc: 49.427,77.096,89.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.977 | Acc: 49.391,76.994,89.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.981 | Acc: 49.368,76.979,89.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.988 | Acc: 49.319,76.902,88.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.000 | Acc: 49.297,76.788,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.003 | Acc: 49.253,76.840,88.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.006 | Acc: 49.377,76.815,88.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.009 | Acc: 49.303,76.827,88.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.011 | Acc: 49.364,76.759,88.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.393 | Acc: 52.344,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 43.862,64.100,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.530 | Acc: 43.750,63.624,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 43.788,63.525,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 2.784 | Acc: 47.656,82.031,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.930 | Acc: 49.554,77.567,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.963 | Acc: 49.638,76.582,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 49.372,77.088,88.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.973 | Acc: 49.489,77.276,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.976 | Acc: 49.428,77.212,89.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.964 | Acc: 49.658,77.292,89.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.956 | Acc: 49.767,77.349,89.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.953 | Acc: 49.830,77.489,89.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.963 | Acc: 49.806,77.404,89.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.955 | Acc: 49.973,77.534,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.959 | Acc: 49.866,77.489,89.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.966 | Acc: 49.767,77.334,89.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.964 | Acc: 49.877,77.326,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.978 | Acc: 49.661,77.196,89.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.982 | Acc: 49.613,77.097,89.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.981 | Acc: 49.718,77.149,88.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.985 | Acc: 49.645,77.050,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.989 | Acc: 49.569,76.989,88.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.995 | Acc: 49.483,76.886,88.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.452 | Acc: 50.781,68.750,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.435 | Acc: 45.164,64.881,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.483 | Acc: 44.798,64.348,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.498 | Acc: 45.031,64.178,69.800,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 3.091 | Acc: 53.125,79.688,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.994 | Acc: 49.293,77.530,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 48.647,77.477,88.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.971 | Acc: 49.705,77.690,89.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.955 | Acc: 49.826,77.787,89.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.957 | Acc: 49.845,77.723,89.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.965 | Acc: 49.800,77.492,89.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.970 | Acc: 49.717,77.576,89.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.966 | Acc: 49.782,77.426,89.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.980 | Acc: 49.616,77.301,88.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.975 | Acc: 49.740,77.313,88.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.976 | Acc: 49.830,77.220,88.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.979 | Acc: 49.754,77.201,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.983 | Acc: 49.542,77.179,88.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.991 | Acc: 49.399,77.130,88.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.992 | Acc: 49.315,77.097,88.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.991 | Acc: 49.328,77.096,88.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.991 | Acc: 49.274,77.055,88.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.989 | Acc: 49.307,77.060,88.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.992 | Acc: 49.274,77.030,88.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.363 | Acc: 53.125,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 44.643,64.732,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 43.788,64.082,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 43.827,63.998,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.973 | Acc: 50.000,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.936 | Acc: 48.884,77.976,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.881 | Acc: 50.667,78.487,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.919 | Acc: 50.128,77.830,89.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.921 | Acc: 50.039,77.894,89.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.932 | Acc: 49.760,77.700,89.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.958 | Acc: 49.638,77.589,89.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.949 | Acc: 49.668,77.671,89.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.944 | Acc: 49.709,77.756,89.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.956 | Acc: 49.655,77.594,89.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.958 | Acc: 49.580,77.561,89.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.967 | Acc: 49.551,77.386,89.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.967 | Acc: 49.494,77.324,89.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.971 | Acc: 49.515,77.239,89.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.971 | Acc: 49.552,77.249,89.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.980 | Acc: 49.419,77.082,89.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.984 | Acc: 49.372,77.010,89.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.976 | Acc: 49.501,77.089,89.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.975 | Acc: 49.500,77.058,89.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.977 | Acc: 49.491,77.077,89.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.465 | Acc: 50.781,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 44.494,64.621,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.517 | Acc: 44.341,63.948,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 44.390,63.896,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.778 | Acc: 47.656,83.594,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 49.405,77.604,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 49.790,77.458,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.938 | Acc: 49.283,77.843,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.960 | Acc: 48.997,77.652,89.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.959 | Acc: 48.948,77.514,89.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.957 | Acc: 49.019,77.570,89.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.956 | Acc: 49.163,77.637,89.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.956 | Acc: 49.093,77.548,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.958 | Acc: 49.111,77.456,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.961 | Acc: 49.122,77.503,89.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.961 | Acc: 49.162,77.450,89.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.959 | Acc: 49.271,77.503,89.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.957 | Acc: 49.362,77.508,89.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.960 | Acc: 49.380,77.452,89.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 49.406,77.346,89.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.964 | Acc: 49.489,77.344,89.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.960 | Acc: 49.569,77.355,89.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.958 | Acc: 49.662,77.294,89.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.956 | Acc: 49.733,77.336,89.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.297 | Acc: 50.000,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.460 | Acc: 45.015,64.397,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 44.226,64.005,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 44.467,64.114,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 2.888 | Acc: 50.781,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.007 | Acc: 48.735,77.009,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.940 | Acc: 49.066,77.382,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.977 | Acc: 49.052,76.921,89.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.977 | Acc: 49.199,76.900,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.973 | Acc: 49.250,77.027,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.950 | Acc: 49.529,77.344,89.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.945 | Acc: 49.535,77.349,89.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.952 | Acc: 49.573,77.159,89.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.956 | Acc: 49.573,77.154,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.950 | Acc: 49.670,77.223,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.944 | Acc: 49.855,77.340,89.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.940 | Acc: 49.825,77.285,89.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 49.761,77.290,89.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.950 | Acc: 49.733,77.241,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.955 | Acc: 49.751,77.266,89.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 49.761,77.222,89.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.954 | Acc: 49.679,77.277,89.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.959 | Acc: 49.645,77.188,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.965 | Acc: 49.610,77.194,89.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.503 | Acc: 44.903,65.327,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 44.207,64.043,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 44.096,63.896,68.532,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 3.199 | Acc: 46.875,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 49.963,78.013,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.947 | Acc: 49.638,76.982,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 49.795,77.523,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.939 | Acc: 49.682,77.344,89.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.938 | Acc: 49.830,77.290,89.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.938 | Acc: 49.690,77.228,89.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.933 | Acc: 49.695,77.383,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.937 | Acc: 49.806,77.358,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 49.879,77.387,89.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.941 | Acc: 49.891,77.460,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.952 | Acc: 49.724,77.298,89.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.963 | Acc: 49.663,77.266,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.977 | Acc: 49.563,77.032,89.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.976 | Acc: 49.577,77.124,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.976 | Acc: 49.611,77.102,89.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.973 | Acc: 49.623,77.171,89.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 49.594,77.128,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 49.595,77.175,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.967 | Acc: 49.645,77.213,89.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 44.717,64.025,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 43.636,63.720,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 43.981,63.537,68.840,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 3.132 | Acc: 46.875,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.006 | Acc: 49.219,77.121,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.967 | Acc: 48.800,77.458,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.951 | Acc: 48.847,77.677,89.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.927 | Acc: 49.084,78.086,89.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.955 | Acc: 49.257,77.862,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.963 | Acc: 49.128,77.899,89.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.963 | Acc: 48.969,77.737,89.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.961 | Acc: 49.122,77.620,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.959 | Acc: 49.184,77.465,89.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.954 | Acc: 49.320,77.546,89.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.947 | Acc: 49.516,77.623,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.950 | Acc: 49.517,77.525,89.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.949 | Acc: 49.563,77.475,89.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.951 | Acc: 49.577,77.355,89.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.948 | Acc: 49.637,77.383,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.950 | Acc: 49.598,77.458,89.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.947 | Acc: 49.652,77.440,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.948 | Acc: 49.667,77.417,89.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.949 | Acc: 49.656,77.438,89.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 50.781,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 44.159,64.137,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 44.017,63.681,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 44.249,63.601,68.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.600 | Acc: 54.688,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.848 | Acc: 50.967,78.423,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.883 | Acc: 50.343,77.877,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.871 | Acc: 50.141,78.189,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.876 | Acc: 50.087,78.000,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 49.930,77.823,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.875 | Acc: 49.858,77.886,90.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.889 | Acc: 49.845,77.632,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.894 | Acc: 49.806,77.611,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.903 | Acc: 49.810,77.499,89.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.907 | Acc: 49.848,77.523,89.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.914 | Acc: 49.753,77.460,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.908 | Acc: 49.809,77.499,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.918 | Acc: 49.623,77.383,89.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.920 | Acc: 49.561,77.366,89.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.929 | Acc: 49.533,77.318,89.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 49.603,77.310,89.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.930 | Acc: 49.624,77.328,89.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.934 | Acc: 49.621,77.294,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.941 | Acc: 49.588,77.282,89.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.674 | Acc: 47.656,67.188,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 43.750,64.583,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.689 | Acc: 42.969,63.548,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 43.635,63.332,68.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.922 | Acc: 52.344,75.781,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.881 | Acc: 50.372,77.976,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 50.171,78.125,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.889 | Acc: 50.038,77.741,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.894 | Acc: 49.913,77.681,90.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.904 | Acc: 49.861,77.429,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.919 | Acc: 49.645,77.337,89.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.928 | Acc: 49.352,77.211,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.928 | Acc: 49.258,77.295,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.929 | Acc: 49.383,77.452,89.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.929 | Acc: 49.588,77.511,89.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.930 | Acc: 49.533,77.489,89.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.936 | Acc: 49.501,77.435,89.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.941 | Acc: 49.518,77.383,89.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.944 | Acc: 49.475,77.305,89.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.939 | Acc: 49.465,77.333,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.941 | Acc: 49.404,77.268,89.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.943 | Acc: 49.436,77.252,89.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.942 | Acc: 49.483,77.257,89.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.937 | Acc: 49.557,77.315,89.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.566 | Acc: 51.562,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.635 | Acc: 44.085,63.616,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.696 | Acc: 42.835,63.262,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 43.186,63.217,68.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 3.109 | Acc: 46.094,80.469,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 49.442,76.972,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.873 | Acc: 49.676,77.896,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.839 | Acc: 50.256,78.407,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 50.039,78.308,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.871 | Acc: 50.093,78.148,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.873 | Acc: 50.045,78.054,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.876 | Acc: 50.066,77.975,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.885 | Acc: 50.107,77.882,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.892 | Acc: 50.056,77.801,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.892 | Acc: 50.074,77.721,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.905 | Acc: 49.908,77.563,90.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.911 | Acc: 49.874,77.499,90.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.920 | Acc: 49.761,77.416,90.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.927 | Acc: 49.705,77.385,90.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.928 | Acc: 49.720,77.390,89.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.934 | Acc: 49.701,77.397,89.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.935 | Acc: 49.629,77.390,89.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.930 | Acc: 49.680,77.458,89.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.934 | Acc: 49.627,77.426,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 51.562,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 44.643,64.025,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 43.559,63.396,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 44.019,63.704,68.801,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.615 | Acc: 56.250,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.888 | Acc: 50.893,76.972,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.933 | Acc: 49.314,76.982,89.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.930 | Acc: 49.513,77.113,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.913 | Acc: 49.470,77.440,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.896 | Acc: 49.691,77.893,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.893 | Acc: 49.813,77.899,90.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.890 | Acc: 49.784,78.053,90.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.895 | Acc: 49.597,77.931,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.895 | Acc: 49.706,78.000,90.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.902 | Acc: 49.701,77.923,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.894 | Acc: 49.816,77.994,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 49.773,77.918,90.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.897 | Acc: 49.841,77.901,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.895 | Acc: 49.892,77.905,89.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.902 | Acc: 49.743,77.821,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.908 | Acc: 49.650,77.731,89.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.913 | Acc: 49.633,77.681,89.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.917 | Acc: 49.671,77.606,89.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.919 | Acc: 49.674,77.592,89.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.455 | Acc: 49.219,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 44.271,64.435,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 43.750,64.367,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 43.942,64.139,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.929 | Acc: 52.344,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.860 | Acc: 50.186,77.641,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.901 | Acc: 49.943,77.553,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 50.166,77.626,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.911 | Acc: 50.039,77.758,90.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.908 | Acc: 50.108,77.800,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.901 | Acc: 50.271,77.815,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.917 | Acc: 50.078,77.709,89.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.920 | Acc: 49.820,77.703,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.926 | Acc: 49.849,77.689,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.932 | Acc: 49.782,77.666,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.927 | Acc: 49.788,77.619,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.929 | Acc: 49.711,77.603,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 49.707,77.577,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.928 | Acc: 49.661,77.619,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.931 | Acc: 49.593,77.575,89.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 49.713,77.643,89.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.930 | Acc: 49.675,77.520,89.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.935 | Acc: 49.604,77.426,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.932 | Acc: 49.645,77.481,89.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 50.000,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 44.866,64.844,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 44.436,64.253,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 44.429,64.306,68.391,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.695 | Acc: 46.875,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.789 | Acc: 50.558,79.762,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 50.724,79.325,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.851 | Acc: 50.154,78.676,90.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.863 | Acc: 50.251,78.771,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.868 | Acc: 50.333,78.643,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 50.194,78.622,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.870 | Acc: 50.111,78.568,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.878 | Acc: 50.131,78.368,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.880 | Acc: 50.060,78.190,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.889 | Acc: 49.957,78.117,90.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.882 | Acc: 50.103,78.111,90.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.880 | Acc: 50.068,78.112,90.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.885 | Acc: 50.039,78.053,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.890 | Acc: 49.953,77.983,90.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.892 | Acc: 49.803,77.977,90.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 49.759,77.918,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.900 | Acc: 49.826,77.827,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.907 | Acc: 49.799,77.729,89.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.911 | Acc: 49.740,77.639,89.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.310 | Acc: 50.781,71.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.521 | Acc: 45.536,64.360,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 44.741,64.024,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 44.903,64.344,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.844 | Acc: 53.125,78.906,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 50.446,79.464,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.827 | Acc: 50.724,79.611,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.843 | Acc: 50.679,79.278,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.857 | Acc: 50.328,78.868,90.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.861 | Acc: 50.402,78.659,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.860 | Acc: 50.110,78.700,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 49.945,78.435,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 49.898,78.241,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 49.836,78.147,90.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.886 | Acc: 49.899,78.176,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.899 | Acc: 49.830,78.005,90.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.900 | Acc: 49.916,78.047,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.902 | Acc: 49.823,77.963,90.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.901 | Acc: 49.750,77.928,90.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.904 | Acc: 49.621,77.871,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.902 | Acc: 49.657,77.889,90.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.909 | Acc: 49.569,77.754,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.912 | Acc: 49.600,77.690,90.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.915 | Acc: 49.606,77.600,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.275 | Acc: 50.000,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.477 | Acc: 45.424,65.327,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 44.970,64.577,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 44.928,64.319,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.931 | Acc: 57.031,79.688,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.882 | Acc: 49.368,77.232,90.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 49.390,77.287,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.892 | Acc: 49.436,77.561,90.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.882 | Acc: 49.923,77.778,90.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.890 | Acc: 49.760,77.769,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.885 | Acc: 49.884,77.744,90.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.886 | Acc: 49.723,77.759,90.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.898 | Acc: 49.549,77.717,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.891 | Acc: 49.801,77.797,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.895 | Acc: 49.689,77.799,90.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.900 | Acc: 49.636,77.775,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.897 | Acc: 49.592,77.833,90.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.898 | Acc: 49.602,77.823,90.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.901 | Acc: 49.619,77.786,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.900 | Acc: 49.665,77.756,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.902 | Acc: 49.679,77.743,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.902 | Acc: 49.688,77.726,90.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.903 | Acc: 49.699,77.781,90.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.905 | Acc: 49.631,77.801,90.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.427 | Acc: 49.219,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 45.164,64.583,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 44.989,63.758,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.657 | Acc: 44.800,63.794,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.760 | Acc: 49.219,81.250,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.806 | Acc: 50.372,78.757,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.797 | Acc: 51.162,78.735,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.802 | Acc: 51.114,78.535,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 50.714,78.154,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.826 | Acc: 50.859,78.187,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.839 | Acc: 50.659,78.028,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 50.410,78.092,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.849 | Acc: 50.243,78.135,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.861 | Acc: 50.259,77.974,90.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.882 | Acc: 50.031,77.837,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.882 | Acc: 49.996,77.817,90.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.883 | Acc: 50.042,77.794,90.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.885 | Acc: 50.030,77.838,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.882 | Acc: 50.114,77.866,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.882 | Acc: 50.117,77.917,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 50.044,77.899,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 50.078,77.898,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.887 | Acc: 50.106,77.926,90.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.888 | Acc: 50.045,77.912,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 47.656,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 45.982,66.257,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 44.665,65.149,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 44.672,64.754,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.103 | Acc: 49.219,76.562,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.907 | Acc: 49.777,78.051,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.880 | Acc: 50.095,77.915,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 50.026,78.112,90.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.870 | Acc: 49.904,78.453,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 49.969,78.659,90.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 49.890,78.338,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.860 | Acc: 50.105,78.463,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.121,78.484,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.865 | Acc: 49.940,78.431,90.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.868 | Acc: 49.918,78.327,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.873 | Acc: 49.905,78.189,90.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 50.136,78.261,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.865 | Acc: 50.063,78.200,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.866 | Acc: 50.142,78.100,90.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.875 | Acc: 50.060,78.055,90.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 50.022,77.918,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 50.050,77.903,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.884 | Acc: 50.024,77.887,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.886 | Acc: 49.990,77.873,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.260 | Acc: 50.000,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 44.494,64.807,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.639 | Acc: 44.284,64.463,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 44.045,64.037,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.942 | Acc: 51.562,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 49.330,76.860,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.893 | Acc: 49.809,77.858,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.882 | Acc: 50.231,78.074,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 50.473,78.231,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.862 | Acc: 50.511,78.241,90.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 50.504,78.235,90.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.871 | Acc: 50.233,78.175,90.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 50.116,78.193,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.870 | Acc: 50.190,78.254,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.869 | Acc: 50.268,78.226,90.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.864 | Acc: 50.255,78.143,90.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 50.191,78.151,90.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 50.108,78.032,90.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.868 | Acc: 50.100,78.094,90.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 50.091,78.102,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.876 | Acc: 49.963,78.059,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.882 | Acc: 49.860,78.017,90.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.882 | Acc: 49.892,77.991,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.886 | Acc: 49.914,77.988,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.253 | Acc: 51.562,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 45.164,65.216,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 44.074,64.253,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.649 | Acc: 44.057,63.973,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 3.123 | Acc: 53.906,79.688,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.863 | Acc: 50.037,77.939,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 50.705,78.087,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.842 | Acc: 50.269,78.138,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.852 | Acc: 49.971,78.308,90.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.870 | Acc: 49.629,78.218,90.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.872 | Acc: 49.748,78.144,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.871 | Acc: 49.701,78.158,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 49.777,78.198,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 49.758,78.021,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.889 | Acc: 49.701,77.826,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 49.745,77.796,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.897 | Acc: 49.705,77.778,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.894 | Acc: 49.793,77.847,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.897 | Acc: 49.789,77.866,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 49.875,77.917,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.892 | Acc: 49.988,77.979,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.886 | Acc: 50.041,78.017,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.884 | Acc: 50.084,77.986,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.888 | Acc: 50.049,78.006,90.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.281 | Acc: 45.312,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.542 | Acc: 45.833,65.365,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 45.389,64.463,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 45.184,64.165,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 3.000 | Acc: 54.688,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.834 | Acc: 49.926,78.906,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.830 | Acc: 49.524,78.697,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.823 | Acc: 49.795,78.612,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 49.942,78.376,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 49.977,78.164,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.848 | Acc: 50.071,78.222,91.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 49.972,78.009,91.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.874 | Acc: 49.675,77.970,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 49.741,78.069,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 49.810,78.005,90.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.868 | Acc: 49.933,78.079,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 50.010,78.060,90.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 49.949,78.011,90.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.869 | Acc: 49.967,78.097,90.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.874 | Acc: 49.894,78.063,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.875 | Acc: 49.864,78.071,90.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.883 | Acc: 49.766,77.976,90.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.882 | Acc: 49.788,77.952,90.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.887 | Acc: 49.717,77.899,90.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.328 | Acc: 53.125,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 44.643,64.955,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.616 | Acc: 44.245,64.253,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 44.518,63.819,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.524 | Acc: 52.344,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.726 | Acc: 50.409,79.762,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.797 | Acc: 49.867,79.116,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.810 | Acc: 49.885,78.612,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 49.720,78.424,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.814 | Acc: 50.062,78.357,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.820 | Acc: 50.213,78.306,90.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 49.906,78.142,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 49.738,78.125,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.845 | Acc: 49.581,78.259,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 49.510,78.288,90.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.854 | Acc: 49.438,78.273,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 49.374,78.209,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.869 | Acc: 49.386,78.185,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.875 | Acc: 49.500,78.117,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.869 | Acc: 49.561,78.211,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 49.525,78.181,90.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.874 | Acc: 49.560,78.100,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.876 | Acc: 49.550,78.045,90.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.872 | Acc: 49.717,78.109,90.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 46.875,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 44.196,65.476,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 43.579,64.672,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.679 | Acc: 43.673,64.395,68.558,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 3.031 | Acc: 52.344,73.438,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.868 | Acc: 48.958,77.976,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 49.428,78.354,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.846 | Acc: 49.411,78.496,90.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.885 | Acc: 49.334,78.154,90.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.876 | Acc: 49.536,78.311,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 49.341,78.409,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.875 | Acc: 49.169,78.252,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.882 | Acc: 49.194,78.183,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.880 | Acc: 49.331,78.242,90.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.882 | Acc: 49.300,78.137,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.878 | Acc: 49.233,78.121,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.873 | Acc: 49.342,78.164,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.874 | Acc: 49.330,78.125,90.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 49.366,78.036,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.872 | Acc: 49.574,78.164,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.873 | Acc: 49.516,78.098,90.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.878 | Acc: 49.489,78.049,90.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.881 | Acc: 49.444,77.995,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.880 | Acc: 49.467,78.004,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.447 | Acc: 50.781,64.844,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.503 | Acc: 46.131,65.253,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.593 | Acc: 45.046,64.558,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 45.095,64.331,68.699,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.895 | Acc: 50.781,78.125,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.796 | Acc: 51.153,79.315,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.870 | Acc: 50.362,78.144,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.873 | Acc: 50.538,77.715,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.877 | Acc: 50.125,77.701,90.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.859 | Acc: 50.309,78.009,90.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.867 | Acc: 50.097,77.893,90.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.866 | Acc: 49.917,77.870,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.869 | Acc: 49.801,77.863,90.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.862 | Acc: 49.819,77.974,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.870 | Acc: 49.747,77.830,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.877 | Acc: 49.735,77.803,90.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.873 | Acc: 49.825,77.759,90.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 49.847,77.808,90.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.873 | Acc: 49.855,77.802,90.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 49.756,77.904,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.869 | Acc: 49.825,77.906,90.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.868 | Acc: 49.824,77.926,90.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.872 | Acc: 49.745,77.829,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.872 | Acc: 49.723,77.822,90.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 50.000,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 43.676,64.621,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.777 | Acc: 42.816,63.434,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.793 | Acc: 43.084,63.115,67.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.583 | Acc: 50.781,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.872 | Acc: 49.926,78.088,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.863 | Acc: 50.076,77.915,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.893 | Acc: 49.552,77.344,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.878 | Acc: 49.846,77.643,91.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.872 | Acc: 50.054,77.738,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 50.039,77.828,90.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.877 | Acc: 49.717,77.837,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.870 | Acc: 49.636,77.941,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 49.823,77.862,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.884 | Acc: 49.565,77.764,90.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.880 | Acc: 49.671,77.835,90.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.873 | Acc: 49.760,77.937,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.878 | Acc: 49.692,77.898,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.881 | Acc: 49.636,77.872,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.879 | Acc: 49.611,77.928,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.877 | Acc: 49.645,77.928,90.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.872 | Acc: 49.688,77.985,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.874 | Acc: 49.710,77.924,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.873 | Acc: 49.733,77.936,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.507 | Acc: 53.125,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 45.015,64.881,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.669 | Acc: 44.245,64.120,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 44.416,63.909,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.818 | Acc: 51.562,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 48.921,77.939,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.880 | Acc: 50.152,78.277,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 50.410,78.189,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.859 | Acc: 49.875,78.347,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.857 | Acc: 49.930,78.419,91.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.846 | Acc: 50.013,78.538,91.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.836 | Acc: 50.094,78.685,91.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.847 | Acc: 49.893,78.474,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 49.853,78.384,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.850 | Acc: 49.977,78.350,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.851 | Acc: 50.092,78.326,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.853 | Acc: 50.120,78.268,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.857 | Acc: 50.054,78.167,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.853 | Acc: 50.111,78.203,90.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.867 | Acc: 49.857,78.011,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.862 | Acc: 49.893,78.120,90.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.865 | Acc: 49.830,78.063,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.868 | Acc: 49.825,78.032,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 49.861,77.992,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 50.781,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 43.899,63.504,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 43.712,63.243,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 43.904,63.204,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.751 | Acc: 50.000,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.814 | Acc: 49.702,77.827,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.811 | Acc: 49.524,77.820,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.808 | Acc: 50.371,77.984,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.806 | Acc: 50.463,78.202,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.812 | Acc: 50.433,78.110,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.821 | Acc: 50.232,78.177,91.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.817 | Acc: 50.344,78.081,91.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.820 | Acc: 50.301,78.212,91.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.815 | Acc: 50.302,78.440,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.822 | Acc: 50.229,78.444,91.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.823 | Acc: 50.233,78.418,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 50.068,78.465,91.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.835 | Acc: 50.066,78.406,90.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.836 | Acc: 50.111,78.356,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 50.130,78.366,90.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 50.124,78.349,90.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.845 | Acc: 50.044,78.230,90.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 49.935,78.121,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.856 | Acc: 49.961,78.072,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.666 | Acc: 42.969,67.969,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.592 | Acc: 44.234,65.030,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.692 | Acc: 43.941,64.120,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.715 | Acc: 43.993,63.934,67.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.423 | Acc: 61.719,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 52.121,79.501,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.562,79.383,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 50.884,79.342,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 50.656,79.061,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.781 | Acc: 50.727,79.177,91.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.777 | Acc: 50.555,79.203,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 50.477,78.962,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.798 | Acc: 50.204,78.853,91.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 50.177,78.777,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 50.187,78.650,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.815 | Acc: 50.187,78.638,91.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.820 | Acc: 50.266,78.624,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.820 | Acc: 50.395,78.637,91.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 50.334,78.531,91.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 50.148,78.356,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 50.090,78.235,90.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.847 | Acc: 50.135,78.237,90.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 50.061,78.196,90.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.852 | Acc: 50.094,78.133,90.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.708 | Acc: 49.219,66.406,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.873 | Acc: 42.299,62.537,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.913 | Acc: 42.130,62.233,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.900 | Acc: 42.341,62.231,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 3.016 | Acc: 47.656,79.688,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.785 | Acc: 49.554,78.869,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.767 | Acc: 50.038,79.402,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 50.371,79.201,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 50.068,78.723,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.809 | Acc: 50.139,78.767,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.805 | Acc: 50.071,78.661,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 49.983,78.651,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.815 | Acc: 50.136,78.547,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.820 | Acc: 50.246,78.505,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.823 | Acc: 50.124,78.549,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.831 | Acc: 50.007,78.418,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.832 | Acc: 50.062,78.404,91.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.835 | Acc: 50.051,78.490,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.840 | Acc: 50.044,78.389,90.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 49.984,78.359,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.843 | Acc: 49.995,78.388,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 49.986,78.377,90.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.848 | Acc: 50.009,78.296,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 50.039,78.252,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 46.094,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.664 | Acc: 44.866,64.137,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.741 | Acc: 44.284,63.357,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.728 | Acc: 44.429,63.384,68.148,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.667 | Acc: 55.469,80.469,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.784 | Acc: 49.702,78.906,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.778 | Acc: 49.695,79.421,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.765 | Acc: 49.731,79.470,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 49.633,79.514,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 49.667,79.239,92.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 49.593,79.010,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.809 | Acc: 49.806,78.790,91.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 50.131,78.877,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.809 | Acc: 49.961,78.712,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.815 | Acc: 49.918,78.537,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.822 | Acc: 49.855,78.468,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 49.793,78.404,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 49.826,78.394,91.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 49.878,78.364,91.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.841 | Acc: 49.881,78.348,91.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.839 | Acc: 49.993,78.368,91.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 50.016,78.324,90.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.848 | Acc: 50.037,78.309,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.848 | Acc: 50.078,78.258,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.349 | Acc: 48.438,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.719 | Acc: 43.824,63.876,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.753 | Acc: 43.540,63.129,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.777 | Acc: 43.507,63.076,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.532 | Acc: 55.469,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 51.265,79.278,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 50.915,79.707,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.761 | Acc: 50.538,79.495,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.784 | Acc: 50.357,79.263,91.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 50.240,79.270,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.813 | Acc: 50.245,79.029,91.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 50.127,79.000,91.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.826 | Acc: 49.985,78.795,91.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 50.000,78.837,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.823 | Acc: 49.961,78.735,91.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.830 | Acc: 49.890,78.556,91.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 49.900,78.495,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.827 | Acc: 49.940,78.553,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 49.942,78.564,91.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 49.904,78.483,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.837 | Acc: 49.917,78.422,91.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.841 | Acc: 49.968,78.350,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.844 | Acc: 49.937,78.238,90.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 49.895,78.195,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.696 | Acc: 46.875,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.802 | Acc: 43.155,62.835,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.859 | Acc: 42.340,62.576,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.847 | Acc: 42.687,62.961,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.627 | Acc: 48.438,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.782 | Acc: 50.409,79.799,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 50.343,79.383,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.826 | Acc: 50.128,78.996,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 50.318,79.138,91.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.823 | Acc: 50.309,79.022,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.818 | Acc: 50.232,78.919,91.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.829 | Acc: 50.122,78.812,91.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.822 | Acc: 50.175,78.785,91.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.831 | Acc: 50.052,78.690,91.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.825 | Acc: 50.101,78.801,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.816 | Acc: 50.152,78.850,91.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 50.104,78.858,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.816 | Acc: 50.087,78.849,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 50.111,78.803,91.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 50.153,78.771,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.819 | Acc: 50.131,78.772,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 50.238,78.789,91.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 50.229,78.705,91.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 50.203,78.705,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 48.438,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.706 | Acc: 45.015,63.579,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.806 | Acc: 43.845,62.976,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.812 | Acc: 43.827,63.102,67.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.469 | Acc: 58.594,82.812,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 49.182,79.241,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 49.867,78.773,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.810 | Acc: 49.206,78.394,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 49.267,78.559,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 49.683,78.767,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.810 | Acc: 49.542,78.693,91.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.822 | Acc: 49.640,78.352,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.823 | Acc: 49.607,78.353,91.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.818 | Acc: 49.668,78.595,91.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.815 | Acc: 49.740,78.560,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 49.784,78.521,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.822 | Acc: 49.767,78.508,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.828 | Acc: 49.707,78.454,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.824 | Acc: 49.803,78.553,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.828 | Acc: 49.873,78.483,90.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.835 | Acc: 49.869,78.417,90.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.833 | Acc: 49.895,78.405,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 49.879,78.313,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.838 | Acc: 49.900,78.244,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.431 | Acc: 45.312,70.312,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.681 | Acc: 44.010,64.397,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.735 | Acc: 43.598,64.005,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.722 | Acc: 43.904,64.050,67.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.857 | Acc: 47.656,75.781,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.814 | Acc: 49.442,78.497,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 49.447,78.468,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 49.910,78.919,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.808 | Acc: 50.260,78.733,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 50.294,78.543,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 50.265,78.512,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 50.089,78.264,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.820 | Acc: 50.034,78.222,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.834 | Acc: 50.047,78.060,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.826 | Acc: 50.144,78.176,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.829 | Acc: 50.131,78.203,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 50.195,78.203,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.832 | Acc: 50.141,78.143,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 50.120,78.119,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 50.093,78.130,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 50.187,78.183,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 50.208,78.194,91.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.837 | Acc: 50.130,78.190,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.119,78.209,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.381 | Acc: 49.219,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.692 | Acc: 44.345,63.914,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.783 | Acc: 43.121,63.053,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.786 | Acc: 43.545,63.051,67.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.513 | Acc: 55.469,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 50.260,80.506,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.784 | Acc: 50.457,79.649,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.798 | Acc: 50.269,79.047,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 49.720,78.906,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.826 | Acc: 49.822,78.868,91.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 49.587,78.603,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.845 | Acc: 49.695,78.557,90.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.852 | Acc: 49.597,78.445,90.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.848 | Acc: 49.840,78.544,90.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 49.743,78.611,90.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.838 | Acc: 49.852,78.592,90.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.835 | Acc: 50.013,78.553,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 50.108,78.583,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.825 | Acc: 50.228,78.681,90.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 50.182,78.709,90.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.829 | Acc: 50.119,78.663,90.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.827 | Acc: 50.179,78.666,90.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 50.139,78.625,90.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 50.039,78.549,90.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 51.562,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 44.494,65.327,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 44.093,64.482,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 44.493,64.408,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.570 | Acc: 48.438,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 50.930,79.501,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 50.400,79.497,91.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 50.269,79.201,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 50.077,79.012,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.795 | Acc: 49.992,78.844,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 50.052,78.919,91.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 50.238,78.568,91.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.808 | Acc: 50.121,78.596,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.816 | Acc: 50.147,78.479,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 50.292,78.444,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.826 | Acc: 50.095,78.362,91.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.820 | Acc: 50.143,78.452,91.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.827 | Acc: 50.000,78.344,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.832 | Acc: 49.953,78.272,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.833 | Acc: 50.039,78.221,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.831 | Acc: 50.005,78.239,91.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 50.060,78.253,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 50.000,78.248,91.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 50.033,78.264,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.268 | Acc: 46.875,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 45.945,64.472,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.670 | Acc: 45.046,64.024,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.673 | Acc: 45.146,63.832,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.873 | Acc: 47.656,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.752 | Acc: 49.963,79.204,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 50.248,79.059,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 49.821,79.086,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.783 | Acc: 49.971,78.993,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 49.938,78.651,91.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.808 | Acc: 49.709,78.661,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.819 | Acc: 49.402,78.463,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.828 | Acc: 49.151,78.246,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.826 | Acc: 49.361,78.250,91.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.830 | Acc: 49.425,78.187,91.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.833 | Acc: 49.307,78.224,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.828 | Acc: 49.400,78.255,91.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.825 | Acc: 49.521,78.299,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 49.647,78.264,91.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 49.681,78.301,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.827 | Acc: 49.718,78.290,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.824 | Acc: 49.814,78.311,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.829 | Acc: 49.885,78.272,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 49.885,78.197,90.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.573 | Acc: 49.219,68.750,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.630 | Acc: 44.382,64.844,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.696 | Acc: 44.093,63.720,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.691 | Acc: 44.570,63.614,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 2.262 | Acc: 66.406,85.938,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 50.781,79.315,91.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 50.514,79.306,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.751 | Acc: 50.961,79.700,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.788 | Acc: 50.367,79.147,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.797 | Acc: 50.240,78.999,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.798 | Acc: 50.181,78.984,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 50.161,78.951,91.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.803 | Acc: 50.039,78.838,91.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.806 | Acc: 50.017,78.742,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.805 | Acc: 49.957,78.677,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 49.929,78.599,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 49.932,78.559,91.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 49.943,78.514,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 50.072,78.587,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.810 | Acc: 50.091,78.566,91.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.819 | Acc: 50.017,78.434,91.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 50.053,78.446,91.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.819 | Acc: 50.067,78.510,91.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.816 | Acc: 50.137,78.562,91.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.511 | Acc: 50.000,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.717 | Acc: 43.452,64.137,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.764 | Acc: 42.816,62.843,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.753 | Acc: 43.097,62.833,67.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.906 | Acc: 53.125,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.737 | Acc: 51.711,79.241,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.781 | Acc: 50.972,78.659,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 51.473,79.137,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.794 | Acc: 50.743,78.578,91.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.785 | Acc: 50.797,78.705,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 50.936,78.880,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.790 | Acc: 50.920,78.851,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.793 | Acc: 50.791,78.775,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.796 | Acc: 50.729,78.695,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 50.591,78.521,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.816 | Acc: 50.502,78.532,91.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 50.499,78.533,91.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 50.380,78.505,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 50.395,78.467,91.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 50.231,78.356,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 50.316,78.312,90.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 50.408,78.356,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 50.320,78.294,91.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.820 | Acc: 50.326,78.297,91.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.564 | Acc: 48.438,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.679 | Acc: 44.234,64.360,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.754 | Acc: 43.312,63.548,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.753 | Acc: 43.379,63.499,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.817 | Acc: 51.562,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.746 | Acc: 50.335,80.097,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 50.553,78.849,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 50.576,79.214,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.750 | Acc: 50.617,79.427,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.750 | Acc: 50.588,79.649,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.748 | Acc: 50.600,79.675,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 50.482,79.505,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.785 | Acc: 49.985,79.110,91.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.795 | Acc: 49.983,78.902,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.797 | Acc: 50.012,78.856,91.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 49.901,78.843,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.801 | Acc: 49.922,78.935,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.798 | Acc: 49.958,78.951,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.806 | Acc: 49.950,78.920,91.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.807 | Acc: 50.070,78.888,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.806 | Acc: 50.168,78.821,91.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.808 | Acc: 50.142,78.789,91.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.056,78.718,91.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 49.955,78.615,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.631 | Acc: 50.781,65.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.797 | Acc: 43.676,63.542,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.853 | Acc: 42.664,62.862,67.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.853 | Acc: 43.020,62.782,67.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.936 | Acc: 48.438,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 52.641,80.171,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.755 | Acc: 51.448,79.383,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.758 | Acc: 51.370,79.303,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 51.128,79.022,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.770 | Acc: 50.851,79.115,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 50.626,78.945,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.785 | Acc: 50.765,78.873,91.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 50.616,78.804,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.792 | Acc: 50.712,78.798,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.800 | Acc: 50.591,78.673,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.800 | Acc: 50.516,78.737,91.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 50.541,78.777,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.791 | Acc: 50.593,78.760,91.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.795 | Acc: 50.500,78.781,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.800 | Acc: 50.413,78.735,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 50.294,78.719,91.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 50.314,78.714,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.807 | Acc: 50.288,78.618,91.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 50.209,78.517,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 50.000,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.722 | Acc: 43.936,63.839,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.774 | Acc: 43.731,63.338,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.774 | Acc: 43.801,63.179,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.294 | Acc: 55.469,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 50.558,78.311,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.808 | Acc: 50.419,78.277,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.785 | Acc: 50.807,78.586,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 50.656,78.607,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 50.627,78.605,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.781 | Acc: 50.581,78.835,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 50.471,78.707,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 50.277,78.547,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.807 | Acc: 50.250,78.561,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.804 | Acc: 50.350,78.533,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.808 | Acc: 50.240,78.401,91.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.813 | Acc: 50.224,78.423,91.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.353,78.415,91.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.814 | Acc: 50.414,78.461,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.815 | Acc: 50.376,78.494,91.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.389,78.424,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.819 | Acc: 50.408,78.432,91.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.819 | Acc: 50.342,78.417,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.821 | Acc: 50.254,78.381,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.706 | Acc: 48.438,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.706 | Acc: 44.531,64.509,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 44.017,63.643,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.795 | Acc: 44.109,63.563,67.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.803 | Acc: 53.125,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.838 | Acc: 49.182,78.609,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.815 | Acc: 49.162,79.116,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.799 | Acc: 49.667,79.252,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.797 | Acc: 50.106,79.167,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.805 | Acc: 50.085,78.829,91.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.803 | Acc: 50.200,78.771,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 50.150,78.701,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.801 | Acc: 50.218,78.688,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.804 | Acc: 50.242,78.690,91.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.295,78.716,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.802 | Acc: 50.279,78.744,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.808 | Acc: 50.282,78.799,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.266,78.751,91.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.808 | Acc: 50.211,78.831,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 50.195,78.675,91.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 50.110,78.602,91.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.825 | Acc: 50.032,78.567,91.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 50.037,78.610,90.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.830 | Acc: 50.062,78.533,90.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.562 | Acc: 44.531,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 44.122,64.732,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.699 | Acc: 43.636,64.139,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.727 | Acc: 44.109,63.973,68.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.691 | Acc: 53.125,81.250,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 49.963,77.567,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.870 | Acc: 49.714,77.763,91.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.813 | Acc: 50.154,78.253,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.807 | Acc: 50.029,78.453,91.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 49.977,78.597,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 50.006,78.319,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.808 | Acc: 49.961,78.247,91.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 49.840,78.314,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 49.974,78.466,91.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 50.019,78.451,91.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 50.042,78.542,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 50.055,78.540,91.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.072,78.637,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.810 | Acc: 50.095,78.667,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.817 | Acc: 50.031,78.574,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 49.944,78.483,91.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.820 | Acc: 50.055,78.528,91.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.818 | Acc: 50.115,78.521,91.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 50.080,78.605,91.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 49.219,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.628 | Acc: 45.610,64.621,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.684 | Acc: 44.893,63.662,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 44.813,63.640,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.627 | Acc: 46.094,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 50.446,79.613,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.773 | Acc: 49.752,78.830,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.770 | Acc: 50.013,79.150,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.769 | Acc: 50.521,78.916,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.768 | Acc: 50.394,79.053,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 50.723,79.074,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 50.477,79.028,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.782 | Acc: 50.262,78.945,91.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.788 | Acc: 50.233,78.859,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 50.222,78.801,91.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.796 | Acc: 50.244,78.701,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.799 | Acc: 50.282,78.660,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 50.216,78.703,91.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.799 | Acc: 50.270,78.767,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.796 | Acc: 50.356,78.831,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.794 | Acc: 50.431,78.799,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.798 | Acc: 50.367,78.728,91.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 50.316,78.731,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.801 | Acc: 50.357,78.761,91.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.554 | Acc: 48.438,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.826 | Acc: 43.638,62.760,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.880 | Acc: 43.350,62.348,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.887 | Acc: 43.174,62.205,67.021,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 3.122 | Acc: 50.781,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.849 | Acc: 49.888,78.460,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.803 | Acc: 50.152,78.392,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 50.448,78.356,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.794 | Acc: 50.222,78.395,91.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.809 | Acc: 50.023,78.403,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.800 | Acc: 49.923,78.648,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 49.767,78.668,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.796 | Acc: 49.898,78.717,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 50.186,78.742,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.799 | Acc: 49.992,78.665,91.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.798 | Acc: 49.989,78.662,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.805 | Acc: 50.036,78.595,91.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 49.970,78.598,91.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.808 | Acc: 49.975,78.575,91.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.805 | Acc: 50.049,78.613,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.804 | Acc: 50.127,78.583,91.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 50.089,78.519,91.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 50.063,78.411,91.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 50.103,78.365,91.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 51.562,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.556 | Acc: 45.499,64.658,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 45.103,64.120,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 45.236,63.755,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 3.246 | Acc: 42.969,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 50.223,80.097,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.801 | Acc: 51.200,79.688,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.801 | Acc: 50.871,79.726,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.782 | Acc: 50.627,79.909,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.712,79.788,92.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.761 | Acc: 50.749,79.713,91.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.770 | Acc: 50.432,79.532,91.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 50.238,79.479,91.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 50.281,79.351,91.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.791 | Acc: 50.292,79.233,91.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.795 | Acc: 50.209,79.168,91.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.797 | Acc: 50.207,79.140,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.800 | Acc: 50.144,78.999,91.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.795 | Acc: 50.153,79.012,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.797 | Acc: 50.156,78.982,91.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 50.173,78.967,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.802 | Acc: 50.117,78.851,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 50.134,78.759,91.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.807 | Acc: 50.090,78.709,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.427 | Acc: 49.219,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.747 | Acc: 43.973,63.876,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 43.331,63.014,67.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.847 | Acc: 43.507,62.961,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.569 | Acc: 49.219,83.594,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 49.963,79.501,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 50.514,79.573,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.759 | Acc: 50.359,79.047,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 50.318,79.032,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.783 | Acc: 50.379,78.984,91.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.781 | Acc: 50.245,78.842,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.784 | Acc: 50.338,78.867,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 50.277,78.838,91.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.786 | Acc: 50.276,78.906,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 50.128,78.887,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.786 | Acc: 50.177,78.892,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.784 | Acc: 50.269,78.858,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.782 | Acc: 50.224,78.837,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.787 | Acc: 50.206,78.820,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.784 | Acc: 50.296,78.815,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.790 | Acc: 50.165,78.721,91.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 50.199,78.650,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.793 | Acc: 50.240,78.731,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 50.180,78.644,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 53.125,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.788 | Acc: 43.824,63.579,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.864 | Acc: 43.540,63.034,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.854 | Acc: 43.712,63.038,66.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.731 | Acc: 57.812,75.000,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.790 | Acc: 50.223,78.720,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.794 | Acc: 50.534,78.754,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.774 | Acc: 50.602,78.624,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 50.039,78.791,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.787 | Acc: 50.093,78.752,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 50.252,78.951,91.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.788 | Acc: 50.050,78.923,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.777 | Acc: 50.432,79.100,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 50.406,79.109,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 50.295,78.972,91.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 50.325,79.055,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.784 | Acc: 50.357,78.945,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 50.344,78.978,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.780 | Acc: 50.328,79.009,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.789 | Acc: 50.278,78.932,91.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.791 | Acc: 50.226,78.926,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 50.087,78.865,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.796 | Acc: 50.110,78.798,91.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.798 | Acc: 50.103,78.726,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.822 | Acc: 46.094,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.997 | Acc: 41.443,62.128,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.054 | Acc: 40.396,61.909,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.070 | Acc: 40.382,61.911,66.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.974 | Acc: 47.656,75.000,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.777 | Acc: 49.293,80.208,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.754 | Acc: 50.610,79.668,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 50.615,79.713,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.732 | Acc: 50.492,79.688,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 50.425,79.254,91.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.745 | Acc: 50.413,79.397,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.756 | Acc: 50.332,79.211,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.755 | Acc: 50.412,79.236,91.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.766 | Acc: 50.453,79.118,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.775 | Acc: 50.443,78.972,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 50.407,79.041,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.779 | Acc: 50.405,78.974,91.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.776 | Acc: 50.446,78.933,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.780 | Acc: 50.331,78.915,91.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.780 | Acc: 50.358,78.984,91.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.786 | Acc: 50.234,78.911,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.791 | Acc: 50.296,78.821,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.791 | Acc: 50.301,78.783,91.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.794 | Acc: 50.205,78.761,91.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.614 | Acc: 52.344,67.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.722 | Acc: 44.792,64.323,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.790 | Acc: 44.131,63.396,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.794 | Acc: 44.185,63.051,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.582 | Acc: 54.688,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.771 | Acc: 50.409,79.985,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.731 | Acc: 50.857,79.935,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 50.961,79.905,92.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.733 | Acc: 51.148,79.630,92.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.733 | Acc: 51.083,79.602,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.740 | Acc: 51.007,79.371,91.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.753 | Acc: 50.748,79.161,91.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.767 | Acc: 50.514,79.018,91.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 50.578,78.980,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.770 | Acc: 50.579,78.891,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 50.350,78.807,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.783 | Acc: 50.263,78.692,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.783 | Acc: 50.239,78.712,91.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.784 | Acc: 50.133,78.817,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.787 | Acc: 50.073,78.839,91.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 49.983,78.741,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 50.041,78.796,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.799 | Acc: 50.006,78.757,91.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.801 | Acc: 49.975,78.779,91.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.625 | Acc: 49.219,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.718 | Acc: 44.978,64.323,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.797 | Acc: 44.036,63.586,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.795 | Acc: 43.904,63.525,67.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.703 | Acc: 47.656,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 50.149,79.799,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.750 | Acc: 50.476,79.002,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 50.179,78.932,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.738 | Acc: 50.646,79.552,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.755 | Acc: 50.596,79.479,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.752 | Acc: 50.504,79.629,91.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.760 | Acc: 50.465,79.372,91.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.760 | Acc: 50.359,79.411,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.769 | Acc: 50.289,79.282,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.778 | Acc: 50.155,79.151,91.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.791 | Acc: 50.025,79.055,91.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.794 | Acc: 49.984,79.052,91.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.794 | Acc: 50.033,79.035,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.790 | Acc: 50.078,79.054,91.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.792 | Acc: 50.117,79.049,91.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 50.219,78.967,91.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 50.133,78.902,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.809 | Acc: 50.141,78.895,91.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.808 | Acc: 50.117,78.871,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.796 | Acc: 49.219,62.500,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.744 | Acc: 44.085,63.951,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.808 | Acc: 43.902,63.434,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.823 | Acc: 43.737,63.281,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.969 | Acc: 41.406,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 49.405,79.762,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.752 | Acc: 49.123,79.192,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.750 | Acc: 49.116,79.329,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.738 | Acc: 49.566,79.485,92.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.721 | Acc: 49.892,79.610,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.714 | Acc: 49.961,79.842,92.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.706 | Acc: 50.271,79.970,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.685 | Acc: 50.713,80.265,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.681 | Acc: 50.824,80.486,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.680 | Acc: 50.742,80.578,92.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.673 | Acc: 50.894,80.631,93.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.675 | Acc: 50.937,80.521,93.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.675 | Acc: 50.976,80.526,93.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.668 | Acc: 50.998,80.566,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.665 | Acc: 50.994,80.614,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.668 | Acc: 50.927,80.527,93.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.655 | Acc: 51.052,80.684,93.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.655 | Acc: 51.037,80.694,93.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.656 | Acc: 51.009,80.668,93.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 51.562,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.466 | Acc: 45.982,65.848,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.538 | Acc: 45.636,64.825,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 45.786,64.882,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.476 | Acc: 50.000,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.585 | Acc: 50.223,81.510,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.631 | Acc: 51.010,81.231,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.626 | Acc: 50.653,81.378,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.625 | Acc: 50.704,81.279,94.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.616 | Acc: 50.704,81.482,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.614 | Acc: 50.736,81.586,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.609 | Acc: 50.798,81.666,94.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.605 | Acc: 50.839,81.847,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.605 | Acc: 50.751,81.820,94.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.610 | Acc: 50.614,81.678,94.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.612 | Acc: 50.467,81.628,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.613 | Acc: 50.554,81.477,94.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.606 | Acc: 50.724,81.555,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.610 | Acc: 50.684,81.439,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.615 | Acc: 50.579,81.356,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.613 | Acc: 50.733,81.338,94.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.611 | Acc: 50.861,81.323,94.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.611 | Acc: 50.870,81.315,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.609 | Acc: 50.974,81.242,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.431 | Acc: 53.125,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.478 | Acc: 46.354,66.109,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 45.808,64.939,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 46.068,64.844,69.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.459 | Acc: 59.375,85.938,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.574 | Acc: 51.637,81.920,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.601 | Acc: 50.648,81.688,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.598 | Acc: 50.884,81.980,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.596 | Acc: 51.138,81.935,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.585 | Acc: 51.416,81.962,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.581 | Acc: 51.556,81.909,94.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.585 | Acc: 51.513,81.782,94.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.584 | Acc: 51.499,81.672,94.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.587 | Acc: 51.398,81.613,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.585 | Acc: 51.512,81.576,94.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.586 | Acc: 51.464,81.536,94.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.593 | Acc: 51.420,81.396,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.593 | Acc: 51.281,81.460,94.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.596 | Acc: 51.268,81.408,94.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.598 | Acc: 51.264,81.349,94.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.594 | Acc: 51.353,81.389,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.594 | Acc: 51.361,81.342,94.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.596 | Acc: 51.379,81.339,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.599 | Acc: 51.314,81.305,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 51.562,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.446 | Acc: 46.838,66.071,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 46.113,65.206,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.514 | Acc: 46.235,65.074,69.621,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.404 | Acc: 54.688,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.654 | Acc: 49.591,80.320,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.633 | Acc: 50.038,81.040,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.594 | Acc: 50.666,81.404,94.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.598 | Acc: 50.801,81.404,94.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.590 | Acc: 51.006,81.652,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.581 | Acc: 51.433,81.470,94.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.583 | Acc: 51.490,81.411,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.583 | Acc: 51.417,81.357,94.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.577 | Acc: 51.468,81.414,94.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.582 | Acc: 51.632,81.440,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.575 | Acc: 51.623,81.462,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.575 | Acc: 51.631,81.438,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.574 | Acc: 51.640,81.430,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.574 | Acc: 51.568,81.411,94.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.579 | Acc: 51.498,81.343,94.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.584 | Acc: 51.385,81.291,94.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.588 | Acc: 51.317,81.223,94.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.585 | Acc: 51.389,81.267,94.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.586 | Acc: 51.386,81.238,94.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.503 | Acc: 52.344,68.750,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.475 | Acc: 46.168,66.109,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 45.427,65.244,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 45.812,65.151,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.441 | Acc: 51.562,84.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.567 | Acc: 52.679,82.031,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.572 | Acc: 52.782,82.069,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.592 | Acc: 52.152,81.878,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.591 | Acc: 51.939,81.684,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.593 | Acc: 51.640,81.521,94.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.577 | Acc: 51.956,81.618,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.576 | Acc: 51.895,81.533,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.571 | Acc: 51.674,81.570,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.571 | Acc: 51.675,81.500,94.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.574 | Acc: 51.508,81.460,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.571 | Acc: 51.548,81.589,94.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.575 | Acc: 51.546,81.535,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.580 | Acc: 51.515,81.466,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.586 | Acc: 51.499,81.420,94.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.581 | Acc: 51.487,81.530,94.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.578 | Acc: 51.482,81.588,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.578 | Acc: 51.498,81.552,94.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.580 | Acc: 51.435,81.540,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.578 | Acc: 51.460,81.517,94.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.449 | Acc: 51.562,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 46.503,65.662,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 45.922,64.768,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 46.145,64.677,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.371 | Acc: 57.031,85.938,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.617 | Acc: 50.595,81.510,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 51.715,82.184,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.533 | Acc: 51.780,82.159,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 52.045,82.215,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.541 | Acc: 51.825,82.116,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.549 | Acc: 51.608,82.076,94.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.547 | Acc: 51.590,81.970,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.545 | Acc: 51.815,81.978,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.549 | Acc: 51.843,81.863,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.551 | Acc: 51.761,81.899,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.555 | Acc: 51.760,81.876,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 51.806,81.872,94.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 51.754,81.843,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.552 | Acc: 51.824,81.862,94.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.552 | Acc: 51.788,81.839,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.557 | Acc: 51.696,81.802,94.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.558 | Acc: 51.755,81.727,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.557 | Acc: 51.764,81.752,94.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.560 | Acc: 51.645,81.734,94.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 52.344,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 46.726,65.588,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.548 | Acc: 45.884,64.634,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 46.004,64.600,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.464 | Acc: 51.562,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.542 | Acc: 52.679,81.957,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.577 | Acc: 51.601,81.745,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.581 | Acc: 51.691,81.212,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.582 | Acc: 51.514,81.211,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.585 | Acc: 51.439,81.289,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.585 | Acc: 51.498,81.205,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.586 | Acc: 51.380,81.206,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.576 | Acc: 51.402,81.415,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.574 | Acc: 51.256,81.479,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.568 | Acc: 51.384,81.507,94.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.572 | Acc: 51.361,81.451,94.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.572 | Acc: 51.316,81.474,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.574 | Acc: 51.260,81.463,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.579 | Acc: 51.209,81.425,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.574 | Acc: 51.189,81.499,94.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.575 | Acc: 51.229,81.474,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.577 | Acc: 51.198,81.449,94.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 51.208,81.440,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.572 | Acc: 51.323,81.455,94.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 50.781,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 46.429,65.513,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 45.922,64.939,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 46.209,64.946,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.297 | Acc: 57.812,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.594 | Acc: 50.930,81.287,93.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.537 | Acc: 52.153,82.050,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.545 | Acc: 52.088,82.070,94.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.554 | Acc: 51.784,82.128,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.551 | Acc: 51.725,82.062,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.549 | Acc: 51.569,82.057,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.550 | Acc: 51.662,82.048,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.553 | Acc: 51.470,81.988,94.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.557 | Acc: 51.338,81.910,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.557 | Acc: 51.306,81.884,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.558 | Acc: 51.354,81.908,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.558 | Acc: 51.303,81.895,94.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.566 | Acc: 51.146,81.783,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.567 | Acc: 51.143,81.781,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.569 | Acc: 51.222,81.754,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.563 | Acc: 51.370,81.756,94.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.563 | Acc: 51.368,81.720,94.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.560 | Acc: 51.366,81.722,94.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.563 | Acc: 51.411,81.668,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.416 | Acc: 52.344,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 46.503,66.071,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.518 | Acc: 45.827,65.206,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.523 | Acc: 46.068,65.113,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.827 | Acc: 53.906,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.544 | Acc: 52.083,81.845,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.550 | Acc: 51.543,81.574,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.533 | Acc: 52.421,81.749,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.544 | Acc: 52.257,81.694,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 52.243,81.490,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.537 | Acc: 52.228,81.657,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.546 | Acc: 52.067,81.566,94.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 52.053,81.687,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.543 | Acc: 51.925,81.643,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.542 | Acc: 52.017,81.740,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 51.898,81.773,95.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.544 | Acc: 51.812,81.736,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.544 | Acc: 51.769,81.768,95.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 51.754,81.756,95.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.547 | Acc: 51.661,81.704,95.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.552 | Acc: 51.548,81.686,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.551 | Acc: 51.592,81.667,94.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.553 | Acc: 51.541,81.663,94.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 51.663,81.664,94.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 53.125,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.689,65.699,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 45.941,64.977,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 46.119,65.036,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.459 | Acc: 52.344,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.535 | Acc: 52.195,81.213,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.523 | Acc: 51.963,81.860,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 52.485,82.236,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 52.382,82.186,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 52.514,82.031,94.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 52.389,82.096,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.526 | Acc: 52.272,82.131,94.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.530 | Acc: 52.150,82.172,94.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.536 | Acc: 52.089,82.109,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 52.076,82.039,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.541 | Acc: 51.927,82.014,94.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.544 | Acc: 51.900,81.872,94.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.546 | Acc: 51.871,81.801,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.551 | Acc: 51.743,81.720,94.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.557 | Acc: 51.607,81.691,94.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.560 | Acc: 51.541,81.688,94.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.556 | Acc: 51.579,81.752,94.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.556 | Acc: 51.647,81.702,94.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.553 | Acc: 51.718,81.750,94.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.455 | Acc: 52.344,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 46.391,65.997,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.531 | Acc: 45.617,65.111,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 46.004,65.074,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.220 | Acc: 52.344,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.527 | Acc: 50.967,83.185,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.543 | Acc: 51.391,82.470,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.540 | Acc: 51.537,82.556,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.523 | Acc: 51.620,82.330,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 51.601,82.155,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.554 | Acc: 51.375,81.902,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.557 | Acc: 51.119,82.042,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.546 | Acc: 51.417,82.104,95.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.551 | Acc: 51.459,82.027,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.560 | Acc: 51.384,81.872,94.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.560 | Acc: 51.251,81.833,94.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.555 | Acc: 51.387,81.866,94.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.558 | Acc: 51.374,81.804,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.559 | Acc: 51.421,81.848,94.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.559 | Acc: 51.459,81.865,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.558 | Acc: 51.470,81.815,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 51.519,81.779,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.554 | Acc: 51.562,81.841,94.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.551 | Acc: 51.599,81.832,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 50.781,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.484 | Acc: 46.168,66.071,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 45.541,65.149,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 45.825,65.074,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.505 | Acc: 52.344,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.570 | Acc: 50.744,81.771,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.595 | Acc: 51.105,81.231,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.589 | Acc: 50.794,80.955,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.583 | Acc: 51.032,81.231,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.549 | Acc: 51.547,81.598,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 51.860,81.747,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.534 | Acc: 51.884,81.937,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.527 | Acc: 51.859,81.949,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.536 | Acc: 51.852,81.919,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 51.796,81.884,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.536 | Acc: 51.796,81.929,94.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 51.637,81.869,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.540 | Acc: 51.649,81.846,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.538 | Acc: 51.702,81.881,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.538 | Acc: 51.726,81.873,94.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.538 | Acc: 51.689,81.888,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.539 | Acc: 51.737,81.937,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.538 | Acc: 51.643,81.925,94.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.542 | Acc: 51.534,81.892,94.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 51.562,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 46.354,65.923,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.536 | Acc: 45.617,65.168,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 45.927,65.138,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.533 | Acc: 53.125,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 50.930,81.399,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 51.772,81.498,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 52.344,81.762,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.529 | Acc: 52.296,81.838,95.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 52.321,81.598,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 52.040,81.450,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.555 | Acc: 51.712,81.438,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.556 | Acc: 51.601,81.638,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.556 | Acc: 51.817,81.660,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.551 | Acc: 51.772,81.798,94.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.554 | Acc: 51.707,81.787,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.550 | Acc: 51.773,81.834,94.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 51.649,81.816,94.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.553 | Acc: 51.682,81.848,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.554 | Acc: 51.617,81.829,94.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.555 | Acc: 51.623,81.785,94.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.553 | Acc: 51.643,81.855,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.553 | Acc: 51.634,81.869,94.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 51.630,81.892,94.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.440 | Acc: 52.344,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.461 | Acc: 46.577,66.109,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.529 | Acc: 46.208,65.282,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 46.299,65.190,69.608,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.931 | Acc: 44.531,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.541 | Acc: 51.860,82.329,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.559 | Acc: 51.410,81.898,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.571 | Acc: 51.319,81.839,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.555 | Acc: 51.437,81.916,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 51.493,82.194,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.551 | Acc: 51.324,81.947,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 51.413,81.920,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 51.465,82.128,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.537 | Acc: 51.623,82.100,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.537 | Acc: 51.757,82.039,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 51.725,81.982,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.539 | Acc: 51.832,81.950,95.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.538 | Acc: 51.742,81.968,95.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 51.613,81.953,95.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.540 | Acc: 51.604,82.005,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.544 | Acc: 51.550,81.978,95.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.544 | Acc: 51.585,81.946,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.546 | Acc: 51.636,81.940,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.547 | Acc: 51.538,81.927,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.480 | Acc: 50.781,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 46.317,66.071,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.527 | Acc: 45.675,65.149,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 45.940,65.279,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.893 | Acc: 40.625,75.000,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 52.604,82.515,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 51.372,82.050,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 52.024,82.249,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.545 | Acc: 51.813,82.263,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.549 | Acc: 51.555,81.993,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.552 | Acc: 51.485,82.064,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 51.385,82.059,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.556 | Acc: 51.291,81.866,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 51.433,82.061,95.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.543 | Acc: 51.446,82.125,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.548 | Acc: 51.372,81.968,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.555 | Acc: 51.203,81.950,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.552 | Acc: 51.317,81.968,94.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.548 | Acc: 51.343,82.042,94.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.549 | Acc: 51.324,81.992,94.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.546 | Acc: 51.334,82.007,94.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.544 | Acc: 51.354,81.976,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.544 | Acc: 51.379,82.007,94.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.545 | Acc: 51.335,82.029,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 52.344,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.475 | Acc: 46.912,65.774,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 45.922,65.091,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 46.004,65.126,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.479 | Acc: 50.000,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 51.525,81.548,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.523 | Acc: 51.562,81.517,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 52.088,81.775,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.521 | Acc: 52.074,82.118,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 52.197,82.263,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.513 | Acc: 52.195,82.406,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.523 | Acc: 52.061,82.314,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.528 | Acc: 51.960,82.196,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 51.701,81.949,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.538 | Acc: 51.761,82.043,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 51.736,82.084,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.538 | Acc: 51.731,82.119,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.542 | Acc: 51.592,82.061,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.538 | Acc: 51.668,82.148,95.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.542 | Acc: 51.524,82.088,95.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.544 | Acc: 51.463,82.014,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 51.459,81.926,95.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 51.621,81.958,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.544 | Acc: 51.601,81.978,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.485 | Acc: 52.344,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 46.466,65.848,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 45.884,64.901,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.548 | Acc: 46.119,64.921,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.547 | Acc: 50.000,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 54.278,82.329,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 53.087,81.936,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.527 | Acc: 52.267,81.903,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.572,81.761,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.540 | Acc: 51.493,81.776,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.542 | Acc: 51.575,81.708,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.537 | Acc: 51.612,81.765,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.535 | Acc: 51.752,81.876,95.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.540 | Acc: 51.502,81.811,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.533 | Acc: 51.629,81.880,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 51.782,81.961,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.529 | Acc: 51.738,81.908,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.534 | Acc: 51.697,81.795,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.532 | Acc: 51.727,81.842,95.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.534 | Acc: 51.703,81.844,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 51.584,81.817,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 51.661,81.832,95.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.537 | Acc: 51.567,81.856,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 51.608,81.900,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 50.000,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.540,65.216,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 45.922,64.825,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 46.094,64.780,69.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.614 | Acc: 55.469,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.547 | Acc: 51.711,82.217,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.589 | Acc: 50.362,81.421,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.573 | Acc: 50.717,81.788,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.553 | Acc: 51.071,81.809,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.543 | Acc: 51.454,81.791,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.543 | Acc: 51.433,81.734,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.542 | Acc: 51.496,81.654,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.550 | Acc: 51.276,81.692,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.557 | Acc: 51.226,81.677,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.562 | Acc: 51.158,81.584,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.559 | Acc: 51.152,81.639,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.560 | Acc: 51.196,81.626,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 51.221,81.699,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.548 | Acc: 51.304,81.739,95.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.543 | Acc: 51.293,81.785,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.543 | Acc: 51.353,81.846,95.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 51.391,81.885,95.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 51.296,81.880,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.542 | Acc: 51.376,81.871,95.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 52.344,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 46.838,65.216,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.922,64.939,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.549 | Acc: 46.158,64.895,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.737 | Acc: 48.438,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.482 | Acc: 52.307,83.482,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.511 | Acc: 52.801,83.041,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 52.497,82.390,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 51.948,82.475,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.833,82.217,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 51.782,82.225,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 51.795,82.242,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 51.791,82.303,95.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.530 | Acc: 51.679,82.243,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.525 | Acc: 51.667,82.412,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 51.743,82.378,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.531 | Acc: 51.747,82.291,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 51.772,82.229,95.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.532 | Acc: 51.735,82.248,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 51.700,82.260,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 51.745,82.226,95.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.534 | Acc: 51.782,82.155,95.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 51.759,82.109,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.537 | Acc: 51.759,82.070,95.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 52.344,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.503,65.216,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 45.846,64.729,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 46.132,64.946,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.439 | Acc: 51.562,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 50.818,82.106,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.473 | Acc: 51.239,82.412,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 51.627,82.505,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 51.591,82.321,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.514 | Acc: 51.733,82.047,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.510 | Acc: 51.621,82.206,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 51.695,82.236,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.517 | Acc: 51.737,82.128,95.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 51.796,82.092,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 51.765,82.093,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.524 | Acc: 51.637,82.056,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.608,82.064,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 51.527,82.043,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 51.565,81.945,95.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.573,81.972,95.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.528 | Acc: 51.594,81.914,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.533 | Acc: 51.556,81.908,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.536 | Acc: 51.465,81.891,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.539 | Acc: 51.417,81.877,95.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 52.344,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.481 | Acc: 46.391,65.997,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.542 | Acc: 45.617,65.072,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 45.876,65.138,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.345 | Acc: 58.594,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.580 | Acc: 50.298,81.399,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 51.048,81.612,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.522 | Acc: 51.204,81.929,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.540 | Acc: 51.350,81.723,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.601,81.977,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.513 | Acc: 51.963,82.083,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 52.006,82.231,95.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.512 | Acc: 51.922,82.225,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.523 | Acc: 51.813,82.053,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 51.947,82.105,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.530 | Acc: 51.775,81.975,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 51.653,81.928,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 51.670,81.944,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 51.702,82.001,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 51.669,82.047,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 51.752,82.036,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 51.705,82.070,95.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 51.699,82.092,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 51.710,82.033,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 51.562,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 46.652,66.034,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.547 | Acc: 45.941,65.244,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 46.107,65.190,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.687 | Acc: 47.656,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.508 | Acc: 51.525,82.292,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 51.315,82.012,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 51.755,82.403,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.507 | Acc: 51.852,82.128,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.515 | Acc: 51.725,81.969,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 51.750,81.986,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 51.840,82.059,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 51.883,82.036,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 51.860,81.897,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 51.846,81.930,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.525 | Acc: 51.813,81.858,95.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.523 | Acc: 51.887,81.918,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 51.883,81.822,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.531 | Acc: 51.818,81.803,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.528 | Acc: 51.897,81.886,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.884,81.875,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.529 | Acc: 51.870,81.832,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 51.909,81.867,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 51.800,81.804,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.510 | Acc: 52.344,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.478 | Acc: 46.726,66.071,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.540 | Acc: 46.113,65.072,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.552 | Acc: 46.273,65.087,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.397 | Acc: 60.156,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 52.158,81.213,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.562 | Acc: 51.601,81.974,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.555 | Acc: 51.460,82.031,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.531 | Acc: 51.640,82.282,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 51.856,82.449,95.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.544 | Acc: 51.685,82.102,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 51.734,82.053,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.533 | Acc: 51.892,82.187,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.533 | Acc: 52.037,82.182,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 52.064,82.354,95.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 52.050,82.303,95.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 52.026,82.310,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 52.014,82.235,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 51.966,82.170,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 51.978,82.101,95.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 51.942,82.085,95.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.529 | Acc: 51.966,82.086,95.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.532 | Acc: 51.855,82.098,95.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.531 | Acc: 51.856,82.115,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 51.562,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 46.726,65.774,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 46.341,65.130,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 46.465,64.972,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.450 | Acc: 43.750,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.541 | Acc: 51.376,82.366,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.539 | Acc: 51.543,82.165,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.548 | Acc: 51.409,81.711,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.542 | Acc: 51.408,81.703,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 51.640,81.931,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 51.653,81.999,95.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.537 | Acc: 51.629,82.009,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.528 | Acc: 51.703,82.109,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.528 | Acc: 51.735,82.109,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 51.706,82.074,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.532 | Acc: 51.693,82.014,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.535 | Acc: 51.579,81.902,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.540 | Acc: 51.476,81.909,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.544 | Acc: 51.435,81.887,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.537 | Acc: 51.594,81.943,95.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 51.648,81.880,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 51.638,81.871,95.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.531 | Acc: 51.684,81.951,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 51.653,81.959,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 52.344,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.488 | Acc: 46.838,65.997,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 46.113,65.434,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 46.260,65.318,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.392 | Acc: 57.031,81.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.474 | Acc: 52.158,82.403,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.172,82.336,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 51.716,81.980,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.502 | Acc: 51.755,82.282,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 51.663,82.101,95.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.518 | Acc: 51.440,82.051,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.517 | Acc: 51.740,82.153,95.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 51.922,82.264,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 51.744,82.187,95.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.522 | Acc: 51.664,82.090,95.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.525 | Acc: 51.591,82.081,95.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.595,82.064,95.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.529 | Acc: 51.509,81.962,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.532 | Acc: 51.529,81.945,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.500,81.922,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.533 | Acc: 51.451,81.888,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.537 | Acc: 51.409,81.802,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.530 | Acc: 51.547,81.852,95.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 51.507,81.906,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.421 | Acc: 52.344,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 45.982,65.848,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.547 | Acc: 45.598,65.225,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.555 | Acc: 45.991,65.138,69.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.194 | Acc: 60.156,91.406,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 52.827,82.626,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.509 | Acc: 52.001,82.260,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 51.972,82.390,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.538 | Acc: 51.784,82.301,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.553 | Acc: 51.825,82.000,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.548 | Acc: 51.743,82.051,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.550 | Acc: 51.773,81.898,95.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 51.805,81.968,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 51.701,81.902,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.538 | Acc: 51.788,82.004,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.707,81.946,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.531 | Acc: 51.725,81.960,95.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.534 | Acc: 51.679,81.953,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 51.688,81.895,95.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.533 | Acc: 51.679,81.959,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 51.762,81.990,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.826,82.070,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 51.887,82.083,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.528 | Acc: 51.827,82.054,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.451 | Acc: 53.906,67.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 46.577,65.513,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 45.827,64.958,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 45.991,64.972,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.438 | Acc: 45.312,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.508 | Acc: 51.190,83.408,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.547 | Acc: 51.181,82.450,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.547 | Acc: 50.781,82.326,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 51.080,82.369,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 51.284,82.573,95.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 51.085,82.438,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 51.346,82.475,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 51.417,82.536,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.518 | Acc: 51.575,82.618,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 51.574,82.614,95.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 51.644,82.558,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.525 | Acc: 51.592,82.401,95.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 51.583,82.331,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 51.710,82.368,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 51.643,82.379,95.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 51.636,82.335,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.527 | Acc: 51.565,82.363,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.528 | Acc: 51.541,82.356,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.529 | Acc: 51.511,82.331,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 52.344,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 46.243,65.588,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 45.598,65.034,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 45.812,64.831,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.280 | Acc: 59.375,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 54.315,82.329,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.527 | Acc: 51.791,82.127,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.516 | Acc: 52.203,82.467,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.527 | Acc: 51.775,82.436,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.519 | Acc: 51.709,82.457,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 51.711,82.296,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 51.684,82.159,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 51.752,82.075,95.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.519 | Acc: 51.787,82.178,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.726,82.292,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.516 | Acc: 51.669,82.219,95.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 51.741,82.125,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.513 | Acc: 51.802,82.223,95.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.514 | Acc: 51.902,82.215,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.509 | Acc: 51.954,82.312,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.510 | Acc: 51.949,82.265,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.515 | Acc: 51.883,82.157,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.514 | Acc: 51.824,82.118,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 51.831,82.111,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.451 | Acc: 50.781,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.280,65.365,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.566 | Acc: 45.846,64.806,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 46.081,64.882,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.391 | Acc: 51.562,87.500,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 54.539,83.519,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 53.792,82.812,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 53.010,82.518,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 52.431,82.784,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 52.127,82.673,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.510 | Acc: 51.943,82.425,95.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 51.995,82.414,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.043,82.366,95.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 51.882,82.256,95.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.870,82.171,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.792,82.187,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 51.806,82.177,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.525 | Acc: 51.820,82.136,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.525 | Acc: 51.724,82.117,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.525 | Acc: 51.752,82.190,95.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 51.670,82.148,95.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.771,82.162,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.526 | Acc: 51.733,82.161,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 51.710,82.089,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.423 | Acc: 53.125,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.516 | Acc: 46.429,65.513,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.713,64.844,68.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 46.017,64.831,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.795 | Acc: 54.688,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.525 | Acc: 51.897,82.440,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 51.905,82.832,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.488 | Acc: 51.537,82.787,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.488 | Acc: 51.505,82.706,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 51.818,82.751,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 51.685,82.509,95.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.491 | Acc: 51.817,82.519,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.498 | Acc: 51.844,82.453,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 51.636,82.381,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.508 | Acc: 51.640,82.334,95.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.520 | Acc: 51.548,82.180,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.640,82.190,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 51.586,82.145,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.528 | Acc: 51.646,82.112,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.529 | Acc: 51.612,82.117,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 51.636,82.180,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 51.705,82.212,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.725,82.230,95.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 51.733,82.160,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 53.125,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 46.503,65.662,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 45.713,64.882,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 45.953,64.831,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.313 | Acc: 58.594,77.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 51.042,81.548,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.537 | Acc: 51.124,81.803,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.529 | Acc: 51.486,81.916,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.531 | Acc: 51.707,81.848,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.532 | Acc: 51.725,81.923,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.534 | Acc: 51.717,81.934,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.537 | Acc: 51.618,81.898,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 51.558,82.070,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.525 | Acc: 51.575,82.092,95.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 51.613,82.113,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.524 | Acc: 51.665,82.077,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 51.627,82.057,95.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 51.718,82.064,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.525 | Acc: 51.699,82.026,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 51.633,81.933,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 51.687,82.000,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 51.679,82.079,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.645,82.023,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.522 | Acc: 51.651,82.011,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.542 | Acc: 51.562,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.168,65.848,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 45.484,64.977,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 45.863,64.933,69.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.393 | Acc: 54.688,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 52.083,81.027,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 52.630,82.031,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 52.164,82.108,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.948,82.253,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.499 | Acc: 52.042,82.364,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 52.189,82.406,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.503 | Acc: 52.200,82.391,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.515 | Acc: 51.975,82.230,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 51.990,82.165,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.517 | Acc: 51.819,82.117,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.516 | Acc: 51.845,82.105,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 51.715,82.103,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.518 | Acc: 51.625,82.049,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 51.588,82.109,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.518 | Acc: 51.586,82.055,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.522 | Acc: 51.451,82.012,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 51.489,82.018,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 51.506,82.007,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 51.544,82.005,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.445 | Acc: 52.344,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.019,65.848,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 45.370,65.091,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.562 | Acc: 45.684,64.933,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.805 | Acc: 52.344,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.518 | Acc: 52.083,81.622,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.496 | Acc: 52.191,82.679,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 52.728,82.454,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 52.681,82.253,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 52.073,82.441,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 51.879,82.509,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.496 | Acc: 51.867,82.419,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 51.674,82.390,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 51.511,82.333,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.510 | Acc: 51.594,82.272,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 51.601,82.208,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.510 | Acc: 51.660,82.193,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.518 | Acc: 51.568,82.115,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 51.596,82.112,95.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 51.596,82.044,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 51.611,82.053,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.521 | Acc: 51.647,82.047,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.688,82.036,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.645,82.066,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.491 | Acc: 50.781,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 45.722,65.513,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.351,64.768,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 45.517,64.690,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.670 | Acc: 46.094,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.538 | Acc: 50.558,81.585,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.479 | Acc: 51.334,82.431,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 51.537,82.505,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.485 | Acc: 51.534,82.861,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.492 | Acc: 51.570,82.782,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.021,83.032,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.492 | Acc: 51.895,82.873,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.501 | Acc: 51.965,82.696,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.951,82.661,95.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.505 | Acc: 51.924,82.645,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 51.729,82.463,95.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 51.660,82.453,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.514 | Acc: 51.664,82.432,95.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 51.690,82.462,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 51.819,82.498,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 51.801,82.462,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.803,82.496,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 51.736,82.410,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 51.671,82.357,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 51.562,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.475 | Acc: 46.317,65.923,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.543 | Acc: 45.732,65.225,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 45.966,65.190,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.332 | Acc: 53.906,87.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.473 | Acc: 53.274,81.920,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 52.782,82.184,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.498 | Acc: 52.382,82.134,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.502 | Acc: 52.508,82.079,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.505 | Acc: 52.274,81.993,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.215,82.367,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.421,82.441,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.407,82.371,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.348,82.484,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 52.340,82.455,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.153,82.356,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 52.101,82.372,95.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 52.113,82.310,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.505 | Acc: 52.124,82.265,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 52.058,82.254,95.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 51.942,82.253,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.510 | Acc: 51.936,82.251,95.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.505 | Acc: 52.054,82.284,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.509 | Acc: 52.003,82.238,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.508 | Acc: 50.000,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 46.205,66.332,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.408,65.568,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 45.799,65.446,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.447 | Acc: 54.688,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.541 | Acc: 53.460,81.994,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.561 | Acc: 52.001,81.460,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.527 | Acc: 52.395,81.967,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.538 | Acc: 52.006,81.867,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.534 | Acc: 51.942,81.606,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.534 | Acc: 51.866,81.605,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.512 | Acc: 52.083,81.959,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.521 | Acc: 51.951,81.905,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.528 | Acc: 51.886,81.906,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 51.901,81.992,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.526 | Acc: 51.746,81.975,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.528 | Acc: 51.673,82.070,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 51.709,81.998,95.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.531 | Acc: 51.510,81.990,95.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 51.557,82.042,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.528 | Acc: 51.448,81.978,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 51.416,81.956,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.526 | Acc: 51.415,81.968,95.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 51.524,82.093,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.497 | Acc: 51.562,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.497 | Acc: 46.689,65.997,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 45.846,65.149,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 46.107,65.087,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.554 | Acc: 47.656,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 51.079,82.812,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 51.353,82.450,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.474 | Acc: 52.254,82.748,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.459 | Acc: 52.296,82.870,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.470 | Acc: 52.135,82.766,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.480 | Acc: 51.814,82.625,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 51.934,82.491,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 51.965,82.550,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.482 | Acc: 51.916,82.541,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 51.858,82.439,95.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 51.898,82.325,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 51.874,82.333,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.500 | Acc: 51.787,82.235,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.504 | Acc: 51.702,82.179,95.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 51.742,82.241,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.501 | Acc: 51.801,82.226,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.503 | Acc: 51.833,82.201,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 51.822,82.189,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 51.770,82.216,95.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 51.562,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.391,66.034,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 45.675,65.187,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 45.876,65.151,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.128 | Acc: 58.594,89.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 52.121,83.147,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.484 | Acc: 52.477,82.889,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 52.164,82.569,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.016,82.523,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 51.779,82.511,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 51.814,82.503,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 51.646,82.680,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 51.766,82.764,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 51.722,82.661,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 51.769,82.692,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 51.676,82.565,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 51.631,82.505,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 51.688,82.522,95.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 51.707,82.496,95.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 51.744,82.581,95.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.495 | Acc: 51.765,82.516,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 51.705,82.391,95.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 51.669,82.354,95.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.504 | Acc: 51.655,82.372,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 52.344,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.205,65.885,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.636,65.187,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.978,65.113,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.509 | Acc: 50.000,81.250,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.471 | Acc: 51.823,82.478,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 52.439,82.717,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 52.331,82.902,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.479 | Acc: 52.132,82.726,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.480 | Acc: 52.174,82.751,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.808,82.748,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 52.000,82.752,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.491 | Acc: 51.781,82.594,95.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.498 | Acc: 51.662,82.437,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 51.667,82.486,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.502 | Acc: 51.665,82.484,95.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 51.598,82.443,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.504 | Acc: 51.646,82.474,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.504 | Acc: 51.696,82.454,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 51.778,82.488,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.500 | Acc: 51.893,82.506,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.503 | Acc: 51.815,82.471,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 51.777,82.429,95.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.504 | Acc: 51.720,82.423,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.449 | Acc: 53.125,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.485 | Acc: 46.466,65.885,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 45.503,65.244,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 45.876,65.138,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.465 | Acc: 53.125,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.456 | Acc: 51.786,82.924,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 51.925,82.870,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 51.857,82.736,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.446 | Acc: 52.170,82.764,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.457 | Acc: 52.011,82.751,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.472 | Acc: 51.879,82.677,95.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 51.779,82.702,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 51.562,82.487,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 51.701,82.584,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 51.710,82.638,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 51.856,82.689,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 51.751,82.715,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.486 | Acc: 51.697,82.714,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 51.663,82.687,95.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 51.521,82.649,95.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 51.487,82.628,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 51.519,82.627,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 51.725,82.678,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.494 | Acc: 51.716,82.675,95.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.420 | Acc: 52.344,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.763,65.625,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 45.865,65.130,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 46.158,64.985,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.615 | Acc: 53.906,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.523 | Acc: 50.967,82.515,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 51.391,82.908,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 51.703,82.569,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 51.813,82.552,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 51.849,82.395,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 51.640,82.483,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.511 | Acc: 51.452,82.486,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 51.310,82.410,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 51.403,82.428,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 51.423,82.435,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.516 | Acc: 51.251,82.335,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 51.374,82.352,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.505 | Acc: 51.389,82.355,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.505 | Acc: 51.451,82.432,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 51.599,82.498,95.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.502 | Acc: 51.599,82.525,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 51.711,82.544,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 51.638,82.581,95.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 51.696,82.609,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 52.344,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 46.354,65.774,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 45.560,65.225,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 45.850,65.049,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.776 | Acc: 48.438,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.422 | Acc: 52.790,82.961,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 52.553,83.175,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.444 | Acc: 52.472,83.222,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.451 | Acc: 52.054,83.179,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.450 | Acc: 52.228,83.238,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.454 | Acc: 52.066,83.168,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.455 | Acc: 52.061,83.272,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 51.985,83.167,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.478 | Acc: 51.908,82.968,95.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.479 | Acc: 51.800,82.976,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 51.813,82.940,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.476 | Acc: 51.916,82.929,95.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.483 | Acc: 51.829,82.854,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 51.863,82.838,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 51.794,82.815,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 51.738,82.725,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.718,82.691,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.779,82.713,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 51.819,82.638,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.412 | Acc: 53.125,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.354,65.811,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 45.522,65.282,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 45.940,65.138,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.588 | Acc: 50.781,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.490 | Acc: 51.079,82.887,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 52.191,82.298,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.503 | Acc: 52.318,82.147,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 52.006,82.369,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.497 | Acc: 51.818,82.403,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.509 | Acc: 51.827,82.257,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 52.111,82.425,95.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.495 | Acc: 51.975,82.468,95.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.502 | Acc: 51.847,82.385,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 51.695,82.303,95.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.511 | Acc: 51.817,82.261,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 51.789,82.226,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.501 | Acc: 51.895,82.226,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.993,82.276,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 51.928,82.327,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 51.932,82.387,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 51.856,82.391,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.501 | Acc: 51.803,82.380,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 51.905,82.411,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.495 | Acc: 53.125,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 46.838,65.737,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 45.808,65.034,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 46.043,64.985,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.548 | Acc: 55.469,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.413 | Acc: 53.013,83.594,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.433 | Acc: 52.534,83.270,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.331,82.953,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 52.344,82.832,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 52.181,82.766,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.486 | Acc: 52.014,82.735,95.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 51.823,82.624,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 51.936,82.643,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.492 | Acc: 51.778,82.610,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 51.726,82.517,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 51.789,82.470,95.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 51.828,82.602,95.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 51.874,82.570,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 51.918,82.551,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 51.835,82.488,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 51.842,82.537,95.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.500 | Acc: 51.746,82.494,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.499 | Acc: 51.814,82.464,95.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 51.852,82.456,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.497 | Acc: 53.125,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.391,65.476,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.570 | Acc: 45.636,64.939,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 45.966,64.818,68.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.493 | Acc: 49.219,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 52.641,82.366,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.442 | Acc: 53.220,83.155,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.497,82.659,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.463 | Acc: 52.440,82.812,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.461 | Acc: 52.367,82.921,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.476 | Acc: 52.163,82.716,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 52.122,82.619,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.481 | Acc: 52.145,82.444,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.236,82.441,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 52.087,82.432,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.047,82.487,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 51.929,82.378,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 51.919,82.349,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 51.821,82.359,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.492 | Acc: 51.845,82.485,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.906,82.620,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.941,82.606,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 51.872,82.527,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 51.866,82.562,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.426 | Acc: 53.125,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.280,65.625,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.598,65.072,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 45.863,65.010,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.269 | Acc: 57.812,85.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 52.046,82.478,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 52.134,82.755,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 52.254,82.774,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 51.833,82.706,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.483 | Acc: 51.996,83.021,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.079,82.858,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 52.056,83.040,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.485 | Acc: 51.878,82.880,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.486 | Acc: 51.886,82.821,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 51.687,82.704,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 51.619,82.618,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 51.621,82.534,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.503 | Acc: 51.718,82.582,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.498 | Acc: 51.696,82.696,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.497 | Acc: 51.739,82.646,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 51.747,82.635,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 51.709,82.648,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.490 | Acc: 51.755,82.644,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.494 | Acc: 51.722,82.560,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.461 | Acc: 53.125,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 46.763,65.848,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.563 | Acc: 45.789,65.187,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 46.158,64.997,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.397 | Acc: 55.469,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.455 | Acc: 53.237,82.775,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.467 | Acc: 52.992,82.641,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 52.561,82.556,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 52.344,82.504,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.503 | Acc: 51.864,82.356,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 51.976,82.386,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 52.022,82.513,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.493 | Acc: 52.101,82.633,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.197,82.549,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.181,82.696,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 52.146,82.629,95.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 52.062,82.612,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 52.098,82.672,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.063,82.598,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.071,82.545,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 52.103,82.537,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 52.115,82.510,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.039,82.499,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.012,82.411,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.496 | Acc: 53.125,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.519 | Acc: 46.503,66.034,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 45.865,65.339,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 46.043,65.151,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.476 | Acc: 54.688,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.434 | Acc: 53.423,82.775,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 51.620,82.774,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.477 | Acc: 51.883,82.889,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.472 | Acc: 51.852,82.803,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 51.709,82.387,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.492 | Acc: 51.743,82.367,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.491 | Acc: 51.762,82.380,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.483 | Acc: 51.888,82.468,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 52.046,82.515,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 52.118,82.595,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 52.128,82.516,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 52.042,82.527,95.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.041,82.540,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.486 | Acc: 51.955,82.582,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 51.908,82.470,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 51.928,82.508,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 51.963,82.430,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.491 | Acc: 51.935,82.416,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 51.821,82.353,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 51.562,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.801,66.034,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 45.941,65.568,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 46.222,65.330,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.713 | Acc: 48.438,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.371 | Acc: 54.241,84.747,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.441 | Acc: 52.744,83.498,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.421,83.145,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.450 | Acc: 52.662,83.333,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 52.444,82.805,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.518,82.683,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.183,82.630,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 51.936,82.337,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 51.834,82.415,95.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 51.846,82.459,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 51.958,82.600,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 51.877,82.560,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 51.850,82.504,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 51.852,82.507,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.499 | Acc: 51.851,82.436,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 51.850,82.428,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 51.858,82.469,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 51.818,82.488,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 51.813,82.476,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.451 | Acc: 53.906,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.493 | Acc: 46.429,65.774,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 45.713,65.187,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 46.094,65.023,69.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.798 | Acc: 53.906,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 51.749,82.329,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 52.077,82.298,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 51.627,82.275,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 51.977,82.070,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 51.996,82.232,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 51.717,82.444,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.495 | Acc: 51.546,82.292,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 51.495,82.182,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 51.748,82.316,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 51.823,82.373,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 51.845,82.537,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.939,82.650,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.479 | Acc: 52.032,82.810,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.482 | Acc: 51.985,82.779,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.484 | Acc: 51.954,82.711,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 51.862,82.693,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 51.771,82.636,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 51.692,82.609,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 51.753,82.607,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 51.562,67.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.429,65.774,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.617,65.091,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.094,65.023,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.645 | Acc: 50.781,72.656,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.548 | Acc: 51.488,81.882,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 51.334,82.717,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.524 | Acc: 51.242,82.403,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 51.505,82.581,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 51.586,82.797,95.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 51.788,83.000,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 51.662,82.945,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.506 | Acc: 51.422,82.706,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.505 | Acc: 51.411,82.800,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 51.539,82.739,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.506 | Acc: 51.555,82.604,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 51.634,82.650,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 51.658,82.567,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.511 | Acc: 51.574,82.479,95.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.509 | Acc: 51.599,82.480,95.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 51.674,82.528,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 51.789,82.593,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 51.844,82.678,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 51.813,82.667,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.472 | Acc: 52.344,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.503,65.662,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 45.827,65.072,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 46.094,64.997,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.269 | Acc: 56.250,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 53.088,81.250,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 52.382,81.841,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 51.895,81.954,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.502 | Acc: 51.746,81.935,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.505 | Acc: 51.679,82.279,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.509 | Acc: 51.498,82.218,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 51.513,82.236,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.498 | Acc: 51.451,82.167,95.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 51.554,82.243,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 51.578,82.058,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.506 | Acc: 51.616,81.932,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.505 | Acc: 51.491,82.044,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.503 | Acc: 51.485,82.064,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.632,82.137,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 51.760,82.148,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.495 | Acc: 51.745,82.192,95.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.496 | Acc: 51.773,82.226,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 51.738,82.269,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.494 | Acc: 51.757,82.273,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 52.344,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 46.205,65.737,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 45.598,65.130,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.564 | Acc: 45.978,64.997,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.271 | Acc: 51.562,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.561 | Acc: 50.670,81.808,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 51.239,82.088,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 51.114,81.673,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 51.370,81.867,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 51.516,82.186,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 51.653,82.322,95.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.495 | Acc: 51.773,82.425,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.493 | Acc: 51.723,82.385,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.494 | Acc: 51.821,82.476,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 51.741,82.408,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 51.669,82.470,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 51.699,82.530,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 51.652,82.528,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.486 | Acc: 51.671,82.521,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 51.614,82.431,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 51.606,82.494,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 51.599,82.494,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 51.647,82.416,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.492 | Acc: 51.702,82.425,95.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 51.562,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 46.615,65.737,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.557 | Acc: 45.903,65.358,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 46.171,65.228,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.435 | Acc: 45.312,85.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.492 | Acc: 51.451,82.738,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.465 | Acc: 51.772,82.812,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 51.767,82.697,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.469 | Acc: 51.910,82.504,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 51.942,82.085,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 52.092,82.277,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.475 | Acc: 52.166,82.297,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.473 | Acc: 52.203,82.361,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.210,82.441,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 52.044,82.381,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 52.156,82.501,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 52.084,82.524,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 52.026,82.522,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.485 | Acc: 51.896,82.484,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 51.944,82.462,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.482 | Acc: 51.969,82.469,95.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 51.918,82.471,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.913,82.460,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.487 | Acc: 51.927,82.431,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.453 | Acc: 53.125,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 46.131,65.774,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 45.560,65.415,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.940,65.190,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.741 | Acc: 46.094,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.501 | Acc: 50.967,82.850,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.479 | Acc: 51.905,82.641,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 52.305,82.556,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.488 | Acc: 52.112,82.581,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.480 | Acc: 51.709,82.580,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.480 | Acc: 51.847,82.664,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 52.011,82.718,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 51.888,82.614,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.482 | Acc: 51.757,82.648,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 51.772,82.700,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.476 | Acc: 51.980,82.752,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.476 | Acc: 51.932,82.686,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.473 | Acc: 51.925,82.714,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.478 | Acc: 51.832,82.654,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 51.755,82.613,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 51.660,82.603,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 51.721,82.648,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.753,82.609,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 51.821,82.638,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.509 | Acc: 53.125,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.317,65.848,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 45.636,65.187,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 45.978,65.292,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.421 | Acc: 50.781,88.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 50.409,82.775,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.528 | Acc: 50.476,82.165,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 51.050,82.236,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.503 | Acc: 51.215,82.726,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.500 | Acc: 51.501,82.503,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 51.537,82.457,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 51.585,82.375,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 51.562,82.342,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.575,82.346,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 51.660,82.443,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.496 | Acc: 51.757,82.477,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 51.734,82.498,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 51.715,82.495,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 51.663,82.512,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 51.755,82.514,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 51.740,82.506,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.494 | Acc: 51.711,82.473,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 51.736,82.488,95.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 51.761,82.509,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.447 | Acc: 52.344,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 46.503,65.923,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 45.770,65.187,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 46.183,65.061,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.394 | Acc: 55.469,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.523 | Acc: 51.860,82.403,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 51.448,82.679,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 51.729,82.800,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.519 | Acc: 51.717,82.417,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 51.733,82.341,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.520 | Acc: 51.698,82.361,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 51.961,82.419,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.515 | Acc: 51.834,82.366,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.510 | Acc: 51.934,82.467,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.511 | Acc: 51.854,82.459,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 51.715,82.371,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.515 | Acc: 51.595,82.320,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 51.685,82.444,95.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 51.735,82.490,95.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 51.845,82.587,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.501 | Acc: 51.728,82.572,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 51.810,82.535,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 51.837,82.514,95.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 51.866,82.536,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.480 | Acc: 53.125,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.243,65.699,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 45.598,65.053,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 46.030,65.061,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.355 | Acc: 55.469,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.518 | Acc: 51.116,82.738,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 51.715,83.098,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 51.550,83.145,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 51.736,82.938,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 51.655,82.812,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 51.737,82.961,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 51.851,82.990,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.476 | Acc: 51.980,83.084,95.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.477 | Acc: 51.903,83.033,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 51.734,82.921,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 51.729,82.943,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 51.682,82.848,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 51.742,82.827,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 51.674,82.815,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 51.617,82.774,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 51.609,82.754,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.496 | Acc: 51.615,82.606,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 51.690,82.592,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 51.667,82.614,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.403 | Acc: 52.344,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.540,66.034,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 45.846,65.282,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 46.119,65.113,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.355 | Acc: 56.250,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.452 | Acc: 52.530,83.110,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.493 | Acc: 52.534,82.374,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 52.395,82.428,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.486 | Acc: 52.691,82.629,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 52.839,82.604,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 52.531,82.515,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 52.094,82.596,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.121,82.507,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.813,82.407,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.041,82.544,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 52.079,82.526,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.007,82.589,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 51.982,82.543,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 51.974,82.596,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 51.949,82.566,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 51.988,82.540,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 51.986,82.457,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 51.963,82.535,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 51.958,82.517,95.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.516 | Acc: 52.344,67.969,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 46.354,65.662,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.541,64.806,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 45.940,64.818,69.160,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.432 | Acc: 54.688,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 52.083,82.999,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 51.829,82.603,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 52.036,82.672,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 52.315,82.755,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.980,82.495,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 52.002,82.457,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 51.817,82.635,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 51.951,82.584,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 51.895,82.489,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 51.877,82.533,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.495 | Acc: 51.845,82.569,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 51.851,82.586,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 51.796,82.576,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 51.852,82.515,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 51.918,82.550,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 51.918,82.545,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 51.982,82.560,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.484 | Acc: 51.963,82.590,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 51.948,82.597,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.454 | Acc: 53.125,68.750,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 46.391,66.034,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 45.636,65.454,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 45.825,65.266,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.903 | Acc: 42.188,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.508 | Acc: 51.600,83.296,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.511 | Acc: 51.543,82.889,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 51.575,82.774,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.509 | Acc: 51.215,82.890,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.497 | Acc: 51.562,82.967,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 51.440,82.774,95.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 51.629,82.768,95.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.498 | Acc: 51.703,82.808,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 51.718,82.817,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 51.776,82.832,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 51.859,82.820,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.486 | Acc: 52.026,82.936,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 51.853,82.902,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.485 | Acc: 51.821,82.899,95.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 51.936,82.872,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.818,82.827,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 51.760,82.794,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 51.863,82.789,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 51.835,82.679,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.455 | Acc: 52.344,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.801,65.960,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 46.037,65.396,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 46.235,65.279,68.891,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.355 | Acc: 56.250,85.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.467 | Acc: 51.897,82.664,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.479 | Acc: 51.067,83.041,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 51.191,83.107,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 51.022,82.919,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 50.951,83.145,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 51.304,83.226,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 51.108,83.145,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.493 | Acc: 51.334,83.070,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 51.282,82.851,95.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.485 | Acc: 51.426,82.995,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 51.580,83.018,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.494,82.978,95.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.661,83.007,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 51.618,82.996,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 51.617,82.966,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.481 | Acc: 51.623,82.822,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.479 | Acc: 51.698,82.842,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 51.705,82.806,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.478 | Acc: 51.733,82.827,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.460 | Acc: 53.125,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 46.280,65.923,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 45.636,65.339,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 45.966,65.318,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.535 | Acc: 51.562,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 51.823,82.738,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.482 | Acc: 52.077,83.041,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 51.575,82.633,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.509 | Acc: 51.611,82.677,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.499 | Acc: 51.416,82.696,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.506 | Acc: 51.401,82.432,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.512 | Acc: 51.252,82.297,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.498 | Acc: 51.553,82.361,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 51.524,82.390,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 51.667,82.552,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 51.661,82.579,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 51.676,82.569,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 51.745,82.561,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 51.790,82.612,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 51.804,82.615,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 51.859,82.657,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 51.817,82.636,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.930,82.620,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 51.917,82.571,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.474 | Acc: 53.125,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 46.205,65.885,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.559 | Acc: 45.636,65.339,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 45.953,65.215,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.825 | Acc: 52.344,78.125,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.455 | Acc: 51.228,82.403,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.501 | Acc: 52.077,82.546,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 52.267,82.915,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.484 | Acc: 51.678,82.677,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.475 | Acc: 51.787,82.805,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 51.937,82.903,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 51.845,82.790,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.486 | Acc: 51.757,82.662,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 51.472,82.623,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 51.699,82.824,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 51.842,82.862,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.845,82.868,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.485 | Acc: 51.769,82.798,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 51.571,82.801,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 51.594,82.833,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 51.521,82.854,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.494 | Acc: 51.485,82.801,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 51.508,82.782,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 51.653,82.794,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 53.125,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.520 | Acc: 46.131,65.923,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.581 | Acc: 45.579,65.244,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 45.812,65.215,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.472 | Acc: 49.219,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.473 | Acc: 51.935,82.440,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 52.229,82.546,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 52.523,82.915,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 51.466,82.610,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 52.034,82.704,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.469 | Acc: 52.144,82.754,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 52.056,82.602,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 51.926,82.541,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 51.826,82.588,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 51.784,82.638,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 51.803,82.523,95.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 51.741,82.537,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 51.766,82.588,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 51.788,82.582,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 51.752,82.672,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 51.908,82.691,95.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 51.902,82.654,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.842,82.663,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 51.833,82.587,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.475 | Acc: 52.344,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.501 | Acc: 46.801,65.811,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.566 | Acc: 46.018,65.091,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 46.363,65.036,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.324 | Acc: 53.125,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.464 | Acc: 52.083,82.961,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.494 | Acc: 51.810,82.412,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 51.921,82.684,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.478 | Acc: 51.987,82.774,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.494 | Acc: 51.679,82.550,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 51.795,82.580,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.492 | Acc: 51.828,82.646,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 51.810,82.575,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 51.796,82.687,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 51.936,82.673,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 51.782,82.593,95.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.491 | Acc: 51.822,82.579,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.492 | Acc: 51.811,82.510,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 51.793,82.590,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 51.864,82.646,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.484 | Acc: 51.881,82.652,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.482 | Acc: 51.886,82.691,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 51.913,82.590,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.483 | Acc: 51.999,82.642,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.494 | Acc: 53.906,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 46.317,65.774,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.713,65.015,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 46.119,64.921,69.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.500 | Acc: 57.031,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 52.530,81.994,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.509 | Acc: 52.210,82.127,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 51.947,82.492,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.506 | Acc: 51.543,82.620,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.497 | Acc: 51.470,82.704,95.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 51.311,82.754,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 51.208,82.635,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 51.402,82.614,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.420,82.571,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 51.675,82.568,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 51.806,82.505,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 51.819,82.595,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.496 | Acc: 51.853,82.504,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 51.891,82.565,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 51.835,82.550,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 51.928,82.623,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 51.865,82.611,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.941,82.648,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 51.876,82.632,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 51.562,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.503 | Acc: 46.317,65.960,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 45.713,65.263,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 45.927,65.202,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.494 | Acc: 53.125,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.454 | Acc: 52.679,82.999,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.492 | Acc: 51.601,83.079,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 51.063,82.531,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.504 | Acc: 51.273,82.475,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 51.640,82.689,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.490 | Acc: 51.575,82.696,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.488 | Acc: 51.452,82.652,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 51.436,82.618,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.498 | Acc: 51.364,82.463,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 51.516,82.513,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 51.665,82.551,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 51.640,82.498,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 51.646,82.549,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.690,82.476,95.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 51.915,82.589,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 51.855,82.603,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.899,82.604,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 51.881,82.579,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.491 | Acc: 51.829,82.612,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 52.344,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.512 | Acc: 46.466,65.327,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.566 | Acc: 45.827,64.939,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.889,64.857,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.294 | Acc: 53.125,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 51.153,82.775,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.470 | Acc: 52.115,82.870,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.024,82.966,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.480 | Acc: 51.698,82.658,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.487 | Acc: 51.532,82.557,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.492 | Acc: 51.627,82.567,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 51.574,82.452,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.497 | Acc: 51.543,82.531,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 51.558,82.497,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 51.629,82.591,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.484 | Acc: 51.806,82.678,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 51.702,82.647,95.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 51.712,82.588,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 51.771,82.662,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 51.765,82.641,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 51.862,82.608,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.821,82.579,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 51.917,82.626,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.485 | Acc: 51.921,82.651,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 51.562,67.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.503,65.848,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 45.846,65.320,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 46.132,65.215,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.747 | Acc: 49.219,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.478 | Acc: 51.525,82.850,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.462 | Acc: 51.810,83.213,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.447 | Acc: 52.267,83.286,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.457 | Acc: 52.180,83.179,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 51.818,82.758,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.472 | Acc: 51.885,82.858,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 51.878,82.857,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 51.854,82.842,95.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 51.718,82.718,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 51.609,82.680,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.486 | Acc: 51.658,82.668,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.484 | Acc: 51.828,82.560,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.486 | Acc: 51.760,82.570,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 51.757,82.573,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 51.755,82.631,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.487 | Acc: 51.813,82.725,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.485 | Acc: 51.874,82.735,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 51.885,82.713,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 51.864,82.661,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 52.344,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 46.168,65.960,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 45.789,65.149,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 46.081,65.049,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.317 | Acc: 47.656,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 50.074,82.143,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 51.048,82.527,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 51.332,82.121,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 51.505,82.205,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 51.454,82.279,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 51.769,82.302,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.501 | Acc: 51.690,82.270,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 51.611,82.322,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 51.407,82.312,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 51.461,82.435,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.495 | Acc: 51.485,82.328,95.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 51.543,82.414,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 51.571,82.480,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.486 | Acc: 51.671,82.498,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 51.713,82.462,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.738,82.457,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 51.851,82.528,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.840,82.486,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 51.833,82.499,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.504 | Acc: 52.344,70.312,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 46.615,65.774,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.571 | Acc: 45.655,65.091,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 46.081,64.959,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.603 | Acc: 46.875,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.479 | Acc: 52.381,82.812,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 52.668,82.546,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.461 | Acc: 52.766,82.672,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 52.566,82.726,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.464 | Acc: 52.653,82.990,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.462 | Acc: 52.525,82.974,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.473 | Acc: 52.399,82.702,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 52.300,82.788,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.468 | Acc: 52.408,82.860,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.467 | Acc: 52.278,82.809,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.463 | Acc: 52.284,82.897,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.464 | Acc: 52.221,82.845,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.463 | Acc: 52.167,82.908,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.469 | Acc: 52.071,82.815,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.473 | Acc: 51.986,82.732,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 51.896,82.720,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.479 | Acc: 51.824,82.725,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 51.857,82.706,95.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.483 | Acc: 51.843,82.702,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.481 | Acc: 52.344,68.750,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 46.652,65.588,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 45.694,64.844,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 46.055,64.895,68.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.367 | Acc: 52.344,85.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 51.339,82.701,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 51.639,82.546,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 51.755,82.851,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 51.669,82.861,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 51.825,82.727,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.847,82.793,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.477 | Acc: 52.067,82.774,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.019,82.788,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.481 | Acc: 51.985,82.683,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.006,82.708,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.479 | Acc: 52.079,82.671,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.485 | Acc: 52.140,82.563,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.056,82.483,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.486 | Acc: 52.066,82.448,95.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.006,82.447,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 51.903,82.394,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.489 | Acc: 51.945,82.405,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.491 | Acc: 51.911,82.384,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 51.858,82.343,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.485 | Acc: 53.125,69.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 46.949,65.997,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.566 | Acc: 46.189,65.396,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 46.414,65.228,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.495 | Acc: 50.781,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.520 | Acc: 51.042,81.994,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 51.162,82.279,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.540 | Acc: 51.255,82.223,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.530 | Acc: 51.215,82.417,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 51.361,82.410,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 51.408,82.438,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 51.596,82.486,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 51.480,82.376,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.416,82.394,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.506 | Acc: 51.590,82.393,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 51.813,82.364,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 51.848,82.440,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.496 | Acc: 51.922,82.453,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 51.988,82.429,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.501 | Acc: 51.877,82.335,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.506 | Acc: 51.808,82.282,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.504 | Acc: 51.831,82.306,95.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 51.781,82.267,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 51.866,82.357,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.433 | Acc: 52.344,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 46.168,65.923,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.655,65.244,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 46.055,65.190,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.456 | Acc: 52.344,79.688,97.656,% | Adaptive Acc: 88.281% | clf_exit: 0.344 0.477 0.180
Batch: 20 | Loss: 2.498 | Acc: 51.637,82.775,96.205,% | Adaptive Acc: 87.277% | clf_exit: 0.349 0.459 0.192
Batch: 40 | Loss: 2.484 | Acc: 52.439,82.603,96.094,% | Adaptive Acc: 87.157% | clf_exit: 0.356 0.456 0.188
Batch: 60 | Loss: 2.458 | Acc: 52.651,82.646,96.158,% | Adaptive Acc: 87.615% | clf_exit: 0.356 0.457 0.187
Batch: 80 | Loss: 2.462 | Acc: 52.469,82.639,96.065,% | Adaptive Acc: 87.500% | clf_exit: 0.357 0.455 0.188
Batch: 100 | Loss: 2.481 | Acc: 51.825,82.325,96.040,% | Adaptive Acc: 87.183% | clf_exit: 0.358 0.454 0.189
Batch: 120 | Loss: 2.491 | Acc: 51.511,82.367,95.990,% | Adaptive Acc: 87.016% | clf_exit: 0.360 0.449 0.192
Batch: 140 | Loss: 2.492 | Acc: 51.324,82.369,95.977,% | Adaptive Acc: 87.018% | clf_exit: 0.359 0.451 0.190
Batch: 160 | Loss: 2.484 | Acc: 51.330,82.521,95.977,% | Adaptive Acc: 87.034% | clf_exit: 0.359 0.452 0.189
Batch: 180 | Loss: 2.476 | Acc: 51.411,82.631,96.038,% | Adaptive Acc: 87.042% | clf_exit: 0.360 0.451 0.189
Batch: 200 | Loss: 2.478 | Acc: 51.485,82.641,96.067,% | Adaptive Acc: 87.053% | clf_exit: 0.359 0.453 0.189
Batch: 220 | Loss: 2.479 | Acc: 51.471,82.607,96.048,% | Adaptive Acc: 86.977% | clf_exit: 0.359 0.452 0.189
Batch: 240 | Loss: 2.485 | Acc: 51.404,82.550,95.996,% | Adaptive Acc: 86.946% | clf_exit: 0.358 0.452 0.190
Batch: 260 | Loss: 2.483 | Acc: 51.407,82.540,95.980,% | Adaptive Acc: 86.922% | clf_exit: 0.359 0.452 0.189
Batch: 280 | Loss: 2.488 | Acc: 51.410,82.368,95.958,% | Adaptive Acc: 86.866% | clf_exit: 0.359 0.452 0.190
Batch: 300 | Loss: 2.486 | Acc: 51.524,82.405,95.954,% | Adaptive Acc: 86.906% | clf_exit: 0.359 0.452 0.190
Batch: 320 | Loss: 2.478 | Acc: 51.623,82.464,95.948,% | Adaptive Acc: 86.984% | clf_exit: 0.359 0.452 0.190
Batch: 340 | Loss: 2.479 | Acc: 51.588,82.510,95.956,% | Adaptive Acc: 86.955% | clf_exit: 0.359 0.452 0.189
Batch: 360 | Loss: 2.482 | Acc: 51.606,82.510,95.957,% | Adaptive Acc: 86.955% | clf_exit: 0.358 0.452 0.189
Batch: 380 | Loss: 2.483 | Acc: 51.618,82.544,95.960,% | Adaptive Acc: 86.991% | clf_exit: 0.358 0.453 0.189
Batch: 0 | Loss: 4.464 | Acc: 53.125,67.188,67.969,% | Adaptive Acc: 66.406% | clf_exit: 0.500 0.320 0.180
Batch: 20 | Loss: 4.508 | Acc: 46.503,65.662,69.382,% | Adaptive Acc: 64.546% | clf_exit: 0.416 0.373 0.212
Batch: 40 | Loss: 4.571 | Acc: 45.751,64.996,69.017,% | Adaptive Acc: 63.834% | clf_exit: 0.403 0.374 0.223
Batch: 60 | Loss: 4.578 | Acc: 46.171,64.972,68.865,% | Adaptive Acc: 63.730% | clf_exit: 0.402 0.379 0.219
model is save as models/resnet56_h12_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 91.347 | Acc: 1.562,0.000,3.125,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 90.787 | Acc: 1.600,0.967,3.013,% | Adaptive Acc: 1.600% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 90.315 | Acc: 1.582,1.143,2.915,% | Adaptive Acc: 1.582% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 89.999 | Acc: 1.434,1.153,2.984,% | Adaptive Acc: 1.434% | clf_exit: 1.000 0.000 0.000
Batch: 0 | Loss: 76.843 | Acc: 1.562,0.781,4.688,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 76.308 | Acc: 1.525,1.414,4.613,% | Adaptive Acc: 1.525% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 75.971 | Acc: 1.524,1.582,4.745,% | Adaptive Acc: 1.524% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 75.696 | Acc: 1.460,1.524,4.841,% | Adaptive Acc: 1.460% | clf_exit: 1.000 0.000 0.000
Batch: 0 | Loss: 54.901 | Acc: 1.562,2.344,7.031,% | Adaptive Acc: 1.562% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 54.637 | Acc: 1.525,2.753,8.594,% | Adaptive Acc: 1.525% | clf_exit: 0.998 0.002 0.000
Batch: 40 | Loss: 54.452 | Acc: 1.524,2.896,8.194,% | Adaptive Acc: 1.524% | clf_exit: 0.998 0.002 0.000
Batch: 60 | Loss: 54.251 | Acc: 1.447,2.728,8.286,% | Adaptive Acc: 1.447% | clf_exit: 0.998 0.002 0.000
Batch: 0 | Loss: 32.618 | Acc: 1.562,7.031,21.875,% | Adaptive Acc: 1.562% | clf_exit: 0.977 0.023 0.000
Batch: 20 | Loss: 32.833 | Acc: 1.860,8.817,21.503,% | Adaptive Acc: 2.046% | clf_exit: 0.978 0.014 0.007
Batch: 40 | Loss: 32.713 | Acc: 1.791,8.384,21.456,% | Adaptive Acc: 1.944% | clf_exit: 0.980 0.014 0.006
Batch: 60 | Loss: 32.559 | Acc: 1.729,8.248,21.273,% | Adaptive Acc: 1.870% | clf_exit: 0.979 0.015 0.006
Batch: 0 | Loss: 13.289 | Acc: 4.688,35.156,53.906,% | Adaptive Acc: 14.844% | clf_exit: 0.758 0.125 0.117
Batch: 20 | Loss: 13.347 | Acc: 4.911,33.594,52.976,% | Adaptive Acc: 15.774% | clf_exit: 0.728 0.151 0.120
Batch: 40 | Loss: 13.289 | Acc: 5.259,33.708,52.992,% | Adaptive Acc: 16.216% | clf_exit: 0.724 0.153 0.123
Batch: 60 | Loss: 13.210 | Acc: 5.123,34.042,53.176,% | Adaptive Acc: 16.214% | clf_exit: 0.724 0.154 0.122
Batch: 0 | Loss: 4.464 | Acc: 53.125,67.188,67.969,% | Adaptive Acc: 66.406% | clf_exit: 0.500 0.320 0.180
Batch: 20 | Loss: 4.508 | Acc: 46.503,65.662,69.382,% | Adaptive Acc: 64.546% | clf_exit: 0.416 0.373 0.212
Batch: 40 | Loss: 4.571 | Acc: 45.751,64.996,69.017,% | Adaptive Acc: 63.834% | clf_exit: 0.403 0.374 0.223
Batch: 60 | Loss: 4.578 | Acc: 46.171,64.972,68.865,% | Adaptive Acc: 63.730% | clf_exit: 0.402 0.379 0.219







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.799 |  Acc: 2.112,1.948,1.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 13.682 |  Acc: 2.920,3.420,1.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 13.222 |  Acc: 3.358,4.812,1.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 13.363 |  Acc: 3.610,3.760,2.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 12.741 |  Acc: 4.254,7.344,2.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 12.520 |  Acc: 4.870,8.300,2.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 12.152 |  Acc: 6.122,9.164,4.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 12.281 |  Acc: 5.520,8.380,5.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 11.752 |  Acc: 7.556,11.164,6.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 11.796 |  Acc: 7.730,9.550,6.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 11.405 |  Acc: 8.600,12.574,8.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 11.626 |  Acc: 7.270,11.220,8.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 11.017 |  Acc: 9.352,15.018,11.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 11.354 |  Acc: 8.960,12.310,7.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 10.577 |  Acc: 10.164,17.544,14.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 11.056 |  Acc: 6.860,16.320,15.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 10.128 |  Acc: 11.892,19.782,18.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 12.786 |  Acc: 4.380,9.420,12.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 9.697 |  Acc: 13.318,21.838,22.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 11.138 |  Acc: 6.850,17.440,19.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 9.273 |  Acc: 15.786,24.298,25.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 9.984 |  Acc: 12.920,18.640,22.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 8.883 |  Acc: 18.116,25.966,28.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 10.145 |  Acc: 12.780,18.740,22.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 8.541 |  Acc: 20.230,28.138,31.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 9.427 |  Acc: 14.970,23.900,27.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 8.213 |  Acc: 22.040,30.112,34.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.881 |  Acc: 19.260,25.880,29.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.941 |  Acc: 23.778,32.216,36.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 9.123 |  Acc: 22.420,23.950,28.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 7.715 |  Acc: 25.292,33.762,37.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 9.575 |  Acc: 17.810,21.630,28.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 7.478 |  Acc: 26.822,35.552,40.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 8.567 |  Acc: 20.730,25.470,34.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 7.297 |  Acc: 27.774,37.030,41.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 8.329 |  Acc: 24.200,27.430,34.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 7.087 |  Acc: 28.806,38.716,43.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 8.239 |  Acc: 24.290,32.190,37.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.934 |  Acc: 29.772,39.842,45.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 8.272 |  Acc: 20.080,30.930,38.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.756 |  Acc: 30.804,41.656,46.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 8.506 |  Acc: 19.250,31.180,36.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.638 |  Acc: 31.360,42.438,47.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 8.317 |  Acc: 22.310,31.680,35.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.518 |  Acc: 31.886,43.704,48.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.623 |  Acc: 26.310,37.420,40.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.386 |  Acc: 32.196,45.104,49.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.815 |  Acc: 22.600,37.870,42.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.304 |  Acc: 32.876,45.728,50.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 7.342 |  Acc: 27.250,39.440,44.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 6.204 |  Acc: 33.632,46.630,51.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 7.170 |  Acc: 27.970,38.810,45.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 6.112 |  Acc: 33.710,47.498,52.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.766 |  Acc: 23.650,37.380,41.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 6.039 |  Acc: 34.056,48.332,53.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 7.428 |  Acc: 25.640,39.200,43.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.957 |  Acc: 34.358,49.290,54.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.201 |  Acc: 24.520,41.770,47.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.886 |  Acc: 34.982,50.072,54.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.744 |  Acc: 20.920,39.320,45.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.827 |  Acc: 34.964,50.226,55.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 7.342 |  Acc: 24.760,40.310,46.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.774 |  Acc: 35.158,50.830,55.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 7.884 |  Acc: 21.820,36.910,43.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.700 |  Acc: 35.680,51.514,56.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 7.676 |  Acc: 22.840,39.300,44.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.673 |  Acc: 35.738,51.848,56.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.763 |  Acc: 22.560,40.070,46.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.591 |  Acc: 36.240,52.482,57.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 6.450 |  Acc: 31.110,45.470,51.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.593 |  Acc: 35.964,52.462,57.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 7.005 |  Acc: 24.720,43.110,50.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.520 |  Acc: 36.394,53.110,58.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.059 |  Acc: 24.790,43.220,49.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.489 |  Acc: 36.674,53.388,58.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 6.836 |  Acc: 27.870,43.270,50.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.435 |  Acc: 36.950,53.912,59.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 6.642 |  Acc: 27.370,45.310,53.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.396 |  Acc: 37.230,54.272,59.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 7.042 |  Acc: 25.700,43.570,52.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.358 |  Acc: 37.412,54.872,60.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 7.683 |  Acc: 24.490,39.480,46.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.323 |  Acc: 37.624,54.984,60.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 6.295 |  Acc: 31.880,47.740,52.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.302 |  Acc: 37.748,55.256,60.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 8.362 |  Acc: 22.040,38.470,44.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.263 |  Acc: 37.894,55.464,61.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 6.641 |  Acc: 29.370,45.520,51.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.242 |  Acc: 38.052,55.822,61.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 7.307 |  Acc: 28.730,40.880,46.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.213 |  Acc: 38.060,56.132,61.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.017 |  Acc: 29.000,41.950,50.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.185 |  Acc: 38.296,56.152,62.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 7.080 |  Acc: 28.200,41.190,47.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.157 |  Acc: 38.364,56.774,62.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 7.925 |  Acc: 20.920,38.560,46.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.155 |  Acc: 38.364,56.722,62.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.677 |  Acc: 26.690,46.740,52.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.100 |  Acc: 38.842,56.764,62.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 6.876 |  Acc: 27.290,45.420,51.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.074 |  Acc: 38.738,57.024,63.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 7.111 |  Acc: 26.110,43.440,49.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.066 |  Acc: 38.788,57.550,63.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 8.009 |  Acc: 25.700,37.550,44.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 5.043 |  Acc: 38.990,57.372,63.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 6.179 |  Acc: 32.230,49.000,55.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 5.039 |  Acc: 39.042,57.420,63.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 8.015 |  Acc: 23.190,40.120,47.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 5.002 |  Acc: 39.240,58.038,64.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.636 |  Acc: 27.860,46.900,53.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.989 |  Acc: 39.122,58.140,64.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 7.293 |  Acc: 23.660,43.290,51.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.957 |  Acc: 39.734,58.508,64.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.752 |  Acc: 26.220,46.210,53.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.951 |  Acc: 39.400,58.690,64.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.458 |  Acc: 30.210,47.510,52.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.922 |  Acc: 39.776,58.774,64.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 7.562 |  Acc: 22.360,42.550,48.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.898 |  Acc: 39.740,58.798,64.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.369 |  Acc: 31.210,48.700,52.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.901 |  Acc: 39.692,59.034,65.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 7.275 |  Acc: 24.100,43.140,50.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.873 |  Acc: 39.774,59.078,65.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 7.310 |  Acc: 25.750,42.390,51.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.845 |  Acc: 40.262,59.584,65.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 7.014 |  Acc: 28.160,46.410,50.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.830 |  Acc: 40.030,59.480,65.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 7.251 |  Acc: 24.630,43.510,50.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.828 |  Acc: 40.202,59.406,65.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 6.167 |  Acc: 33.130,48.830,55.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.824 |  Acc: 40.118,59.644,65.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 7.410 |  Acc: 26.540,40.670,50.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.809 |  Acc: 40.382,59.940,65.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 11.172 |  Acc: 11.730,27.170,40.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.790 |  Acc: 40.452,59.976,66.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.969 |  Acc: 27.520,45.990,51.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.767 |  Acc: 40.454,60.006,66.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 7.419 |  Acc: 25.250,42.470,52.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.764 |  Acc: 40.472,60.262,66.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.207 |  Acc: 32.590,48.470,54.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.760 |  Acc: 40.556,60.050,66.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.884 |  Acc: 27.820,46.570,52.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.728 |  Acc: 40.832,60.612,66.944,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 7.690 |  Acc: 21.610,42.590,49.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.733 |  Acc: 40.400,60.248,66.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.762 |  Acc: 26.900,45.340,54.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.728 |  Acc: 40.574,60.160,66.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.495 |  Acc: 30.520,48.660,54.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.704 |  Acc: 40.550,60.612,67.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 6.777 |  Acc: 25.530,46.760,54.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.708 |  Acc: 40.548,60.576,67.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 7.438 |  Acc: 25.210,42.060,49.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.676 |  Acc: 40.818,60.830,67.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.818 |  Acc: 28.730,46.880,53.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.656 |  Acc: 40.862,61.292,67.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.041 |  Acc: 33.140,49.250,56.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.674 |  Acc: 40.798,60.932,67.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.529 |  Acc: 29.560,47.830,54.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.664 |  Acc: 40.514,60.772,67.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 7.534 |  Acc: 21.590,44.550,53.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.640 |  Acc: 41.230,61.474,68.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 7.011 |  Acc: 27.260,46.220,51.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.628 |  Acc: 41.106,61.536,68.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.494 |  Acc: 29.450,47.950,55.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.613 |  Acc: 41.314,61.746,68.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 6.439 |  Acc: 29.080,47.370,56.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.607 |  Acc: 41.092,61.374,68.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 6.710 |  Acc: 27.550,46.340,55.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.612 |  Acc: 40.954,61.632,67.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.607 |  Acc: 27.730,46.670,54.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.610 |  Acc: 40.898,61.612,68.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.265 |  Acc: 30.350,49.510,55.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.591 |  Acc: 40.906,62.044,68.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 7.035 |  Acc: 25.160,45.490,53.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.568 |  Acc: 41.324,61.706,68.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 7.128 |  Acc: 24.970,44.770,52.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.592 |  Acc: 41.086,61.520,68.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 6.935 |  Acc: 28.320,45.720,53.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.581 |  Acc: 41.154,61.902,68.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 8.126 |  Acc: 18.950,38.340,49.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.578 |  Acc: 41.318,61.942,68.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 6.999 |  Acc: 27.920,42.880,51.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.554 |  Acc: 41.306,62.056,69.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 11.182 |  Acc: 14.530,27.830,39.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.544 |  Acc: 41.518,62.272,69.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 8.676 |  Acc: 17.190,40.960,51.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.542 |  Acc: 41.688,62.330,69.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 6.740 |  Acc: 27.410,47.730,54.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.532 |  Acc: 41.714,62.408,69.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 8.270 |  Acc: 21.660,40.850,49.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.530 |  Acc: 41.450,62.280,69.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 6.660 |  Acc: 27.690,48.140,54.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.530 |  Acc: 41.548,62.332,69.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 8.822 |  Acc: 19.670,38.230,48.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.511 |  Acc: 41.634,62.418,69.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 7.459 |  Acc: 24.350,44.800,53.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.511 |  Acc: 41.510,62.548,69.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.709 |  Acc: 27.940,47.330,54.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.502 |  Acc: 41.600,62.666,69.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 7.157 |  Acc: 27.220,42.690,51.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.493 |  Acc: 41.618,62.766,69.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.577 |  Acc: 30.220,47.000,53.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.500 |  Acc: 41.492,62.546,69.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.708 |  Acc: 24.600,48.460,56.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.474 |  Acc: 41.564,62.714,69.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.359 |  Acc: 31.260,49.580,56.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.487 |  Acc: 41.834,62.840,69.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 8.963 |  Acc: 18.260,40.960,50.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.465 |  Acc: 42.016,62.870,70.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.738 |  Acc: 28.270,45.970,54.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.473 |  Acc: 42.016,62.952,69.940,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 6.232 |  Acc: 31.280,48.310,57.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.463 |  Acc: 41.918,62.884,70.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 5.948 |  Acc: 32.650,51.660,58.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.471 |  Acc: 41.916,62.920,69.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 7.672 |  Acc: 25.110,41.780,49.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.460 |  Acc: 41.698,62.548,69.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 7.047 |  Acc: 26.530,46.340,53.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.436 |  Acc: 41.914,63.338,70.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.783 |  Acc: 26.290,48.590,56.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.432 |  Acc: 41.870,63.268,70.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 6.739 |  Acc: 26.860,46.970,53.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.427 |  Acc: 41.940,63.252,70.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.886 |  Acc: 25.880,45.670,52.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.437 |  Acc: 41.950,62.956,70.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.870 |  Acc: 26.120,48.440,54.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.442 |  Acc: 41.836,63.128,70.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.773 |  Acc: 28.390,44.700,53.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.416 |  Acc: 42.184,63.558,70.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 7.077 |  Acc: 29.220,44.220,53.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.408 |  Acc: 42.028,63.412,70.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.942 |  Acc: 27.550,46.560,53.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.408 |  Acc: 42.070,63.458,70.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 6.731 |  Acc: 30.180,46.950,53.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.406 |  Acc: 42.152,63.538,70.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.022 |  Acc: 31.430,51.290,59.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.388 |  Acc: 41.974,63.612,70.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 7.349 |  Acc: 27.000,43.190,50.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.399 |  Acc: 42.022,63.468,70.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 6.192 |  Acc: 31.470,50.620,57.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.388 |  Acc: 42.268,63.554,70.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 6.612 |  Acc: 27.490,46.680,55.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.395 |  Acc: 42.028,63.748,70.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 6.727 |  Acc: 27.580,47.660,54.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.392 |  Acc: 41.758,63.298,70.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 6.485 |  Acc: 27.540,50.020,57.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.386 |  Acc: 42.324,63.390,70.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 6.264 |  Acc: 30.840,49.460,57.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.369 |  Acc: 42.438,63.660,70.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.753 |  Acc: 27.220,48.630,56.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.367 |  Acc: 42.448,63.952,71.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 7.463 |  Acc: 24.020,44.580,51.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.367 |  Acc: 42.606,63.940,70.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 6.375 |  Acc: 32.880,48.900,55.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.359 |  Acc: 42.338,64.196,71.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.983 |  Acc: 25.160,46.770,54.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.340 |  Acc: 42.592,63.998,71.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.472 |  Acc: 30.510,48.290,55.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.368 |  Acc: 42.274,64.230,70.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.506 |  Acc: 31.040,47.670,54.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.355 |  Acc: 42.418,63.906,71.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.319 |  Acc: 29.490,50.170,57.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.364 |  Acc: 42.248,63.776,71.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 7.143 |  Acc: 26.820,48.240,54.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.338 |  Acc: 42.764,64.082,71.612,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 7.155 |  Acc: 28.490,44.120,50.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.327 |  Acc: 42.294,63.948,71.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 7.726 |  Acc: 21.190,43.560,53.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.327 |  Acc: 43.022,63.922,71.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 6.740 |  Acc: 29.280,47.700,55.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.342 |  Acc: 42.316,63.784,71.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 7.957 |  Acc: 22.970,42.510,49.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.331 |  Acc: 42.426,64.146,71.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 7.881 |  Acc: 25.950,42.400,49.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.351 |  Acc: 42.368,64.058,71.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 6.767 |  Acc: 29.650,45.640,52.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.343 |  Acc: 42.418,64.100,71.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.715 |  Acc: 24.500,49.250,56.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.313 |  Acc: 42.746,64.156,71.494,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 6.849 |  Acc: 26.370,47.720,55.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.324 |  Acc: 42.756,63.994,71.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 7.431 |  Acc: 28.890,43.350,49.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.318 |  Acc: 42.372,64.104,71.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 6.279 |  Acc: 34.020,49.890,57.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.298 |  Acc: 42.748,64.478,71.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 7.745 |  Acc: 27.100,42.540,50.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.310 |  Acc: 42.720,64.184,71.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.553 |  Acc: 29.850,49.540,56.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.318 |  Acc: 42.436,64.252,71.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.758 |  Acc: 27.160,49.710,56.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.313 |  Acc: 42.700,64.444,71.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 6.342 |  Acc: 33.060,49.220,54.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.307 |  Acc: 42.478,64.150,71.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.455 |  Acc: 27.860,50.520,56.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.276 |  Acc: 42.672,64.720,72.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.832 |  Acc: 28.760,47.880,54.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.295 |  Acc: 42.814,64.490,71.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 7.257 |  Acc: 25.930,46.520,55.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.283 |  Acc: 42.304,64.592,71.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 7.217 |  Acc: 26.780,45.420,52.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.631 |  Acc: 46.654,71.322,79.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.374 |  Acc: 44.090,64.880,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.434 |  Acc: 47.526,73.384,82.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.364 |  Acc: 43.900,64.700,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.357 |  Acc: 48.156,74.100,83.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.363 |  Acc: 44.110,64.820,70.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.313 |  Acc: 48.074,74.678,83.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.327 |  Acc: 44.490,65.200,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.279 |  Acc: 48.156,74.954,84.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.337 |  Acc: 44.290,65.010,70.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.260 |  Acc: 48.520,75.012,84.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.378 |  Acc: 44.570,64.520,70.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.226 |  Acc: 48.618,75.040,85.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.348 |  Acc: 44.410,65.260,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.201 |  Acc: 48.610,75.436,85.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.360 |  Acc: 44.470,64.690,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.180 |  Acc: 48.576,75.612,86.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.358 |  Acc: 44.210,65.330,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.172 |  Acc: 48.942,75.586,86.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.393 |  Acc: 44.520,65.040,70.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.154 |  Acc: 48.894,75.838,86.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.394 |  Acc: 44.480,64.930,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.140 |  Acc: 48.732,75.894,86.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.422 |  Acc: 44.060,65.060,70.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.110 |  Acc: 49.202,76.132,87.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.419 |  Acc: 44.590,64.860,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.109 |  Acc: 48.864,76.122,87.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.407 |  Acc: 44.430,64.880,69.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.099 |  Acc: 48.880,76.292,87.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.418 |  Acc: 44.680,64.940,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.081 |  Acc: 49.148,76.432,87.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.421 |  Acc: 44.760,64.960,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.070 |  Acc: 49.232,76.508,87.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.466 |  Acc: 44.070,65.130,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.050 |  Acc: 49.292,76.478,87.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.471 |  Acc: 44.610,64.660,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.050 |  Acc: 48.974,76.504,88.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.389 |  Acc: 45.100,65.030,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.034 |  Acc: 49.240,76.932,88.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.517 |  Acc: 43.530,64.480,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.024 |  Acc: 49.512,76.724,88.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.556 |  Acc: 43.850,64.470,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.015 |  Acc: 49.278,76.792,88.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.478 |  Acc: 44.040,64.830,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 3.009 |  Acc: 49.212,76.920,88.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.507 |  Acc: 43.720,64.950,69.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 3.009 |  Acc: 49.412,76.740,88.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.542 |  Acc: 43.700,63.970,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.995 |  Acc: 49.486,76.870,88.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.471 |  Acc: 44.900,64.840,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.992 |  Acc: 49.278,76.994,88.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.561 |  Acc: 43.750,64.450,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.978 |  Acc: 49.490,77.048,89.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.517 |  Acc: 44.220,64.340,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.958 |  Acc: 49.740,77.340,89.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.514 |  Acc: 44.210,64.700,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.963 |  Acc: 49.638,77.224,89.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.550 |  Acc: 44.050,64.510,68.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.967 |  Acc: 49.648,77.222,89.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.571 |  Acc: 43.860,64.020,68.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.952 |  Acc: 49.646,77.384,89.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.565 |  Acc: 44.040,64.000,68.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.941 |  Acc: 49.578,77.270,89.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.640 |  Acc: 43.470,63.800,68.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.939 |  Acc: 49.500,77.302,89.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.656 |  Acc: 43.080,63.580,68.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.939 |  Acc: 49.588,77.366,89.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.586 |  Acc: 43.890,64.330,68.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.924 |  Acc: 49.644,77.496,89.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.584 |  Acc: 43.690,64.450,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.930 |  Acc: 49.688,77.474,89.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.537 |  Acc: 44.280,64.790,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.909 |  Acc: 49.746,77.630,89.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.533 |  Acc: 44.720,64.740,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.914 |  Acc: 49.624,77.614,89.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.543 |  Acc: 44.820,64.700,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.906 |  Acc: 49.670,77.782,90.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.641 |  Acc: 44.490,64.340,68.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.890 |  Acc: 50.034,77.912,90.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.564 |  Acc: 44.480,65.190,68.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.888 |  Acc: 49.928,77.882,90.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.633 |  Acc: 43.870,64.160,68.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.887 |  Acc: 49.904,77.964,90.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.624 |  Acc: 43.900,64.360,68.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.894 |  Acc: 49.968,77.954,90.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.600 |  Acc: 45.020,64.640,68.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.887 |  Acc: 49.722,77.922,90.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.620 |  Acc: 44.370,64.100,68.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.876 |  Acc: 49.706,78.028,90.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.666 |  Acc: 43.390,64.680,68.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.883 |  Acc: 49.446,77.974,90.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.577 |  Acc: 44.980,64.550,68.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.871 |  Acc: 49.734,77.836,90.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.753 |  Acc: 43.010,63.520,68.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.871 |  Acc: 49.824,77.930,90.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.650 |  Acc: 44.410,64.450,67.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.870 |  Acc: 49.910,77.986,90.654,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.657 |  Acc: 43.810,63.730,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.859 |  Acc: 49.918,78.062,90.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.698 |  Acc: 43.860,64.350,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.854 |  Acc: 50.082,78.132,90.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.885 |  Acc: 42.100,62.620,67.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.855 |  Acc: 50.008,78.192,90.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.713 |  Acc: 44.000,63.910,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.850 |  Acc: 50.092,78.228,90.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.770 |  Acc: 43.210,63.470,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.843 |  Acc: 49.916,78.196,90.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.838 |  Acc: 42.710,63.350,67.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.831 |  Acc: 50.170,78.634,90.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.795 |  Acc: 43.760,63.690,67.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.840 |  Acc: 49.910,78.252,90.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.702 |  Acc: 43.950,64.290,68.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.836 |  Acc: 50.098,78.252,91.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.764 |  Acc: 43.300,63.240,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.837 |  Acc: 50.048,78.566,90.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.634 |  Acc: 44.240,64.540,68.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.835 |  Acc: 50.078,78.278,91.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.655 |  Acc: 44.870,64.170,68.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.833 |  Acc: 49.952,78.262,90.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.667 |  Acc: 44.490,64.270,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.821 |  Acc: 50.096,78.464,91.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.728 |  Acc: 42.960,63.370,68.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.823 |  Acc: 50.298,78.278,91.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.732 |  Acc: 43.270,63.830,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.819 |  Acc: 49.948,78.634,91.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.825 |  Acc: 42.800,63.090,67.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.819 |  Acc: 50.142,78.486,91.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.748 |  Acc: 43.700,63.480,67.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.823 |  Acc: 50.242,78.402,91.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.774 |  Acc: 43.920,63.940,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.828 |  Acc: 50.068,78.502,90.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.706 |  Acc: 44.000,64.300,68.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.814 |  Acc: 50.064,78.550,91.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.686 |  Acc: 44.650,64.010,68.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.802 |  Acc: 50.356,78.702,91.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.885 |  Acc: 42.970,62.630,67.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.812 |  Acc: 50.112,78.360,91.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.624 |  Acc: 45.110,64.000,67.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.806 |  Acc: 50.116,78.738,91.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.856 |  Acc: 43.080,63.190,67.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.799 |  Acc: 50.172,78.626,91.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.840 |  Acc: 43.650,63.510,67.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.797 |  Acc: 50.110,78.722,91.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 5.028 |  Acc: 40.320,62.150,66.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.796 |  Acc: 50.220,78.740,91.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.770 |  Acc: 43.920,63.410,67.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.801 |  Acc: 49.982,78.764,91.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.766 |  Acc: 43.690,63.800,67.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.807 |  Acc: 50.126,78.906,91.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.786 |  Acc: 43.650,63.550,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.655 |  Acc: 51.054,80.684,93.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.507 |  Acc: 45.630,65.260,69.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.609 |  Acc: 50.944,81.222,94.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.515 |  Acc: 45.940,65.170,69.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.598 |  Acc: 51.312,81.310,94.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.491 |  Acc: 46.020,65.460,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.586 |  Acc: 51.326,81.240,94.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.517 |  Acc: 45.730,65.480,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.581 |  Acc: 51.412,81.510,94.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.520 |  Acc: 45.840,65.170,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.564 |  Acc: 51.590,81.716,94.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.524 |  Acc: 45.910,65.060,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.575 |  Acc: 51.312,81.442,94.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.518 |  Acc: 45.990,65.290,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.567 |  Acc: 51.364,81.638,94.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.498 |  Acc: 45.940,65.500,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.552 |  Acc: 51.646,81.636,94.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.528 |  Acc: 45.990,65.480,69.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.555 |  Acc: 51.682,81.752,94.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.520 |  Acc: 45.820,65.330,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.550 |  Acc: 51.646,81.840,94.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.520 |  Acc: 45.750,65.400,69.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.545 |  Acc: 51.488,81.856,94.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.522 |  Acc: 45.720,65.410,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.557 |  Acc: 51.538,81.828,94.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.523 |  Acc: 46.020,65.470,69.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.548 |  Acc: 51.552,81.942,95.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.522 |  Acc: 45.690,65.580,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.545 |  Acc: 51.348,82.014,94.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.531 |  Acc: 45.810,65.510,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.546 |  Acc: 51.600,81.956,95.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.526 |  Acc: 45.940,65.310,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.538 |  Acc: 51.558,81.918,95.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.534 |  Acc: 45.890,65.110,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.539 |  Acc: 51.410,81.900,95.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.530 |  Acc: 45.950,65.250,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.536 |  Acc: 51.708,82.050,95.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.539 |  Acc: 45.950,65.270,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.536 |  Acc: 51.478,81.920,95.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.535 |  Acc: 45.600,65.590,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.528 |  Acc: 51.714,82.046,95.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.538 |  Acc: 45.930,65.530,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.535 |  Acc: 51.738,81.778,95.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.530 |  Acc: 46.080,65.430,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.532 |  Acc: 51.848,82.102,95.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.545 |  Acc: 46.250,65.310,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.532 |  Acc: 51.656,81.968,95.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.534 |  Acc: 46.010,65.670,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.532 |  Acc: 51.494,81.900,95.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.533 |  Acc: 45.700,65.530,69.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.531 |  Acc: 51.786,81.992,95.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.550 |  Acc: 45.730,65.420,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.528 |  Acc: 51.496,82.302,95.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.554 |  Acc: 45.720,65.190,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.517 |  Acc: 51.798,82.116,95.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.554 |  Acc: 45.950,65.300,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.527 |  Acc: 51.724,82.074,95.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.570 |  Acc: 45.860,65.260,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.522 |  Acc: 51.742,82.194,95.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.551 |  Acc: 45.720,65.340,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.525 |  Acc: 51.618,81.994,95.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.561 |  Acc: 45.740,65.370,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.526 |  Acc: 51.588,82.020,95.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.543 |  Acc: 45.580,65.310,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.523 |  Acc: 51.680,82.074,95.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.566 |  Acc: 45.390,65.100,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.516 |  Acc: 51.646,82.332,95.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.535 |  Acc: 45.670,65.590,69.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.510 |  Acc: 52.012,82.220,95.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.556 |  Acc: 45.630,65.670,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.517 |  Acc: 51.508,82.094,95.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.552 |  Acc: 45.970,65.470,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.508 |  Acc: 51.758,82.196,95.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.548 |  Acc: 45.620,65.520,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.506 |  Acc: 51.638,82.352,95.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.550 |  Acc: 45.710,65.560,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.503 |  Acc: 51.744,82.414,95.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.528 |  Acc: 45.770,65.490,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.498 |  Acc: 51.680,82.624,95.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.549 |  Acc: 45.940,65.430,69.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.495 |  Acc: 51.722,82.576,95.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.560 |  Acc: 45.780,65.460,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.493 |  Acc: 51.798,82.582,95.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.542 |  Acc: 45.750,65.600,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.499 |  Acc: 51.898,82.366,95.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.561 |  Acc: 45.920,65.400,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.500 |  Acc: 51.840,82.462,95.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.552 |  Acc: 45.850,65.370,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.493 |  Acc: 51.842,82.548,95.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.561 |  Acc: 45.640,65.390,69.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.494 |  Acc: 51.770,82.572,95.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.548 |  Acc: 45.960,65.430,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.497 |  Acc: 52.034,82.418,95.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.567 |  Acc: 45.880,65.550,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.496 |  Acc: 51.826,82.340,95.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.548 |  Acc: 46.020,65.690,69.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.498 |  Acc: 51.816,82.458,95.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.540 |  Acc: 45.880,65.450,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.487 |  Acc: 51.786,82.660,95.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.553 |  Acc: 45.850,65.470,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.491 |  Acc: 51.832,82.678,95.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.543 |  Acc: 45.880,65.380,69.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.498 |  Acc: 51.710,82.204,95.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.541 |  Acc: 45.750,65.360,69.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.494 |  Acc: 51.668,82.420,95.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.545 |  Acc: 45.910,65.660,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.486 |  Acc: 51.890,82.458,95.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.556 |  Acc: 45.720,65.670,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.485 |  Acc: 51.800,82.608,95.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.547 |  Acc: 45.770,65.760,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.490 |  Acc: 51.784,82.498,95.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.551 |  Acc: 45.980,65.580,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.492 |  Acc: 51.932,82.546,95.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.558 |  Acc: 45.770,65.560,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.492 |  Acc: 51.736,82.654,95.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.547 |  Acc: 45.980,65.510,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.490 |  Acc: 51.988,82.538,95.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.558 |  Acc: 45.870,65.320,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.485 |  Acc: 51.972,82.616,95.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.549 |  Acc: 45.720,65.740,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.495 |  Acc: 51.808,82.620,95.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.544 |  Acc: 46.020,65.700,68.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.480 |  Acc: 51.736,82.810,95.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.547 |  Acc: 45.810,65.700,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.491 |  Acc: 51.878,82.528,95.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.550 |  Acc: 45.800,65.650,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.490 |  Acc: 51.722,82.770,95.736,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.565 |  Acc: 45.590,65.590,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.494 |  Acc: 51.888,82.582,95.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.550 |  Acc: 46.170,65.490,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.484 |  Acc: 51.960,82.646,96.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.566 |  Acc: 45.910,65.390,69.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.491 |  Acc: 51.850,82.624,95.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.559 |  Acc: 45.710,65.520,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.490 |  Acc: 51.858,82.634,95.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.551 |  Acc: 45.760,65.290,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.488 |  Acc: 51.858,82.652,95.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.546 |  Acc: 46.030,65.510,69.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.489 |  Acc: 51.872,82.674,95.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.554 |  Acc: 45.990,65.600,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.491 |  Acc: 51.762,82.456,95.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.562 |  Acc: 45.980,65.460,69.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.486 |  Acc: 51.790,82.664,95.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.560 |  Acc: 45.860,65.310,69.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.495 |  Acc: 51.886,82.336,95.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.560 |  Acc: 46.210,65.600,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.498 |  Acc: 51.852,82.396,95.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.556 |  Acc: 45.760,65.590,69.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.486 |  Acc: 51.594,82.538,95.938,% | Adaptive Acc:86.942% | clf_exit: 0.358 0.452 0.190
Testing: Epoch=299 | Loss: 4.556 |  Acc: 45.920,65.370,69.140,% | Adaptive Acc:63.960% | clf_exit: 0.402 0.379 0.220

circles: 0
Testing: Epoch=299 | Loss: 89.675 |  Acc: 1.410,1.090,2.950,% | Adaptive Acc:1.410% | clf_exit: 1.000 0.000 0.000
circles: 1
Testing: Epoch=299 | Loss: 75.422 |  Acc: 1.440,1.450,4.910,% | Adaptive Acc:1.440% | clf_exit: 1.000 0.000 0.000
circles: 2
Testing: Epoch=299 | Loss: 54.032 |  Acc: 1.440,2.800,8.440,% | Adaptive Acc:1.440% | clf_exit: 0.998 0.002 0.000
circles: 3
Testing: Epoch=299 | Loss: 32.405 |  Acc: 1.710,8.430,21.470,% | Adaptive Acc:1.870% | clf_exit: 0.980 0.014 0.005
circles: 4
Testing: Epoch=299 | Loss: 13.108 |  Acc: 5.050,34.670,53.700,% | Adaptive Acc:16.370% | clf_exit: 0.723 0.153 0.125
circles: 5
Testing: Epoch=299 | Loss: 4.556 |  Acc: 45.920,65.370,69.140,% | Adaptive Acc:63.960% | clf_exit: 0.402 0.379 0.220
