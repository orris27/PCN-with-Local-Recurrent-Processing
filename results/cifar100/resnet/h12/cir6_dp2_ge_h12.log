==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=16, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=64, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=64, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule2(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.470 | Acc: 0.781,0.781,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.740 | Acc: 0.707,1.302,1.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.516 | Acc: 0.857,1.296,1.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.363 | Acc: 0.961,1.191,1.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.268 | Acc: 1.051,1.235,1.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.218 | Acc: 1.083,1.230,1.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 14.167 | Acc: 1.123,1.240,1.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 14.126 | Acc: 1.258,1.374,1.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 14.098 | Acc: 1.320,1.470,1.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 14.069 | Acc: 1.373,1.550,1.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 14.047 | Acc: 1.415,1.644,1.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 14.025 | Acc: 1.446,1.693,1.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 14.009 | Acc: 1.426,1.721,1.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.994 | Acc: 1.449,1.751,1.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.977 | Acc: 1.496,1.760,1.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.960 | Acc: 1.524,1.830,1.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.942 | Acc: 1.521,1.850,1.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.926 | Acc: 1.553,1.881,1.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.911 | Acc: 1.554,1.898,1.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.894 | Acc: 1.581,1.917,1.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.897 | Acc: 2.344,2.344,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.569 | Acc: 2.344,2.381,1.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.512 | Acc: 1.982,2.210,1.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.518 | Acc: 1.972,2.152,1.101,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 13.767 | Acc: 0.781,0.781,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.550 | Acc: 2.121,2.604,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.563 | Acc: 2.191,2.325,1.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.554 | Acc: 2.113,2.395,1.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.567 | Acc: 2.093,2.479,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.567 | Acc: 2.042,2.522,1.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.559 | Acc: 2.053,2.550,1.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.558 | Acc: 1.950,2.466,1.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.550 | Acc: 1.941,2.455,1.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.537 | Acc: 1.994,2.581,1.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.527 | Acc: 1.986,2.608,1.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.528 | Acc: 2.004,2.598,1.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.527 | Acc: 2.033,2.584,1.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.519 | Acc: 2.050,2.610,1.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.513 | Acc: 2.057,2.683,1.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.510 | Acc: 2.035,2.720,1.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.505 | Acc: 2.040,2.726,1.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.493 | Acc: 2.064,2.800,1.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.483 | Acc: 2.119,2.885,1.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.473 | Acc: 2.133,2.940,1.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.316 | Acc: 1.562,1.562,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.580 | Acc: 2.344,2.753,1.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.561 | Acc: 2.210,3.068,1.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.545 | Acc: 2.113,3.074,1.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 13.379 | Acc: 2.344,5.469,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.224 | Acc: 2.158,4.018,1.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.241 | Acc: 2.420,3.830,1.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.218 | Acc: 2.510,3.919,1.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.225 | Acc: 2.382,4.012,1.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.210 | Acc: 2.529,4.076,1.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.198 | Acc: 2.596,4.152,1.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.193 | Acc: 2.549,4.338,1.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.190 | Acc: 2.552,4.430,1.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.183 | Acc: 2.577,4.498,1.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.177 | Acc: 2.519,4.579,1.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.166 | Acc: 2.542,4.645,1.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.161 | Acc: 2.593,4.587,1.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.156 | Acc: 2.577,4.670,1.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.149 | Acc: 2.591,4.788,1.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.137 | Acc: 2.621,4.924,1.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.128 | Acc: 2.624,5.011,1.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.117 | Acc: 2.644,5.130,1.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.111 | Acc: 2.645,5.231,1.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.103 | Acc: 2.655,5.381,1.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.879 | Acc: 0.781,5.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.068 | Acc: 2.083,6.399,1.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.061 | Acc: 2.020,6.383,1.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.064 | Acc: 1.985,6.327,1.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 12.794 | Acc: 3.125,7.812,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.952 | Acc: 2.121,8.036,1.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.917 | Acc: 2.439,7.832,1.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.907 | Acc: 2.433,7.544,1.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.902 | Acc: 2.546,7.677,1.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.886 | Acc: 2.630,7.604,1.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.885 | Acc: 2.692,7.690,1.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.879 | Acc: 2.770,7.752,1.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.868 | Acc: 2.800,7.866,1.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.856 | Acc: 2.849,7.860,1.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.845 | Acc: 2.849,7.945,1.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.836 | Acc: 2.839,7.929,1.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.830 | Acc: 2.846,7.910,1.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.823 | Acc: 2.859,7.965,1.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.816 | Acc: 2.850,8.063,1.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.807 | Acc: 2.842,8.085,1.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.797 | Acc: 2.850,8.195,1.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.791 | Acc: 2.852,8.225,1.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.789 | Acc: 2.844,8.213,1.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.781 | Acc: 2.838,8.280,1.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.743 | Acc: 0.000,9.375,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.840 | Acc: 2.716,6.696,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.837 | Acc: 2.801,6.860,2.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.845 | Acc: 2.715,7.057,2.011,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 12.832 | Acc: 3.125,10.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.657 | Acc: 3.199,8.966,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.621 | Acc: 3.068,9.737,2.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.625 | Acc: 3.356,9.900,2.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.614 | Acc: 3.270,9.992,2.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.610 | Acc: 3.311,10.195,2.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.592 | Acc: 3.390,10.169,1.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.580 | Acc: 3.469,10.084,1.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.568 | Acc: 3.358,10.059,1.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.562 | Acc: 3.345,10.104,1.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.554 | Acc: 3.347,10.187,1.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.553 | Acc: 3.344,10.156,1.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.549 | Acc: 3.339,10.130,1.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.549 | Acc: 3.367,10.192,1.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.543 | Acc: 3.445,10.201,1.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.538 | Acc: 3.496,10.247,1.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.532 | Acc: 3.519,10.314,1.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.522 | Acc: 3.551,10.369,1.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.520 | Acc: 3.590,10.368,1.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.512 | Acc: 3.621,10.388,1.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.471 | Acc: 2.344,9.375,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.602 | Acc: 1.972,10.156,1.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.580 | Acc: 2.210,10.137,1.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.587 | Acc: 2.305,10.361,1.947,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 12.148 | Acc: 5.469,16.406,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.353 | Acc: 4.427,10.751,1.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.341 | Acc: 4.745,11.109,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.345 | Acc: 4.867,10.989,1.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.335 | Acc: 4.697,11.169,1.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.320 | Acc: 4.757,11.239,1.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.319 | Acc: 4.629,11.325,1.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.303 | Acc: 4.654,11.442,1.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.299 | Acc: 4.668,11.432,1.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.295 | Acc: 4.631,11.464,1.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.282 | Acc: 4.668,11.478,1.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.275 | Acc: 4.663,11.471,1.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.268 | Acc: 4.752,11.599,1.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.265 | Acc: 4.801,11.632,1.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.261 | Acc: 4.843,11.655,1.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.256 | Acc: 4.877,11.708,1.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.254 | Acc: 4.916,11.692,1.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.248 | Acc: 4.951,11.730,1.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.239 | Acc: 4.997,11.840,1.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.229 | Acc: 5.067,11.905,1.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.527 | Acc: 5.469,7.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.840 | Acc: 5.097,7.143,1.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.834 | Acc: 4.973,7.241,1.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.847 | Acc: 5.174,7.159,1.883,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 11.844 | Acc: 7.812,17.969,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.117 | Acc: 6.399,13.021,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.058 | Acc: 6.860,13.453,2.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.065 | Acc: 6.545,13.102,2.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.070 | Acc: 6.260,13.166,2.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.074 | Acc: 6.157,13.018,2.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.057 | Acc: 6.250,13.100,2.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.064 | Acc: 6.355,13.065,2.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.054 | Acc: 6.332,13.160,2.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.042 | Acc: 6.423,13.195,2.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.037 | Acc: 6.460,13.161,1.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.035 | Acc: 6.494,13.150,1.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.027 | Acc: 6.522,13.216,2.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.016 | Acc: 6.573,13.236,2.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.003 | Acc: 6.712,13.287,2.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.001 | Acc: 6.722,13.382,2.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.996 | Acc: 6.751,13.415,1.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.985 | Acc: 6.807,13.485,1.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.981 | Acc: 6.843,13.537,2.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.975 | Acc: 6.918,13.603,1.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.976 | Acc: 9.375,8.594,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.102 | Acc: 7.999,11.533,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.078 | Acc: 7.298,11.814,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.089 | Acc: 7.403,11.744,2.395,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 11.859 | Acc: 7.812,14.844,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.846 | Acc: 9.040,14.844,2.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.790 | Acc: 9.032,15.587,2.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.823 | Acc: 8.876,14.946,2.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.838 | Acc: 8.565,15.114,2.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.860 | Acc: 8.400,14.960,2.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.866 | Acc: 8.503,15.044,2.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.860 | Acc: 8.633,15.293,2.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.862 | Acc: 8.671,15.276,2.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.866 | Acc: 8.572,15.267,2.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.861 | Acc: 8.574,15.302,2.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.843 | Acc: 8.626,15.427,2.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.838 | Acc: 8.522,15.346,2.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.825 | Acc: 8.543,15.454,2.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.821 | Acc: 8.488,15.519,2.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.811 | Acc: 8.503,15.555,2.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.803 | Acc: 8.501,15.550,2.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.791 | Acc: 8.500,15.634,2.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.782 | Acc: 8.550,15.670,2.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.770 | Acc: 8.586,15.754,2.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.255 | Acc: 9.375,9.375,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.284 | Acc: 7.515,11.979,2.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.213 | Acc: 7.755,12.214,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.222 | Acc: 7.928,12.039,2.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 11.624 | Acc: 10.156,17.969,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.530 | Acc: 9.933,16.853,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.555 | Acc: 9.070,16.978,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.564 | Acc: 9.196,16.419,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.551 | Acc: 9.510,16.705,2.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.521 | Acc: 9.746,17.164,2.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.512 | Acc: 9.892,17.401,2.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.503 | Acc: 9.962,17.420,2.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.488 | Acc: 9.787,17.420,2.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.483 | Acc: 9.845,17.554,2.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.477 | Acc: 9.873,17.561,2.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.465 | Acc: 9.923,17.707,2.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.452 | Acc: 9.933,17.855,2.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.450 | Acc: 9.917,17.912,2.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.444 | Acc: 9.995,18.002,2.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.441 | Acc: 9.980,17.982,2.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.438 | Acc: 9.891,17.993,2.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.432 | Acc: 9.913,18.047,2.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.424 | Acc: 9.946,18.129,2.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.423 | Acc: 9.951,18.172,2.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.978 | Acc: 7.812,16.406,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.890 | Acc: 8.110,13.914,2.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.895 | Acc: 8.518,13.319,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.916 | Acc: 8.991,13.371,2.561,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 11.400 | Acc: 10.156,15.625,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.259 | Acc: 10.751,18.601,2.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.262 | Acc: 11.109,19.245,2.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.257 | Acc: 10.886,19.506,2.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.252 | Acc: 10.909,19.618,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.233 | Acc: 10.953,19.841,2.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.221 | Acc: 11.067,19.809,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.223 | Acc: 10.976,19.792,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.222 | Acc: 10.981,19.740,2.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.207 | Acc: 10.955,19.842,2.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.204 | Acc: 10.864,19.850,2.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.214 | Acc: 10.736,19.849,2.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.211 | Acc: 10.717,19.911,2.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.212 | Acc: 10.788,19.866,2.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.199 | Acc: 10.876,19.937,2.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.192 | Acc: 10.880,19.926,2.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.188 | Acc: 10.877,19.926,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.183 | Acc: 10.931,19.884,2.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.176 | Acc: 11.024,19.977,2.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.179 | Acc: 11.003,19.972,2.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.436 | Acc: 7.031,20.312,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.458 | Acc: 8.445,18.601,2.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.445 | Acc: 8.651,18.274,2.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.450 | Acc: 8.773,18.097,2.497,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 11.035 | Acc: 11.719,17.969,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.954 | Acc: 12.165,20.833,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.051 | Acc: 11.776,20.541,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.033 | Acc: 11.898,20.902,2.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.000 | Acc: 12.191,21.209,2.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.001 | Acc: 12.299,21.241,2.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.007 | Acc: 12.248,21.320,2.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.012 | Acc: 12.317,21.177,2.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.002 | Acc: 12.194,21.215,2.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.992 | Acc: 12.258,21.297,2.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.983 | Acc: 12.306,21.354,2.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.988 | Acc: 12.299,21.341,2.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.983 | Acc: 12.328,21.470,2.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.976 | Acc: 12.276,21.441,2.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.977 | Acc: 12.236,21.455,2.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.969 | Acc: 12.279,21.514,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.971 | Acc: 12.266,21.483,2.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.966 | Acc: 12.230,21.547,2.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.958 | Acc: 12.245,21.654,2.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.954 | Acc: 12.227,21.736,2.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.002 | Acc: 13.281,22.656,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.195 | Acc: 12.909,19.568,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.178 | Acc: 12.881,18.960,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.152 | Acc: 12.859,19.006,2.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 11.111 | Acc: 14.844,17.188,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.797 | Acc: 13.802,22.693,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.785 | Acc: 12.995,23.075,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.776 | Acc: 13.140,23.053,2.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.792 | Acc: 12.934,23.023,2.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.794 | Acc: 12.778,23.291,2.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.789 | Acc: 13.004,23.399,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.804 | Acc: 12.910,23.221,2.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.807 | Acc: 13.048,23.171,2.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.796 | Acc: 13.147,23.394,2.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.793 | Acc: 13.246,23.492,2.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.787 | Acc: 13.338,23.526,2.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.774 | Acc: 13.482,23.684,2.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.765 | Acc: 13.616,23.722,2.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.754 | Acc: 13.707,23.782,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.751 | Acc: 13.720,23.759,2.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.743 | Acc: 13.873,23.876,2.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.743 | Acc: 13.907,23.827,2.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.736 | Acc: 13.989,23.914,2.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.734 | Acc: 14.048,23.926,2.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.069 | Acc: 10.938,21.094,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.197 | Acc: 11.607,19.792,1.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.167 | Acc: 11.547,19.817,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.144 | Acc: 11.629,20.197,2.228,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 10.396 | Acc: 16.406,26.562,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.640 | Acc: 14.211,25.149,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.578 | Acc: 15.492,25.724,2.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.594 | Acc: 15.548,25.564,2.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.602 | Acc: 15.548,25.309,2.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.610 | Acc: 15.524,25.186,2.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.602 | Acc: 15.548,25.181,2.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.602 | Acc: 15.475,24.967,2.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.588 | Acc: 15.576,24.918,2.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.580 | Acc: 15.647,24.987,2.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.567 | Acc: 15.660,25.074,2.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.567 | Acc: 15.667,25.039,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.567 | Acc: 15.583,25.016,2.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.560 | Acc: 15.667,25.084,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.552 | Acc: 15.706,25.153,2.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.549 | Acc: 15.672,25.182,2.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.547 | Acc: 15.715,25.175,2.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.540 | Acc: 15.815,25.259,2.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.531 | Acc: 15.902,25.346,2.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.526 | Acc: 15.982,25.367,2.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.824 | Acc: 9.375,19.531,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.710 | Acc: 9.003,17.299,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.665 | Acc: 9.356,17.664,2.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.667 | Acc: 9.580,17.482,2.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 10.227 | Acc: 19.531,28.125,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.440 | Acc: 16.964,26.414,2.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.352 | Acc: 17.588,27.039,2.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.368 | Acc: 17.380,26.460,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.381 | Acc: 17.477,26.543,2.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.386 | Acc: 17.420,26.477,2.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.393 | Acc: 17.497,26.588,2.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.391 | Acc: 17.260,26.452,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.384 | Acc: 17.328,26.393,2.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.385 | Acc: 17.192,26.260,2.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.382 | Acc: 17.215,26.310,2.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.384 | Acc: 17.212,26.294,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.382 | Acc: 17.191,26.374,2.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.380 | Acc: 17.167,26.446,2.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.367 | Acc: 17.196,26.576,2.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.368 | Acc: 17.138,26.562,2.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.361 | Acc: 17.178,26.650,2.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.358 | Acc: 17.279,26.691,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.357 | Acc: 17.289,26.692,2.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.348 | Acc: 17.304,26.866,2.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.628 | Acc: 14.844,20.312,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.901 | Acc: 14.658,21.466,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.831 | Acc: 14.920,21.837,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.811 | Acc: 14.613,22.041,2.792,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 11.346 | Acc: 12.500,21.094,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.381 | Acc: 16.443,26.451,2.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.318 | Acc: 17.321,27.001,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.321 | Acc: 17.264,27.126,2.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.317 | Acc: 17.332,27.305,2.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.324 | Acc: 17.288,27.259,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.311 | Acc: 17.575,27.395,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.295 | Acc: 17.559,27.593,2.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.289 | Acc: 17.488,27.679,2.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.271 | Acc: 17.749,27.788,2.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.260 | Acc: 17.747,27.888,2.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.255 | Acc: 17.778,27.991,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.256 | Acc: 17.816,27.930,2.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.250 | Acc: 17.870,27.930,2.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.247 | Acc: 18.002,28.019,2.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.245 | Acc: 18.049,28.021,2.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.246 | Acc: 18.125,28.028,2.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.242 | Acc: 18.207,28.059,2.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.232 | Acc: 18.337,28.108,2.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.237 | Acc: 18.365,28.100,2.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.378 | Acc: 11.719,28.125,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.769 | Acc: 11.384,24.182,1.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.730 | Acc: 11.452,23.819,1.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.724 | Acc: 11.386,23.630,1.934,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 10.724 | Acc: 14.844,23.438,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.309 | Acc: 19.234,29.427,2.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.335 | Acc: 18.388,28.887,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.322 | Acc: 19.121,29.380,2.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.329 | Acc: 19.271,29.562,2.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.326 | Acc: 19.353,29.602,2.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.325 | Acc: 19.363,29.513,2.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.321 | Acc: 19.398,29.765,2.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.315 | Acc: 19.308,29.615,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.317 | Acc: 19.328,29.480,2.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.315 | Acc: 19.360,29.524,2.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.316 | Acc: 19.326,29.440,2.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.318 | Acc: 19.278,29.380,2.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.311 | Acc: 19.244,29.460,2.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.312 | Acc: 19.281,29.443,2.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.295 | Acc: 19.396,29.623,2.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.297 | Acc: 19.434,29.576,2.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.285 | Acc: 19.499,29.649,2.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.279 | Acc: 19.551,29.670,2.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.272 | Acc: 19.593,29.739,2.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.589 | Acc: 22.656,32.031,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.997 | Acc: 14.993,24.740,2.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.906 | Acc: 15.720,24.943,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.879 | Acc: 15.766,24.769,2.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 10.280 | Acc: 20.312,28.125,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.107 | Acc: 20.312,30.469,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.067 | Acc: 20.598,30.640,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.101 | Acc: 20.172,30.161,2.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.119 | Acc: 20.100,30.141,2.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.105 | Acc: 20.622,30.391,2.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.104 | Acc: 20.448,30.294,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.114 | Acc: 20.429,30.629,2.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.135 | Acc: 20.439,30.231,2.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.134 | Acc: 20.494,30.210,2.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.125 | Acc: 20.519,30.403,2.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.129 | Acc: 20.560,30.299,2.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.134 | Acc: 20.672,30.310,2.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.126 | Acc: 20.636,30.271,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.123 | Acc: 20.749,30.374,2.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.111 | Acc: 20.858,30.445,2.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.106 | Acc: 20.889,30.481,2.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.099 | Acc: 20.947,30.560,2.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.091 | Acc: 21.044,30.631,2.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.089 | Acc: 21.001,30.649,2.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.789 | Acc: 11.719,25.000,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.362 | Acc: 13.244,22.396,2.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.326 | Acc: 13.815,22.713,2.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.312 | Acc: 13.806,22.579,2.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 10.375 | Acc: 14.844,28.906,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.925 | Acc: 22.173,31.287,2.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.918 | Acc: 22.561,32.146,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.925 | Acc: 22.643,31.993,2.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.967 | Acc: 22.309,31.520,2.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.968 | Acc: 22.084,31.799,2.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.961 | Acc: 22.308,31.702,2.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.980 | Acc: 22.135,31.577,2.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.965 | Acc: 22.118,31.740,2.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.949 | Acc: 22.229,31.902,2.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.938 | Acc: 22.236,32.016,2.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.928 | Acc: 22.476,32.166,2.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.922 | Acc: 22.608,32.287,2.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.908 | Acc: 22.725,32.552,2.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.906 | Acc: 22.784,32.657,2.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.902 | Acc: 22.778,32.698,2.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.907 | Acc: 22.737,32.679,2.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.905 | Acc: 22.785,32.721,2.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.902 | Acc: 22.821,32.771,2.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.898 | Acc: 22.831,32.784,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.347 | Acc: 16.406,32.812,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.303 | Acc: 19.234,30.097,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.323 | Acc: 18.979,29.592,2.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.307 | Acc: 19.173,29.406,3.048,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 9.795 | Acc: 28.906,37.500,0.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.811 | Acc: 23.251,35.751,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.734 | Acc: 23.628,35.309,2.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.743 | Acc: 23.412,34.516,2.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.743 | Acc: 23.650,34.240,2.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.767 | Acc: 23.654,33.640,2.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.763 | Acc: 23.625,33.704,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.760 | Acc: 23.615,33.771,2.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.753 | Acc: 23.874,34.074,2.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.753 | Acc: 23.964,34.228,2.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.749 | Acc: 23.978,34.293,2.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.745 | Acc: 24.120,34.322,2.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.745 | Acc: 24.096,34.326,2.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.748 | Acc: 24.150,34.336,2.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.746 | Acc: 24.160,34.336,2.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.744 | Acc: 24.281,34.388,2.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.742 | Acc: 24.289,34.382,2.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.736 | Acc: 24.349,34.405,2.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.732 | Acc: 24.364,34.343,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.727 | Acc: 24.426,34.348,2.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.433 | Acc: 22.656,30.469,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.502 | Acc: 17.113,28.906,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.473 | Acc: 17.721,29.554,2.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.490 | Acc: 17.380,29.342,2.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 9.815 | Acc: 25.000,32.031,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.657 | Acc: 24.293,35.156,2.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.651 | Acc: 24.619,35.213,2.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.658 | Acc: 24.616,35.259,2.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.666 | Acc: 24.691,34.973,2.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.663 | Acc: 24.482,35.133,2.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.637 | Acc: 24.768,35.395,2.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.626 | Acc: 25.011,35.544,2.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.605 | Acc: 25.165,35.714,2.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.601 | Acc: 25.393,35.791,2.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.598 | Acc: 25.439,35.844,2.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.599 | Acc: 25.421,35.782,2.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.601 | Acc: 25.298,35.850,2.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.597 | Acc: 25.290,35.818,2.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.583 | Acc: 25.475,35.960,2.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.581 | Acc: 25.517,36.101,2.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.584 | Acc: 25.499,36.098,2.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.582 | Acc: 25.511,36.052,2.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.580 | Acc: 25.504,36.011,2.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.584 | Acc: 25.494,35.927,2.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.345 | Acc: 10.938,24.219,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.707 | Acc: 10.082,22.879,2.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.722 | Acc: 9.718,22.351,2.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.653 | Acc: 9.823,22.605,2.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 9.862 | Acc: 20.312,35.156,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.494 | Acc: 26.004,37.426,3.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.474 | Acc: 26.677,37.767,3.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.487 | Acc: 26.396,37.398,3.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.488 | Acc: 26.495,37.587,2.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.520 | Acc: 26.354,36.989,3.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.515 | Acc: 26.330,36.983,2.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.519 | Acc: 26.263,37.007,2.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.512 | Acc: 26.461,37.126,2.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.507 | Acc: 26.394,37.198,2.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.503 | Acc: 26.380,37.166,2.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.500 | Acc: 26.467,37.129,2.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.503 | Acc: 26.475,37.011,2.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.485 | Acc: 26.700,37.183,3.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.483 | Acc: 26.740,37.147,3.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.474 | Acc: 26.770,37.186,3.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.461 | Acc: 26.767,37.137,3.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.454 | Acc: 26.801,37.177,3.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.436 | Acc: 26.790,37.242,3.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.430 | Acc: 26.702,37.194,4.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.549 | Acc: 16.406,25.781,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.997 | Acc: 17.597,25.781,5.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.098 | Acc: 17.302,25.362,5.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.124 | Acc: 17.264,24.923,5.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 8.889 | Acc: 28.906,42.969,5.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.043 | Acc: 27.902,38.244,7.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.063 | Acc: 28.525,38.186,8.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.010 | Acc: 29.214,38.909,8.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.981 | Acc: 28.954,39.178,8.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.962 | Acc: 29.069,39.635,8.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.972 | Acc: 28.926,39.340,8.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.977 | Acc: 28.746,39.240,8.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.982 | Acc: 28.533,38.985,8.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.986 | Acc: 28.483,38.894,9.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.984 | Acc: 28.358,38.825,9.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.982 | Acc: 28.284,38.812,9.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.979 | Acc: 28.148,38.667,9.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.970 | Acc: 28.131,38.742,9.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.965 | Acc: 28.086,38.729,9.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.960 | Acc: 28.117,38.684,9.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.953 | Acc: 28.127,38.676,9.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.941 | Acc: 28.175,38.712,9.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.936 | Acc: 28.186,38.744,10.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.937 | Acc: 28.088,38.656,10.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.150 | Acc: 16.406,25.781,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.001 | Acc: 16.704,25.298,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.021 | Acc: 16.178,25.095,7.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.009 | Acc: 16.022,24.834,7.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 8.686 | Acc: 29.688,35.938,10.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.635 | Acc: 29.539,41.815,11.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.628 | Acc: 29.287,41.006,11.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.649 | Acc: 29.239,40.651,12.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.670 | Acc: 28.983,40.394,12.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.645 | Acc: 29.324,40.555,12.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.652 | Acc: 29.177,40.438,12.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.663 | Acc: 28.917,40.071,12.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.674 | Acc: 28.882,39.941,12.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.665 | Acc: 28.911,40.021,12.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.660 | Acc: 28.898,39.984,12.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.656 | Acc: 29.041,40.045,12.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.646 | Acc: 29.094,40.080,12.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.642 | Acc: 29.098,40.122,12.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.642 | Acc: 29.023,40.080,12.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.640 | Acc: 29.015,40.010,12.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.636 | Acc: 29.038,39.995,12.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.637 | Acc: 28.966,39.940,12.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.626 | Acc: 29.056,39.943,12.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.622 | Acc: 29.019,39.954,12.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.202 | Acc: 24.219,38.281,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.339 | Acc: 22.433,35.714,9.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.350 | Acc: 22.428,35.099,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.349 | Acc: 22.669,34.939,9.772,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 8.311 | Acc: 30.469,39.062,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.485 | Acc: 28.943,40.439,12.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.458 | Acc: 29.668,40.568,12.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.458 | Acc: 29.726,40.471,12.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.455 | Acc: 29.485,40.355,13.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.479 | Acc: 29.363,40.161,13.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.482 | Acc: 29.294,40.192,13.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.470 | Acc: 29.521,40.337,13.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.446 | Acc: 29.731,40.504,13.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.458 | Acc: 29.532,40.288,13.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.444 | Acc: 29.653,40.330,13.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.441 | Acc: 29.617,40.282,13.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.424 | Acc: 29.704,40.515,13.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.424 | Acc: 29.682,40.418,13.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.426 | Acc: 29.587,40.325,13.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.420 | Acc: 29.599,40.314,13.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.415 | Acc: 29.624,40.377,13.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.411 | Acc: 29.646,40.293,13.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.406 | Acc: 29.703,40.344,13.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.401 | Acc: 29.681,40.381,13.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.922 | Acc: 17.969,30.469,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.909 | Acc: 21.168,28.943,11.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.985 | Acc: 20.827,28.773,11.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.006 | Acc: 20.722,28.381,10.784,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 8.300 | Acc: 27.344,34.375,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.227 | Acc: 30.320,40.923,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.208 | Acc: 30.431,41.311,14.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.210 | Acc: 30.085,41.816,14.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.208 | Acc: 29.929,42.178,14.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.211 | Acc: 30.136,41.917,15.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.197 | Acc: 30.094,42.091,15.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.182 | Acc: 30.408,42.215,15.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.183 | Acc: 30.275,42.391,15.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.194 | Acc: 30.171,42.157,15.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.193 | Acc: 30.057,42.114,15.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.194 | Acc: 29.999,41.958,15.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.193 | Acc: 30.005,41.776,15.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.206 | Acc: 29.885,41.715,15.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.190 | Acc: 30.057,41.879,15.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.192 | Acc: 30.048,41.860,15.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.198 | Acc: 29.967,41.706,15.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.203 | Acc: 29.896,41.631,15.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.195 | Acc: 29.973,41.698,15.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.191 | Acc: 29.944,41.734,15.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.775 | Acc: 25.000,42.188,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.125 | Acc: 22.693,35.193,14.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.130 | Acc: 22.618,35.099,14.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.153 | Acc: 22.477,34.273,14.101,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 8.643 | Acc: 29.688,40.625,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.066 | Acc: 30.729,43.936,17.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.052 | Acc: 30.183,42.797,18.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.067 | Acc: 29.905,42.789,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.026 | Acc: 30.488,42.757,18.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.007 | Acc: 30.840,43.000,18.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.021 | Acc: 30.598,42.840,18.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.029 | Acc: 30.430,42.670,18.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.022 | Acc: 30.508,42.634,18.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.022 | Acc: 30.637,42.632,18.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.019 | Acc: 30.659,42.580,18.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.003 | Acc: 30.865,42.746,18.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.985 | Acc: 30.926,42.894,18.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.981 | Acc: 30.900,42.765,19.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.972 | Acc: 30.933,42.660,19.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.971 | Acc: 30.853,42.533,19.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.966 | Acc: 30.744,42.426,19.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.955 | Acc: 30.718,42.460,20.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.943 | Acc: 30.668,42.426,20.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.933 | Acc: 30.631,42.358,20.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.988 | Acc: 15.625,32.031,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.632 | Acc: 19.457,33.110,19.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.647 | Acc: 19.417,32.755,19.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.670 | Acc: 19.467,32.531,18.750,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 7.292 | Acc: 32.031,41.406,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.463 | Acc: 32.478,44.234,29.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.483 | Acc: 31.421,43.445,29.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.483 | Acc: 31.314,43.366,30.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.508 | Acc: 31.096,43.065,30.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.510 | Acc: 30.941,42.891,30.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.487 | Acc: 31.166,42.840,30.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.468 | Acc: 31.200,42.958,31.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.452 | Acc: 31.129,43.129,31.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.428 | Acc: 31.207,43.077,31.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.409 | Acc: 31.199,43.093,31.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.403 | Acc: 31.144,43.004,32.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.393 | Acc: 31.182,43.001,32.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.379 | Acc: 31.238,42.963,32.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.374 | Acc: 31.189,42.955,32.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.355 | Acc: 31.302,43.028,32.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.339 | Acc: 31.274,43.047,33.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.329 | Acc: 31.268,43.024,33.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.327 | Acc: 31.215,43.016,33.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.311 | Acc: 31.205,43.079,33.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.126 | Acc: 18.750,26.562,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.984 | Acc: 18.936,32.068,29.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.971 | Acc: 19.055,32.412,30.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.959 | Acc: 19.083,32.403,30.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 6.282 | Acc: 34.375,46.875,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.042 | Acc: 30.097,43.452,37.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.048 | Acc: 31.231,43.445,38.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.013 | Acc: 31.609,43.904,38.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.978 | Acc: 31.742,43.933,38.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.999 | Acc: 31.799,43.758,38.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.992 | Acc: 31.805,43.744,38.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.999 | Acc: 31.627,43.855,38.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.006 | Acc: 31.507,43.740,38.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.007 | Acc: 31.367,43.517,38.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.001 | Acc: 31.518,43.598,38.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.989 | Acc: 31.600,43.647,38.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.983 | Acc: 31.642,43.640,38.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.979 | Acc: 31.690,43.675,39.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.974 | Acc: 31.692,43.703,39.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.970 | Acc: 31.816,43.706,39.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.968 | Acc: 31.824,43.628,39.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.967 | Acc: 31.871,43.684,39.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.962 | Acc: 31.795,43.657,39.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.963 | Acc: 31.713,43.572,39.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.684 | Acc: 23.438,35.938,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.046 | Acc: 23.549,32.961,33.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.000 | Acc: 25.057,33.003,33.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.959 | Acc: 25.051,33.402,33.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 6.921 | Acc: 30.469,47.656,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.594 | Acc: 32.106,45.387,42.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.673 | Acc: 31.631,44.950,42.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.724 | Acc: 31.621,44.634,42.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.755 | Acc: 31.617,44.338,42.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.767 | Acc: 31.915,44.369,42.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.772 | Acc: 31.818,44.564,42.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.767 | Acc: 31.782,44.559,42.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.747 | Acc: 31.793,44.701,42.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.739 | Acc: 31.811,44.976,42.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.725 | Acc: 31.860,45.033,42.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.723 | Acc: 31.943,45.069,42.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.718 | Acc: 31.882,45.047,42.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.711 | Acc: 31.864,45.082,42.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.711 | Acc: 31.923,45.059,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.724 | Acc: 31.785,44.923,42.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.732 | Acc: 31.751,44.853,42.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.733 | Acc: 31.784,44.827,42.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.728 | Acc: 31.763,44.875,42.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.727 | Acc: 31.756,44.853,42.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.795 | Acc: 24.219,34.375,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.623 | Acc: 26.786,38.430,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.557 | Acc: 27.020,38.529,40.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.567 | Acc: 26.793,38.384,39.588,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 6.008 | Acc: 43.750,55.469,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.617 | Acc: 32.775,45.647,43.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.636 | Acc: 32.031,45.598,44.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.635 | Acc: 32.044,45.517,44.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.618 | Acc: 32.195,45.901,44.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.598 | Acc: 32.263,46.016,44.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.608 | Acc: 32.122,45.771,44.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.608 | Acc: 32.214,45.739,44.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.601 | Acc: 32.201,45.730,44.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.597 | Acc: 32.100,45.701,44.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.582 | Acc: 32.113,45.721,44.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.578 | Acc: 32.212,45.786,44.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.593 | Acc: 32.158,45.627,44.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.599 | Acc: 32.196,45.597,44.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.604 | Acc: 32.140,45.518,44.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.590 | Acc: 32.223,45.694,44.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.592 | Acc: 32.297,45.724,44.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.590 | Acc: 32.302,45.727,44.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.592 | Acc: 32.271,45.667,44.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.589 | Acc: 32.359,45.677,44.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.771 | Acc: 21.094,45.312,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.841 | Acc: 22.619,37.574,37.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.810 | Acc: 22.961,37.424,37.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.809 | Acc: 23.233,37.372,37.154,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 6.610 | Acc: 29.688,40.625,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.398 | Acc: 33.780,47.135,46.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.444 | Acc: 32.717,46.608,46.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.418 | Acc: 32.941,46.913,46.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.404 | Acc: 32.533,46.827,46.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.393 | Acc: 32.805,47.099,46.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.404 | Acc: 32.729,46.965,46.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.394 | Acc: 32.779,47.163,46.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.398 | Acc: 33.007,47.166,46.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.395 | Acc: 33.080,47.061,46.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.401 | Acc: 33.026,47.003,46.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.407 | Acc: 32.911,46.879,46.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.422 | Acc: 32.754,46.881,46.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.427 | Acc: 32.818,46.962,46.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.426 | Acc: 32.838,46.945,46.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.428 | Acc: 32.844,46.961,46.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.432 | Acc: 32.761,46.899,46.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.431 | Acc: 32.728,46.902,46.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.431 | Acc: 32.713,46.910,46.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.432 | Acc: 32.722,46.941,46.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.783 | Acc: 23.438,36.719,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.538 | Acc: 20.722,33.929,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.554 | Acc: 21.170,33.956,36.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.614 | Acc: 20.684,33.504,36.168,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 6.253 | Acc: 35.156,49.219,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.160 | Acc: 34.487,48.698,47.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.216 | Acc: 33.403,48.247,47.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.218 | Acc: 33.645,49.014,48.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.241 | Acc: 33.449,48.746,47.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.256 | Acc: 33.385,48.909,47.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.239 | Acc: 33.561,49.070,48.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.271 | Acc: 33.616,48.626,47.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.288 | Acc: 33.434,48.345,47.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.296 | Acc: 33.460,48.343,47.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.301 | Acc: 33.384,48.430,47.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.316 | Acc: 33.212,48.307,47.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.315 | Acc: 33.214,48.211,47.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.317 | Acc: 33.244,48.180,47.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.330 | Acc: 33.107,48.071,47.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.338 | Acc: 32.994,48.022,47.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.341 | Acc: 32.944,47.978,47.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.346 | Acc: 32.932,47.929,47.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.351 | Acc: 32.936,47.894,47.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.349 | Acc: 33.001,47.876,47.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.153 | Acc: 25.781,39.844,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.843 | Acc: 25.521,37.723,41.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.936 | Acc: 25.705,37.348,39.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.895 | Acc: 25.666,37.077,39.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 6.280 | Acc: 36.719,53.125,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.292 | Acc: 33.222,47.917,48.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.304 | Acc: 33.098,48.075,48.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.281 | Acc: 33.466,48.169,48.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.246 | Acc: 33.546,48.698,48.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.225 | Acc: 33.516,48.948,48.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.238 | Acc: 33.704,48.831,48.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.231 | Acc: 33.511,49.003,49.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.231 | Acc: 33.327,48.957,49.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.229 | Acc: 33.408,48.826,48.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.221 | Acc: 33.605,48.916,49.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.220 | Acc: 33.512,48.865,48.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.211 | Acc: 33.623,48.849,49.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.206 | Acc: 33.633,48.895,49.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.213 | Acc: 33.599,48.843,48.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.212 | Acc: 33.589,48.832,48.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.218 | Acc: 33.574,48.849,48.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.222 | Acc: 33.582,48.802,48.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.222 | Acc: 33.594,48.821,48.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.223 | Acc: 33.633,48.841,48.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.178 | Acc: 19.531,36.719,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.270 | Acc: 16.741,32.254,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.406 | Acc: 16.463,31.898,33.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.433 | Acc: 16.611,31.647,33.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.734 | Acc: 38.281,55.469,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.972 | Acc: 35.714,51.153,51.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.993 | Acc: 34.756,50.705,51.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.039 | Acc: 34.119,50.179,51.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.078 | Acc: 33.912,49.875,51.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.100 | Acc: 33.772,49.722,50.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.096 | Acc: 33.865,49.722,50.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.107 | Acc: 33.804,49.684,50.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.111 | Acc: 33.841,49.655,50.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.119 | Acc: 33.930,49.732,50.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.121 | Acc: 33.928,49.701,50.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.128 | Acc: 34.029,49.703,50.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.125 | Acc: 34.103,49.624,50.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.124 | Acc: 34.145,49.686,50.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.112 | Acc: 34.194,49.744,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.118 | Acc: 34.167,49.681,50.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.126 | Acc: 34.124,49.625,50.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.131 | Acc: 34.107,49.611,50.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.126 | Acc: 34.091,49.665,50.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.127 | Acc: 34.151,49.645,50.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.747 | Acc: 23.438,40.625,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.363 | Acc: 27.902,40.625,42.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.428 | Acc: 27.382,39.558,41.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.468 | Acc: 27.318,39.690,41.163,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.998 | Acc: 33.594,50.000,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.911 | Acc: 35.045,51.376,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.039 | Acc: 33.880,50.724,51.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.030 | Acc: 34.042,50.384,51.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.992 | Acc: 34.645,50.492,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.012 | Acc: 34.545,50.503,50.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.022 | Acc: 34.685,50.446,50.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.038 | Acc: 34.480,50.349,50.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.045 | Acc: 34.322,50.359,50.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.045 | Acc: 34.444,50.315,50.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.035 | Acc: 34.519,50.431,50.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.055 | Acc: 34.315,50.304,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.062 | Acc: 34.171,50.246,50.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.053 | Acc: 34.195,50.168,50.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.049 | Acc: 34.236,50.261,50.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.058 | Acc: 34.175,50.215,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.056 | Acc: 34.173,50.256,50.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.055 | Acc: 34.187,50.247,50.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.055 | Acc: 34.187,50.201,50.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.056 | Acc: 34.258,50.156,50.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.791 | Acc: 25.781,34.375,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.851 | Acc: 23.326,37.463,42.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.892 | Acc: 22.752,37.519,41.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.882 | Acc: 22.746,37.948,41.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.679 | Acc: 37.500,49.219,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.857 | Acc: 34.263,51.451,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.930 | Acc: 34.604,51.944,51.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.900 | Acc: 34.273,52.062,52.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.892 | Acc: 34.713,52.344,52.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.935 | Acc: 34.398,51.887,52.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.938 | Acc: 34.588,51.879,52.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.929 | Acc: 34.896,51.828,52.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.918 | Acc: 34.996,51.941,52.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.920 | Acc: 34.915,51.891,52.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.930 | Acc: 34.834,51.749,51.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.934 | Acc: 34.866,51.654,51.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.932 | Acc: 34.929,51.738,51.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.946 | Acc: 34.878,51.551,51.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.944 | Acc: 34.992,51.535,51.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.951 | Acc: 34.899,51.459,51.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.953 | Acc: 34.871,51.343,51.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.958 | Acc: 34.810,51.278,51.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.971 | Acc: 34.721,51.192,51.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.973 | Acc: 34.652,51.085,51.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.954 | Acc: 26.562,46.875,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.734 | Acc: 28.348,44.420,47.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.775 | Acc: 28.011,43.845,47.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.763 | Acc: 28.291,43.686,47.272,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.462 | Acc: 39.062,56.250,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.836 | Acc: 33.891,52.195,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.786 | Acc: 34.737,52.439,53.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.879 | Acc: 34.170,51.242,52.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.874 | Acc: 34.500,51.543,52.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.878 | Acc: 34.630,51.601,52.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.891 | Acc: 34.775,51.479,52.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.887 | Acc: 35.040,51.640,52.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.866 | Acc: 35.132,52.028,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.883 | Acc: 35.104,51.895,52.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.905 | Acc: 34.974,51.629,52.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.907 | Acc: 34.873,51.601,52.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.904 | Acc: 34.916,51.747,52.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.906 | Acc: 34.911,51.652,52.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.898 | Acc: 34.895,51.688,52.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.899 | Acc: 34.876,51.594,52.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.904 | Acc: 34.884,51.524,52.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.901 | Acc: 34.925,51.581,52.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.904 | Acc: 34.901,51.606,52.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.904 | Acc: 34.961,51.642,52.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.180 | Acc: 22.656,38.281,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.628 | Acc: 24.628,40.811,44.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.736 | Acc: 23.857,41.101,43.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.801 | Acc: 23.412,40.471,42.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.832 | Acc: 25.781,56.250,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.760 | Acc: 36.272,53.832,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.804 | Acc: 35.061,52.458,53.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.814 | Acc: 35.143,52.472,53.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.833 | Acc: 34.877,52.324,53.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.798 | Acc: 35.342,52.761,53.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.798 | Acc: 35.318,52.557,53.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.803 | Acc: 35.284,52.527,53.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.808 | Acc: 35.341,52.460,53.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.789 | Acc: 35.523,52.538,53.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.805 | Acc: 35.459,52.441,53.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.811 | Acc: 35.443,52.280,53.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.816 | Acc: 35.448,52.321,53.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.818 | Acc: 35.423,52.335,53.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.821 | Acc: 35.365,52.302,53.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.813 | Acc: 35.437,52.388,53.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.812 | Acc: 35.485,52.444,53.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.813 | Acc: 35.388,52.353,53.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.814 | Acc: 35.403,52.348,53.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.821 | Acc: 35.386,52.237,53.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.940 | Acc: 25.000,38.281,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.905 | Acc: 23.103,40.216,43.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.903 | Acc: 22.999,40.434,42.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.865 | Acc: 22.682,40.676,42.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 6.220 | Acc: 28.125,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.609 | Acc: 36.421,54.315,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.640 | Acc: 35.995,54.040,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.655 | Acc: 36.027,53.817,54.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.685 | Acc: 36.121,53.897,54.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.771 | Acc: 35.589,53.179,54.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.767 | Acc: 35.595,53.228,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.765 | Acc: 35.306,53.203,54.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.785 | Acc: 34.952,52.834,53.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.788 | Acc: 35.109,52.801,53.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.785 | Acc: 35.211,52.806,53.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.788 | Acc: 35.185,52.729,53.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.791 | Acc: 35.279,52.687,53.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.785 | Acc: 35.360,52.712,53.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.796 | Acc: 35.298,52.552,53.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.793 | Acc: 35.359,52.611,53.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.791 | Acc: 35.331,52.680,53.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.796 | Acc: 35.278,52.545,53.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.793 | Acc: 35.303,52.601,53.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.785 | Acc: 35.402,52.631,53.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.828 | Acc: 28.906,43.750,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.476 | Acc: 31.176,46.949,49.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.534 | Acc: 30.678,46.570,48.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.529 | Acc: 30.533,46.670,48.899,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.492 | Acc: 32.031,51.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.698 | Acc: 34.747,52.567,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.683 | Acc: 35.137,52.630,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.637 | Acc: 35.745,53.189,55.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.675 | Acc: 35.552,52.874,54.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.690 | Acc: 35.675,52.870,54.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.696 | Acc: 35.737,52.860,54.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.690 | Acc: 35.860,52.998,54.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.698 | Acc: 35.845,52.848,54.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.722 | Acc: 35.791,52.823,53.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.721 | Acc: 35.704,52.810,53.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.712 | Acc: 35.725,52.941,54.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.710 | Acc: 35.808,52.963,54.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.705 | Acc: 35.869,53.101,54.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.718 | Acc: 35.746,52.980,54.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.718 | Acc: 35.673,52.990,54.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.718 | Acc: 35.697,53.052,54.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.728 | Acc: 35.676,53.004,54.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.728 | Acc: 35.671,53.054,54.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.726 | Acc: 35.700,53.049,54.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.228 | Acc: 28.906,41.406,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.249 | Acc: 26.823,41.481,46.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.256 | Acc: 26.944,40.720,45.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.254 | Acc: 27.113,40.779,45.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 6.038 | Acc: 30.469,49.219,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.688 | Acc: 34.338,54.613,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.687 | Acc: 35.575,53.811,55.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.691 | Acc: 35.412,53.343,54.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.688 | Acc: 35.851,53.434,54.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.667 | Acc: 36.046,53.759,54.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.665 | Acc: 36.235,53.809,55.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.648 | Acc: 36.143,54.028,55.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.636 | Acc: 36.069,54.110,55.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.637 | Acc: 36.218,54.010,55.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.646 | Acc: 36.299,53.957,55.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.664 | Acc: 36.196,53.843,54.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.673 | Acc: 36.090,53.822,54.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.658 | Acc: 36.225,53.954,54.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.659 | Acc: 36.216,53.845,54.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.669 | Acc: 36.059,53.667,54.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.671 | Acc: 36.047,53.609,54.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.673 | Acc: 36.057,53.668,54.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.668 | Acc: 36.152,53.653,54.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.666 | Acc: 36.169,53.652,54.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.185 | Acc: 19.531,37.500,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.235 | Acc: 21.801,34.821,38.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.260 | Acc: 21.742,34.680,38.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.273 | Acc: 21.824,34.529,39.062,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.647 | Acc: 35.938,53.125,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.486 | Acc: 36.124,55.208,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.496 | Acc: 35.918,54.668,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.515 | Acc: 36.258,54.521,57.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.526 | Acc: 36.535,54.765,56.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.527 | Acc: 36.549,54.773,56.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.529 | Acc: 36.570,54.797,56.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.558 | Acc: 36.226,54.300,56.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.543 | Acc: 36.398,54.455,56.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.556 | Acc: 36.546,54.325,56.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.561 | Acc: 36.458,54.299,55.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.557 | Acc: 36.489,54.514,56.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.561 | Acc: 36.378,54.487,56.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.565 | Acc: 36.485,54.409,56.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.571 | Acc: 36.480,54.371,55.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.590 | Acc: 36.363,54.176,55.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.598 | Acc: 36.320,54.060,55.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.600 | Acc: 36.322,53.966,55.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.607 | Acc: 36.329,53.945,55.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.618 | Acc: 36.309,53.900,55.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.976 | Acc: 33.594,42.188,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.048 | Acc: 29.353,43.490,45.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.066 | Acc: 29.002,42.702,44.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.059 | Acc: 29.086,42.738,45.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 5.554 | Acc: 37.500,63.281,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.561 | Acc: 35.863,53.869,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.589 | Acc: 36.052,54.021,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.557 | Acc: 36.770,54.380,56.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.572 | Acc: 36.478,54.225,55.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.542 | Acc: 36.726,54.618,56.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.550 | Acc: 36.628,54.384,56.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.558 | Acc: 36.564,54.333,55.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.575 | Acc: 36.301,54.324,55.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.585 | Acc: 36.304,54.165,55.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.594 | Acc: 36.416,54.104,55.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.587 | Acc: 36.464,54.168,55.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.589 | Acc: 36.424,54.130,55.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.577 | Acc: 36.584,54.253,55.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.576 | Acc: 36.557,54.276,55.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.574 | Acc: 36.501,54.283,55.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.573 | Acc: 36.495,54.393,55.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.572 | Acc: 36.458,54.374,55.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.570 | Acc: 36.548,54.417,55.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.573 | Acc: 36.577,54.345,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.635 | Acc: 31.250,43.750,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.643 | Acc: 28.906,45.015,50.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.693 | Acc: 29.040,45.103,49.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.712 | Acc: 28.778,45.492,49.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.587 | Acc: 30.469,52.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.442 | Acc: 36.496,55.469,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.477 | Acc: 36.833,55.088,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.481 | Acc: 37.013,54.623,56.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.491 | Acc: 37.037,54.601,56.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.510 | Acc: 36.966,54.688,56.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.505 | Acc: 37.171,54.952,56.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.506 | Acc: 37.079,54.865,56.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.500 | Acc: 37.214,54.872,56.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.506 | Acc: 37.172,54.696,56.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.512 | Acc: 37.076,54.789,56.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.517 | Acc: 36.913,54.769,56.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.519 | Acc: 36.904,54.765,56.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.519 | Acc: 36.931,54.804,56.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.515 | Acc: 37.002,54.854,56.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.516 | Acc: 36.976,54.778,56.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.516 | Acc: 36.967,54.787,56.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.509 | Acc: 36.964,54.919,56.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.515 | Acc: 36.898,54.791,56.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.522 | Acc: 36.873,54.743,56.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.362 | Acc: 22.656,44.531,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.340 | Acc: 23.549,42.857,47.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.417 | Acc: 23.628,42.359,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.442 | Acc: 23.463,42.277,46.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 5.531 | Acc: 46.094,55.469,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.427 | Acc: 38.170,56.138,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.433 | Acc: 37.043,55.450,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.433 | Acc: 37.026,55.686,57.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.398 | Acc: 37.471,56.047,58.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.405 | Acc: 37.562,55.995,57.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.424 | Acc: 37.539,55.746,57.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.437 | Acc: 37.528,55.652,57.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.446 | Acc: 37.408,55.566,57.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.453 | Acc: 37.552,55.521,57.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.467 | Acc: 37.500,55.589,57.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.452 | Acc: 37.542,55.670,57.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.447 | Acc: 37.600,55.663,57.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.470 | Acc: 37.413,55.475,57.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.465 | Acc: 37.475,55.469,57.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.474 | Acc: 37.381,55.368,57.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.484 | Acc: 37.310,55.410,57.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.488 | Acc: 37.216,55.324,57.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.496 | Acc: 37.141,55.265,56.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.496 | Acc: 37.086,55.258,57.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.348 | Acc: 28.125,49.219,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.648 | Acc: 28.720,45.796,49.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.775 | Acc: 28.373,44.112,48.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.788 | Acc: 28.535,44.608,48.130,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 5.639 | Acc: 38.281,54.688,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.291 | Acc: 37.760,58.408,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.322 | Acc: 37.957,57.736,59.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.318 | Acc: 37.910,57.377,59.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.345 | Acc: 37.587,56.944,58.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.378 | Acc: 37.198,56.668,58.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.374 | Acc: 37.306,56.476,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.368 | Acc: 37.267,56.449,58.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.385 | Acc: 37.068,56.216,58.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.398 | Acc: 37.077,56.194,58.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.410 | Acc: 37.131,56.067,58.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.422 | Acc: 37.146,56.063,57.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.425 | Acc: 37.296,56.043,57.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.431 | Acc: 37.249,55.963,57.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.419 | Acc: 37.347,56.075,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.415 | Acc: 37.352,56.027,57.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.419 | Acc: 37.281,55.980,57.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.421 | Acc: 37.282,55.872,57.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.430 | Acc: 37.130,55.796,57.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.432 | Acc: 37.221,55.807,57.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.296 | Acc: 31.250,46.094,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.277 | Acc: 27.269,45.052,47.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.412 | Acc: 26.086,43.788,46.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.427 | Acc: 25.909,43.455,45.991,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 5.006 | Acc: 35.156,61.719,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.353 | Acc: 36.682,55.878,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.335 | Acc: 37.005,56.250,58.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.340 | Acc: 37.308,55.917,58.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.319 | Acc: 37.587,56.424,58.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.324 | Acc: 37.802,56.242,58.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.330 | Acc: 37.965,56.263,58.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.339 | Acc: 37.993,56.394,58.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.349 | Acc: 37.976,56.313,58.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.358 | Acc: 37.936,56.246,58.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.376 | Acc: 37.718,56.091,58.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.379 | Acc: 37.691,55.981,58.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.380 | Acc: 37.591,55.984,58.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.384 | Acc: 37.572,55.993,58.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.380 | Acc: 37.650,56.039,58.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.399 | Acc: 37.409,55.853,57.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.409 | Acc: 37.300,55.831,57.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.404 | Acc: 37.333,55.851,57.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.410 | Acc: 37.327,55.878,57.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.416 | Acc: 37.266,55.774,57.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.996 | Acc: 25.000,44.531,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.968 | Acc: 21.205,39.658,44.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.964 | Acc: 21.589,39.329,44.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.948 | Acc: 21.247,39.536,44.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.180 | Acc: 39.062,57.812,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.271 | Acc: 38.207,57.515,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.260 | Acc: 38.167,57.470,59.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.290 | Acc: 38.192,57.108,59.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.306 | Acc: 38.069,56.944,59.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.304 | Acc: 37.972,56.753,59.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.337 | Acc: 37.965,56.541,58.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.341 | Acc: 37.866,56.521,58.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.345 | Acc: 37.806,56.391,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.354 | Acc: 37.729,56.289,58.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.357 | Acc: 37.702,56.269,58.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.369 | Acc: 37.606,56.193,58.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.370 | Acc: 37.558,56.201,58.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.370 | Acc: 37.557,56.205,58.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.371 | Acc: 37.620,56.286,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.377 | Acc: 37.630,56.229,58.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.385 | Acc: 37.578,56.075,57.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.380 | Acc: 37.592,56.090,57.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.382 | Acc: 37.519,56.060,57.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.375 | Acc: 37.566,56.129,57.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.855 | Acc: 27.344,46.875,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.657 | Acc: 28.051,48.289,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.737 | Acc: 27.668,47.599,51.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.755 | Acc: 27.830,47.208,50.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 4.934 | Acc: 43.750,62.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.237 | Acc: 38.021,57.403,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.258 | Acc: 37.671,57.222,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.269 | Acc: 38.025,57.236,59.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.299 | Acc: 37.963,57.195,58.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.312 | Acc: 37.755,57.109,58.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.298 | Acc: 37.791,57.128,58.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.326 | Acc: 37.434,56.776,58.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.342 | Acc: 37.442,56.740,58.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.331 | Acc: 37.491,56.971,58.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.325 | Acc: 37.702,57.074,58.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.324 | Acc: 37.652,57.038,58.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.331 | Acc: 37.539,56.885,59.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.335 | Acc: 37.410,56.780,58.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.343 | Acc: 37.289,56.684,58.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.348 | Acc: 37.324,56.543,58.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.347 | Acc: 37.252,56.549,58.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.345 | Acc: 37.262,56.536,58.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.343 | Acc: 37.338,56.579,58.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.332 | Acc: 37.432,56.627,58.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.208 | Acc: 27.344,50.781,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.372 | Acc: 31.548,48.884,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.362 | Acc: 31.288,48.571,52.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.385 | Acc: 30.981,48.489,52.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 5.266 | Acc: 35.938,57.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.274 | Acc: 37.612,56.101,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.317 | Acc: 37.005,56.021,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.280 | Acc: 37.282,56.557,58.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.288 | Acc: 37.452,56.597,58.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.268 | Acc: 37.802,56.892,58.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.294 | Acc: 37.610,56.805,58.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.307 | Acc: 37.550,56.782,58.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.300 | Acc: 37.607,56.730,58.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.328 | Acc: 37.379,56.518,58.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.315 | Acc: 37.539,56.646,58.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.315 | Acc: 37.627,56.731,58.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.320 | Acc: 37.643,56.697,58.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.312 | Acc: 37.802,56.720,58.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.310 | Acc: 37.836,56.759,58.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.308 | Acc: 37.858,56.754,58.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.318 | Acc: 37.831,56.681,58.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.308 | Acc: 37.871,56.804,58.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.313 | Acc: 37.762,56.746,58.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.311 | Acc: 37.785,56.820,58.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.328 | Acc: 17.188,40.625,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.693 | Acc: 22.991,41.481,46.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.780 | Acc: 21.970,40.835,45.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.764 | Acc: 22.003,40.535,45.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 5.076 | Acc: 38.281,58.594,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.212 | Acc: 37.351,57.478,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.185 | Acc: 38.110,57.527,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.213 | Acc: 38.281,57.633,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.176 | Acc: 38.609,58.005,60.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.210 | Acc: 38.335,57.619,60.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.232 | Acc: 38.165,57.354,59.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.240 | Acc: 37.932,57.286,59.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.224 | Acc: 38.136,57.468,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.231 | Acc: 38.173,57.472,59.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.241 | Acc: 38.227,57.397,59.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.244 | Acc: 38.221,57.473,59.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.248 | Acc: 38.210,57.440,59.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.258 | Acc: 38.144,57.304,59.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.268 | Acc: 38.053,57.251,59.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.272 | Acc: 38.159,57.158,59.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.272 | Acc: 38.113,57.143,59.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.271 | Acc: 37.999,57.187,59.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.270 | Acc: 38.048,57.159,59.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.274 | Acc: 37.984,57.181,59.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.297 | Acc: 32.031,52.344,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.594 | Acc: 30.246,48.586,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.624 | Acc: 30.221,47.542,50.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.623 | Acc: 29.931,47.464,50.832,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.881 | Acc: 39.062,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.204 | Acc: 38.318,58.110,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.179 | Acc: 39.024,58.422,61.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.176 | Acc: 38.512,58.184,61.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.190 | Acc: 38.465,57.928,61.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.194 | Acc: 38.420,57.712,60.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.207 | Acc: 38.210,57.328,60.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.210 | Acc: 38.353,57.281,60.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.219 | Acc: 38.213,57.327,60.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.228 | Acc: 38.307,57.256,60.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.211 | Acc: 38.433,57.338,60.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.223 | Acc: 38.437,57.314,60.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.237 | Acc: 38.262,57.268,60.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.231 | Acc: 38.320,57.310,60.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.235 | Acc: 38.320,57.357,60.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.233 | Acc: 38.434,57.405,60.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.236 | Acc: 38.403,57.377,59.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.233 | Acc: 38.407,57.437,60.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.238 | Acc: 38.338,57.406,60.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.245 | Acc: 38.220,57.361,60.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.383 | Acc: 24.219,42.969,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.429 | Acc: 25.967,42.001,45.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.444 | Acc: 25.667,41.559,44.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.437 | Acc: 25.333,41.240,44.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 5.097 | Acc: 37.500,57.031,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.177 | Acc: 37.872,58.259,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.111 | Acc: 39.005,58.270,60.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.183 | Acc: 38.486,57.608,60.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.171 | Acc: 38.706,57.514,60.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.160 | Acc: 38.637,57.557,60.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.183 | Acc: 38.765,57.277,60.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.191 | Acc: 38.597,57.297,60.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.182 | Acc: 38.582,57.584,60.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.200 | Acc: 38.532,57.571,60.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.206 | Acc: 38.437,57.517,60.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.219 | Acc: 38.341,57.540,60.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.224 | Acc: 38.343,57.543,60.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.228 | Acc: 38.287,57.567,60.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.228 | Acc: 38.326,57.571,60.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.231 | Acc: 38.294,57.556,59.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.232 | Acc: 38.259,57.586,60.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.225 | Acc: 38.206,57.567,60.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.218 | Acc: 38.247,57.629,60.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.214 | Acc: 38.300,57.671,60.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.061 | Acc: 28.906,51.562,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.561 | Acc: 24.256,43.936,48.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.553 | Acc: 23.800,43.159,47.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.558 | Acc: 23.950,43.122,47.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.924 | Acc: 36.719,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.117 | Acc: 39.286,57.180,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.181 | Acc: 38.491,57.393,60.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.183 | Acc: 38.281,57.544,60.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.180 | Acc: 38.580,57.417,60.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.189 | Acc: 38.552,57.418,59.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.192 | Acc: 38.456,57.412,60.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.187 | Acc: 38.503,57.558,60.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.185 | Acc: 38.568,57.662,60.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.178 | Acc: 38.683,57.730,60.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.170 | Acc: 38.685,57.855,60.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.183 | Acc: 38.606,57.816,60.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.167 | Acc: 38.758,57.942,60.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.170 | Acc: 38.763,57.896,60.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.174 | Acc: 38.776,57.863,60.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.174 | Acc: 38.774,57.859,60.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.180 | Acc: 38.785,57.808,60.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.186 | Acc: 38.723,57.792,60.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.190 | Acc: 38.688,57.745,60.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.191 | Acc: 38.661,57.761,60.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.405 | Acc: 22.656,46.875,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.845 | Acc: 20.089,42.336,47.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.792 | Acc: 20.827,43.083,47.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.774 | Acc: 21.043,43.122,47.618,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 5.894 | Acc: 35.938,48.438,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.974 | Acc: 39.993,59.040,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.093 | Acc: 38.681,58.327,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.054 | Acc: 38.845,58.888,61.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.095 | Acc: 38.397,58.748,61.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.085 | Acc: 38.482,59.066,61.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.097 | Acc: 38.281,58.942,61.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.111 | Acc: 38.143,58.710,61.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.115 | Acc: 38.184,58.652,61.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.129 | Acc: 38.173,58.417,61.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.127 | Acc: 38.250,58.407,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.113 | Acc: 38.426,58.647,61.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.115 | Acc: 38.411,58.662,61.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.125 | Acc: 38.380,58.627,61.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.129 | Acc: 38.476,58.613,61.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.137 | Acc: 38.471,58.441,60.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.142 | Acc: 38.491,58.336,60.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.149 | Acc: 38.529,58.239,60.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.148 | Acc: 38.589,58.267,60.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.151 | Acc: 38.562,58.266,60.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.628 | Acc: 29.688,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.552 | Acc: 29.129,48.214,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.659 | Acc: 28.887,46.970,51.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.662 | Acc: 28.817,47.323,51.396,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.660 | Acc: 42.969,61.719,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.973 | Acc: 39.807,59.040,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.974 | Acc: 39.748,59.299,62.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.987 | Acc: 39.511,59.170,62.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.012 | Acc: 39.410,58.970,61.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.062 | Acc: 39.086,58.679,61.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.079 | Acc: 39.017,58.549,61.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.088 | Acc: 38.874,58.566,61.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.093 | Acc: 38.854,58.516,61.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.098 | Acc: 38.678,58.546,61.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.113 | Acc: 38.697,58.419,61.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.113 | Acc: 38.702,58.417,61.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.121 | Acc: 38.612,58.396,61.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.115 | Acc: 38.628,58.441,61.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.113 | Acc: 38.618,58.549,61.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.114 | Acc: 38.655,58.508,61.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.125 | Acc: 38.595,58.428,61.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.129 | Acc: 38.579,58.424,61.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.131 | Acc: 38.567,58.380,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.138 | Acc: 38.574,58.292,60.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.295 | Acc: 32.031,48.438,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.620 | Acc: 28.534,47.693,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.635 | Acc: 27.954,46.589,49.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.684 | Acc: 28.240,46.337,49.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.937 | Acc: 43.750,55.469,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.991 | Acc: 40.885,57.440,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.954 | Acc: 40.225,58.498,62.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.959 | Acc: 39.626,58.696,62.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.969 | Acc: 39.709,58.709,62.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.989 | Acc: 39.782,58.671,62.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.028 | Acc: 39.663,58.497,62.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.056 | Acc: 39.539,58.372,61.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.067 | Acc: 39.392,58.317,61.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.063 | Acc: 39.334,58.400,61.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.070 | Acc: 39.230,58.454,61.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.081 | Acc: 39.176,58.364,61.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.091 | Acc: 39.221,58.331,61.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.092 | Acc: 39.254,58.324,61.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.087 | Acc: 39.332,58.424,61.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.090 | Acc: 39.270,58.365,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.103 | Acc: 39.148,58.226,61.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.107 | Acc: 39.131,58.227,61.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.104 | Acc: 39.121,58.217,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.113 | Acc: 39.093,58.141,60.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.932 | Acc: 36.719,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.422 | Acc: 31.362,48.847,53.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.391 | Acc: 31.117,49.066,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.411 | Acc: 30.994,49.257,52.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 5.370 | Acc: 35.938,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.939 | Acc: 38.914,59.673,63.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.997 | Acc: 38.815,58.975,62.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.997 | Acc: 39.088,59.311,62.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.007 | Acc: 39.390,59.394,62.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.021 | Acc: 39.287,59.197,62.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.004 | Acc: 39.527,59.349,62.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.004 | Acc: 39.279,59.347,62.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.040 | Acc: 39.121,58.977,62.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.035 | Acc: 39.024,59.094,62.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.044 | Acc: 38.961,58.924,62.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.042 | Acc: 39.070,58.937,62.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.058 | Acc: 39.014,58.827,61.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.066 | Acc: 38.952,58.645,61.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.060 | Acc: 39.163,58.697,61.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.066 | Acc: 39.148,58.664,61.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.069 | Acc: 39.089,58.674,61.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.068 | Acc: 39.124,58.662,61.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.074 | Acc: 39.108,58.637,61.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.078 | Acc: 39.052,58.581,61.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.871 | Acc: 32.812,44.531,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.558 | Acc: 31.324,47.321,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.599 | Acc: 30.602,46.456,50.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.565 | Acc: 30.930,46.606,50.666,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.798 | Acc: 41.406,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.903 | Acc: 39.323,59.859,64.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.963 | Acc: 39.653,59.985,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.960 | Acc: 39.690,60.259,63.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.980 | Acc: 39.246,59.867,62.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.991 | Acc: 39.310,59.924,62.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.997 | Acc: 39.405,60.059,62.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.014 | Acc: 39.256,59.835,62.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.028 | Acc: 39.033,59.579,62.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.026 | Acc: 39.037,59.543,62.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.032 | Acc: 39.031,59.484,62.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.030 | Acc: 39.055,59.421,62.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.021 | Acc: 39.218,59.550,62.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.023 | Acc: 39.314,59.528,62.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.030 | Acc: 39.243,59.445,62.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.028 | Acc: 39.283,59.427,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.037 | Acc: 39.274,59.283,61.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.037 | Acc: 39.319,59.288,61.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.041 | Acc: 39.249,59.204,61.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.046 | Acc: 39.202,59.133,61.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.361 | Acc: 31.250,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.338 | Acc: 31.362,48.438,52.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.347 | Acc: 31.822,48.533,51.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.366 | Acc: 31.557,48.399,51.767,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 5.788 | Acc: 23.438,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.097 | Acc: 38.467,58.222,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.031 | Acc: 39.158,58.594,61.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.043 | Acc: 38.409,58.760,62.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.018 | Acc: 38.648,58.864,62.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.023 | Acc: 38.451,58.988,62.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.003 | Acc: 38.662,59.285,62.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.012 | Acc: 38.730,59.192,62.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.007 | Acc: 38.995,59.200,62.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.014 | Acc: 39.015,59.228,62.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.023 | Acc: 39.125,59.223,62.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.025 | Acc: 39.144,59.195,62.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.016 | Acc: 39.293,59.284,62.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.015 | Acc: 39.299,59.273,62.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.023 | Acc: 39.257,59.197,62.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.029 | Acc: 39.218,59.269,62.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.034 | Acc: 39.157,59.256,62.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.032 | Acc: 39.257,59.194,62.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.030 | Acc: 39.311,59.208,62.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.038 | Acc: 39.190,59.154,61.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.422 | Acc: 26.562,44.531,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.265 | Acc: 24.702,44.420,50.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.365 | Acc: 24.276,43.312,49.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.371 | Acc: 24.603,43.584,49.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 5.345 | Acc: 41.406,56.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.878 | Acc: 40.067,60.231,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.889 | Acc: 40.625,60.175,63.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.898 | Acc: 40.369,60.348,63.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.919 | Acc: 40.114,60.166,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.947 | Acc: 40.045,60.156,63.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.952 | Acc: 39.889,60.066,63.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.974 | Acc: 39.572,59.918,62.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.977 | Acc: 39.533,59.860,62.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.976 | Acc: 39.524,59.681,62.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.982 | Acc: 39.506,59.593,62.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.985 | Acc: 39.480,59.502,62.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.984 | Acc: 39.490,59.582,62.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.992 | Acc: 39.386,59.489,62.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.990 | Acc: 39.474,59.489,62.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.987 | Acc: 39.615,59.515,62.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.989 | Acc: 39.637,59.489,62.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.003 | Acc: 39.640,59.402,62.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.002 | Acc: 39.638,59.405,62.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.004 | Acc: 39.626,59.396,62.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.008 | Acc: 35.938,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.362 | Acc: 31.324,49.293,53.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.372 | Acc: 30.564,49.028,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.403 | Acc: 30.238,48.386,52.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.561 | Acc: 46.094,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.980 | Acc: 39.286,60.417,63.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.979 | Acc: 39.024,60.099,62.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.008 | Acc: 38.960,59.529,62.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.042 | Acc: 38.551,59.008,62.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.024 | Acc: 38.637,59.089,62.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.010 | Acc: 38.824,59.298,62.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.002 | Acc: 39.207,59.342,63.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.993 | Acc: 39.349,59.496,63.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.990 | Acc: 39.507,59.526,62.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.985 | Acc: 39.587,59.663,63.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.989 | Acc: 39.504,59.555,62.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.987 | Acc: 39.435,59.557,62.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.983 | Acc: 39.485,59.540,62.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.998 | Acc: 39.460,59.467,62.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.005 | Acc: 39.460,59.385,62.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.004 | Acc: 39.513,59.475,62.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.995 | Acc: 39.548,59.579,62.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.992 | Acc: 39.595,59.650,62.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.990 | Acc: 39.602,59.705,62.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.041 | Acc: 34.375,53.125,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.297 | Acc: 32.180,49.479,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.318 | Acc: 32.107,48.418,53.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.296 | Acc: 32.236,48.732,53.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 5.175 | Acc: 36.719,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.900 | Acc: 40.327,60.193,63.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.881 | Acc: 40.282,59.737,63.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.863 | Acc: 40.305,59.862,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.871 | Acc: 40.037,59.886,63.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.879 | Acc: 40.176,60.002,63.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.900 | Acc: 39.863,59.872,63.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.899 | Acc: 39.805,59.962,63.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.900 | Acc: 39.834,59.860,63.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.924 | Acc: 39.740,59.841,63.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.947 | Acc: 39.583,59.604,63.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.956 | Acc: 39.550,59.601,63.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.956 | Acc: 39.520,59.660,63.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.961 | Acc: 39.470,59.531,62.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.968 | Acc: 39.399,59.545,62.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.972 | Acc: 39.431,59.487,62.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.969 | Acc: 39.457,59.565,62.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.973 | Acc: 39.424,59.485,62.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.972 | Acc: 39.521,59.568,62.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.977 | Acc: 39.485,59.541,62.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.222 | Acc: 26.562,41.406,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.619 | Acc: 22.879,38.393,43.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.549 | Acc: 23.152,38.167,43.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.453 | Acc: 22.861,38.525,44.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.735 | Acc: 37.500,57.031,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.839 | Acc: 40.067,60.268,64.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.794 | Acc: 40.663,60.938,64.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.792 | Acc: 41.368,61.488,65.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.805 | Acc: 40.837,61.227,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.838 | Acc: 40.579,60.760,64.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.865 | Acc: 40.315,60.447,64.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.856 | Acc: 40.259,60.583,64.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.875 | Acc: 40.242,60.447,63.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.881 | Acc: 40.133,60.320,63.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.890 | Acc: 40.034,60.370,63.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.897 | Acc: 39.883,60.312,63.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.914 | Acc: 39.701,60.150,63.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.919 | Acc: 39.604,60.078,63.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.920 | Acc: 39.691,60.092,63.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.921 | Acc: 39.672,59.967,63.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.931 | Acc: 39.634,59.889,63.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.937 | Acc: 39.603,59.815,63.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.939 | Acc: 39.562,59.829,63.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.951 | Acc: 39.507,59.777,62.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.343 | Acc: 34.375,50.000,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.888 | Acc: 29.464,47.693,51.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.796 | Acc: 29.021,47.694,51.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.785 | Acc: 28.471,47.554,51.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 5.023 | Acc: 37.500,58.594,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.797 | Acc: 41.109,61.719,64.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 40.720,61.090,63.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.872 | Acc: 40.330,60.489,63.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.904 | Acc: 40.345,60.176,63.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.898 | Acc: 40.207,60.257,63.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.876 | Acc: 40.283,60.331,63.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.897 | Acc: 40.154,60.195,63.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.906 | Acc: 40.140,60.132,63.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.905 | Acc: 40.051,60.225,63.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.912 | Acc: 39.991,60.172,63.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.916 | Acc: 39.953,60.103,63.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.919 | Acc: 39.909,60.156,63.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.920 | Acc: 40.047,60.096,63.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.921 | Acc: 40.061,60.128,63.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.926 | Acc: 40.025,60.003,63.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.929 | Acc: 40.009,59.991,63.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.937 | Acc: 39.926,59.918,63.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.941 | Acc: 39.883,59.860,63.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.949 | Acc: 39.840,59.849,62.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.105 | Acc: 30.469,50.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.329 | Acc: 25.000,46.652,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.474 | Acc: 25.095,44.874,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.488 | Acc: 24.821,44.672,50.192,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 5.204 | Acc: 39.062,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.953 | Acc: 39.062,60.119,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.922 | Acc: 39.005,60.785,64.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.937 | Acc: 38.832,60.502,64.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.902 | Acc: 39.236,60.658,64.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.906 | Acc: 39.403,60.535,64.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.887 | Acc: 39.476,60.511,64.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.873 | Acc: 39.522,60.605,64.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.897 | Acc: 39.499,60.263,63.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.897 | Acc: 39.537,60.212,63.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.904 | Acc: 39.506,60.172,63.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.905 | Acc: 39.593,60.149,63.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.901 | Acc: 39.678,60.124,63.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.920 | Acc: 39.526,59.932,63.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.921 | Acc: 39.560,59.914,63.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.934 | Acc: 39.478,59.767,63.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.926 | Acc: 39.613,59.918,63.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.931 | Acc: 39.605,59.923,63.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.927 | Acc: 39.662,60.003,63.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.926 | Acc: 39.760,60.052,63.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.012 | Acc: 33.594,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.178 | Acc: 32.366,50.074,53.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.207 | Acc: 32.755,48.895,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.234 | Acc: 32.915,48.655,52.177,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.679 | Acc: 40.625,68.750,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.771 | Acc: 39.360,60.975,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.796 | Acc: 40.072,60.995,64.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.865 | Acc: 39.178,60.476,64.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.855 | Acc: 39.670,60.619,64.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.834 | Acc: 39.998,60.845,64.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.825 | Acc: 40.225,60.866,64.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.830 | Acc: 40.082,60.854,64.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.845 | Acc: 40.106,60.753,64.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.856 | Acc: 40.090,60.674,64.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.858 | Acc: 40.042,60.677,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.857 | Acc: 39.999,60.725,64.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.869 | Acc: 39.889,60.565,63.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.878 | Acc: 39.847,60.521,63.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.882 | Acc: 39.796,60.490,63.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.890 | Acc: 39.753,60.439,63.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.895 | Acc: 39.824,60.314,63.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.904 | Acc: 39.880,60.133,63.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.908 | Acc: 39.822,60.109,63.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.906 | Acc: 39.858,60.113,63.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.902 | Acc: 28.906,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.384 | Acc: 30.506,48.214,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.406 | Acc: 30.545,48.247,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.404 | Acc: 30.891,47.938,53.893,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.735 | Acc: 41.406,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.799 | Acc: 40.327,61.161,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.831 | Acc: 40.072,60.899,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.872 | Acc: 39.536,60.873,64.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.890 | Acc: 39.969,60.774,64.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.860 | Acc: 40.053,60.930,64.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.869 | Acc: 39.902,60.718,64.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.884 | Acc: 39.866,60.516,64.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.887 | Acc: 39.853,60.612,64.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.887 | Acc: 39.848,60.553,64.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.880 | Acc: 39.988,60.615,64.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.881 | Acc: 40.141,60.616,64.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.882 | Acc: 40.178,60.600,64.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.880 | Acc: 40.161,60.518,64.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.882 | Acc: 40.141,60.529,64.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.885 | Acc: 40.147,60.452,63.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.896 | Acc: 40.012,60.285,63.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.904 | Acc: 39.917,60.179,63.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.900 | Acc: 39.982,60.176,63.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.911 | Acc: 39.889,60.060,63.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.139 | Acc: 35.156,53.125,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.695 | Acc: 31.176,47.433,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.675 | Acc: 31.040,46.818,50.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.669 | Acc: 31.634,46.721,50.218,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.704 | Acc: 35.938,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.915 | Acc: 40.588,60.007,63.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.906 | Acc: 39.806,59.527,63.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.914 | Acc: 38.909,59.606,63.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.902 | Acc: 39.265,59.819,63.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.890 | Acc: 39.364,59.940,63.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.874 | Acc: 39.560,60.169,64.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.868 | Acc: 39.517,60.068,64.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.873 | Acc: 39.621,60.069,64.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.860 | Acc: 39.775,60.174,64.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.855 | Acc: 39.960,60.312,64.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.870 | Acc: 39.950,60.329,64.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.883 | Acc: 39.954,60.156,63.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.892 | Acc: 39.886,60.129,63.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.895 | Acc: 39.949,60.078,63.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.890 | Acc: 40.028,60.143,63.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.886 | Acc: 40.129,60.171,63.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.879 | Acc: 40.185,60.271,63.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.888 | Acc: 40.060,60.180,63.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.892 | Acc: 40.024,60.167,63.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.258 | Acc: 30.469,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.192 | Acc: 34.449,50.484,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.261 | Acc: 33.232,48.990,54.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.268 | Acc: 33.222,48.758,53.740,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 5.013 | Acc: 35.938,58.594,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.678 | Acc: 41.481,62.426,65.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.703 | Acc: 41.940,61.757,65.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.763 | Acc: 41.099,61.475,64.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.776 | Acc: 41.435,61.497,64.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.762 | Acc: 41.228,61.363,64.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.775 | Acc: 41.090,60.957,64.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.811 | Acc: 40.619,60.583,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.822 | Acc: 40.504,60.525,64.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.811 | Acc: 40.660,60.808,64.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.823 | Acc: 40.489,60.720,64.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.825 | Acc: 40.409,60.715,64.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.821 | Acc: 40.366,60.727,64.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.823 | Acc: 40.457,60.692,64.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.824 | Acc: 40.405,60.648,64.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.827 | Acc: 40.342,60.566,64.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.830 | Acc: 40.391,60.551,64.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.828 | Acc: 40.396,60.614,64.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.834 | Acc: 40.339,60.576,64.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.846 | Acc: 40.233,60.474,64.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.232 | Acc: 32.812,45.312,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.591 | Acc: 29.129,48.475,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.624 | Acc: 28.773,47.904,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.623 | Acc: 28.599,47.900,52.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.888 | Acc: 44.531,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 41.146,62.277,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 40.968,61.986,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.712 | Acc: 40.612,61.322,65.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.742 | Acc: 40.114,61.265,65.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.766 | Acc: 40.068,61.162,65.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.764 | Acc: 40.212,61.325,65.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.764 | Acc: 40.293,61.281,65.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.775 | Acc: 40.310,61.141,65.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.781 | Acc: 40.401,61.171,65.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.789 | Acc: 40.357,61.031,64.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.801 | Acc: 40.293,60.948,64.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.800 | Acc: 40.418,60.934,64.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.798 | Acc: 40.505,60.991,64.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.809 | Acc: 40.514,60.843,64.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.823 | Acc: 40.394,60.727,64.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.823 | Acc: 40.355,60.721,64.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.834 | Acc: 40.297,60.669,64.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.837 | Acc: 40.383,60.598,64.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.839 | Acc: 40.473,60.546,64.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.774 | Acc: 29.688,50.000,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.616 | Acc: 31.548,46.540,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.624 | Acc: 30.983,45.998,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.622 | Acc: 30.917,46.145,51.729,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.877 | Acc: 40.625,58.594,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.775 | Acc: 40.737,60.640,64.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.802 | Acc: 40.225,60.938,65.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.816 | Acc: 40.292,60.745,64.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.782 | Acc: 40.596,60.764,64.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.828 | Acc: 40.354,60.512,64.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.813 | Acc: 40.373,60.511,64.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.819 | Acc: 40.348,60.683,64.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.829 | Acc: 40.101,60.724,64.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.830 | Acc: 40.180,60.704,64.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.832 | Acc: 40.217,60.724,64.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.817 | Acc: 40.409,60.945,64.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.831 | Acc: 40.340,60.821,64.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.829 | Acc: 40.308,60.785,64.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.834 | Acc: 40.252,60.754,64.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.831 | Acc: 40.220,60.756,64.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.832 | Acc: 40.187,60.748,64.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.828 | Acc: 40.242,60.754,64.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.826 | Acc: 40.257,60.788,64.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.828 | Acc: 40.317,60.784,64.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.358 | Acc: 28.906,49.219,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.209 | Acc: 33.185,49.777,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.267 | Acc: 32.374,48.933,54.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.262 | Acc: 32.531,49.321,54.086,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.155 | Acc: 43.750,62.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 41.183,62.984,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 41.921,62.995,66.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 41.509,62.538,66.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.691 | Acc: 41.503,62.211,65.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.719 | Acc: 41.058,61.873,65.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.740 | Acc: 40.877,61.532,65.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.769 | Acc: 40.631,61.253,65.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.763 | Acc: 40.591,61.224,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.773 | Acc: 40.383,61.296,65.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.783 | Acc: 40.516,61.221,65.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.790 | Acc: 40.554,61.065,65.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.798 | Acc: 40.495,61.116,64.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.807 | Acc: 40.418,60.994,64.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.807 | Acc: 40.505,60.946,64.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.812 | Acc: 40.433,60.917,64.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.811 | Acc: 40.462,60.998,64.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.812 | Acc: 40.513,60.908,64.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.813 | Acc: 40.445,60.870,64.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.814 | Acc: 40.436,60.802,64.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.189 | Acc: 32.812,50.000,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.464 | Acc: 31.324,47.991,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.546 | Acc: 30.526,47.580,52.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.532 | Acc: 30.571,47.195,52.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 4.122 | Acc: 50.781,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.871 | Acc: 40.067,60.789,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.877 | Acc: 40.339,60.347,65.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.804 | Acc: 40.574,61.014,66.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.782 | Acc: 40.635,61.314,66.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.774 | Acc: 40.795,61.200,66.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.781 | Acc: 40.457,61.202,66.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.785 | Acc: 40.221,61.170,65.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.793 | Acc: 40.057,61.151,65.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.788 | Acc: 40.271,61.270,65.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.788 | Acc: 40.205,61.159,65.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.789 | Acc: 40.385,61.051,65.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.789 | Acc: 40.453,61.145,65.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.783 | Acc: 40.454,61.207,65.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.786 | Acc: 40.547,61.165,65.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.791 | Acc: 40.534,61.119,65.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.803 | Acc: 40.352,61.052,65.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.804 | Acc: 40.352,60.990,64.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.804 | Acc: 40.404,61.011,64.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.810 | Acc: 40.303,60.991,64.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.874 | Acc: 29.688,43.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.978 | Acc: 26.562,45.945,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.036 | Acc: 26.296,45.027,51.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.022 | Acc: 26.204,45.402,51.627,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.260 | Acc: 42.188,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.666 | Acc: 39.658,61.384,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.629 | Acc: 40.206,61.947,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 40.651,62.372,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.665 | Acc: 40.316,62.105,66.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.678 | Acc: 40.184,61.889,66.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.687 | Acc: 40.412,61.725,66.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.712 | Acc: 40.387,61.408,65.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.728 | Acc: 40.232,61.379,65.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.728 | Acc: 40.362,61.473,65.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.727 | Acc: 40.431,61.517,65.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.731 | Acc: 40.484,61.439,65.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.738 | Acc: 40.486,61.401,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.745 | Acc: 40.371,61.270,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.754 | Acc: 40.369,61.277,65.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.766 | Acc: 40.376,61.124,65.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.767 | Acc: 40.433,61.183,65.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.768 | Acc: 40.435,61.238,65.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.778 | Acc: 40.367,61.180,65.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.774 | Acc: 40.432,61.186,65.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.757 | Acc: 31.250,51.562,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.034 | Acc: 29.353,47.507,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.062 | Acc: 29.021,47.504,50.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.030 | Acc: 28.804,47.541,50.461,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.760 | Acc: 41.406,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.598 | Acc: 42.150,63.653,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 41.978,63.148,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 41.867,62.436,66.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.674 | Acc: 41.657,62.153,66.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.693 | Acc: 41.429,61.928,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.725 | Acc: 41.142,61.693,66.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.717 | Acc: 41.162,61.846,65.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.719 | Acc: 41.013,61.859,66.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.727 | Acc: 41.104,61.753,65.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.738 | Acc: 40.979,61.723,65.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.738 | Acc: 40.915,61.690,65.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.738 | Acc: 40.920,61.612,65.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.742 | Acc: 40.781,61.506,65.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.739 | Acc: 40.722,61.530,65.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.746 | Acc: 40.609,61.496,65.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.753 | Acc: 40.489,61.342,65.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.755 | Acc: 40.536,61.293,65.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.762 | Acc: 40.525,61.232,65.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.774 | Acc: 40.479,61.138,65.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.226 | Acc: 24.219,41.406,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.326 | Acc: 26.228,44.308,49.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.453 | Acc: 25.400,44.284,48.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.451 | Acc: 25.077,44.121,48.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.805 | Acc: 42.969,64.062,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.584 | Acc: 41.704,62.537,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 40.949,61.776,66.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 41.060,62.090,66.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.647 | Acc: 41.020,61.892,66.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.682 | Acc: 40.370,61.587,65.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.694 | Acc: 40.709,61.628,65.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.706 | Acc: 40.858,61.708,65.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.695 | Acc: 40.950,61.869,65.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.706 | Acc: 41.009,61.853,65.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.710 | Acc: 41.037,61.824,65.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.713 | Acc: 40.954,61.927,65.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.718 | Acc: 40.875,61.803,65.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.728 | Acc: 40.796,61.728,65.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.732 | Acc: 40.786,61.580,65.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.737 | Acc: 40.817,61.464,65.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.740 | Acc: 40.747,61.407,65.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.737 | Acc: 40.742,61.403,65.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.746 | Acc: 40.610,61.227,65.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.749 | Acc: 40.604,61.274,65.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.110 | Acc: 32.031,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.254 | Acc: 31.734,48.549,53.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.374 | Acc: 31.136,48.095,52.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.358 | Acc: 31.301,48.181,52.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.465 | Acc: 46.094,69.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 41.146,63.765,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.547 | Acc: 41.178,63.796,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 40.894,63.025,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.655 | Acc: 40.654,62.606,66.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.705 | Acc: 40.269,62.136,65.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.712 | Acc: 40.386,61.829,65.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.722 | Acc: 40.403,61.602,65.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.732 | Acc: 40.324,61.466,65.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.718 | Acc: 40.530,61.460,65.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.727 | Acc: 40.590,61.462,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.724 | Acc: 40.576,61.542,65.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.723 | Acc: 40.570,61.647,65.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.735 | Acc: 40.475,61.587,65.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.738 | Acc: 40.500,61.594,65.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.741 | Acc: 40.578,61.563,65.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.744 | Acc: 40.525,61.497,65.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.754 | Acc: 40.437,61.451,65.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.766 | Acc: 40.430,61.336,65.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.768 | Acc: 40.434,61.249,65.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.271 | Acc: 32.812,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.619 | Acc: 31.064,47.805,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.684 | Acc: 30.945,47.580,54.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.714 | Acc: 30.776,47.439,53.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.670 | Acc: 42.188,63.281,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 39.955,62.351,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.680 | Acc: 40.206,61.490,65.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 40.638,61.796,65.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.709 | Acc: 40.557,61.487,65.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.706 | Acc: 40.610,61.788,65.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.707 | Acc: 40.470,61.796,65.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.705 | Acc: 40.470,61.879,65.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.686 | Acc: 40.606,62.112,65.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.689 | Acc: 40.500,62.137,65.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.704 | Acc: 40.349,62.037,65.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.710 | Acc: 40.381,61.973,65.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.713 | Acc: 40.434,61.861,65.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.723 | Acc: 40.469,61.752,65.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.726 | Acc: 40.505,61.680,65.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.736 | Acc: 40.495,61.646,65.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.744 | Acc: 40.352,61.558,65.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.742 | Acc: 40.368,61.554,65.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.741 | Acc: 40.467,61.574,65.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.741 | Acc: 40.467,61.585,65.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.942 | Acc: 26.562,50.000,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.510 | Acc: 26.562,44.234,47.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.576 | Acc: 26.467,43.445,47.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.601 | Acc: 26.358,43.430,47.554,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 4.493 | Acc: 44.531,61.719,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.616 | Acc: 40.551,62.016,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.666 | Acc: 39.996,61.928,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.706 | Acc: 39.690,61.527,65.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.722 | Acc: 40.017,61.593,65.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.706 | Acc: 40.385,61.641,65.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.685 | Acc: 40.554,61.900,66.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.700 | Acc: 40.542,61.791,66.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.703 | Acc: 40.707,61.830,66.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.695 | Acc: 40.772,61.801,66.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.692 | Acc: 40.808,61.859,66.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.690 | Acc: 40.685,61.867,66.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.695 | Acc: 40.680,61.787,66.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.700 | Acc: 40.610,61.749,66.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.707 | Acc: 40.505,61.752,66.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.708 | Acc: 40.511,61.758,65.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.704 | Acc: 40.574,61.799,66.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.718 | Acc: 40.543,61.751,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.719 | Acc: 40.562,61.751,65.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.721 | Acc: 40.557,61.784,65.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.152 | Acc: 38.281,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.101 | Acc: 34.226,50.818,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.158 | Acc: 33.861,50.572,54.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.218 | Acc: 33.671,49.846,54.265,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.772 | Acc: 38.281,64.062,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 40.290,62.612,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 40.587,62.671,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 40.638,62.551,68.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.615 | Acc: 40.799,62.490,67.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.665 | Acc: 40.370,61.997,66.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.669 | Acc: 40.451,62.164,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.671 | Acc: 40.437,62.084,66.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.676 | Acc: 40.344,62.126,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.672 | Acc: 40.629,62.163,66.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.678 | Acc: 40.808,62.041,66.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.679 | Acc: 40.872,62.065,66.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.689 | Acc: 40.845,61.929,66.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.688 | Acc: 40.876,61.955,66.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.686 | Acc: 40.928,61.980,66.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.695 | Acc: 40.843,61.877,66.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.699 | Acc: 40.846,61.838,66.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.697 | Acc: 40.843,61.840,66.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.700 | Acc: 40.863,61.840,65.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.707 | Acc: 40.785,61.793,65.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.091 | Acc: 31.250,60.156,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.233 | Acc: 30.804,50.632,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.202 | Acc: 30.373,50.953,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.209 | Acc: 30.238,50.845,56.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.030 | Acc: 49.219,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 42.039,61.533,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.693 | Acc: 41.006,60.899,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.727 | Acc: 40.369,60.912,66.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.714 | Acc: 40.606,61.121,66.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.712 | Acc: 40.772,61.293,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.725 | Acc: 40.457,61.202,66.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.711 | Acc: 40.736,61.475,66.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.713 | Acc: 40.683,61.418,66.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.715 | Acc: 40.621,61.408,66.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.713 | Acc: 40.613,61.552,66.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.715 | Acc: 40.667,61.411,66.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.725 | Acc: 40.687,61.339,66.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.719 | Acc: 40.760,61.431,66.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.723 | Acc: 40.695,61.388,66.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.732 | Acc: 40.609,61.298,66.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.733 | Acc: 40.571,61.222,66.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.731 | Acc: 40.575,61.206,66.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.730 | Acc: 40.590,61.204,66.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.727 | Acc: 40.660,61.225,66.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.659 | Acc: 32.812,52.344,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.949 | Acc: 29.353,46.168,51.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.841 | Acc: 29.668,46.418,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.869 | Acc: 29.342,46.107,51.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.738 | Acc: 35.938,59.375,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.689 | Acc: 40.290,62.351,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 40.758,63.072,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 40.561,62.577,67.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.662 | Acc: 40.278,62.269,66.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.647 | Acc: 40.857,62.523,67.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.638 | Acc: 40.735,62.642,67.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.638 | Acc: 40.703,62.478,66.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.659 | Acc: 40.771,62.408,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.671 | Acc: 40.703,62.245,66.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.685 | Acc: 40.539,62.139,66.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.683 | Acc: 40.653,62.055,66.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.687 | Acc: 40.654,61.981,66.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.688 | Acc: 40.733,61.916,66.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.696 | Acc: 40.631,61.841,66.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.698 | Acc: 40.609,61.854,66.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.698 | Acc: 40.664,61.860,66.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.705 | Acc: 40.614,61.787,66.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.704 | Acc: 40.675,61.816,65.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.711 | Acc: 40.602,61.756,65.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.402 | Acc: 26.562,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.011 | Acc: 25.372,46.540,53.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.023 | Acc: 25.572,46.265,52.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.021 | Acc: 25.576,46.324,52.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.695 | Acc: 37.500,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.521 | Acc: 40.923,62.574,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 40.358,62.786,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 40.535,62.897,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.587 | Acc: 40.712,62.809,67.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.573 | Acc: 40.726,62.732,67.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.595 | Acc: 40.715,62.597,66.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.587 | Acc: 40.824,62.688,66.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.589 | Acc: 40.950,62.791,67.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.582 | Acc: 41.177,62.893,67.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.587 | Acc: 41.212,62.768,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.595 | Acc: 41.141,62.659,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.609 | Acc: 41.102,62.461,66.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.621 | Acc: 41.089,62.431,66.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.624 | Acc: 41.087,62.414,66.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.643 | Acc: 40.986,62.272,66.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.649 | Acc: 41.005,62.279,66.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.666 | Acc: 40.943,62.182,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.672 | Acc: 40.963,62.184,66.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.680 | Acc: 40.912,62.147,66.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.658 | Acc: 32.812,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.910 | Acc: 28.088,46.205,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.988 | Acc: 28.049,46.075,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.044 | Acc: 28.112,45.761,50.922,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 5.008 | Acc: 42.969,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.632 | Acc: 40.551,62.760,68.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 40.854,61.700,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.669 | Acc: 40.817,61.616,66.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.670 | Acc: 40.847,61.564,66.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.706 | Acc: 40.764,61.572,66.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.675 | Acc: 40.941,61.880,66.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.648 | Acc: 41.135,62.295,66.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.657 | Acc: 40.984,62.335,66.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.671 | Acc: 40.716,62.159,66.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.655 | Acc: 40.862,62.286,66.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.647 | Acc: 41.046,62.359,66.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.647 | Acc: 41.069,62.338,66.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.648 | Acc: 41.155,62.281,66.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.648 | Acc: 41.150,62.269,66.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.647 | Acc: 41.121,62.305,66.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.644 | Acc: 41.180,62.298,66.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.648 | Acc: 41.163,62.237,66.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.656 | Acc: 41.075,62.169,66.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.656 | Acc: 41.060,62.149,66.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.683 | Acc: 25.000,55.469,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.737 | Acc: 26.153,50.446,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.729 | Acc: 26.239,49.524,54.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.719 | Acc: 26.230,49.270,54.355,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.775 | Acc: 41.406,57.812,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 41.443,62.314,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.526 | Acc: 41.101,63.681,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.529 | Acc: 41.291,63.576,68.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.560 | Acc: 41.184,62.915,67.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.577 | Acc: 41.105,62.840,67.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.577 | Acc: 41.187,62.784,67.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.595 | Acc: 41.085,62.744,67.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.615 | Acc: 40.931,62.587,67.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.621 | Acc: 40.824,62.491,67.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.627 | Acc: 41.006,62.333,67.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.639 | Acc: 40.858,62.327,66.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.641 | Acc: 40.842,62.361,66.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.643 | Acc: 40.778,62.302,66.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.638 | Acc: 40.897,62.389,67.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.646 | Acc: 40.833,62.336,66.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.657 | Acc: 40.744,62.237,66.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.658 | Acc: 40.817,62.269,66.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.665 | Acc: 40.798,62.147,66.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.671 | Acc: 40.799,62.067,66.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.807 | Acc: 39.062,60.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.135 | Acc: 31.994,52.158,57.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.145 | Acc: 32.222,51.181,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.182 | Acc: 32.275,50.871,55.853,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.338 | Acc: 42.188,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 40.588,63.876,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.582 | Acc: 40.263,62.938,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 40.740,62.705,67.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.566 | Acc: 41.040,62.384,67.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.573 | Acc: 41.012,62.338,67.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.599 | Acc: 40.696,62.087,67.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.627 | Acc: 40.597,62.051,67.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.629 | Acc: 40.824,62.024,66.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.632 | Acc: 40.867,62.034,66.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.632 | Acc: 40.858,62.115,66.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.644 | Acc: 40.894,62.030,66.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.645 | Acc: 41.008,62.088,66.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.646 | Acc: 41.020,62.072,66.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.661 | Acc: 40.906,62.047,66.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.654 | Acc: 41.022,62.056,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.659 | Acc: 40.990,62.081,66.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.656 | Acc: 40.955,62.104,66.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.665 | Acc: 40.928,61.996,66.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.663 | Acc: 40.916,62.018,66.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.875 | Acc: 35.156,54.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.304 | Acc: 28.460,50.074,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.298 | Acc: 29.040,49.428,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.320 | Acc: 29.162,49.219,55.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 3.959 | Acc: 51.562,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 41.890,65.476,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.417 | Acc: 41.768,64.882,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.445 | Acc: 42.597,64.408,69.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.458 | Acc: 42.284,64.111,69.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.462 | Acc: 42.211,64.070,68.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.513 | Acc: 41.871,63.617,68.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.523 | Acc: 41.866,63.686,68.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.543 | Acc: 41.649,63.446,67.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.564 | Acc: 41.480,63.290,67.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.567 | Acc: 41.616,63.153,67.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.566 | Acc: 41.601,63.027,67.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.576 | Acc: 41.497,62.892,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.588 | Acc: 41.454,62.757,67.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.598 | Acc: 41.395,62.581,67.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.608 | Acc: 41.308,62.477,67.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.614 | Acc: 41.328,62.449,66.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.615 | Acc: 41.390,62.427,66.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.617 | Acc: 41.411,62.409,66.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.622 | Acc: 41.437,62.361,66.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.277 | Acc: 32.031,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.702 | Acc: 30.655,47.731,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.674 | Acc: 30.926,47.580,51.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.662 | Acc: 31.250,47.374,51.883,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.389 | Acc: 36.719,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 41.109,62.202,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.565 | Acc: 41.578,63.091,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 41.522,63.691,68.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.561 | Acc: 41.464,63.011,68.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.582 | Acc: 41.399,62.894,67.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.580 | Acc: 41.393,62.791,67.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.569 | Acc: 41.329,62.949,67.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.571 | Acc: 41.275,63.024,67.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.589 | Acc: 41.143,62.832,67.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.595 | Acc: 41.235,62.788,67.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.595 | Acc: 41.215,62.818,67.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.605 | Acc: 41.150,62.789,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.604 | Acc: 41.122,62.713,67.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.616 | Acc: 41.073,62.525,67.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.621 | Acc: 41.061,62.503,67.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.635 | Acc: 40.951,62.410,67.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.638 | Acc: 40.840,62.314,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.646 | Acc: 40.850,62.199,66.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.643 | Acc: 40.898,62.178,66.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.987 | Acc: 26.562,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.233 | Acc: 26.674,44.159,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.370 | Acc: 26.791,43.350,50.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.358 | Acc: 26.985,43.148,50.564,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.702 | Acc: 39.844,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 42.932,63.132,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.466 | Acc: 42.740,63.681,68.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.465 | Acc: 42.520,63.934,69.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.505 | Acc: 42.101,63.571,68.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.501 | Acc: 42.218,63.800,68.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.509 | Acc: 42.271,63.552,67.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.528 | Acc: 41.988,63.259,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.544 | Acc: 41.804,63.170,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.550 | Acc: 41.821,63.009,67.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.560 | Acc: 41.651,63.071,67.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.568 | Acc: 41.590,62.998,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.577 | Acc: 41.533,62.821,67.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.593 | Acc: 41.355,62.611,67.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.590 | Acc: 41.376,62.656,67.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.607 | Acc: 41.217,62.484,66.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.610 | Acc: 41.253,62.408,66.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.615 | Acc: 41.276,62.353,66.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.616 | Acc: 41.274,62.387,66.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.622 | Acc: 41.189,62.361,66.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.892 | Acc: 28.125,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.085 | Acc: 25.670,45.833,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.128 | Acc: 24.924,44.950,51.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.094 | Acc: 24.936,45.415,52.049,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.383 | Acc: 42.969,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.745 | Acc: 39.732,61.496,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.567 | Acc: 41.597,62.995,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 41.381,63.153,67.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.572 | Acc: 41.483,62.751,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.590 | Acc: 41.553,62.817,67.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.575 | Acc: 41.451,62.752,67.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.591 | Acc: 41.179,62.627,67.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.602 | Acc: 41.358,62.587,67.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.609 | Acc: 41.160,62.530,67.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.612 | Acc: 41.123,62.492,67.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.604 | Acc: 41.000,62.585,67.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.598 | Acc: 41.095,62.646,67.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.607 | Acc: 41.059,62.590,66.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.611 | Acc: 41.170,62.481,66.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.616 | Acc: 41.160,62.422,66.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.615 | Acc: 41.209,62.420,66.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.626 | Acc: 41.182,62.310,66.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.627 | Acc: 41.201,62.325,66.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.627 | Acc: 41.168,62.369,66.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.171 | Acc: 29.688,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.959 | Acc: 29.650,46.503,51.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.950 | Acc: 29.535,45.598,52.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.930 | Acc: 29.956,45.543,51.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.926 | Acc: 35.156,57.812,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 42.225,64.435,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.482 | Acc: 41.940,64.082,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.483 | Acc: 41.995,63.486,68.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.498 | Acc: 41.975,63.426,68.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.512 | Acc: 41.847,63.219,68.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.518 | Acc: 41.742,63.159,67.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.535 | Acc: 41.639,62.988,67.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.535 | Acc: 41.819,63.029,67.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.542 | Acc: 41.903,62.983,67.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.558 | Acc: 41.826,62.842,67.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.567 | Acc: 41.731,62.786,67.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.567 | Acc: 41.679,62.870,67.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.570 | Acc: 41.634,62.754,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.570 | Acc: 41.768,62.778,67.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.581 | Acc: 41.713,62.718,67.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.585 | Acc: 41.545,62.687,67.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.591 | Acc: 41.541,62.621,67.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.593 | Acc: 41.525,62.565,67.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.605 | Acc: 41.419,62.471,67.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.557 | Acc: 35.156,50.000,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.647 | Acc: 29.985,48.326,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.767 | Acc: 29.421,47.104,52.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.808 | Acc: 29.521,46.273,51.691,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.596 | Acc: 40.625,60.938,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 42.374,64.025,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.497 | Acc: 41.749,63.605,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.513 | Acc: 41.342,63.153,68.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.516 | Acc: 41.551,63.291,68.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.532 | Acc: 41.468,63.103,68.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.543 | Acc: 41.497,62.984,68.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.546 | Acc: 41.528,63.187,67.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.550 | Acc: 41.712,63.092,67.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.550 | Acc: 41.777,63.052,67.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.562 | Acc: 41.737,63.040,67.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.570 | Acc: 41.657,62.970,67.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.576 | Acc: 41.594,62.801,67.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.572 | Acc: 41.631,62.790,67.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.570 | Acc: 41.723,62.825,67.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.575 | Acc: 41.606,62.741,67.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.586 | Acc: 41.511,62.673,67.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.594 | Acc: 41.404,62.553,67.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.596 | Acc: 41.452,62.548,67.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.596 | Acc: 41.478,62.615,67.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.959 | Acc: 35.938,50.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.224 | Acc: 33.073,50.446,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.236 | Acc: 32.431,49.981,55.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.243 | Acc: 32.800,50.205,54.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.256 | Acc: 49.219,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.376 | Acc: 42.039,64.062,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 41.502,63.186,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.490 | Acc: 41.714,62.782,68.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.532 | Acc: 41.628,62.452,67.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.544 | Acc: 41.638,62.446,67.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.540 | Acc: 41.529,62.506,67.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.522 | Acc: 41.717,62.733,67.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.532 | Acc: 41.727,62.684,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.535 | Acc: 41.795,62.660,67.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.528 | Acc: 41.838,62.815,67.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.533 | Acc: 41.873,62.818,67.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.539 | Acc: 41.756,62.701,67.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.544 | Acc: 41.706,62.698,67.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.554 | Acc: 41.695,62.581,67.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.562 | Acc: 41.578,62.570,67.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.562 | Acc: 41.633,62.561,67.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.569 | Acc: 41.564,62.537,67.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.579 | Acc: 41.549,62.461,67.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.584 | Acc: 41.560,62.490,67.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.961 | Acc: 31.250,58.594,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.234 | Acc: 29.613,52.976,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.282 | Acc: 28.982,51.696,54.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.303 | Acc: 29.124,51.037,54.867,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.244 | Acc: 40.625,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 41.443,62.835,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.555 | Acc: 41.673,62.424,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 41.573,62.257,67.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.556 | Acc: 41.946,62.674,67.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.567 | Acc: 41.847,62.608,67.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.571 | Acc: 41.942,62.655,67.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.578 | Acc: 41.689,62.644,67.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.596 | Acc: 41.542,62.573,67.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.600 | Acc: 41.544,62.556,67.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.590 | Acc: 41.636,62.586,67.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.582 | Acc: 41.597,62.585,67.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.571 | Acc: 41.614,62.610,67.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.562 | Acc: 41.730,62.683,67.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.574 | Acc: 41.620,62.603,67.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.587 | Acc: 41.510,62.542,67.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.584 | Acc: 41.455,62.622,67.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.590 | Acc: 41.475,62.527,67.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.592 | Acc: 41.439,62.513,67.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.594 | Acc: 41.451,62.426,67.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.580 | Acc: 39.844,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.729 | Acc: 36.496,53.274,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.781 | Acc: 35.728,53.144,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.816 | Acc: 35.451,52.485,56.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.221 | Acc: 46.875,67.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.395 | Acc: 42.894,64.621,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.385 | Acc: 43.045,65.225,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.407 | Acc: 42.777,64.882,69.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.441 | Acc: 42.496,64.815,68.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.473 | Acc: 42.296,64.349,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.518 | Acc: 41.845,63.630,68.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.524 | Acc: 41.766,63.664,67.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.528 | Acc: 41.557,63.441,67.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.530 | Acc: 41.480,63.311,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.540 | Acc: 41.402,63.207,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.539 | Acc: 41.480,63.055,67.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.541 | Acc: 41.403,63.093,67.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.547 | Acc: 41.316,63.063,67.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.553 | Acc: 41.287,62.964,67.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.563 | Acc: 41.191,62.739,67.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.570 | Acc: 41.182,62.702,67.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.569 | Acc: 41.212,62.697,67.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.570 | Acc: 41.272,62.699,67.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.576 | Acc: 41.332,62.666,67.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.623 | Acc: 28.125,49.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.302 | Acc: 26.525,44.494,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.275 | Acc: 26.677,43.998,49.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.307 | Acc: 26.588,44.057,49.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.806 | Acc: 40.625,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.498 | Acc: 42.225,63.653,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 42.188,64.043,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.456 | Acc: 42.495,64.114,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.439 | Acc: 42.486,64.149,69.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.443 | Acc: 42.597,64.356,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.470 | Acc: 42.259,64.075,68.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.493 | Acc: 42.071,63.869,68.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.519 | Acc: 41.940,63.694,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.525 | Acc: 41.881,63.730,68.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.534 | Acc: 41.818,63.487,68.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.544 | Acc: 41.742,63.391,68.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.556 | Acc: 41.617,63.239,68.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.553 | Acc: 41.616,63.359,68.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.555 | Acc: 41.604,63.287,68.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.562 | Acc: 41.585,63.258,67.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.566 | Acc: 41.477,63.199,67.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.568 | Acc: 41.464,63.103,67.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.568 | Acc: 41.419,63.099,67.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.575 | Acc: 41.365,63.056,67.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.656 | Acc: 37.500,59.375,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.924 | Acc: 34.152,53.906,57.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.924 | Acc: 33.765,52.992,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.955 | Acc: 34.183,52.421,56.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.512 | Acc: 43.750,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 42.188,63.616,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.431 | Acc: 42.931,63.872,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.428 | Acc: 42.777,64.062,68.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.467 | Acc: 42.091,63.648,68.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.488 | Acc: 41.832,63.475,68.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.515 | Acc: 41.581,63.307,68.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.522 | Acc: 41.645,63.237,68.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.529 | Acc: 41.532,63.160,68.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.528 | Acc: 41.531,63.208,68.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.515 | Acc: 41.783,63.340,68.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.520 | Acc: 41.799,63.352,67.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.536 | Acc: 41.666,63.236,67.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.546 | Acc: 41.655,63.111,67.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.540 | Acc: 41.698,63.101,67.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.545 | Acc: 41.642,63.102,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.556 | Acc: 41.574,63.045,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.566 | Acc: 41.429,62.910,67.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.568 | Acc: 41.469,62.911,67.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.572 | Acc: 41.478,62.892,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.700 | Acc: 35.156,58.594,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.829 | Acc: 33.371,53.237,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.810 | Acc: 33.613,53.011,57.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.828 | Acc: 34.324,52.805,57.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.776 | Acc: 42.188,63.281,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.384 | Acc: 42.634,63.318,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.384 | Acc: 42.435,64.082,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.401 | Acc: 42.111,64.229,69.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.434 | Acc: 42.226,64.313,68.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.482 | Acc: 41.638,63.761,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.499 | Acc: 41.522,63.520,68.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.491 | Acc: 41.467,63.597,68.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.505 | Acc: 41.358,63.315,68.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.499 | Acc: 41.765,63.342,68.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.507 | Acc: 41.877,63.343,68.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.507 | Acc: 41.912,63.451,68.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.511 | Acc: 41.837,63.401,68.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.514 | Acc: 41.846,63.311,68.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.520 | Acc: 41.784,63.198,68.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.523 | Acc: 41.751,63.188,68.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.524 | Acc: 41.786,63.257,67.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.526 | Acc: 41.855,63.375,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.531 | Acc: 41.826,63.296,68.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.545 | Acc: 41.734,63.160,67.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.751 | Acc: 40.625,52.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.147 | Acc: 33.519,52.083,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.149 | Acc: 33.232,50.991,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.139 | Acc: 32.864,50.730,54.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.533 | Acc: 41.406,63.281,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.452 | Acc: 42.299,64.918,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.505 | Acc: 41.864,62.938,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.500 | Acc: 41.957,63.038,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.466 | Acc: 42.159,63.619,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.448 | Acc: 42.157,63.784,69.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.490 | Acc: 41.774,63.468,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.483 | Acc: 41.994,63.608,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.497 | Acc: 41.969,63.451,68.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.504 | Acc: 41.985,63.411,68.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.516 | Acc: 41.845,63.289,68.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.518 | Acc: 41.876,63.221,68.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.519 | Acc: 41.789,63.152,68.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.532 | Acc: 41.724,63.069,68.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.535 | Acc: 41.729,63.081,68.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.539 | Acc: 41.749,63.040,68.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.542 | Acc: 41.771,62.953,68.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.546 | Acc: 41.764,62.931,68.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.542 | Acc: 41.783,62.952,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.545 | Acc: 41.736,62.959,68.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.974 | Acc: 36.719,53.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.201 | Acc: 32.775,50.446,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.176 | Acc: 32.774,50.267,56.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.200 | Acc: 33.158,50.461,56.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.477 | Acc: 32.812,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 43.118,66.778,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 41.806,64.958,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.403 | Acc: 41.483,64.511,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.396 | Acc: 41.821,64.468,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.396 | Acc: 41.839,64.472,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.429 | Acc: 41.761,64.095,69.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.451 | Acc: 41.645,63.946,69.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.450 | Acc: 41.799,64.082,69.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.462 | Acc: 41.842,63.898,68.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.471 | Acc: 41.783,63.775,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.475 | Acc: 41.813,63.748,68.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.484 | Acc: 41.659,63.719,68.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.499 | Acc: 41.595,63.497,68.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.505 | Acc: 41.506,63.412,68.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.508 | Acc: 41.513,63.372,68.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.525 | Acc: 41.433,63.284,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.521 | Acc: 41.512,63.348,68.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.525 | Acc: 41.432,63.374,68.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.526 | Acc: 41.414,63.355,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.618 | Acc: 38.281,56.250,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.032 | Acc: 32.143,51.302,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.103 | Acc: 31.517,50.343,55.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.134 | Acc: 31.865,50.154,55.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.409 | Acc: 42.188,59.375,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.507 | Acc: 42.374,63.467,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 42.607,63.624,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.441 | Acc: 42.520,63.845,69.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.438 | Acc: 42.390,63.850,68.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.455 | Acc: 42.242,63.792,68.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.476 | Acc: 41.987,63.591,68.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.485 | Acc: 41.960,63.514,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.499 | Acc: 41.877,63.461,68.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.487 | Acc: 42.131,63.463,68.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.483 | Acc: 42.098,63.421,68.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.476 | Acc: 42.064,63.578,68.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.482 | Acc: 41.954,63.537,68.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.489 | Acc: 41.885,63.527,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.513 | Acc: 41.768,63.342,68.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.521 | Acc: 41.731,63.297,68.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.516 | Acc: 41.801,63.340,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.517 | Acc: 41.835,63.304,68.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.517 | Acc: 41.794,63.262,68.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.525 | Acc: 41.818,63.179,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.162 | Acc: 26.562,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.319 | Acc: 30.878,49.479,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.277 | Acc: 30.507,49.295,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.280 | Acc: 30.264,48.975,56.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 5.126 | Acc: 39.844,57.812,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.457 | Acc: 40.848,63.542,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.470 | Acc: 41.216,63.377,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.510 | Acc: 41.009,62.961,69.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.463 | Acc: 41.233,63.252,69.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.445 | Acc: 41.445,63.498,69.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.456 | Acc: 41.606,63.372,69.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.446 | Acc: 41.567,63.730,69.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.452 | Acc: 41.688,63.616,69.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.448 | Acc: 41.575,63.782,69.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.451 | Acc: 41.628,63.888,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.461 | Acc: 41.512,63.698,68.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.478 | Acc: 41.409,63.609,68.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.488 | Acc: 41.457,63.545,68.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.494 | Acc: 41.534,63.495,68.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.497 | Acc: 41.616,63.382,68.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.495 | Acc: 41.664,63.396,68.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.491 | Acc: 41.754,63.446,68.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.495 | Acc: 41.705,63.394,68.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.505 | Acc: 41.702,63.343,68.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.730 | Acc: 35.156,54.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.081 | Acc: 33.073,52.046,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.086 | Acc: 33.041,51.658,57.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.082 | Acc: 33.466,51.614,56.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.584 | Acc: 41.406,65.625,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.296 | Acc: 42.969,65.885,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 42.607,65.663,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.371 | Acc: 42.623,65.228,70.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.387 | Acc: 42.390,64.593,69.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.414 | Acc: 42.188,64.163,69.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.413 | Acc: 42.058,64.153,69.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.434 | Acc: 41.816,64.179,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.423 | Acc: 41.911,64.339,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.448 | Acc: 41.855,64.188,69.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.453 | Acc: 41.900,64.160,69.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.454 | Acc: 41.912,64.158,69.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.472 | Acc: 41.828,63.884,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.476 | Acc: 41.900,63.811,68.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.488 | Acc: 41.795,63.682,68.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.499 | Acc: 41.811,63.556,68.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.502 | Acc: 41.752,63.491,68.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.499 | Acc: 41.839,63.471,68.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.508 | Acc: 41.768,63.420,68.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.518 | Acc: 41.708,63.341,68.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.932 | Acc: 25.781,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.852 | Acc: 26.079,48.177,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.049 | Acc: 24.829,46.570,52.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.073 | Acc: 24.398,46.222,52.164,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 3.970 | Acc: 42.969,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.336 | Acc: 42.188,64.993,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.383 | Acc: 42.550,64.444,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 42.252,64.511,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.416 | Acc: 41.889,64.400,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.462 | Acc: 41.313,63.800,68.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.430 | Acc: 41.658,64.114,68.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.434 | Acc: 41.678,64.212,68.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.443 | Acc: 41.678,64.198,68.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.458 | Acc: 41.756,64.067,68.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.468 | Acc: 41.741,64.082,68.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.476 | Acc: 41.820,64.077,68.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.475 | Acc: 41.805,63.991,68.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.483 | Acc: 41.709,63.940,68.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.491 | Acc: 41.676,63.837,68.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.496 | Acc: 41.619,63.800,68.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.495 | Acc: 41.616,63.780,68.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.506 | Acc: 41.562,63.678,68.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.517 | Acc: 41.501,63.539,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.518 | Acc: 41.570,63.515,68.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.294 | Acc: 36.719,54.688,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.704 | Acc: 30.320,48.549,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.733 | Acc: 29.364,47.809,52.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.759 | Acc: 29.034,47.746,52.472,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.258 | Acc: 41.406,60.156,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 41.592,65.402,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.347 | Acc: 41.978,65.358,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.351 | Acc: 42.162,65.164,70.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.364 | Acc: 42.197,65.220,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.406 | Acc: 42.033,64.681,70.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.418 | Acc: 42.104,64.450,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.426 | Acc: 41.949,64.295,69.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.416 | Acc: 42.032,64.407,69.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 41.941,64.218,69.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.441 | Acc: 41.849,63.961,69.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.447 | Acc: 41.838,63.935,69.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.452 | Acc: 41.870,63.878,69.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.459 | Acc: 41.718,63.889,69.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.463 | Acc: 41.701,63.876,69.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.467 | Acc: 41.697,63.844,68.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.465 | Acc: 41.696,63.907,68.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.473 | Acc: 41.649,63.808,68.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.473 | Acc: 41.718,63.796,68.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.486 | Acc: 41.689,63.741,68.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.083 | Acc: 32.031,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.433 | Acc: 31.845,48.624,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.451 | Acc: 31.250,48.361,54.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.468 | Acc: 31.071,48.425,54.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.400 | Acc: 46.094,64.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.398 | Acc: 42.671,64.025,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.386 | Acc: 42.588,64.596,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.371 | Acc: 42.392,64.562,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.417 | Acc: 42.274,64.091,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.415 | Acc: 42.273,64.109,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.413 | Acc: 42.181,64.269,69.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.410 | Acc: 42.332,64.168,69.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.409 | Acc: 42.231,64.179,69.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.424 | Acc: 42.166,64.050,69.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.438 | Acc: 42.118,63.891,69.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.458 | Acc: 41.972,63.804,69.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.460 | Acc: 41.925,63.735,69.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.469 | Acc: 41.885,63.667,68.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.477 | Acc: 41.898,63.615,68.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.481 | Acc: 41.840,63.590,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.493 | Acc: 41.625,63.559,68.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.500 | Acc: 41.555,63.460,68.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.503 | Acc: 41.592,63.413,68.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.502 | Acc: 41.654,63.470,68.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.887 | Acc: 34.375,55.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.933 | Acc: 33.259,52.865,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.961 | Acc: 33.365,52.363,57.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.988 | Acc: 33.235,52.318,56.583,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 4.131 | Acc: 42.188,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.271 | Acc: 42.262,64.918,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 41.711,64.082,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.354 | Acc: 41.995,63.934,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.393 | Acc: 41.937,63.532,69.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.384 | Acc: 42.180,63.622,69.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.414 | Acc: 41.755,63.559,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.395 | Acc: 41.960,63.835,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.411 | Acc: 41.867,63.757,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.411 | Acc: 41.795,63.825,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.430 | Acc: 41.690,63.705,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.428 | Acc: 41.700,63.737,69.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.437 | Acc: 41.698,63.631,69.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.446 | Acc: 41.762,63.619,68.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.448 | Acc: 41.748,63.723,68.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.461 | Acc: 41.746,63.624,68.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.457 | Acc: 41.808,63.707,68.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.461 | Acc: 41.789,63.609,68.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.463 | Acc: 41.848,63.595,68.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.480 | Acc: 41.765,63.433,68.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.994 | Acc: 31.250,53.125,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.908 | Acc: 26.414,48.400,54.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.948 | Acc: 26.239,47.561,52.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.921 | Acc: 26.627,47.567,52.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.428 | Acc: 38.281,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.444 | Acc: 40.997,65.104,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 41.845,65.282,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.404 | Acc: 41.893,65.061,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.379 | Acc: 42.139,64.969,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.361 | Acc: 42.257,65.107,70.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.375 | Acc: 42.246,64.863,70.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.407 | Acc: 41.999,64.423,69.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.432 | Acc: 41.785,64.043,69.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.432 | Acc: 41.838,64.024,69.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.426 | Acc: 41.989,64.101,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.418 | Acc: 42.046,64.098,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.423 | Acc: 42.071,64.118,69.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.425 | Acc: 42.137,64.098,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.433 | Acc: 42.074,64.129,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 41.936,63.974,69.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.448 | Acc: 41.920,63.951,68.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.456 | Acc: 41.871,63.852,68.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.463 | Acc: 41.774,63.850,68.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.471 | Acc: 41.745,63.798,68.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.128 | Acc: 30.469,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.223 | Acc: 32.961,50.335,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.217 | Acc: 32.927,50.381,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.243 | Acc: 33.081,49.949,53.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.279 | Acc: 44.531,67.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.464 | Acc: 40.439,63.393,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.360 | Acc: 40.758,65.244,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.378 | Acc: 41.470,64.857,70.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.373 | Acc: 41.474,65.191,70.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.403 | Acc: 41.545,64.921,69.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.393 | Acc: 41.652,64.811,69.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.404 | Acc: 41.783,64.583,69.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.414 | Acc: 41.814,64.490,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.415 | Acc: 41.747,64.425,69.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.421 | Acc: 41.814,64.319,69.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.430 | Acc: 41.834,64.289,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.442 | Acc: 41.867,64.153,69.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.442 | Acc: 41.966,64.188,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.452 | Acc: 42.023,64.096,68.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.455 | Acc: 41.993,64.060,68.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.459 | Acc: 41.981,64.043,68.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.466 | Acc: 41.851,63.911,68.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 41.952,63.848,68.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.466 | Acc: 41.845,63.888,68.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.722 | Acc: 34.375,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.104 | Acc: 32.292,50.372,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.110 | Acc: 32.031,50.438,55.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.122 | Acc: 32.390,50.218,54.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.333 | Acc: 42.969,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.380 | Acc: 44.122,63.914,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.393 | Acc: 43.274,63.891,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.366 | Acc: 43.199,64.536,69.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.352 | Acc: 43.528,64.969,69.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.380 | Acc: 43.085,64.697,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.385 | Acc: 43.020,64.721,69.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.397 | Acc: 42.902,64.517,69.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.410 | Acc: 42.668,64.194,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.419 | Acc: 42.442,64.097,69.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.420 | Acc: 42.362,64.031,69.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.438 | Acc: 42.272,64.055,69.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.445 | Acc: 42.178,63.978,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.447 | Acc: 42.235,63.970,68.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.448 | Acc: 42.324,63.937,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.445 | Acc: 42.320,63.948,68.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.450 | Acc: 42.226,63.841,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.462 | Acc: 42.094,63.719,68.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.468 | Acc: 42.001,63.656,68.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.469 | Acc: 41.952,63.708,68.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.441 | Acc: 34.375,57.031,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.812 | Acc: 35.268,54.167,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.829 | Acc: 35.499,53.620,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.858 | Acc: 35.361,53.176,56.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.674 | Acc: 39.844,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.262 | Acc: 43.452,64.844,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 43.540,65.072,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.314 | Acc: 42.969,64.933,70.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.338 | Acc: 42.795,64.796,70.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.350 | Acc: 42.791,64.573,70.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.375 | Acc: 42.530,64.405,70.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.379 | Acc: 42.520,64.395,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.396 | Acc: 42.367,64.227,70.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.405 | Acc: 42.360,64.175,69.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.418 | Acc: 42.137,64.062,69.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.431 | Acc: 42.078,64.002,69.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.430 | Acc: 42.204,64.050,69.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.434 | Acc: 42.164,64.012,69.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.435 | Acc: 42.135,63.993,69.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.449 | Acc: 41.977,63.915,69.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.454 | Acc: 41.951,63.873,69.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.455 | Acc: 41.961,63.810,68.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.460 | Acc: 41.965,63.751,68.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.464 | Acc: 41.937,63.749,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.071 | Acc: 39.844,54.688,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.438 | Acc: 32.366,46.949,52.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.435 | Acc: 32.050,47.180,52.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.484 | Acc: 31.724,47.208,51.588,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.309 | Acc: 41.406,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.301 | Acc: 41.592,67.374,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.258 | Acc: 42.511,66.425,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.306 | Acc: 42.700,65.446,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 42.255,65.085,69.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.356 | Acc: 42.350,64.975,69.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.351 | Acc: 42.420,65.102,70.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.350 | Acc: 42.492,64.982,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.374 | Acc: 42.236,64.664,69.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.402 | Acc: 42.058,64.369,69.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.415 | Acc: 42.129,64.222,69.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.411 | Acc: 42.209,64.282,69.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.416 | Acc: 42.155,64.218,69.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.415 | Acc: 42.271,64.272,69.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.408 | Acc: 42.368,64.254,69.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.416 | Acc: 42.408,64.138,69.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 42.319,64.007,69.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 42.275,63.934,69.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.446 | Acc: 42.229,63.857,69.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.455 | Acc: 42.110,63.790,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.924 | Acc: 29.688,52.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.869 | Acc: 24.256,48.028,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.996 | Acc: 24.066,46.970,54.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.010 | Acc: 23.873,46.760,54.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.075 | Acc: 42.188,74.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.367 | Acc: 42.560,65.327,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.360 | Acc: 42.664,64.825,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.409 | Acc: 42.354,64.588,69.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.412 | Acc: 42.486,64.535,69.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.390 | Acc: 42.667,64.558,70.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.395 | Acc: 42.710,64.418,69.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.424 | Acc: 42.332,64.195,69.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.435 | Acc: 42.270,64.077,69.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.441 | Acc: 41.976,64.015,69.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.434 | Acc: 42.055,64.051,69.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.445 | Acc: 42.032,63.921,69.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.442 | Acc: 41.996,63.952,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.440 | Acc: 41.951,63.982,69.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.437 | Acc: 42.029,63.993,69.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.428 | Acc: 42.125,64.127,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.435 | Acc: 42.149,64.060,69.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 42.142,63.962,69.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.441 | Acc: 42.179,63.928,69.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.447 | Acc: 42.089,63.759,69.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.905 | Acc: 18.750,35.938,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.654 | Acc: 19.271,36.161,46.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.769 | Acc: 18.617,35.347,45.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.747 | Acc: 18.532,35.476,45.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 4.391 | Acc: 39.844,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.302 | Acc: 43.601,64.249,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.299 | Acc: 43.750,64.386,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.361 | Acc: 43.007,63.665,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.388 | Acc: 42.843,63.638,69.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.389 | Acc: 42.876,63.946,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.388 | Acc: 42.872,63.966,69.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.392 | Acc: 42.891,63.902,69.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.398 | Acc: 42.663,64.009,69.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.418 | Acc: 42.442,63.976,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.432 | Acc: 42.180,63.895,69.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.433 | Acc: 42.177,63.847,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.439 | Acc: 42.158,63.748,69.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.453 | Acc: 42.029,63.652,69.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.455 | Acc: 42.065,63.556,69.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.449 | Acc: 42.128,63.684,69.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.448 | Acc: 42.153,63.732,69.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.455 | Acc: 42.155,63.719,69.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.465 | Acc: 42.090,63.636,68.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.472 | Acc: 42.017,63.585,68.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.354 | Acc: 32.031,57.031,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.084 | Acc: 31.399,51.339,56.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.204 | Acc: 30.640,50.381,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.255 | Acc: 30.277,49.910,55.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 4.302 | Acc: 42.188,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.407 | Acc: 41.629,63.244,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.407 | Acc: 41.787,63.205,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.391 | Acc: 42.098,63.589,69.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.406 | Acc: 41.908,63.773,69.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.409 | Acc: 41.894,63.761,69.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.413 | Acc: 41.955,63.604,69.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.394 | Acc: 42.132,63.708,69.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.394 | Acc: 41.930,63.839,69.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.398 | Acc: 42.023,63.980,69.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.402 | Acc: 42.048,63.996,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.412 | Acc: 42.039,63.946,69.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.424 | Acc: 41.909,63.806,69.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.432 | Acc: 41.885,63.805,69.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.430 | Acc: 41.962,63.857,69.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.441 | Acc: 41.798,63.774,69.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.440 | Acc: 41.849,63.846,69.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.443 | Acc: 41.933,63.822,69.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.438 | Acc: 41.982,63.859,68.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.440 | Acc: 41.946,63.804,69.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.761 | Acc: 35.938,54.688,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.363 | Acc: 33.854,49.107,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.522 | Acc: 33.308,47.523,53.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.545 | Acc: 33.274,47.567,53.484,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.471 | Acc: 33.594,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.362 | Acc: 42.522,65.067,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.357 | Acc: 41.540,64.729,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.349 | Acc: 41.983,64.921,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.404 | Acc: 41.676,64.612,70.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.417 | Acc: 41.623,64.434,69.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.402 | Acc: 41.794,64.637,69.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.409 | Acc: 41.883,64.556,69.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.401 | Acc: 42.207,64.611,69.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.404 | Acc: 42.140,64.520,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.415 | Acc: 41.989,64.440,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.430 | Acc: 41.912,64.296,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.440 | Acc: 41.961,64.270,69.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.436 | Acc: 41.972,64.233,69.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.436 | Acc: 41.976,64.271,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.444 | Acc: 41.944,64.146,69.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.450 | Acc: 41.959,64.024,69.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.456 | Acc: 41.933,63.975,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.456 | Acc: 42.025,64.006,69.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.447 | Acc: 42.134,64.044,69.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.432 | Acc: 26.562,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.291 | Acc: 30.060,52.158,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.406 | Acc: 29.840,50.229,55.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.384 | Acc: 29.764,50.448,55.635,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 3.950 | Acc: 51.562,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.131 | Acc: 44.382,66.146,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 43.369,65.473,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 43.776,65.138,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.271 | Acc: 43.538,65.191,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.315 | Acc: 43.085,64.805,70.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.322 | Acc: 43.020,64.708,70.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.345 | Acc: 42.980,64.822,70.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.350 | Acc: 42.716,64.645,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.358 | Acc: 42.641,64.468,70.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.370 | Acc: 42.530,64.303,70.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.371 | Acc: 42.562,64.335,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.390 | Acc: 42.372,64.192,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.400 | Acc: 42.298,64.086,69.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.415 | Acc: 42.174,64.037,69.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.420 | Acc: 42.094,63.974,69.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.416 | Acc: 42.114,64.026,69.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.419 | Acc: 42.052,64.021,69.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.417 | Acc: 42.110,64.006,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.420 | Acc: 42.091,63.999,69.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.911 | Acc: 31.250,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.299 | Acc: 32.924,50.521,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.440 | Acc: 32.622,49.619,54.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.465 | Acc: 32.287,49.488,53.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.409 | Acc: 36.719,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 43.527,65.402,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.289 | Acc: 43.883,65.454,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.329 | Acc: 43.238,65.010,71.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.296 | Acc: 43.181,65.316,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.327 | Acc: 42.868,65.114,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.352 | Acc: 42.459,64.792,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 42.525,64.639,70.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.354 | Acc: 42.493,64.504,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.382 | Acc: 42.188,64.265,70.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.387 | Acc: 42.250,64.362,70.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.405 | Acc: 42.092,64.246,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.410 | Acc: 42.084,64.153,70.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.416 | Acc: 42.131,64.140,69.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.418 | Acc: 42.062,64.079,69.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.422 | Acc: 41.967,64.037,69.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 41.839,63.963,69.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.424 | Acc: 41.878,64.085,69.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.433 | Acc: 41.872,63.948,69.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.432 | Acc: 41.905,63.952,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.639 | Acc: 32.031,60.156,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.074 | Acc: 32.812,52.121,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.039 | Acc: 33.060,51.486,57.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.056 | Acc: 33.402,51.370,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.775 | Acc: 46.875,64.844,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.332 | Acc: 42.150,64.323,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.301 | Acc: 41.692,65.149,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.316 | Acc: 41.983,64.908,70.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.324 | Acc: 42.052,64.796,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.318 | Acc: 42.025,64.697,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.322 | Acc: 42.246,64.682,70.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.329 | Acc: 42.381,64.738,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.349 | Acc: 42.188,64.514,70.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.353 | Acc: 42.136,64.628,70.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.373 | Acc: 41.989,64.494,69.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.378 | Acc: 42.018,64.455,69.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.377 | Acc: 42.048,64.471,69.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.391 | Acc: 42.017,64.278,69.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.401 | Acc: 42.015,64.165,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.410 | Acc: 42.006,64.161,69.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.416 | Acc: 41.956,64.150,69.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.416 | Acc: 41.977,64.053,69.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.420 | Acc: 41.991,63.987,69.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.425 | Acc: 42.001,63.921,69.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.550 | Acc: 28.125,52.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.150 | Acc: 25.893,45.871,53.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.141 | Acc: 26.372,46.227,53.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.105 | Acc: 26.460,46.632,53.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.346 | Acc: 50.000,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 41.667,64.732,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 42.283,64.825,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.325 | Acc: 42.943,65.215,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.332 | Acc: 42.824,65.133,70.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.315 | Acc: 42.675,65.424,70.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.331 | Acc: 42.388,65.257,70.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 42.581,65.165,70.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.339 | Acc: 42.522,65.261,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.356 | Acc: 42.429,65.042,70.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.377 | Acc: 42.184,64.801,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.390 | Acc: 42.043,64.688,69.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.396 | Acc: 42.061,64.759,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.398 | Acc: 42.143,64.724,69.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.393 | Acc: 42.207,64.766,69.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.391 | Acc: 42.239,64.820,69.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.394 | Acc: 42.224,64.737,69.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.401 | Acc: 42.259,64.640,69.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.398 | Acc: 42.376,64.649,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.405 | Acc: 42.327,64.489,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.521 | Acc: 31.250,44.531,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.552 | Acc: 30.394,49.516,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.647 | Acc: 29.935,48.133,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.653 | Acc: 29.752,47.848,52.203,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.497 | Acc: 45.312,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 42.076,63.095,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.350 | Acc: 42.359,64.120,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.348 | Acc: 43.110,64.536,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.382 | Acc: 42.515,64.381,69.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.352 | Acc: 42.961,64.619,70.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.359 | Acc: 42.807,64.553,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.341 | Acc: 42.924,64.617,70.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.340 | Acc: 42.920,64.698,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.351 | Acc: 42.995,64.533,70.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.336 | Acc: 43.179,64.863,70.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.351 | Acc: 43.068,64.724,70.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.353 | Acc: 43.131,64.737,70.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 43.103,64.772,69.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.364 | Acc: 43.005,64.735,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.366 | Acc: 43.049,64.719,69.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.366 | Acc: 43.017,64.625,69.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.379 | Acc: 42.966,64.534,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.386 | Acc: 42.861,64.528,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.391 | Acc: 42.770,64.460,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.517 | Acc: 30.469,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.788 | Acc: 28.720,47.210,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.830 | Acc: 27.858,46.875,53.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.891 | Acc: 27.561,46.926,53.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.223 | Acc: 42.969,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.294 | Acc: 41.071,64.695,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.258 | Acc: 42.016,64.691,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 42.687,64.972,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.263 | Acc: 42.612,64.969,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.272 | Acc: 42.551,64.944,71.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.288 | Acc: 42.633,64.779,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.314 | Acc: 42.586,64.650,70.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.333 | Acc: 42.445,64.460,70.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.356 | Acc: 42.399,64.291,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.357 | Acc: 42.421,64.296,70.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.371 | Acc: 42.340,64.091,70.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.361 | Acc: 42.444,64.182,70.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.363 | Acc: 42.460,64.200,70.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.365 | Acc: 42.393,64.168,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.381 | Acc: 42.190,64.073,70.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.386 | Acc: 42.212,64.058,69.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.389 | Acc: 42.245,64.021,69.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.397 | Acc: 42.149,63.976,69.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.394 | Acc: 42.204,64.028,69.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.202 | Acc: 32.031,53.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.829 | Acc: 30.804,47.024,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.931 | Acc: 30.278,45.827,52.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.972 | Acc: 29.816,45.377,51.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.466 | Acc: 39.062,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.248 | Acc: 42.560,65.737,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.310 | Acc: 41.768,64.977,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.320 | Acc: 42.277,65.049,70.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.355 | Acc: 41.995,64.545,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.354 | Acc: 42.133,64.759,70.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.362 | Acc: 42.039,64.669,70.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.351 | Acc: 42.282,64.605,70.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.357 | Acc: 42.362,64.553,70.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.372 | Acc: 42.326,64.477,69.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.382 | Acc: 42.362,64.346,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.386 | Acc: 42.329,64.253,69.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.401 | Acc: 42.175,64.040,69.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.407 | Acc: 42.223,64.089,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.414 | Acc: 42.085,64.074,69.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.412 | Acc: 42.104,64.096,69.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.418 | Acc: 42.105,64.094,69.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.415 | Acc: 42.185,64.099,69.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.419 | Acc: 42.188,64.119,69.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.413 | Acc: 42.229,64.114,69.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.958 | Acc: 28.906,51.562,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.779 | Acc: 29.315,49.330,51.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.851 | Acc: 29.859,48.342,50.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.844 | Acc: 29.662,47.976,50.692,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 3.970 | Acc: 42.969,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.402 | Acc: 41.109,64.323,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.373 | Acc: 41.082,64.901,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.320 | Acc: 42.213,65.164,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.294 | Acc: 42.515,65.258,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.293 | Acc: 42.845,65.347,71.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.305 | Acc: 42.788,65.302,71.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.319 | Acc: 42.564,65.126,70.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.319 | Acc: 42.692,65.130,70.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.338 | Acc: 42.541,64.921,70.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.339 | Acc: 42.561,64.902,70.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.353 | Acc: 42.400,64.713,70.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.365 | Acc: 42.353,64.597,70.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.367 | Acc: 42.334,64.485,70.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.377 | Acc: 42.352,64.416,70.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.373 | Acc: 42.424,64.473,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.376 | Acc: 42.419,64.481,70.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.385 | Acc: 42.343,64.470,70.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.402 | Acc: 42.222,64.268,69.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.401 | Acc: 42.241,64.329,69.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.856 | Acc: 22.656,46.875,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.550 | Acc: 24.665,43.638,50.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.528 | Acc: 24.714,44.017,50.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.523 | Acc: 24.641,44.006,50.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 3.739 | Acc: 45.312,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.280 | Acc: 41.257,66.741,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.253 | Acc: 42.759,66.101,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.272 | Acc: 42.623,65.856,70.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.301 | Acc: 42.679,65.451,70.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.303 | Acc: 42.512,65.292,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.297 | Acc: 42.530,65.276,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.304 | Acc: 42.354,65.099,70.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.319 | Acc: 42.338,64.921,70.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.318 | Acc: 42.554,65.025,70.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.323 | Acc: 42.611,64.906,70.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.336 | Acc: 42.573,64.844,70.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.343 | Acc: 42.486,64.672,70.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.354 | Acc: 42.448,64.440,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.362 | Acc: 42.468,64.404,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.369 | Acc: 42.411,64.335,70.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.374 | Acc: 42.416,64.282,69.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.379 | Acc: 42.433,64.278,69.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.385 | Acc: 42.356,64.264,69.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.399 | Acc: 42.239,64.145,69.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.941 | Acc: 30.469,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.172 | Acc: 32.366,51.711,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.212 | Acc: 31.898,50.686,55.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.240 | Acc: 31.596,50.538,55.008,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 3.681 | Acc: 48.438,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.340 | Acc: 43.564,64.100,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 43.007,64.577,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 43.353,65.407,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.307 | Acc: 43.036,65.114,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.356 | Acc: 42.969,64.728,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.354 | Acc: 42.853,64.799,70.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.342 | Acc: 42.869,64.838,70.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.346 | Acc: 42.658,64.621,70.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.368 | Acc: 42.308,64.477,70.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.363 | Acc: 42.374,64.591,70.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.371 | Acc: 42.329,64.476,69.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.382 | Acc: 42.265,64.393,69.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.384 | Acc: 42.277,64.464,69.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.383 | Acc: 42.299,64.429,69.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.381 | Acc: 42.302,64.504,69.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.382 | Acc: 42.212,64.520,69.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.387 | Acc: 42.167,64.390,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.387 | Acc: 42.175,64.394,69.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.386 | Acc: 42.120,64.331,69.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.066 | Acc: 28.906,52.344,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.550 | Acc: 29.762,49.740,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.575 | Acc: 29.630,49.466,53.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.635 | Acc: 29.559,49.603,53.112,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.212 | Acc: 46.094,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.422 | Acc: 42.113,64.286,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.356 | Acc: 42.683,64.425,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.353 | Acc: 42.444,65.023,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.369 | Acc: 42.351,64.969,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.373 | Acc: 42.481,64.875,70.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.384 | Acc: 42.104,64.863,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.375 | Acc: 42.337,64.971,70.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.363 | Acc: 42.498,64.955,70.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.371 | Acc: 42.533,64.779,70.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.369 | Acc: 42.506,64.887,70.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.364 | Acc: 42.467,64.918,70.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.363 | Acc: 42.437,65.016,70.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.370 | Acc: 42.472,64.817,70.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.371 | Acc: 42.415,64.771,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.373 | Acc: 42.406,64.732,70.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.374 | Acc: 42.387,64.669,70.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.375 | Acc: 42.341,64.585,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.373 | Acc: 42.397,64.521,69.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.372 | Acc: 42.444,64.530,69.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.253 | Acc: 38.281,60.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.700 | Acc: 35.342,54.204,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.792 | Acc: 34.909,53.258,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.809 | Acc: 34.759,52.677,56.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.041 | Acc: 39.062,70.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.190 | Acc: 43.527,66.406,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.216 | Acc: 43.521,66.063,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 43.302,66.304,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.252 | Acc: 42.940,66.069,71.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.266 | Acc: 43.046,65.702,71.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.256 | Acc: 43.072,65.748,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.270 | Acc: 42.897,65.553,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.288 | Acc: 42.862,65.460,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.299 | Acc: 42.615,65.336,71.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.313 | Acc: 42.487,65.116,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.329 | Acc: 42.446,64.897,70.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.334 | Acc: 42.447,64.811,70.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.334 | Acc: 42.526,64.916,70.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.338 | Acc: 42.552,64.841,70.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.340 | Acc: 42.522,64.763,70.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.348 | Acc: 42.472,64.683,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.347 | Acc: 42.561,64.681,70.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.348 | Acc: 42.590,64.692,70.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.359 | Acc: 42.503,64.573,70.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.611 | Acc: 39.844,56.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.013 | Acc: 34.301,52.195,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.104 | Acc: 34.318,51.124,54.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.141 | Acc: 33.837,50.730,54.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.280 | Acc: 44.531,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.384 | Acc: 41.815,63.802,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.334 | Acc: 42.340,64.101,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.307 | Acc: 42.687,64.652,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.293 | Acc: 42.959,65.210,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.310 | Acc: 42.799,64.821,71.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.299 | Acc: 42.775,64.895,71.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.325 | Acc: 42.553,64.644,70.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.341 | Acc: 42.382,64.490,70.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.352 | Acc: 42.352,64.343,70.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.355 | Acc: 42.495,64.362,70.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.353 | Acc: 42.474,64.444,70.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.359 | Acc: 42.350,64.409,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 42.298,64.266,70.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.373 | Acc: 42.221,64.090,70.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.372 | Acc: 42.211,64.068,70.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.374 | Acc: 42.178,64.011,70.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.379 | Acc: 42.183,64.019,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.380 | Acc: 42.166,63.991,70.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.378 | Acc: 42.206,64.062,70.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.277 | Acc: 28.906,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.569 | Acc: 29.241,49.591,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.574 | Acc: 29.421,48.990,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.614 | Acc: 29.124,48.553,55.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.949 | Acc: 35.938,66.406,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.219 | Acc: 42.522,65.439,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.233 | Acc: 42.816,65.816,72.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.273 | Acc: 42.649,65.382,71.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.275 | Acc: 42.409,65.162,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.313 | Acc: 42.211,64.906,71.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.308 | Acc: 42.342,64.831,71.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.330 | Acc: 42.265,64.622,71.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.347 | Acc: 42.265,64.325,71.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.364 | Acc: 42.162,64.244,70.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.368 | Acc: 42.145,64.125,70.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 42.074,63.942,70.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.377 | Acc: 42.116,64.030,70.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.365 | Acc: 42.229,64.215,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.371 | Acc: 42.249,64.160,70.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.378 | Acc: 42.245,64.138,70.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.364 | Acc: 42.424,64.282,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.365 | Acc: 42.529,64.328,70.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.363 | Acc: 42.516,64.363,70.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.375 | Acc: 42.413,64.249,70.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.425 | Acc: 34.375,56.250,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.830 | Acc: 29.018,46.875,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.811 | Acc: 29.287,46.875,52.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.844 | Acc: 29.098,46.811,51.934,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 3.701 | Acc: 47.656,72.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.185 | Acc: 43.973,66.555,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.198 | Acc: 44.322,66.197,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.221 | Acc: 44.057,66.124,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.244 | Acc: 44.020,65.905,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 43.912,65.695,71.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.276 | Acc: 43.782,65.522,71.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.286 | Acc: 43.639,65.464,71.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 43.420,65.290,71.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.316 | Acc: 43.141,65.215,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.321 | Acc: 43.015,65.170,70.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.332 | Acc: 42.838,65.013,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.349 | Acc: 42.651,64.792,70.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.352 | Acc: 42.598,64.724,70.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.355 | Acc: 42.568,64.738,70.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.361 | Acc: 42.582,64.610,70.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.370 | Acc: 42.611,64.518,70.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.374 | Acc: 42.543,64.436,69.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.380 | Acc: 42.486,64.394,69.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.382 | Acc: 42.495,64.327,69.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.823 | Acc: 26.562,50.781,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.722 | Acc: 30.134,47.619,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.751 | Acc: 29.116,47.580,52.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.724 | Acc: 29.329,47.567,52.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.487 | Acc: 40.625,60.938,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 43.229,64.993,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.287 | Acc: 43.007,64.691,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.283 | Acc: 42.918,64.716,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.248 | Acc: 43.480,64.988,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.262 | Acc: 43.286,65.223,71.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.247 | Acc: 43.466,65.289,71.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.252 | Acc: 43.362,65.232,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.265 | Acc: 43.168,65.188,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.277 | Acc: 43.133,65.029,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.281 | Acc: 43.015,64.949,70.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.302 | Acc: 42.863,64.922,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.318 | Acc: 42.651,64.802,70.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.316 | Acc: 42.699,64.757,70.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 42.632,64.788,70.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.329 | Acc: 42.538,64.649,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.340 | Acc: 42.499,64.540,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.344 | Acc: 42.504,64.500,70.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.356 | Acc: 42.434,64.417,70.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.363 | Acc: 42.454,64.384,70.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.953 | Acc: 20.312,53.906,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.473 | Acc: 19.048,47.731,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.507 | Acc: 18.883,46.627,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.497 | Acc: 18.993,46.324,52.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.882 | Acc: 32.031,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 38.170,63.318,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 39.882,63.891,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.358 | Acc: 40.881,64.370,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.353 | Acc: 40.992,64.419,70.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.332 | Acc: 41.491,64.650,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.324 | Acc: 41.839,64.786,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.325 | Acc: 42.032,64.678,71.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.319 | Acc: 42.285,64.747,71.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.330 | Acc: 42.390,64.762,70.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.347 | Acc: 42.327,64.607,70.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.349 | Acc: 42.180,64.487,70.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.357 | Acc: 42.158,64.477,70.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.350 | Acc: 42.238,64.643,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.355 | Acc: 42.196,64.602,70.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.363 | Acc: 42.146,64.561,70.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.362 | Acc: 42.149,64.632,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.365 | Acc: 42.146,64.638,70.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.362 | Acc: 42.207,64.645,70.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.365 | Acc: 42.202,64.544,70.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.621 | Acc: 27.344,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.613 | Acc: 30.097,49.182,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.706 | Acc: 29.306,48.628,55.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.722 | Acc: 29.162,48.476,55.277,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.923 | Acc: 42.188,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 42.746,64.993,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.310 | Acc: 42.626,65.053,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.276 | Acc: 42.982,65.497,71.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.281 | Acc: 42.969,65.336,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.275 | Acc: 42.930,65.122,71.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.272 | Acc: 42.820,65.257,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 42.819,65.337,71.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.275 | Acc: 42.993,65.363,71.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.284 | Acc: 43.033,65.176,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.289 | Acc: 42.965,65.112,70.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.293 | Acc: 42.909,65.218,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.292 | Acc: 42.816,65.168,70.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.309 | Acc: 42.610,65.020,70.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 42.543,64.927,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.321 | Acc: 42.507,64.859,70.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.330 | Acc: 42.453,64.771,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.337 | Acc: 42.410,64.658,70.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.334 | Acc: 42.477,64.701,70.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.337 | Acc: 42.493,64.674,70.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.994 | Acc: 23.438,49.219,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.215 | Acc: 24.368,46.466,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.171 | Acc: 24.143,46.341,53.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.180 | Acc: 23.911,45.953,53.125,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.330 | Acc: 44.531,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 43.043,67.634,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 42.816,66.349,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.243 | Acc: 43.033,65.202,72.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.248 | Acc: 43.007,65.230,72.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 42.992,65.037,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.271 | Acc: 42.859,65.012,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.273 | Acc: 42.836,65.076,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.274 | Acc: 42.823,65.130,71.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.267 | Acc: 42.921,65.146,71.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 42.895,65.120,71.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.278 | Acc: 42.820,65.049,71.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.291 | Acc: 42.658,64.909,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.303 | Acc: 42.592,64.766,71.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.314 | Acc: 42.713,64.705,71.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.325 | Acc: 42.626,64.571,70.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.340 | Acc: 42.601,64.474,70.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.348 | Acc: 42.488,64.470,70.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.356 | Acc: 42.532,64.387,70.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.362 | Acc: 42.501,64.411,70.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.042 | Acc: 27.344,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.346 | Acc: 30.060,51.302,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.417 | Acc: 29.840,50.248,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.446 | Acc: 29.316,50.013,55.443,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.597 | Acc: 35.938,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.320 | Acc: 41.964,63.467,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.274 | Acc: 41.806,64.920,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.271 | Acc: 42.149,65.292,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.292 | Acc: 41.802,65.143,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.277 | Acc: 42.102,65.323,71.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.278 | Acc: 42.162,65.405,71.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.284 | Acc: 42.271,65.326,71.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.287 | Acc: 42.212,65.242,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.300 | Acc: 42.244,65.077,70.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 42.246,64.984,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.322 | Acc: 42.241,64.900,70.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.324 | Acc: 42.278,64.828,70.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.326 | Acc: 42.382,64.841,70.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.335 | Acc: 42.329,64.721,70.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.341 | Acc: 42.361,64.717,70.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.345 | Acc: 42.360,64.683,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.341 | Acc: 42.444,64.718,70.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.341 | Acc: 42.419,64.740,70.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.346 | Acc: 42.514,64.643,70.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.153 | Acc: 28.125,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.630 | Acc: 31.585,50.037,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.744 | Acc: 30.640,48.571,53.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.760 | Acc: 30.879,47.989,53.663,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.471 | Acc: 45.312,60.156,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 43.824,65.997,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.200 | Acc: 43.483,65.987,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 43.020,65.330,71.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.291 | Acc: 42.448,65.374,70.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.264 | Acc: 42.559,65.818,71.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.270 | Acc: 42.556,65.780,71.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.285 | Acc: 42.525,65.453,71.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.290 | Acc: 42.581,65.271,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.282 | Acc: 42.783,65.362,71.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.295 | Acc: 42.642,65.236,71.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.306 | Acc: 42.559,65.042,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.332 | Acc: 42.392,64.892,70.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.337 | Acc: 42.424,64.862,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.336 | Acc: 42.504,64.863,70.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.342 | Acc: 42.447,64.776,70.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.348 | Acc: 42.424,64.749,70.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.345 | Acc: 42.508,64.814,70.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.353 | Acc: 42.475,64.768,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.350 | Acc: 42.509,64.792,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.974 | Acc: 32.812,52.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.563 | Acc: 30.283,49.554,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.581 | Acc: 29.592,48.495,54.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.601 | Acc: 29.022,48.271,54.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 4.750 | Acc: 37.500,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.151 | Acc: 44.085,65.885,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.173 | Acc: 43.559,65.434,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.236 | Acc: 42.789,65.254,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.258 | Acc: 42.795,65.152,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 42.845,65.200,71.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.238 | Acc: 43.085,65.218,71.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.240 | Acc: 43.157,65.392,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.253 | Acc: 43.148,65.193,71.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.264 | Acc: 43.120,65.137,71.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.271 | Acc: 43.132,65.054,70.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.292 | Acc: 42.902,64.946,70.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.304 | Acc: 42.658,64.931,70.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.307 | Acc: 42.657,64.820,70.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.313 | Acc: 42.694,64.794,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.321 | Acc: 42.665,64.696,70.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.318 | Acc: 42.784,64.749,70.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.322 | Acc: 42.774,64.635,70.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.329 | Acc: 42.733,64.569,70.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.331 | Acc: 42.811,64.542,70.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.808 | Acc: 35.156,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.428 | Acc: 30.804,49.814,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.508 | Acc: 30.183,49.295,53.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.517 | Acc: 29.969,49.308,53.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 5.084 | Acc: 32.031,57.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 39.918,63.653,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.398 | Acc: 41.273,64.367,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 42.341,64.741,70.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.307 | Acc: 42.679,64.863,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.292 | Acc: 42.969,65.138,70.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.286 | Acc: 42.853,65.147,70.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.293 | Acc: 42.658,65.016,70.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.282 | Acc: 42.804,65.203,71.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.297 | Acc: 42.623,65.163,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.303 | Acc: 42.654,65.085,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.303 | Acc: 42.732,65.038,70.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.314 | Acc: 42.690,64.990,70.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.328 | Acc: 42.508,64.871,70.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 42.413,64.880,70.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.330 | Acc: 42.307,64.826,70.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.334 | Acc: 42.295,64.790,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.335 | Acc: 42.302,64.775,70.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.340 | Acc: 42.257,64.655,70.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.347 | Acc: 42.298,64.499,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.803 | Acc: 28.906,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.861 | Acc: 32.924,54.836,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.919 | Acc: 32.698,53.868,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.980 | Acc: 32.390,53.548,59.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 4.410 | Acc: 38.281,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 41.778,64.621,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.309 | Acc: 42.111,64.558,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.280 | Acc: 42.572,65.010,71.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.276 | Acc: 42.708,65.133,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.261 | Acc: 43.085,65.401,71.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 43.195,65.593,71.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.266 | Acc: 43.285,65.608,71.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.298 | Acc: 43.105,65.334,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.303 | Acc: 43.107,65.288,70.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.315 | Acc: 43.132,65.236,70.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.321 | Acc: 42.983,65.091,70.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.322 | Acc: 42.829,65.074,70.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.323 | Acc: 42.822,64.981,70.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.329 | Acc: 42.807,64.833,70.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.330 | Acc: 42.650,64.779,70.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.324 | Acc: 42.721,64.858,70.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.329 | Acc: 42.673,64.796,70.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.333 | Acc: 42.651,64.759,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.335 | Acc: 42.721,64.706,70.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.822 | Acc: 32.812,58.594,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.646 | Acc: 29.539,48.735,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.578 | Acc: 29.211,48.114,54.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.600 | Acc: 29.047,48.181,53.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.860 | Acc: 48.438,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.103 | Acc: 44.420,66.257,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.160 | Acc: 43.617,65.835,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.173 | Acc: 43.225,65.625,72.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 42.641,65.365,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.253 | Acc: 42.520,65.447,71.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.255 | Acc: 42.652,65.470,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.262 | Acc: 42.675,65.293,71.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.261 | Acc: 42.949,65.329,71.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.266 | Acc: 43.033,65.193,71.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.275 | Acc: 42.918,65.030,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.280 | Acc: 42.870,64.982,71.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.292 | Acc: 42.800,64.970,71.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.297 | Acc: 42.840,64.996,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.311 | Acc: 42.691,64.874,70.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.315 | Acc: 42.662,64.833,70.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.320 | Acc: 42.589,64.827,70.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.327 | Acc: 42.637,64.738,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.327 | Acc: 42.638,64.759,70.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.325 | Acc: 42.661,64.786,70.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.810 | Acc: 35.156,60.938,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.959 | Acc: 35.751,53.423,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.052 | Acc: 35.004,52.363,55.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.059 | Acc: 34.849,52.228,55.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 3.926 | Acc: 42.969,64.062,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.101 | Acc: 43.824,66.071,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.141 | Acc: 43.617,66.063,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.192 | Acc: 43.455,65.651,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.216 | Acc: 43.490,65.818,72.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.254 | Acc: 43.007,65.455,71.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.260 | Acc: 42.840,65.593,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.271 | Acc: 42.841,65.459,71.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.269 | Acc: 42.838,65.411,71.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.263 | Acc: 42.999,65.383,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.262 | Acc: 43.105,65.392,71.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.267 | Acc: 43.188,65.378,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.279 | Acc: 43.030,65.178,71.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.300 | Acc: 42.801,65.008,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.306 | Acc: 42.769,64.935,70.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.310 | Acc: 42.746,64.914,70.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.311 | Acc: 42.769,64.810,70.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.317 | Acc: 42.703,64.828,70.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.323 | Acc: 42.635,64.738,70.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.332 | Acc: 42.550,64.624,70.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.306 | Acc: 37.500,56.250,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.299 | Acc: 32.850,50.484,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.383 | Acc: 32.279,49.695,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.436 | Acc: 31.954,49.744,53.676,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 3.802 | Acc: 44.531,75.000,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.291 | Acc: 41.741,66.034,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.223 | Acc: 42.264,66.025,72.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.184 | Acc: 43.340,66.381,72.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.176 | Acc: 43.625,66.416,72.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.175 | Acc: 43.680,66.329,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.176 | Acc: 43.827,66.219,72.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.201 | Acc: 43.606,65.963,72.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.235 | Acc: 43.347,65.635,71.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.250 | Acc: 43.249,65.414,71.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.262 | Acc: 43.241,65.353,71.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.274 | Acc: 43.191,65.254,71.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.277 | Acc: 43.111,65.158,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.293 | Acc: 42.981,64.960,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.305 | Acc: 42.846,64.872,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 42.688,64.797,70.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.321 | Acc: 42.696,64.761,70.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.324 | Acc: 42.726,64.752,70.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.330 | Acc: 42.690,64.772,70.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.334 | Acc: 42.653,64.698,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.433 | Acc: 28.125,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.704 | Acc: 28.162,49.814,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.826 | Acc: 27.153,48.838,54.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.853 | Acc: 27.190,48.425,54.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.034 | Acc: 42.188,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.199 | Acc: 41.220,66.257,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 42.226,65.816,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.251 | Acc: 42.392,65.907,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.265 | Acc: 42.313,65.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.259 | Acc: 42.474,65.594,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.251 | Acc: 42.678,65.528,71.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.243 | Acc: 42.559,65.614,71.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.254 | Acc: 42.653,65.470,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.272 | Acc: 42.762,65.392,71.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.276 | Acc: 42.802,65.341,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.287 | Acc: 42.834,65.257,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.296 | Acc: 42.752,65.038,71.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.303 | Acc: 42.858,64.999,71.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.297 | Acc: 42.885,65.008,71.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.305 | Acc: 42.847,64.981,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.310 | Acc: 42.798,64.980,70.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.312 | Acc: 42.712,64.993,70.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.317 | Acc: 42.657,64.928,70.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.319 | Acc: 42.661,64.862,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.658 | Acc: 32.031,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.520 | Acc: 28.423,48.624,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.557 | Acc: 27.534,48.552,56.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.563 | Acc: 27.164,48.361,56.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.670 | Acc: 53.125,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.126 | Acc: 43.304,66.778,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.216 | Acc: 42.550,65.682,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.226 | Acc: 42.354,65.497,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.237 | Acc: 42.506,65.268,72.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.251 | Acc: 42.435,65.200,71.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.245 | Acc: 42.723,65.212,71.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.247 | Acc: 42.758,65.221,71.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.269 | Acc: 42.648,64.970,71.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.263 | Acc: 42.697,65.180,71.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.269 | Acc: 42.689,65.124,71.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.281 | Acc: 42.636,64.967,71.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.284 | Acc: 42.713,65.022,71.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.285 | Acc: 42.619,65.107,71.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.283 | Acc: 42.602,65.069,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.281 | Acc: 42.582,65.173,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.295 | Acc: 42.538,65.092,71.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.291 | Acc: 42.591,65.066,71.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.300 | Acc: 42.586,65.054,70.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.309 | Acc: 42.524,64.977,70.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.953 | Acc: 31.250,56.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.448 | Acc: 29.539,50.112,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.538 | Acc: 28.430,49.104,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.576 | Acc: 28.023,48.950,55.277,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.157 | Acc: 45.312,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.232 | Acc: 41.183,65.699,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.174 | Acc: 43.312,66.387,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.156 | Acc: 43.635,66.445,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.202 | Acc: 43.567,65.905,71.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.223 | Acc: 43.479,65.695,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.219 | Acc: 43.511,65.774,71.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.209 | Acc: 43.606,65.852,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.219 | Acc: 43.590,65.902,71.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.248 | Acc: 43.262,65.590,71.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.266 | Acc: 43.183,65.512,71.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.263 | Acc: 43.241,65.547,71.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.262 | Acc: 43.290,65.505,71.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.274 | Acc: 43.244,65.386,71.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.288 | Acc: 43.163,65.286,70.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.303 | Acc: 43.093,65.166,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.303 | Acc: 43.069,65.116,70.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.306 | Acc: 42.987,65.110,70.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.310 | Acc: 42.945,65.067,70.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.319 | Acc: 42.917,64.971,70.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.833 | Acc: 32.812,61.719,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.079 | Acc: 35.714,51.302,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.153 | Acc: 35.042,51.181,55.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.212 | Acc: 34.337,50.576,54.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 4.689 | Acc: 36.719,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.198 | Acc: 43.862,65.402,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.191 | Acc: 44.017,65.320,72.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.234 | Acc: 43.391,65.420,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.237 | Acc: 43.422,65.461,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.243 | Acc: 43.031,65.532,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 43.162,65.431,71.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.259 | Acc: 42.996,65.293,71.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.253 | Acc: 43.197,65.280,71.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.247 | Acc: 43.219,65.375,71.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.250 | Acc: 43.035,65.450,71.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.258 | Acc: 43.011,65.257,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.267 | Acc: 42.910,65.200,71.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.277 | Acc: 42.927,65.089,71.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.286 | Acc: 42.908,64.880,70.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.296 | Acc: 42.803,64.828,70.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.300 | Acc: 42.767,64.785,70.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.286 | Acc: 42.937,64.924,70.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.286 | Acc: 42.980,64.967,70.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.290 | Acc: 42.946,64.875,70.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.606 | Acc: 29.688,48.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.816 | Acc: 28.162,46.615,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.933 | Acc: 27.058,46.037,54.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.951 | Acc: 26.537,46.414,54.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.507 | Acc: 34.375,68.750,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.219 | Acc: 44.531,66.518,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.171 | Acc: 43.579,67.111,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.240 | Acc: 43.532,65.689,71.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.228 | Acc: 43.220,65.721,71.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.208 | Acc: 43.348,65.919,71.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.205 | Acc: 43.221,65.961,72.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.218 | Acc: 43.207,65.680,72.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.221 | Acc: 43.100,65.722,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.229 | Acc: 43.116,65.582,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.240 | Acc: 43.190,65.582,71.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.246 | Acc: 43.290,65.522,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.243 | Acc: 43.286,65.418,71.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.256 | Acc: 43.154,65.269,71.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.270 | Acc: 43.019,65.119,71.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 43.026,65.054,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 43.120,65.080,71.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.292 | Acc: 42.978,64.961,71.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.292 | Acc: 42.936,64.982,71.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.303 | Acc: 42.846,64.846,71.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.976 | Acc: 35.156,55.469,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.485 | Acc: 31.808,48.661,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.485 | Acc: 32.565,48.075,53.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.524 | Acc: 32.646,47.554,53.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.021 | Acc: 42.188,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.188 | Acc: 43.601,65.030,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.186 | Acc: 42.873,65.777,72.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.196 | Acc: 43.110,65.881,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.219 | Acc: 43.258,65.741,72.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 43.162,65.625,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.225 | Acc: 43.221,65.644,72.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.233 | Acc: 43.201,65.570,72.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.233 | Acc: 43.308,65.567,71.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.239 | Acc: 43.258,65.483,71.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.248 | Acc: 43.299,65.403,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.251 | Acc: 43.276,65.310,71.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.255 | Acc: 43.361,65.281,71.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.263 | Acc: 43.376,65.206,71.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.267 | Acc: 43.369,65.158,71.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.274 | Acc: 43.319,64.994,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.273 | Acc: 43.331,65.024,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.277 | Acc: 43.255,65.004,71.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.287 | Acc: 43.168,64.919,71.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.294 | Acc: 43.104,64.856,70.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.539 | Acc: 28.906,53.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.202 | Acc: 24.851,44.866,53.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.300 | Acc: 24.428,44.188,52.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.322 | Acc: 25.051,43.904,51.908,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.131 | Acc: 44.531,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.034 | Acc: 44.792,68.118,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.936 | Acc: 45.122,68.902,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.900 | Acc: 45.581,69.096,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.854 | Acc: 45.978,69.194,76.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.831 | Acc: 46.055,69.686,76.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.802 | Acc: 46.145,70.022,76.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.759 | Acc: 46.432,70.567,77.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.750 | Acc: 46.424,70.628,77.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.734 | Acc: 46.569,70.796,77.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.725 | Acc: 46.475,70.876,77.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.719 | Acc: 46.433,70.966,77.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.708 | Acc: 46.564,71.087,77.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.691 | Acc: 46.648,71.207,77.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.676 | Acc: 46.758,71.372,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.672 | Acc: 46.737,71.384,78.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.670 | Acc: 46.817,71.393,78.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.659 | Acc: 46.793,71.488,78.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.654 | Acc: 46.804,71.544,78.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.650 | Acc: 46.842,71.549,78.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.219 | Acc: 44.531,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.411 | Acc: 44.271,64.137,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 43.674,63.834,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.475 | Acc: 43.929,63.627,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.777 | Acc: 51.562,69.531,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.466 | Acc: 47.135,73.996,82.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.474 | Acc: 47.847,73.533,82.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.458 | Acc: 47.938,74.155,82.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.445 | Acc: 47.695,74.363,82.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.431 | Acc: 48.097,74.435,82.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.422 | Acc: 48.366,74.509,82.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.420 | Acc: 48.404,74.485,82.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.432 | Acc: 48.180,74.326,82.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.441 | Acc: 48.170,74.180,82.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.434 | Acc: 48.115,74.048,81.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.437 | Acc: 48.045,73.918,81.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.434 | Acc: 48.094,73.924,81.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.436 | Acc: 47.932,73.788,81.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.434 | Acc: 47.926,73.855,81.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.431 | Acc: 47.978,73.928,81.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.432 | Acc: 47.965,73.934,81.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.436 | Acc: 47.977,73.912,81.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.437 | Acc: 48.065,73.905,81.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.434 | Acc: 48.132,73.967,81.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.116 | Acc: 39.844,71.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.360 | Acc: 43.564,65.104,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.410 | Acc: 43.579,64.520,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.442 | Acc: 43.968,64.280,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.466 | Acc: 44.531,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.404 | Acc: 48.698,72.954,81.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.359 | Acc: 48.628,74.123,82.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.378 | Acc: 48.335,74.577,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.381 | Acc: 48.139,74.325,81.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.370 | Acc: 48.213,74.242,82.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.381 | Acc: 47.811,74.270,82.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.391 | Acc: 47.728,74.202,82.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.385 | Acc: 47.899,74.209,82.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.398 | Acc: 47.889,74.068,81.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.393 | Acc: 47.944,74.125,82.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.389 | Acc: 47.893,74.208,82.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.393 | Acc: 47.993,74.203,82.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.398 | Acc: 48.000,74.192,81.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.396 | Acc: 47.973,74.202,81.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.396 | Acc: 47.973,74.237,81.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.394 | Acc: 48.016,74.231,81.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.388 | Acc: 48.133,74.276,82.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.387 | Acc: 48.145,74.292,82.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.383 | Acc: 48.157,74.340,82.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.203 | Acc: 43.750,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.322 | Acc: 45.164,65.513,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.360 | Acc: 44.970,64.710,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.381 | Acc: 45.044,64.370,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.263 | Acc: 50.781,74.219,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.288 | Acc: 48.810,75.000,83.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.341 | Acc: 48.133,74.981,82.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.349 | Acc: 47.964,75.154,83.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.348 | Acc: 47.743,74.971,83.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.363 | Acc: 47.525,74.861,82.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.357 | Acc: 47.695,74.903,83.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.355 | Acc: 47.806,74.928,83.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.352 | Acc: 48.015,74.845,82.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.365 | Acc: 47.786,74.676,82.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.371 | Acc: 47.862,74.534,82.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.362 | Acc: 48.013,74.523,82.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.355 | Acc: 48.045,74.543,82.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.354 | Acc: 48.018,74.569,82.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.349 | Acc: 48.098,74.630,82.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.349 | Acc: 48.046,74.629,82.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.351 | Acc: 48.038,74.581,82.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.353 | Acc: 48.121,74.565,82.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.350 | Acc: 48.206,74.552,82.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.348 | Acc: 48.273,74.573,82.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.156 | Acc: 43.750,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 45.275,65.774,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.392 | Acc: 44.493,65.072,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.411 | Acc: 44.672,64.741,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.014 | Acc: 54.688,77.344,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.313 | Acc: 48.772,74.814,83.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.264 | Acc: 49.371,75.248,83.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.279 | Acc: 48.847,75.077,83.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.267 | Acc: 49.190,75.010,84.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.294 | Acc: 49.002,74.807,83.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.297 | Acc: 49.012,74.819,83.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.301 | Acc: 48.947,74.673,83.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.302 | Acc: 48.928,74.583,83.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.307 | Acc: 49.059,74.581,83.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.304 | Acc: 49.009,74.623,83.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.308 | Acc: 48.897,74.668,83.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.312 | Acc: 48.765,74.686,83.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.310 | Acc: 48.836,74.719,83.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.308 | Acc: 48.791,74.797,83.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.303 | Acc: 48.876,74.894,83.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.301 | Acc: 48.788,74.922,83.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.296 | Acc: 48.795,74.918,83.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.293 | Acc: 48.753,74.900,83.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.293 | Acc: 48.770,74.936,83.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.074 | Acc: 43.750,67.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.317 | Acc: 45.015,65.625,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.349 | Acc: 44.665,64.901,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.373 | Acc: 44.851,64.549,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.616 | Acc: 41.406,72.656,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.302 | Acc: 47.507,74.926,84.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.284 | Acc: 47.694,75.591,84.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.284 | Acc: 48.002,75.564,84.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.267 | Acc: 48.322,75.550,84.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.274 | Acc: 48.453,75.356,84.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.271 | Acc: 48.347,75.316,84.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.276 | Acc: 48.255,75.327,84.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.269 | Acc: 48.336,75.311,84.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.277 | Acc: 48.295,75.229,84.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.282 | Acc: 48.235,75.159,84.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.282 | Acc: 48.268,75.134,84.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.281 | Acc: 48.272,75.159,84.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.283 | Acc: 48.240,75.227,84.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.280 | Acc: 48.335,75.264,84.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.280 | Acc: 48.344,75.244,84.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.276 | Acc: 48.508,75.265,84.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.273 | Acc: 48.557,75.312,84.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.270 | Acc: 48.624,75.344,84.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.268 | Acc: 48.649,75.377,84.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 43.750,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.311 | Acc: 45.201,65.588,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.357 | Acc: 44.855,64.901,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.384 | Acc: 45.184,64.626,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.199 | Acc: 49.219,75.000,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.146 | Acc: 49.182,76.488,85.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.198 | Acc: 49.466,76.029,84.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.182 | Acc: 49.565,76.101,84.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.189 | Acc: 49.518,75.984,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.201 | Acc: 49.304,75.611,84.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.202 | Acc: 49.432,75.588,84.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.209 | Acc: 49.036,75.504,84.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.214 | Acc: 49.117,75.505,84.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.212 | Acc: 49.180,75.527,84.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.210 | Acc: 49.289,75.536,84.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.217 | Acc: 49.127,75.513,84.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.228 | Acc: 49.021,75.431,84.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.228 | Acc: 49.111,75.449,84.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.222 | Acc: 49.191,75.603,84.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.224 | Acc: 49.224,75.579,84.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.231 | Acc: 49.255,75.523,84.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.230 | Acc: 49.242,75.515,84.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.236 | Acc: 49.098,75.476,84.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.239 | Acc: 49.069,75.418,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.111 | Acc: 49.219,68.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 45.945,65.885,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.342 | Acc: 45.617,65.149,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.385 | Acc: 45.300,64.575,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.149 | Acc: 53.125,71.875,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.163 | Acc: 49.702,75.409,84.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.183 | Acc: 49.466,75.324,84.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.214 | Acc: 49.206,75.256,84.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.214 | Acc: 48.997,75.193,84.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.229 | Acc: 48.724,75.255,84.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.230 | Acc: 48.767,75.271,83.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.222 | Acc: 48.637,75.277,84.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.220 | Acc: 48.622,75.340,84.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.232 | Acc: 48.476,75.155,84.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.230 | Acc: 48.472,75.101,84.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.232 | Acc: 48.462,75.209,84.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.224 | Acc: 48.486,75.305,84.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.227 | Acc: 48.518,75.266,84.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.224 | Acc: 48.557,75.336,84.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.225 | Acc: 48.539,75.356,84.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.221 | Acc: 48.596,75.421,84.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.223 | Acc: 48.545,75.545,84.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.224 | Acc: 48.580,75.556,84.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.221 | Acc: 48.669,75.630,84.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.055 | Acc: 43.750,72.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.350 | Acc: 45.238,65.551,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.380 | Acc: 44.874,64.825,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.412 | Acc: 45.069,64.447,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 2.896 | Acc: 52.344,75.000,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.191 | Acc: 48.326,76.116,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.147 | Acc: 48.933,76.448,85.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.146 | Acc: 49.129,76.191,85.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.165 | Acc: 49.219,75.743,85.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.172 | Acc: 49.103,75.781,85.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.185 | Acc: 48.896,75.749,85.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.194 | Acc: 48.803,75.803,85.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.186 | Acc: 48.928,75.854,85.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.185 | Acc: 48.891,75.915,85.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.182 | Acc: 49.118,75.987,85.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.187 | Acc: 49.148,75.880,85.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.179 | Acc: 49.235,76.070,85.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.180 | Acc: 49.210,76.114,85.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.182 | Acc: 49.208,76.104,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.190 | Acc: 49.133,76.054,85.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.192 | Acc: 49.107,75.964,84.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.194 | Acc: 49.058,75.978,84.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.200 | Acc: 48.976,75.868,84.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.201 | Acc: 48.887,75.865,84.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 43.750,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.346 | Acc: 44.457,65.960,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 44.322,65.091,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.456 | Acc: 44.493,64.613,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 3.539 | Acc: 39.844,71.875,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.238 | Acc: 47.396,75.595,85.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.178 | Acc: 49.162,75.991,85.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.171 | Acc: 49.155,75.999,85.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.159 | Acc: 49.267,76.273,85.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.185 | Acc: 49.072,76.129,85.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.178 | Acc: 49.180,76.111,85.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.178 | Acc: 49.379,76.053,85.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.166 | Acc: 49.413,76.199,85.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.174 | Acc: 49.271,76.075,85.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.180 | Acc: 49.199,75.863,85.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.182 | Acc: 49.215,75.898,85.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.185 | Acc: 49.206,75.866,85.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.177 | Acc: 49.347,75.991,85.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.183 | Acc: 49.272,75.976,85.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.185 | Acc: 49.201,75.963,85.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.190 | Acc: 49.129,75.801,85.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.189 | Acc: 49.161,75.818,85.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.190 | Acc: 49.156,75.788,85.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.189 | Acc: 49.133,75.845,85.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.088 | Acc: 46.094,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.343 | Acc: 46.168,65.476,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.377 | Acc: 45.617,64.729,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.398 | Acc: 45.402,64.524,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.798 | Acc: 50.781,80.469,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.102 | Acc: 49.628,77.418,86.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.095 | Acc: 50.743,77.420,85.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.105 | Acc: 50.282,76.908,85.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.129 | Acc: 49.923,76.736,85.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.120 | Acc: 50.116,76.756,85.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.138 | Acc: 49.800,76.472,85.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.154 | Acc: 49.584,76.330,85.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.146 | Acc: 49.670,76.315,85.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.153 | Acc: 49.521,76.187,85.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.154 | Acc: 49.382,76.170,85.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.154 | Acc: 49.413,76.089,85.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.152 | Acc: 49.442,76.115,85.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.159 | Acc: 49.312,76.051,85.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.159 | Acc: 49.313,75.998,85.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.164 | Acc: 49.258,75.953,85.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.165 | Acc: 49.299,76.003,85.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.166 | Acc: 49.265,75.937,85.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.167 | Acc: 49.249,75.959,85.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.164 | Acc: 49.241,75.958,85.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.091 | Acc: 50.781,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.315 | Acc: 46.577,66.369,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.361 | Acc: 45.560,65.568,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.394 | Acc: 45.441,64.831,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.412 | Acc: 48.438,76.562,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.186 | Acc: 47.879,74.963,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.141 | Acc: 48.780,75.972,86.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.098 | Acc: 50.077,76.294,86.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.110 | Acc: 49.971,76.186,86.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.123 | Acc: 49.466,76.168,86.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.121 | Acc: 49.380,76.098,86.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.123 | Acc: 49.446,76.147,86.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.121 | Acc: 49.214,76.218,86.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.113 | Acc: 49.283,76.247,86.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.108 | Acc: 49.320,76.368,86.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.114 | Acc: 49.251,76.269,86.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.124 | Acc: 49.199,76.222,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.128 | Acc: 49.141,76.209,86.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.131 | Acc: 49.174,76.140,86.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.133 | Acc: 49.164,76.132,85.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.142 | Acc: 49.173,76.059,85.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.147 | Acc: 49.084,75.971,85.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.150 | Acc: 49.022,75.974,85.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.155 | Acc: 48.989,75.939,85.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.114 | Acc: 44.531,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.331 | Acc: 46.466,65.551,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.384 | Acc: 45.617,64.539,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.418 | Acc: 45.530,64.293,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.367 | Acc: 49.219,73.438,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.043 | Acc: 50.558,77.716,86.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.070 | Acc: 50.210,77.001,86.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.095 | Acc: 50.218,76.652,86.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.112 | Acc: 49.740,76.408,86.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.125 | Acc: 49.621,76.369,86.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.121 | Acc: 49.561,76.375,86.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.127 | Acc: 49.407,76.247,86.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.131 | Acc: 49.262,76.334,86.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.137 | Acc: 49.167,76.252,86.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.127 | Acc: 49.234,76.275,86.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.131 | Acc: 49.145,76.283,86.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.123 | Acc: 49.241,76.306,86.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.127 | Acc: 49.108,76.275,86.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.134 | Acc: 49.010,76.223,86.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.135 | Acc: 48.980,76.189,86.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.133 | Acc: 49.017,76.214,86.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.134 | Acc: 49.054,76.253,86.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.134 | Acc: 49.050,76.195,86.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.136 | Acc: 49.059,76.216,86.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.121 | Acc: 42.188,72.656,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.337 | Acc: 45.796,65.923,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 45.122,65.072,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 45.095,64.844,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 3.241 | Acc: 46.875,78.906,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.118 | Acc: 49.665,75.335,87.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.094 | Acc: 50.152,76.086,86.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.080 | Acc: 50.333,76.524,86.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.084 | Acc: 50.077,76.562,86.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.072 | Acc: 50.155,76.926,86.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.083 | Acc: 49.884,76.569,86.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.088 | Acc: 49.817,76.457,86.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.095 | Acc: 49.631,76.334,86.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.090 | Acc: 49.637,76.338,86.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.101 | Acc: 49.584,76.287,86.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.110 | Acc: 49.639,76.244,86.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.113 | Acc: 49.566,76.264,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.116 | Acc: 49.446,76.272,86.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.113 | Acc: 49.452,76.371,86.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.116 | Acc: 49.377,76.331,86.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.117 | Acc: 49.353,76.387,86.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.120 | Acc: 49.214,76.434,86.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.118 | Acc: 49.277,76.480,86.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.121 | Acc: 49.260,76.487,86.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.020 | Acc: 46.094,71.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.330 | Acc: 45.871,65.960,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.405 | Acc: 45.217,65.206,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.432 | Acc: 45.210,64.613,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.145 | Acc: 50.000,75.781,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.977 | Acc: 50.074,77.641,87.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.035 | Acc: 49.600,77.229,86.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.030 | Acc: 49.859,77.357,86.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.032 | Acc: 50.096,77.353,86.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.053 | Acc: 49.961,77.220,86.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.054 | Acc: 49.974,77.221,86.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.067 | Acc: 50.055,77.056,86.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.074 | Acc: 49.898,76.975,86.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.072 | Acc: 50.065,76.947,86.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.079 | Acc: 49.953,76.796,86.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.071 | Acc: 50.021,76.941,86.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.077 | Acc: 49.844,76.861,86.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.081 | Acc: 49.826,76.805,86.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.094 | Acc: 49.666,76.643,86.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.099 | Acc: 49.686,76.633,86.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.097 | Acc: 49.788,76.696,86.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.098 | Acc: 49.743,76.732,86.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.101 | Acc: 49.671,76.682,86.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.105 | Acc: 49.553,76.583,86.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.240 | Acc: 44.531,72.656,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 44.196,65.104,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 43.140,64.215,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 43.571,63.768,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.688 | Acc: 56.250,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.888 | Acc: 51.935,78.497,87.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.979 | Acc: 50.724,77.630,87.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.999 | Acc: 50.346,77.280,87.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.019 | Acc: 50.096,77.238,87.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.030 | Acc: 50.193,77.390,87.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.041 | Acc: 50.039,77.002,87.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.052 | Acc: 50.017,76.995,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.055 | Acc: 49.985,77.048,87.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.066 | Acc: 49.875,76.929,86.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.077 | Acc: 49.747,76.753,86.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.074 | Acc: 49.756,76.838,86.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.086 | Acc: 49.465,76.705,86.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.082 | Acc: 49.449,76.751,86.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 49.500,76.735,86.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.082 | Acc: 49.538,76.752,86.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.080 | Acc: 49.484,76.738,86.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.084 | Acc: 49.423,76.773,86.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.088 | Acc: 49.381,76.705,86.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 49.346,76.610,86.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.184 | Acc: 42.969,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.386 | Acc: 45.759,65.699,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.422 | Acc: 45.103,64.882,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.451 | Acc: 45.095,64.677,69.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 2.912 | Acc: 54.688,82.812,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.028 | Acc: 48.512,75.930,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.061 | Acc: 49.657,76.429,87.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.061 | Acc: 49.424,76.755,87.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.056 | Acc: 49.325,76.948,87.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.053 | Acc: 49.667,76.895,87.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.054 | Acc: 49.684,76.782,87.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.064 | Acc: 49.512,76.684,86.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.074 | Acc: 49.335,76.529,86.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.072 | Acc: 49.478,76.701,86.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.078 | Acc: 49.468,76.652,86.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.077 | Acc: 49.360,76.651,86.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.081 | Acc: 49.358,76.598,86.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.077 | Acc: 49.485,76.607,86.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 49.472,76.588,86.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.076 | Acc: 49.494,76.752,86.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.083 | Acc: 49.360,76.672,86.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.083 | Acc: 49.375,76.583,86.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.084 | Acc: 49.312,76.571,86.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.079 | Acc: 49.342,76.624,86.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.257 | Acc: 44.531,72.656,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.427 | Acc: 45.573,65.588,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 44.760,65.168,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.500 | Acc: 44.839,64.588,68.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 2.860 | Acc: 52.344,83.594,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.012 | Acc: 49.851,77.902,88.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 49.619,77.915,87.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 49.872,77.228,87.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.033 | Acc: 49.913,77.257,87.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 50.054,77.305,87.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.038 | Acc: 49.877,76.956,87.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.057 | Acc: 49.712,76.773,87.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.061 | Acc: 49.626,76.630,87.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.065 | Acc: 49.668,76.688,87.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.057 | Acc: 49.708,76.749,87.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.051 | Acc: 49.717,76.944,87.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.054 | Acc: 49.650,76.890,87.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.061 | Acc: 49.602,76.667,87.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.062 | Acc: 49.627,76.663,87.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.062 | Acc: 49.639,76.674,87.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.065 | Acc: 49.659,76.677,87.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.061 | Acc: 49.629,76.670,87.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.060 | Acc: 49.608,76.716,87.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.065 | Acc: 49.457,76.669,87.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.060 | Acc: 42.969,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.352 | Acc: 46.503,65.960,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.405 | Acc: 45.827,65.053,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.447 | Acc: 45.453,64.626,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.935 | Acc: 52.344,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.973 | Acc: 50.409,78.162,88.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 50.076,77.401,87.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.009 | Acc: 50.051,77.510,87.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.039 | Acc: 49.778,77.083,87.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.041 | Acc: 49.783,76.872,87.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.023 | Acc: 49.923,77.182,87.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.042 | Acc: 49.623,77.067,87.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.043 | Acc: 49.515,76.951,87.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.042 | Acc: 49.439,76.908,87.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.043 | Acc: 49.495,77.048,87.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.048 | Acc: 49.530,77.004,87.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.057 | Acc: 49.391,76.955,87.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.060 | Acc: 49.332,76.961,87.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.057 | Acc: 49.419,76.982,87.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.060 | Acc: 49.439,76.905,87.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.057 | Acc: 49.550,76.937,87.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.053 | Acc: 49.624,76.993,87.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.052 | Acc: 49.619,77.015,87.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.054 | Acc: 49.576,76.997,87.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.119 | Acc: 44.531,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.418 | Acc: 45.312,65.253,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.453 | Acc: 44.970,64.425,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.498 | Acc: 44.787,63.998,68.852,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 3.038 | Acc: 50.000,77.344,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.077 | Acc: 48.475,77.158,87.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.068 | Acc: 48.533,77.306,87.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.082 | Acc: 48.386,77.190,87.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.072 | Acc: 48.611,77.238,87.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.069 | Acc: 48.925,77.212,87.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.058 | Acc: 49.154,77.344,87.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.057 | Acc: 49.318,77.244,87.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.049 | Acc: 49.384,77.300,87.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.049 | Acc: 49.314,77.227,87.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.045 | Acc: 49.382,77.095,87.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.039 | Acc: 49.516,77.255,87.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.046 | Acc: 49.416,77.146,87.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.045 | Acc: 49.431,77.170,87.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.043 | Acc: 49.502,77.224,87.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.044 | Acc: 49.551,77.193,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.043 | Acc: 49.559,77.176,87.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.045 | Acc: 49.512,77.124,87.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.044 | Acc: 49.589,77.112,87.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.049 | Acc: 49.625,77.075,87.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.073 | Acc: 46.094,72.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.444 | Acc: 45.499,65.402,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.468 | Acc: 44.931,64.729,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.499 | Acc: 45.146,64.101,68.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 2.525 | Acc: 55.469,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.021 | Acc: 50.000,75.856,88.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 50.191,77.344,88.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.978 | Acc: 50.538,76.960,88.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.970 | Acc: 50.376,76.919,88.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.984 | Acc: 50.433,77.042,88.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.987 | Acc: 50.407,77.137,87.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.990 | Acc: 50.427,77.255,87.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.987 | Acc: 50.524,77.305,87.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.989 | Acc: 50.514,77.206,87.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.997 | Acc: 50.494,77.173,87.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.006 | Acc: 50.438,77.128,87.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.020 | Acc: 50.318,77.007,87.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.026 | Acc: 50.230,76.892,87.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.026 | Acc: 50.117,76.899,87.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.034 | Acc: 50.073,76.799,87.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.039 | Acc: 49.973,76.823,87.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.039 | Acc: 49.943,76.782,87.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.040 | Acc: 49.933,76.809,87.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.045 | Acc: 49.750,76.747,87.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 42.188,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.480 | Acc: 45.424,65.365,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 44.531,64.520,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 44.442,64.050,68.443,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 3.304 | Acc: 39.844,75.000,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.962 | Acc: 50.632,78.274,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.975 | Acc: 50.267,78.449,88.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.025 | Acc: 50.000,77.561,87.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.009 | Acc: 50.299,77.691,87.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.012 | Acc: 49.946,77.816,87.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.996 | Acc: 50.239,77.834,87.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.991 | Acc: 50.310,77.826,87.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.997 | Acc: 50.320,77.635,87.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.997 | Acc: 50.376,77.629,87.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.001 | Acc: 50.408,77.577,87.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.005 | Acc: 50.297,77.400,87.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.017 | Acc: 50.201,77.178,87.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.020 | Acc: 50.165,77.134,87.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.018 | Acc: 50.125,77.160,87.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.022 | Acc: 50.016,77.102,87.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.025 | Acc: 49.946,77.108,87.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.020 | Acc: 49.975,77.149,87.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.027 | Acc: 49.814,77.043,87.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.032 | Acc: 49.746,77.069,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.168 | Acc: 45.312,75.000,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 45.275,66.592,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.477 | Acc: 44.989,65.358,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 45.056,64.716,69.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 3.402 | Acc: 44.531,65.625,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.988 | Acc: 49.516,77.307,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.988 | Acc: 49.200,77.096,87.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.986 | Acc: 48.886,77.152,88.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.972 | Acc: 49.103,77.315,88.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.970 | Acc: 49.513,77.297,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.959 | Acc: 49.858,77.570,88.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.974 | Acc: 49.861,77.355,88.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.981 | Acc: 49.670,77.295,88.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.989 | Acc: 49.624,77.352,88.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.993 | Acc: 49.495,77.309,87.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.999 | Acc: 49.470,77.234,87.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.997 | Acc: 49.588,77.224,87.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.000 | Acc: 49.674,77.137,87.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.005 | Acc: 49.719,77.130,87.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.006 | Acc: 49.694,77.211,87.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.007 | Acc: 49.615,77.302,87.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.013 | Acc: 49.624,77.227,87.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.019 | Acc: 49.636,77.151,87.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.020 | Acc: 49.633,77.137,87.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 44.531,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.480 | Acc: 45.610,65.104,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.531 | Acc: 45.160,64.062,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 44.941,63.755,68.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.866 | Acc: 48.438,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 49.926,77.790,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.953 | Acc: 50.667,77.763,88.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.945 | Acc: 50.948,78.189,88.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.958 | Acc: 50.627,78.241,88.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.963 | Acc: 50.418,78.055,88.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.987 | Acc: 50.052,77.763,88.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.986 | Acc: 49.945,77.776,87.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.979 | Acc: 50.126,77.882,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.978 | Acc: 50.078,77.888,88.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.983 | Acc: 50.066,77.853,88.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.992 | Acc: 50.007,77.740,88.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.997 | Acc: 49.951,77.681,87.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.002 | Acc: 49.886,77.592,87.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.006 | Acc: 49.886,77.538,87.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.012 | Acc: 49.857,77.422,87.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.021 | Acc: 49.715,77.332,87.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.024 | Acc: 49.647,77.238,87.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.024 | Acc: 49.673,77.151,87.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.024 | Acc: 49.617,77.176,87.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.139 | Acc: 43.750,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.428 | Acc: 45.982,64.993,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.489 | Acc: 45.598,64.082,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.529 | Acc: 45.581,63.678,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 2.890 | Acc: 48.438,85.938,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.921 | Acc: 50.632,78.385,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.959 | Acc: 50.038,77.706,88.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.991 | Acc: 49.488,77.702,88.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.998 | Acc: 49.537,77.479,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.994 | Acc: 49.660,77.444,88.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.982 | Acc: 49.684,77.544,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.974 | Acc: 49.873,77.637,88.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.980 | Acc: 49.942,77.669,88.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.978 | Acc: 49.905,77.749,88.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.984 | Acc: 49.984,77.701,88.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.993 | Acc: 49.806,77.552,88.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.994 | Acc: 49.805,77.470,88.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.995 | Acc: 49.719,77.434,87.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.000 | Acc: 49.697,77.397,87.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.008 | Acc: 49.689,77.250,87.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.012 | Acc: 49.596,77.224,87.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.008 | Acc: 49.592,77.277,87.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.005 | Acc: 49.708,77.296,87.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.007 | Acc: 49.727,77.258,87.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.251 | Acc: 43.750,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.420 | Acc: 45.833,66.146,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.470 | Acc: 45.465,65.034,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.502 | Acc: 45.633,64.524,68.788,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 3.200 | Acc: 39.062,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.934 | Acc: 50.521,78.869,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.966 | Acc: 50.286,78.487,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.972 | Acc: 50.013,78.484,88.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.965 | Acc: 49.836,78.144,88.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.976 | Acc: 50.170,77.816,88.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.976 | Acc: 50.161,77.608,88.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.969 | Acc: 50.139,77.759,88.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.980 | Acc: 50.252,77.586,88.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.984 | Acc: 50.276,77.495,88.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.987 | Acc: 50.288,77.503,87.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.981 | Acc: 50.368,77.598,87.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.987 | Acc: 50.266,77.486,87.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.992 | Acc: 50.108,77.469,87.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.000 | Acc: 50.003,77.380,87.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.004 | Acc: 49.940,77.302,87.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.000 | Acc: 49.922,77.378,87.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.003 | Acc: 49.922,77.307,87.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.004 | Acc: 49.948,77.324,87.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.002 | Acc: 49.973,77.338,87.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.054 | Acc: 50.000,73.438,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.450 | Acc: 45.982,66.778,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 45.255,65.282,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.545 | Acc: 45.069,64.805,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 3.143 | Acc: 46.875,78.125,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.934 | Acc: 50.595,77.716,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 50.724,78.296,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.943 | Acc: 50.359,77.830,88.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.954 | Acc: 50.222,77.855,88.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.967 | Acc: 49.683,77.700,88.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.968 | Acc: 49.658,77.576,88.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.970 | Acc: 49.612,77.565,88.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.979 | Acc: 49.554,77.528,88.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.971 | Acc: 49.672,77.577,88.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.975 | Acc: 49.674,77.569,88.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.977 | Acc: 49.731,77.616,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.979 | Acc: 49.728,77.535,88.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.980 | Acc: 49.814,77.667,88.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.983 | Acc: 49.819,77.575,88.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.986 | Acc: 49.842,77.567,88.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.987 | Acc: 49.781,77.575,88.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.987 | Acc: 49.769,77.580,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.990 | Acc: 49.682,77.560,88.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.990 | Acc: 49.707,77.543,88.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.159 | Acc: 47.656,68.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.466 | Acc: 45.610,65.774,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.529 | Acc: 44.703,64.405,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 44.723,63.755,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.879 | Acc: 47.656,79.688,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.937 | Acc: 48.661,77.307,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.952 | Acc: 48.361,77.611,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.966 | Acc: 48.809,77.267,88.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.976 | Acc: 49.315,77.527,88.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.994 | Acc: 49.281,77.282,88.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.984 | Acc: 49.348,77.324,88.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.983 | Acc: 49.457,77.388,88.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.985 | Acc: 49.481,77.281,88.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.993 | Acc: 49.499,77.150,88.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.988 | Acc: 49.452,77.231,88.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.995 | Acc: 49.371,77.199,88.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.000 | Acc: 49.332,77.224,88.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.997 | Acc: 49.383,77.221,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.995 | Acc: 49.436,77.235,88.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.988 | Acc: 49.489,77.331,88.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.990 | Acc: 49.477,77.334,88.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.989 | Acc: 49.441,77.348,88.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.989 | Acc: 49.507,77.396,88.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.993 | Acc: 49.514,77.344,88.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.126 | Acc: 45.312,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.438 | Acc: 45.871,65.737,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.483 | Acc: 45.503,64.996,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 45.300,64.319,68.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 2.977 | Acc: 50.781,82.812,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.033 | Acc: 49.033,76.414,87.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.006 | Acc: 48.952,77.191,88.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.974 | Acc: 49.283,77.677,88.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.950 | Acc: 49.711,77.961,88.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.948 | Acc: 49.814,78.071,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.963 | Acc: 49.890,77.751,88.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.970 | Acc: 49.640,77.493,88.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.965 | Acc: 49.743,77.552,88.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.967 | Acc: 49.767,77.538,88.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.961 | Acc: 49.868,77.674,88.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.965 | Acc: 49.880,77.796,88.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.959 | Acc: 49.981,77.742,88.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.956 | Acc: 50.090,77.637,88.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.957 | Acc: 50.033,77.586,88.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.961 | Acc: 50.029,77.525,88.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.957 | Acc: 50.049,77.609,88.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.962 | Acc: 50.087,77.518,88.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.969 | Acc: 50.017,77.441,88.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.973 | Acc: 50.014,77.436,88.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 48.438,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.462 | Acc: 45.908,66.071,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.498 | Acc: 45.465,64.939,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.557 | Acc: 45.210,64.562,68.443,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 3.242 | Acc: 46.875,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 48.847,78.199,88.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.984 | Acc: 48.723,77.877,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.002 | Acc: 49.014,77.997,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.965 | Acc: 49.354,78.270,88.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.961 | Acc: 49.489,78.148,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.953 | Acc: 49.684,78.106,88.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.957 | Acc: 49.706,78.059,88.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.958 | Acc: 49.709,77.989,88.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.961 | Acc: 49.702,77.948,88.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.967 | Acc: 49.635,77.884,88.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.971 | Acc: 49.597,77.832,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.968 | Acc: 49.734,77.807,88.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.963 | Acc: 49.728,77.832,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.963 | Acc: 49.755,77.844,88.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.964 | Acc: 49.774,77.795,88.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.966 | Acc: 49.783,77.711,88.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.966 | Acc: 49.817,77.667,88.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.965 | Acc: 49.844,77.642,88.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.969 | Acc: 49.818,77.660,88.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.111 | Acc: 46.094,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.414 | Acc: 46.280,66.146,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 45.808,65.111,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.500 | Acc: 45.556,64.485,68.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 3.385 | Acc: 44.531,72.656,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 50.186,78.460,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.945 | Acc: 50.210,78.601,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.949 | Acc: 49.821,78.215,88.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.943 | Acc: 49.952,78.308,88.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.941 | Acc: 50.108,78.357,88.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.932 | Acc: 50.232,78.319,88.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.937 | Acc: 50.172,78.252,88.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.935 | Acc: 50.286,78.130,88.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.937 | Acc: 50.177,77.978,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.949 | Acc: 50.019,77.802,88.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.957 | Acc: 50.018,77.658,88.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.954 | Acc: 49.994,77.700,88.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.961 | Acc: 49.919,77.562,88.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.967 | Acc: 49.869,77.513,88.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.967 | Acc: 49.855,77.531,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.969 | Acc: 49.737,77.426,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.970 | Acc: 49.808,77.419,88.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.973 | Acc: 49.721,77.383,88.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.974 | Acc: 49.744,77.354,88.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.102 | Acc: 44.531,73.438,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 46.243,66.109,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.496 | Acc: 45.484,64.710,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.529 | Acc: 45.581,64.267,68.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 3.014 | Acc: 47.656,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.880 | Acc: 51.079,78.609,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.908 | Acc: 50.019,78.316,89.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 50.038,78.227,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.916 | Acc: 50.048,78.173,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.930 | Acc: 49.822,77.908,89.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.923 | Acc: 49.935,78.048,89.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.921 | Acc: 49.873,78.014,88.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.926 | Acc: 49.709,78.018,89.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.923 | Acc: 49.927,78.060,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.933 | Acc: 49.775,77.977,88.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.935 | Acc: 49.841,77.892,88.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.944 | Acc: 49.793,77.778,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 49.743,77.808,88.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.953 | Acc: 49.647,77.711,88.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.949 | Acc: 49.803,77.733,88.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 49.815,77.745,88.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.955 | Acc: 49.851,77.621,88.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.959 | Acc: 49.792,77.558,88.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.959 | Acc: 49.863,77.506,88.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.013 | Acc: 46.875,71.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.420 | Acc: 46.540,66.183,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 45.865,64.863,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.514 | Acc: 45.825,64.408,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 3.083 | Acc: 45.312,73.438,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.858 | Acc: 51.674,78.571,89.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.916 | Acc: 50.991,78.030,88.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.929 | Acc: 50.307,78.023,88.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.948 | Acc: 50.125,77.749,88.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.969 | Acc: 49.706,77.429,88.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.964 | Acc: 49.768,77.667,88.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.962 | Acc: 50.017,77.687,88.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.954 | Acc: 50.087,77.732,88.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.958 | Acc: 49.953,77.667,88.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.954 | Acc: 50.054,77.783,88.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.960 | Acc: 50.042,77.687,88.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.960 | Acc: 50.032,77.671,88.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.959 | Acc: 50.018,77.655,88.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.955 | Acc: 50.044,77.719,88.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.959 | Acc: 49.951,77.671,88.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.955 | Acc: 50.024,77.697,88.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.961 | Acc: 49.945,77.623,88.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.960 | Acc: 50.002,77.616,88.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.960 | Acc: 50.004,77.557,88.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.225 | Acc: 44.531,72.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.480 | Acc: 45.945,65.141,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 45.598,64.272,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 45.607,63.819,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 3.018 | Acc: 52.344,76.562,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.865 | Acc: 50.260,78.125,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 50.877,78.373,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 51.383,78.778,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.875 | Acc: 50.685,78.588,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.884 | Acc: 50.534,78.512,89.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.887 | Acc: 50.549,78.319,89.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 50.565,78.186,89.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.903 | Acc: 50.548,78.009,89.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.899 | Acc: 50.721,78.047,89.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.897 | Acc: 50.727,78.211,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.910 | Acc: 50.520,78.093,89.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.916 | Acc: 50.477,78.041,89.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.924 | Acc: 50.308,77.984,89.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.924 | Acc: 50.328,78.067,88.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.927 | Acc: 50.379,78.026,88.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.924 | Acc: 50.350,78.052,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.929 | Acc: 50.270,77.960,88.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.928 | Acc: 50.229,77.978,88.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.939 | Acc: 50.135,77.854,88.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.354 | Acc: 43.750,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 45.312,65.365,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 45.046,64.005,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.671 | Acc: 44.736,63.563,67.841,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.593 | Acc: 48.438,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.918 | Acc: 49.665,77.344,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.900 | Acc: 50.210,78.258,89.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.908 | Acc: 50.269,78.368,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.909 | Acc: 49.855,78.376,89.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.914 | Acc: 49.737,78.388,89.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.917 | Acc: 49.774,78.274,89.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.928 | Acc: 49.856,77.981,89.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.913 | Acc: 50.073,78.057,89.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.913 | Acc: 50.065,78.108,89.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.920 | Acc: 50.074,77.927,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.917 | Acc: 50.064,78.083,89.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.926 | Acc: 49.997,77.914,88.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 49.880,77.859,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.927 | Acc: 49.947,77.889,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.924 | Acc: 49.997,77.904,88.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.928 | Acc: 50.068,77.845,88.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.930 | Acc: 50.060,77.793,88.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.932 | Acc: 50.054,77.826,88.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.935 | Acc: 49.967,77.787,88.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.124 | Acc: 46.094,71.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.549 | Acc: 45.164,65.737,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.584 | Acc: 44.893,64.386,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 45.056,63.947,68.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.761 | Acc: 51.562,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.918 | Acc: 48.698,78.348,88.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.930 | Acc: 48.914,78.144,88.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 49.155,78.586,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.904 | Acc: 49.527,78.443,89.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.892 | Acc: 49.714,78.543,89.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.887 | Acc: 49.800,78.441,89.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.896 | Acc: 49.817,78.302,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.903 | Acc: 49.864,78.174,89.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.905 | Acc: 49.879,78.008,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.908 | Acc: 50.000,77.896,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.898 | Acc: 50.046,78.012,89.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 50.162,78.099,89.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.904 | Acc: 50.147,77.981,89.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.903 | Acc: 50.214,77.989,89.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.909 | Acc: 50.254,77.891,88.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.917 | Acc: 50.107,77.850,88.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.924 | Acc: 49.993,77.811,89.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.921 | Acc: 49.998,77.805,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.929 | Acc: 49.967,77.713,88.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.195 | Acc: 45.312,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 45.759,65.737,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 45.293,64.329,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 45.338,63.832,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.773 | Acc: 58.594,83.594,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.860 | Acc: 51.935,78.274,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.880 | Acc: 50.591,78.373,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.871 | Acc: 50.256,78.381,89.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.865 | Acc: 50.222,78.337,89.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.873 | Acc: 50.162,78.651,89.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.893 | Acc: 50.058,78.461,89.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.896 | Acc: 50.116,78.402,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.908 | Acc: 50.116,78.334,89.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.911 | Acc: 50.065,78.298,89.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.927 | Acc: 49.903,78.113,88.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.929 | Acc: 49.912,77.987,88.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.927 | Acc: 50.065,77.986,89.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.926 | Acc: 50.042,78.047,88.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.925 | Acc: 50.042,78.003,88.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.927 | Acc: 50.060,77.998,88.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.933 | Acc: 49.966,77.947,88.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.937 | Acc: 49.911,77.955,88.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 49.926,77.906,88.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.935 | Acc: 49.943,77.904,88.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.245 | Acc: 42.969,71.875,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 45.871,64.844,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 45.084,64.062,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 45.031,63.653,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 3.200 | Acc: 46.094,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.913 | Acc: 48.996,78.013,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 49.981,78.430,89.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.870 | Acc: 49.962,78.496,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.866 | Acc: 50.270,78.655,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.875 | Acc: 50.248,78.411,89.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.865 | Acc: 50.407,78.390,89.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.879 | Acc: 50.266,78.164,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.890 | Acc: 50.228,78.096,89.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.887 | Acc: 50.216,78.168,89.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.905 | Acc: 50.062,78.183,89.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.905 | Acc: 50.117,78.213,89.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.905 | Acc: 50.068,78.174,89.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.910 | Acc: 50.093,78.173,89.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.922 | Acc: 49.853,77.989,89.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.929 | Acc: 49.766,77.884,88.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 49.839,77.930,88.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.930 | Acc: 49.814,77.791,88.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.929 | Acc: 49.864,77.803,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.930 | Acc: 49.850,77.793,88.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.200 | Acc: 46.875,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.515 | Acc: 47.321,65.290,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.561 | Acc: 46.532,64.158,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 46.235,63.601,67.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.911 | Acc: 50.000,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 50.893,78.646,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.869 | Acc: 50.400,78.887,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.864 | Acc: 49.974,78.996,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.889 | Acc: 49.817,78.733,89.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.907 | Acc: 49.660,78.403,89.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.900 | Acc: 49.968,78.499,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.902 | Acc: 50.083,78.391,89.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.904 | Acc: 50.325,78.421,89.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.905 | Acc: 50.401,78.397,89.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.908 | Acc: 50.229,78.319,89.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.909 | Acc: 50.240,78.284,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.904 | Acc: 50.311,78.261,89.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.910 | Acc: 50.230,78.182,89.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.912 | Acc: 50.225,78.183,89.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.915 | Acc: 50.208,78.130,88.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.918 | Acc: 50.165,78.023,89.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.921 | Acc: 50.064,77.976,88.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.915 | Acc: 50.184,78.017,88.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.919 | Acc: 50.125,77.986,88.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 40.625,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 44.382,64.621,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.671 | Acc: 44.341,63.967,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.715 | Acc: 44.454,63.537,67.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 3.156 | Acc: 48.438,76.562,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.776 | Acc: 51.004,80.208,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.829 | Acc: 50.476,79.078,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.837 | Acc: 50.564,78.893,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.867 | Acc: 50.637,78.366,89.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.861 | Acc: 50.673,78.295,89.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.868 | Acc: 50.600,78.170,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.867 | Acc: 50.659,78.147,89.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.879 | Acc: 50.461,78.144,89.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.881 | Acc: 50.276,78.289,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 50.233,78.086,89.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.896 | Acc: 50.177,78.040,89.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.898 | Acc: 50.195,78.008,89.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.905 | Acc: 50.123,78.005,89.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.906 | Acc: 50.161,77.989,89.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.906 | Acc: 50.169,78.050,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.906 | Acc: 50.214,78.037,89.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.911 | Acc: 50.234,77.971,89.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.915 | Acc: 50.154,77.948,89.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.915 | Acc: 50.189,77.973,89.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.153 | Acc: 45.312,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 46.726,66.295,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 45.865,65.149,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 45.607,64.703,67.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.061 | Acc: 51.562,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.875 | Acc: 51.153,78.683,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 50.896,78.678,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.857 | Acc: 50.961,78.599,90.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.863 | Acc: 50.810,78.385,90.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.867 | Acc: 50.835,78.373,90.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.856 | Acc: 50.859,78.499,90.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.866 | Acc: 50.754,78.574,89.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.868 | Acc: 50.699,78.411,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 50.604,78.388,89.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.884 | Acc: 50.498,78.265,89.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.881 | Acc: 50.604,78.273,89.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.880 | Acc: 50.584,78.300,89.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.882 | Acc: 50.593,78.290,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.887 | Acc: 50.442,78.314,89.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.890 | Acc: 50.446,78.289,89.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.901 | Acc: 50.336,78.137,89.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.902 | Acc: 50.417,78.141,89.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.902 | Acc: 50.370,78.131,89.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.904 | Acc: 50.402,78.092,89.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 40.625,66.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.622 | Acc: 44.606,64.695,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.658 | Acc: 44.150,63.891,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.699 | Acc: 44.314,63.550,66.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 2.483 | Acc: 59.375,84.375,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 51.600,78.609,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.835 | Acc: 50.591,78.544,90.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.839 | Acc: 50.487,78.676,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.841 | Acc: 50.424,78.704,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.858 | Acc: 50.456,78.666,89.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.870 | Acc: 50.245,78.383,89.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.873 | Acc: 50.183,78.336,89.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.876 | Acc: 50.063,78.474,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 50.047,78.220,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.881 | Acc: 50.047,78.172,89.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 50.141,78.150,89.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.887 | Acc: 50.149,78.073,89.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.892 | Acc: 50.114,77.972,89.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.901 | Acc: 50.111,77.861,89.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.903 | Acc: 50.109,77.845,89.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.904 | Acc: 50.080,77.872,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.906 | Acc: 50.101,77.859,89.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.911 | Acc: 50.002,77.764,89.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.912 | Acc: 49.998,77.713,89.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.310 | Acc: 42.969,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 45.573,65.179,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.651 | Acc: 45.236,64.482,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 45.248,63.960,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.846 | Acc: 50.781,81.250,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.874 | Acc: 50.446,78.311,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.890 | Acc: 50.591,78.582,89.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.877 | Acc: 50.525,78.560,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.887 | Acc: 50.270,78.202,89.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.875 | Acc: 50.549,78.326,89.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.876 | Acc: 50.517,78.345,89.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.885 | Acc: 50.421,78.313,89.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 50.393,78.377,89.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 50.466,78.401,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 50.564,78.300,89.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.878 | Acc: 50.534,78.305,89.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.881 | Acc: 50.522,78.277,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.881 | Acc: 50.509,78.209,89.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.889 | Acc: 50.459,78.072,89.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.887 | Acc: 50.420,78.099,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.890 | Acc: 50.375,78.030,89.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 50.275,78.001,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.892 | Acc: 50.262,77.993,89.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.898 | Acc: 50.215,77.951,89.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.556 | Acc: 42.969,65.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.705 | Acc: 43.787,64.769,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.733 | Acc: 43.617,63.548,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.798 | Acc: 43.507,63.038,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.603 | Acc: 56.250,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.789 | Acc: 50.818,78.832,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 50.686,79.211,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.814 | Acc: 51.127,79.188,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 51.235,78.906,90.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.844 | Acc: 50.951,78.458,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.856 | Acc: 50.859,78.461,90.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.849 | Acc: 50.820,78.585,89.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.853 | Acc: 50.801,78.508,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.861 | Acc: 50.695,78.453,89.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.863 | Acc: 50.634,78.424,89.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 50.629,78.397,89.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 50.626,78.297,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.876 | Acc: 50.521,78.272,89.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.880 | Acc: 50.498,78.236,89.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.884 | Acc: 50.511,78.148,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.892 | Acc: 50.399,78.067,89.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.895 | Acc: 50.330,78.033,89.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 50.305,77.956,89.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.899 | Acc: 50.332,77.889,89.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.277 | Acc: 42.188,72.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.586 | Acc: 44.978,65.402,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.681 | Acc: 44.646,64.082,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.724 | Acc: 44.749,63.563,66.880,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.622 | Acc: 53.125,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 51.265,79.539,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 50.400,79.478,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.833 | Acc: 49.859,78.906,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.848 | Acc: 49.884,78.665,90.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.856 | Acc: 49.985,78.697,89.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.876 | Acc: 49.890,78.532,89.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.881 | Acc: 50.072,78.402,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.880 | Acc: 49.893,78.406,89.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 50.013,78.393,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.870 | Acc: 50.117,78.490,89.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 50.106,78.510,89.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.864 | Acc: 50.272,78.553,89.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.868 | Acc: 50.284,78.562,89.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 50.309,78.575,89.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.877 | Acc: 50.278,78.475,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.879 | Acc: 50.202,78.456,89.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.881 | Acc: 50.181,78.370,89.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.887 | Acc: 50.102,78.270,89.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.892 | Acc: 50.033,78.225,89.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.572 | Acc: 46.094,69.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 45.387,64.769,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.685 | Acc: 44.817,63.815,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.738 | Acc: 44.800,63.307,66.816,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 3.017 | Acc: 50.781,78.906,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 51.004,80.580,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.840 | Acc: 49.600,78.906,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.841 | Acc: 50.282,79.252,90.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.849 | Acc: 50.241,78.926,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 50.162,78.790,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.854 | Acc: 50.187,78.577,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.854 | Acc: 50.078,78.585,90.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.853 | Acc: 50.223,78.533,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.860 | Acc: 50.259,78.397,89.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.868 | Acc: 50.117,78.273,89.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.877 | Acc: 50.067,78.153,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.874 | Acc: 50.078,78.235,89.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.878 | Acc: 49.994,78.236,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.874 | Acc: 50.064,78.239,89.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.876 | Acc: 50.005,78.255,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.879 | Acc: 49.951,78.222,89.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.879 | Acc: 50.000,78.162,89.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.879 | Acc: 50.032,78.186,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.882 | Acc: 50.080,78.160,89.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 40.625,71.094,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.649 | Acc: 43.936,65.216,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.683 | Acc: 44.131,64.196,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.734 | Acc: 44.109,63.819,66.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.905 | Acc: 44.531,82.812,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.805 | Acc: 52.046,78.757,88.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.854 | Acc: 50.838,78.697,89.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 49.885,78.535,89.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.861 | Acc: 50.000,78.665,89.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.871 | Acc: 49.961,78.380,89.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 49.890,78.416,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.882 | Acc: 49.806,78.236,89.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.876 | Acc: 50.131,78.343,89.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 50.242,78.367,89.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.870 | Acc: 50.330,78.331,89.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.865 | Acc: 50.385,78.383,89.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.870 | Acc: 50.438,78.320,89.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.870 | Acc: 50.446,78.320,89.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.871 | Acc: 50.334,78.334,89.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.867 | Acc: 50.439,78.398,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.870 | Acc: 50.419,78.366,89.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.872 | Acc: 50.323,78.269,89.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.873 | Acc: 50.277,78.296,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 50.244,78.232,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.232 | Acc: 41.406,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 45.089,66.220,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.649 | Acc: 45.103,64.405,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.712 | Acc: 45.005,63.998,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.700 | Acc: 50.000,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.790 | Acc: 49.442,79.092,91.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.827 | Acc: 49.905,78.544,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.854 | Acc: 50.320,78.074,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.864 | Acc: 50.125,77.971,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.878 | Acc: 50.031,78.133,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 50.562,78.215,89.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.865 | Acc: 50.881,78.236,89.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 50.781,78.222,89.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.873 | Acc: 50.643,78.185,89.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.872 | Acc: 50.626,78.160,89.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.871 | Acc: 50.622,78.256,89.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.874 | Acc: 50.519,78.183,89.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.880 | Acc: 50.257,78.131,89.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.885 | Acc: 50.170,78.089,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 50.057,78.070,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.890 | Acc: 50.061,78.018,89.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 50.154,78.043,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.890 | Acc: 50.115,78.010,89.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.891 | Acc: 50.174,78.031,89.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.410 | Acc: 38.281,71.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 45.312,65.253,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.656 | Acc: 44.931,64.558,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.728 | Acc: 45.056,63.845,66.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.471 | Acc: 55.469,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.795 | Acc: 50.149,79.613,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.878 | Acc: 49.600,78.792,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.852 | Acc: 50.077,79.124,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.871 | Acc: 50.096,78.781,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.851 | Acc: 50.286,79.107,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.850 | Acc: 50.413,78.880,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.851 | Acc: 50.083,78.884,90.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 50.257,78.911,90.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.862 | Acc: 50.117,78.790,89.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.869 | Acc: 50.023,78.673,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.867 | Acc: 50.064,78.631,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.871 | Acc: 50.029,78.537,89.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.872 | Acc: 49.958,78.583,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.870 | Acc: 49.958,78.620,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 49.982,78.579,89.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.867 | Acc: 50.041,78.639,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 49.945,78.533,89.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 50.043,78.530,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.872 | Acc: 50.035,78.492,89.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.241 | Acc: 42.188,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.626 | Acc: 45.015,65.067,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.718 | Acc: 44.646,63.796,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.780 | Acc: 44.736,63.128,66.534,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.397 | Acc: 54.688,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.682 | Acc: 53.237,80.543,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 51.772,79.764,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.787 | Acc: 51.370,79.073,90.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.791 | Acc: 51.196,79.061,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 51.122,79.061,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.816 | Acc: 50.930,78.958,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.835 | Acc: 50.693,78.801,89.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.841 | Acc: 50.539,78.630,89.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.847 | Acc: 50.445,78.561,89.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.848 | Acc: 50.404,78.506,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.856 | Acc: 50.417,78.380,89.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.856 | Acc: 50.395,78.371,89.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.863 | Acc: 50.287,78.260,89.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.862 | Acc: 50.339,78.289,89.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.859 | Acc: 50.348,78.346,89.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.867 | Acc: 50.217,78.252,89.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.875 | Acc: 50.105,78.173,89.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.875 | Acc: 50.141,78.207,89.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.878 | Acc: 50.135,78.197,89.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.448 | Acc: 44.531,69.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.663 | Acc: 45.312,64.583,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.740 | Acc: 44.627,63.853,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.788 | Acc: 44.275,63.320,66.803,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.778 | Acc: 45.312,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.797 | Acc: 51.339,78.534,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.842 | Acc: 50.553,78.316,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 50.410,78.484,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.831 | Acc: 50.434,78.713,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.829 | Acc: 50.456,78.806,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 50.568,78.758,90.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.846 | Acc: 50.321,78.729,90.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.860 | Acc: 50.082,78.625,90.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.862 | Acc: 50.056,78.583,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.868 | Acc: 50.105,78.444,90.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.870 | Acc: 50.159,78.447,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.867 | Acc: 50.301,78.446,90.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.867 | Acc: 50.224,78.412,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.867 | Acc: 50.320,78.464,89.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.870 | Acc: 50.298,78.400,89.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.869 | Acc: 50.282,78.371,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.871 | Acc: 50.222,78.322,89.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.871 | Acc: 50.279,78.339,89.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 50.306,78.330,89.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.187 | Acc: 41.406,70.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.657 | Acc: 43.973,64.844,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.731 | Acc: 43.731,63.700,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.780 | Acc: 44.109,63.204,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 3.313 | Acc: 47.656,75.000,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.865 | Acc: 50.298,78.683,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 51.048,78.887,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.848 | Acc: 50.897,78.701,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.844 | Acc: 50.752,78.655,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.855 | Acc: 50.665,78.334,89.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 50.646,78.467,89.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.846 | Acc: 50.416,78.546,89.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.848 | Acc: 50.364,78.513,89.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 50.298,78.522,89.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.849 | Acc: 50.412,78.591,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 50.481,78.556,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.852 | Acc: 50.499,78.401,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.853 | Acc: 50.482,78.442,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.851 | Acc: 50.478,78.453,89.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.854 | Acc: 50.413,78.460,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.854 | Acc: 50.431,78.468,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 50.495,78.540,89.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 50.465,78.560,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 50.390,78.494,89.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.292 | Acc: 43.750,72.656,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 45.536,65.737,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 45.103,64.577,66.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 45.031,64.306,66.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.796 | Acc: 53.906,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 51.228,78.869,88.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 50.934,78.258,89.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.827 | Acc: 50.499,78.957,90.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.827 | Acc: 50.685,79.070,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 50.766,78.752,90.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 50.452,78.428,90.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.840 | Acc: 50.587,78.491,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.842 | Acc: 50.456,78.368,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.850 | Acc: 50.306,78.367,89.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.855 | Acc: 50.249,78.401,89.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.855 | Acc: 50.293,78.401,89.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.849 | Acc: 50.392,78.433,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.852 | Acc: 50.380,78.469,89.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.859 | Acc: 50.381,78.453,89.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.860 | Acc: 50.343,78.377,89.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.858 | Acc: 50.268,78.405,89.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.858 | Acc: 50.277,78.443,89.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.861 | Acc: 50.305,78.404,89.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.867 | Acc: 50.275,78.351,89.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.238 | Acc: 42.188,70.312,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.759 | Acc: 44.531,63.653,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.826 | Acc: 43.617,62.881,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.882 | Acc: 43.763,62.705,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.634 | Acc: 51.562,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 50.521,79.055,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.777 | Acc: 51.181,78.639,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.829 | Acc: 50.499,77.946,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.816 | Acc: 50.810,78.250,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.830 | Acc: 50.657,78.148,89.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.814 | Acc: 50.807,78.403,90.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.817 | Acc: 50.875,78.341,90.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.818 | Acc: 50.820,78.353,90.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.822 | Acc: 50.811,78.362,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.819 | Acc: 50.816,78.510,90.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 50.594,78.380,90.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.833 | Acc: 50.600,78.371,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.836 | Acc: 50.467,78.358,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 50.464,78.306,90.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.847 | Acc: 50.402,78.263,89.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 50.428,78.295,89.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.403,78.251,89.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 50.307,78.212,89.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.863 | Acc: 50.283,78.184,89.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.260 | Acc: 42.188,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.675 | Acc: 45.536,64.807,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.712 | Acc: 44.855,64.024,66.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.756 | Acc: 44.839,63.717,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.816 | Acc: 50.781,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.819 | Acc: 50.744,78.609,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.832 | Acc: 50.171,78.544,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 50.218,78.624,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.836 | Acc: 50.241,78.559,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 50.387,78.558,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.841 | Acc: 50.252,78.396,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.826 | Acc: 50.465,78.757,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.833 | Acc: 50.272,78.508,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.827 | Acc: 50.337,78.613,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.836 | Acc: 50.295,78.595,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 50.127,78.433,90.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.850 | Acc: 50.019,78.371,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.851 | Acc: 50.135,78.266,90.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.853 | Acc: 50.186,78.253,90.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.859 | Acc: 50.021,78.192,89.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.856 | Acc: 50.156,78.198,89.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.197,78.230,89.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.858 | Acc: 50.173,78.233,89.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.859 | Acc: 50.191,78.176,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.284 | Acc: 44.531,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.637 | Acc: 45.089,65.216,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.706 | Acc: 44.760,63.758,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.767 | Acc: 44.339,63.166,66.855,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 3.202 | Acc: 50.781,71.094,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 50.781,78.943,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 50.896,78.449,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.815 | Acc: 50.653,78.945,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 50.627,78.935,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.853 | Acc: 50.101,78.581,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.853 | Acc: 49.994,78.693,90.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 49.961,78.579,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 50.146,78.668,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.843 | Acc: 50.237,78.764,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 50.272,78.751,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.843 | Acc: 50.293,78.666,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.839 | Acc: 50.331,78.699,90.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.840 | Acc: 50.434,78.733,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 50.361,78.637,90.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 50.275,78.623,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.848 | Acc: 50.248,78.568,90.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 50.259,78.581,90.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.852 | Acc: 50.195,78.486,90.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 50.248,78.529,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.106 | Acc: 42.969,77.344,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.732 | Acc: 45.164,65.104,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.788 | Acc: 44.607,63.662,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.825 | Acc: 44.698,63.204,66.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.834 | Acc: 53.125,78.125,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.712 | Acc: 53.385,79.539,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 52.553,79.459,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.751 | Acc: 52.049,79.419,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 51.669,79.495,90.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.793 | Acc: 51.323,79.231,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.795 | Acc: 51.098,79.177,90.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.796 | Acc: 50.970,79.217,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.799 | Acc: 51.106,79.227,90.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 51.122,79.053,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.816 | Acc: 51.147,79.019,90.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 51.156,78.935,90.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 51.274,79.029,90.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.818 | Acc: 51.164,78.972,90.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.821 | Acc: 51.079,78.976,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 50.937,78.854,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.832 | Acc: 50.789,78.753,90.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.834 | Acc: 50.742,78.698,90.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 50.680,78.638,89.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.844 | Acc: 50.664,78.613,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.410 | Acc: 43.750,68.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.678 | Acc: 45.610,64.546,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.745 | Acc: 45.389,63.777,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.794 | Acc: 45.223,63.115,66.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.562 | Acc: 60.156,80.469,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.833 | Acc: 49.665,79.688,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.857 | Acc: 49.600,78.830,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.854 | Acc: 50.115,78.484,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.833 | Acc: 50.347,78.791,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 50.348,78.875,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.840 | Acc: 50.103,78.577,90.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.828 | Acc: 50.249,78.585,90.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.824 | Acc: 50.330,78.557,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 50.522,78.665,90.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.831 | Acc: 50.451,78.607,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.831 | Acc: 50.375,78.549,90.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.833 | Acc: 50.408,78.634,90.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 50.527,78.655,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.830 | Acc: 50.620,78.620,90.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.835 | Acc: 50.574,78.603,90.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.838 | Acc: 50.577,78.541,90.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 50.582,78.590,90.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.839 | Acc: 50.569,78.571,90.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.843 | Acc: 50.468,78.564,90.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.447 | Acc: 42.188,67.969,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.763 | Acc: 44.196,65.030,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.825 | Acc: 43.483,63.491,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.876 | Acc: 43.302,63.166,65.868,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 3.223 | Acc: 44.531,75.781,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.772 | Acc: 51.190,79.650,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.809 | Acc: 50.667,78.639,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.840 | Acc: 50.397,78.535,90.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 50.588,78.733,90.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.824 | Acc: 50.774,78.991,90.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.818 | Acc: 50.897,79.029,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.822 | Acc: 51.020,78.790,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.832 | Acc: 50.810,78.576,90.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.836 | Acc: 50.578,78.501,90.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.834 | Acc: 50.579,78.448,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.836 | Acc: 50.431,78.433,90.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.841 | Acc: 50.434,78.368,90.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.841 | Acc: 50.467,78.412,89.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 50.414,78.342,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 50.433,78.426,89.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.852 | Acc: 50.411,78.412,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 50.406,78.393,89.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.852 | Acc: 50.405,78.406,89.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.851 | Acc: 50.361,78.428,89.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.243 | Acc: 45.312,72.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.642 | Acc: 45.536,65.439,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.697 | Acc: 45.465,64.348,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.752 | Acc: 45.633,63.781,66.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.950 | Acc: 47.656,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.706 | Acc: 52.307,80.246,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.739 | Acc: 51.372,80.183,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.763 | Acc: 51.191,79.816,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 51.128,79.504,90.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 50.828,79.301,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 50.865,79.294,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.790 | Acc: 50.637,79.133,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.791 | Acc: 50.723,79.110,90.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 50.604,79.092,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.795 | Acc: 50.711,79.178,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.797 | Acc: 50.721,79.200,90.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.800 | Acc: 50.665,79.217,90.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.817 | Acc: 50.518,79.065,90.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.824 | Acc: 50.389,78.979,90.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 50.418,78.958,90.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 50.448,78.955,90.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.836 | Acc: 50.357,78.826,90.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 50.385,78.809,90.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.398,78.826,90.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.237 | Acc: 39.844,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.655 | Acc: 45.164,64.844,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.696 | Acc: 44.607,64.329,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.760 | Acc: 44.634,63.986,66.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 2.870 | Acc: 49.219,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.832 | Acc: 50.409,79.464,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.796 | Acc: 50.438,79.745,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 50.538,79.316,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.799 | Acc: 50.367,79.215,91.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 50.209,79.316,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 50.187,79.171,91.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 50.194,79.272,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.810 | Acc: 50.063,79.047,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 50.082,78.824,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.826 | Acc: 50.132,78.930,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.825 | Acc: 50.247,78.899,90.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 50.353,78.809,90.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.836 | Acc: 50.335,78.706,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.838 | Acc: 50.361,78.714,90.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 50.317,78.722,90.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 50.268,78.670,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.844 | Acc: 50.277,78.602,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.840 | Acc: 50.325,78.664,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.843 | Acc: 50.238,78.619,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.465 | Acc: 43.750,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.749 | Acc: 43.787,64.769,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.825 | Acc: 43.045,63.643,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.867 | Acc: 42.956,62.935,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.841 | Acc: 53.906,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 52.604,79.874,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.768 | Acc: 50.877,78.963,90.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.783 | Acc: 50.576,78.829,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.790 | Acc: 50.916,78.858,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 50.936,78.736,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.797 | Acc: 50.678,78.648,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.799 | Acc: 50.626,78.657,90.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.791 | Acc: 50.806,78.761,90.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 50.816,78.816,90.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 50.470,78.654,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 50.484,78.539,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 50.486,78.491,90.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.822 | Acc: 50.509,78.463,90.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 50.581,78.442,90.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.827 | Acc: 50.478,78.421,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.827 | Acc: 50.450,78.449,90.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 50.396,78.416,90.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.831 | Acc: 50.407,78.465,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.342,78.404,89.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.458 | Acc: 42.969,73.438,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.705 | Acc: 44.754,64.249,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.775 | Acc: 44.436,62.824,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.839 | Acc: 44.378,62.654,65.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 3.256 | Acc: 49.219,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.771 | Acc: 49.851,79.762,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 49.600,79.306,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.777 | Acc: 50.448,79.470,91.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.795 | Acc: 50.424,79.147,90.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.801 | Acc: 50.333,79.069,90.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.795 | Acc: 50.717,79.055,90.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.793 | Acc: 50.748,79.078,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.797 | Acc: 50.645,79.023,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.802 | Acc: 50.751,78.954,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.802 | Acc: 50.758,78.883,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.801 | Acc: 50.799,78.878,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.807 | Acc: 50.817,78.828,90.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.813 | Acc: 50.706,78.745,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.819 | Acc: 50.695,78.662,90.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.821 | Acc: 50.613,78.660,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.826 | Acc: 50.582,78.629,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 50.493,78.503,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 50.422,78.471,90.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.846 | Acc: 50.330,78.365,90.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.589 | Acc: 42.188,67.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.928 | Acc: 43.043,63.132,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.965 | Acc: 42.416,62.081,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.025 | Acc: 42.188,61.783,65.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.652 | Acc: 52.344,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 51.004,79.539,91.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.789 | Acc: 51.067,79.306,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 51.409,79.342,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.781 | Acc: 51.350,79.302,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.814 | Acc: 50.975,78.891,90.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.824 | Acc: 50.549,78.919,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.826 | Acc: 50.410,78.951,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.829 | Acc: 50.194,78.838,90.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.820 | Acc: 50.376,79.083,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 50.319,79.101,90.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 50.428,79.065,90.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 50.464,78.981,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.818 | Acc: 50.530,79.011,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 50.539,78.917,90.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.827 | Acc: 50.426,78.841,90.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.825 | Acc: 50.453,78.843,90.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 50.495,78.789,90.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.834 | Acc: 50.457,78.731,90.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.833 | Acc: 50.482,78.724,90.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.355 | Acc: 44.531,73.438,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.695 | Acc: 45.722,65.216,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.773 | Acc: 45.008,63.700,66.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.844 | Acc: 45.018,63.281,65.433,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 3.069 | Acc: 42.188,74.219,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.828 | Acc: 50.298,79.464,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 49.695,78.887,90.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.825 | Acc: 49.693,78.919,90.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.817 | Acc: 50.154,79.138,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.843 | Acc: 50.116,78.906,90.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.843 | Acc: 50.200,78.861,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.838 | Acc: 50.244,78.895,90.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.843 | Acc: 50.364,78.707,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.834 | Acc: 50.406,78.759,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 50.463,78.898,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.843 | Acc: 50.371,78.687,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.837 | Acc: 50.541,78.718,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 50.566,78.790,90.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.838 | Acc: 50.592,78.806,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.834 | Acc: 50.550,78.813,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.833 | Acc: 50.567,78.804,90.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 50.458,78.821,90.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.838 | Acc: 50.435,78.722,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.441,78.662,90.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 46.094,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.709 | Acc: 44.940,64.546,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.778 | Acc: 44.264,63.700,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.827 | Acc: 44.237,63.204,66.189,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.725 | Acc: 50.000,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.789 | Acc: 51.823,78.683,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.787 | Acc: 51.486,79.192,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 51.345,79.137,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.789 | Acc: 51.215,78.983,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.782 | Acc: 50.789,78.953,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 50.517,79.061,91.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 50.604,78.812,90.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 50.412,78.780,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.531,78.807,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.754,78.883,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 50.650,78.737,90.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 50.629,78.712,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 50.623,78.610,90.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.817 | Acc: 50.626,78.620,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.819 | Acc: 50.563,78.558,90.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.822 | Acc: 50.528,78.563,90.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.823 | Acc: 50.440,78.597,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.823 | Acc: 50.463,78.618,90.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 50.465,78.668,90.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.352 | Acc: 44.531,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 45.461,64.658,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 44.989,63.720,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.718 | Acc: 44.903,63.422,66.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.578 | Acc: 53.125,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.783 | Acc: 51.302,78.088,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 51.315,79.230,91.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 51.268,79.329,90.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.785 | Acc: 51.100,79.051,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 50.920,79.146,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 50.975,79.055,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.798 | Acc: 50.848,79.050,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.784 | Acc: 50.956,79.095,90.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 50.988,79.092,90.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 51.119,78.976,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.795 | Acc: 50.976,78.973,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.802 | Acc: 50.859,78.916,90.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.803 | Acc: 50.790,78.939,90.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.805 | Acc: 50.801,78.965,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.808 | Acc: 50.828,78.940,90.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.757,78.841,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.822 | Acc: 50.703,78.750,90.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 50.684,78.768,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.828 | Acc: 50.638,78.664,90.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.582 | Acc: 40.625,68.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.774 | Acc: 44.494,64.918,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.831 | Acc: 44.093,63.891,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.900 | Acc: 43.968,63.204,65.830,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.619 | Acc: 53.906,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.805 | Acc: 50.930,78.534,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 50.438,78.468,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.790 | Acc: 50.269,78.804,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 50.203,78.694,90.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.794 | Acc: 50.217,78.636,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.802 | Acc: 50.297,78.538,90.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.801 | Acc: 50.393,78.696,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 50.291,78.654,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 50.289,78.669,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.807 | Acc: 50.280,78.755,90.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.198,78.542,90.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 50.373,78.595,90.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.816 | Acc: 50.383,78.610,90.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 50.378,78.475,90.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.820 | Acc: 50.485,78.447,90.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.823 | Acc: 50.411,78.422,90.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 50.261,78.377,90.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 50.227,78.365,90.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.837 | Acc: 50.219,78.332,90.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.544 | Acc: 46.875,65.625,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.669 | Acc: 45.089,64.807,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.727 | Acc: 44.436,64.120,66.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.796 | Acc: 44.378,63.332,66.214,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.484 | Acc: 47.656,87.500,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.787 | Acc: 50.186,79.725,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.720 | Acc: 50.915,80.564,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.749 | Acc: 50.154,80.225,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.756 | Acc: 50.309,79.929,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.271,79.726,91.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 50.220,79.513,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 50.299,79.471,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.252,79.411,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.787 | Acc: 50.168,79.243,90.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.802 | Acc: 49.957,79.124,90.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.815 | Acc: 49.855,78.995,90.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.818 | Acc: 49.925,78.997,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.816 | Acc: 49.919,79.014,90.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.816 | Acc: 50.022,78.942,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.816 | Acc: 49.992,78.930,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.814 | Acc: 50.051,78.914,90.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.818 | Acc: 49.975,78.833,90.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.814 | Acc: 50.132,78.872,90.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 50.174,78.884,90.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.489 | Acc: 42.188,68.750,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.970 | Acc: 42.820,64.249,65.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.971 | Acc: 42.454,63.110,65.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.028 | Acc: 42.520,62.551,65.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.643 | Acc: 56.250,85.156,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 52.158,80.357,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.752 | Acc: 51.181,79.478,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.735 | Acc: 51.191,79.790,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.745 | Acc: 51.051,79.581,91.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.765 | Acc: 50.758,79.432,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.753 | Acc: 50.910,79.474,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.765 | Acc: 50.787,79.222,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.778 | Acc: 50.665,78.955,90.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.778 | Acc: 50.673,79.044,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.778 | Acc: 50.738,79.174,90.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.779 | Acc: 50.785,79.207,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.780 | Acc: 50.840,79.140,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 50.826,79.188,90.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 50.762,79.145,90.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.795 | Acc: 50.719,79.111,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.806 | Acc: 50.543,78.962,90.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.813 | Acc: 50.458,78.815,90.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.815 | Acc: 50.454,78.792,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.815 | Acc: 50.455,78.757,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.536 | Acc: 41.406,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.751 | Acc: 44.866,64.472,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.796 | Acc: 44.607,63.281,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.851 | Acc: 44.442,62.782,65.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.911 | Acc: 46.094,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.734 | Acc: 50.818,79.836,90.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 50.305,79.192,90.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.765 | Acc: 50.961,79.214,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 50.675,79.070,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.769 | Acc: 50.920,79.247,90.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.761 | Acc: 51.085,79.494,90.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.753 | Acc: 51.108,79.610,90.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.764 | Acc: 50.951,79.595,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 50.863,79.511,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.783 | Acc: 50.758,79.357,90.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.788 | Acc: 50.757,79.313,90.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.788 | Acc: 50.827,79.289,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.793 | Acc: 50.700,79.277,90.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 50.687,79.229,90.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.799 | Acc: 50.729,79.171,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.809 | Acc: 50.630,79.072,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.554,79.007,90.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 50.558,78.967,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.821 | Acc: 50.509,78.898,90.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.456 | Acc: 47.656,66.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.714 | Acc: 45.610,64.509,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.764 | Acc: 45.274,63.396,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.826 | Acc: 44.941,62.859,65.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.777 | Acc: 50.000,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.673 | Acc: 52.269,80.171,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.735 | Acc: 50.934,79.497,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 50.986,79.124,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.772 | Acc: 50.907,79.003,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 50.712,79.308,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 50.491,79.093,90.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 50.621,79.056,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.793 | Acc: 50.582,79.023,90.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 50.540,79.057,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.797 | Acc: 50.486,79.151,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 50.516,79.178,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 50.454,79.240,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.794 | Acc: 50.482,79.301,90.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.795 | Acc: 50.548,79.251,90.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.798 | Acc: 50.558,79.145,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.800 | Acc: 50.562,79.159,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.803 | Acc: 50.529,79.124,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.808 | Acc: 50.485,79.069,90.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 50.453,78.972,90.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.655 | Acc: 40.625,66.406,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.888 | Acc: 43.304,64.137,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.006 | Acc: 42.473,62.614,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.066 | Acc: 42.239,62.218,65.202,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.646 | Acc: 51.562,82.031,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.812 | Acc: 50.112,78.646,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.797 | Acc: 49.943,79.040,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.795 | Acc: 50.704,78.881,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.782 | Acc: 50.666,78.916,90.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.787 | Acc: 50.526,79.022,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 50.523,78.984,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.786 | Acc: 50.776,79.034,90.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 50.592,78.979,90.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 50.578,78.993,90.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.801 | Acc: 50.622,78.992,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.802 | Acc: 50.672,78.956,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.798 | Acc: 50.616,79.020,90.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.807 | Acc: 50.482,79.062,90.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.810 | Acc: 50.517,79.090,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 50.535,79.020,90.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.816 | Acc: 50.482,78.933,90.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.818 | Acc: 50.454,78.844,90.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 50.524,78.787,90.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.818 | Acc: 50.560,78.810,90.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.224 | Acc: 46.094,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.678 | Acc: 45.685,65.439,67.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.737 | Acc: 45.236,63.986,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.802 | Acc: 45.210,63.409,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.521 | Acc: 47.656,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.785 | Acc: 50.446,78.795,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.765 | Acc: 50.495,79.516,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 50.564,79.239,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.802 | Acc: 50.405,78.868,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.797 | Acc: 50.209,78.929,90.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.796 | Acc: 50.207,79.087,90.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.808 | Acc: 50.238,78.845,90.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.811 | Acc: 50.354,78.809,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.814 | Acc: 50.276,78.777,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.803 | Acc: 50.288,78.926,90.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.804 | Acc: 50.219,78.949,90.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 50.182,78.819,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 50.162,78.801,90.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 50.203,78.884,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.810 | Acc: 50.223,78.885,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.809 | Acc: 50.299,78.877,90.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.302,78.805,90.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.292,78.792,90.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 50.357,78.793,90.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 42.969,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.834 | Acc: 43.043,63.876,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.872 | Acc: 42.988,63.281,66.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.952 | Acc: 42.866,62.538,66.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.372 | Acc: 56.250,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.735 | Acc: 51.190,78.943,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.742 | Acc: 51.505,79.097,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.762 | Acc: 50.858,79.329,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.768 | Acc: 51.042,79.022,91.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.769 | Acc: 51.238,79.154,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.769 | Acc: 51.246,79.197,90.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.765 | Acc: 51.125,79.244,90.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.951,79.028,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 50.915,79.105,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.781 | Acc: 50.941,79.112,90.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.777 | Acc: 51.018,79.242,90.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 51.041,79.273,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 51.170,79.200,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.790 | Acc: 51.151,79.101,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.791 | Acc: 51.046,79.083,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.800 | Acc: 50.891,78.972,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.799 | Acc: 50.871,78.977,90.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.804 | Acc: 50.851,78.928,90.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.808 | Acc: 50.800,78.859,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.528 | Acc: 43.750,70.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.798 | Acc: 44.606,65.179,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.845 | Acc: 44.474,63.910,66.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.891 | Acc: 44.531,63.268,66.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.770 | Acc: 52.344,79.688,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.751 | Acc: 49.814,80.729,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 50.248,81.136,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.719 | Acc: 50.820,80.866,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.695 | Acc: 50.945,80.922,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.674 | Acc: 51.416,80.995,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.670 | Acc: 51.356,80.869,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.676 | Acc: 51.380,80.823,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.663 | Acc: 51.509,80.886,92.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.658 | Acc: 51.519,80.840,92.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.659 | Acc: 51.524,80.865,92.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.661 | Acc: 51.573,80.893,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.661 | Acc: 51.537,80.819,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.663 | Acc: 51.380,80.804,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.657 | Acc: 51.501,80.847,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.659 | Acc: 51.583,80.801,92.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.665 | Acc: 51.404,80.729,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.666 | Acc: 51.427,80.666,92.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.662 | Acc: 51.428,80.642,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.665 | Acc: 51.368,80.592,92.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 45.312,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.525 | Acc: 46.354,66.146,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.573 | Acc: 45.808,65.053,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.624 | Acc: 45.850,64.524,67.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.585 | Acc: 56.250,85.156,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.648 | Acc: 52.381,80.990,93.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.641 | Acc: 51.905,81.002,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.646 | Acc: 51.614,80.635,93.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.622 | Acc: 51.919,81.076,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.610 | Acc: 52.011,81.219,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.619 | Acc: 51.898,81.063,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.620 | Acc: 51.956,81.056,93.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.620 | Acc: 52.004,81.056,93.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.616 | Acc: 51.886,81.116,93.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.615 | Acc: 51.893,81.180,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.616 | Acc: 51.891,81.239,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.615 | Acc: 51.760,81.308,93.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.617 | Acc: 51.697,81.184,93.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.615 | Acc: 51.682,81.231,93.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.613 | Acc: 51.697,81.266,93.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.620 | Acc: 51.618,81.206,93.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.618 | Acc: 51.645,81.291,93.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.620 | Acc: 51.645,81.265,93.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.620 | Acc: 51.622,81.227,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.261 | Acc: 46.875,70.312,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 46.987,66.778,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.546 | Acc: 46.341,65.568,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 46.286,64.908,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.629 | Acc: 46.875,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.600 | Acc: 51.190,81.250,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.637 | Acc: 51.105,81.136,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.615 | Acc: 51.434,81.378,93.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.595 | Acc: 51.399,81.501,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.594 | Acc: 51.632,81.498,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.599 | Acc: 51.575,81.392,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.594 | Acc: 51.612,81.494,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.598 | Acc: 51.645,81.371,93.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.596 | Acc: 51.580,81.427,93.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.604 | Acc: 51.446,81.343,93.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.601 | Acc: 51.460,81.409,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.604 | Acc: 51.400,81.399,93.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.609 | Acc: 51.452,81.304,93.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.608 | Acc: 51.479,81.278,93.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.607 | Acc: 51.466,81.224,93.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.603 | Acc: 51.521,81.260,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.602 | Acc: 51.645,81.294,93.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.603 | Acc: 51.625,81.287,93.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.602 | Acc: 51.591,81.297,93.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.320 | Acc: 44.531,69.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.522 | Acc: 46.763,66.629,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.569 | Acc: 46.265,65.606,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 46.196,64.921,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.754 | Acc: 42.969,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.550 | Acc: 52.530,80.841,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.607 | Acc: 51.181,81.136,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.621 | Acc: 50.807,80.520,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.617 | Acc: 51.283,80.527,93.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.613 | Acc: 51.075,80.693,93.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.597 | Acc: 51.311,80.953,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.594 | Acc: 51.213,81.078,93.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.592 | Acc: 51.441,81.027,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.582 | Acc: 51.649,81.259,94.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.578 | Acc: 51.691,81.351,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.583 | Acc: 51.654,81.345,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.590 | Acc: 51.572,81.250,94.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.586 | Acc: 51.571,81.343,94.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.589 | Acc: 51.401,81.272,93.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.590 | Acc: 51.469,81.234,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.592 | Acc: 51.429,81.257,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.590 | Acc: 51.423,81.243,93.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.588 | Acc: 51.469,81.282,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.597 | Acc: 51.407,81.199,93.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.276 | Acc: 43.750,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 46.689,66.778,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.545 | Acc: 46.303,65.644,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 46.376,64.908,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 3.096 | Acc: 43.750,76.562,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.584 | Acc: 52.195,81.771,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 52.782,81.631,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 52.690,81.660,93.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.559 | Acc: 52.392,81.578,94.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.573 | Acc: 52.166,81.443,94.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.565 | Acc: 52.182,81.689,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.579 | Acc: 51.939,81.477,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.590 | Acc: 51.839,81.425,93.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.597 | Acc: 51.575,81.224,93.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.595 | Acc: 51.644,81.238,93.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.593 | Acc: 51.644,81.303,93.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.592 | Acc: 51.550,81.412,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.586 | Acc: 51.580,81.492,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.582 | Acc: 51.635,81.492,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.582 | Acc: 51.638,81.515,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.582 | Acc: 51.592,81.540,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.585 | Acc: 51.624,81.465,93.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.583 | Acc: 51.647,81.510,93.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.579 | Acc: 51.688,81.560,94.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 45.312,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.517 | Acc: 46.466,66.109,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 46.380,65.072,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 46.478,64.549,67.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.715 | Acc: 51.562,78.906,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.582 | Acc: 52.046,80.766,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.610 | Acc: 51.696,81.441,93.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.601 | Acc: 51.588,81.352,93.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.588 | Acc: 51.900,81.597,93.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.573 | Acc: 52.158,81.784,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.575 | Acc: 52.014,81.657,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.590 | Acc: 51.718,81.433,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.589 | Acc: 51.490,81.502,93.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.586 | Acc: 51.619,81.453,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.579 | Acc: 51.691,81.483,93.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.581 | Acc: 51.658,81.444,93.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.588 | Acc: 51.686,81.341,93.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.586 | Acc: 51.613,81.394,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.584 | Acc: 51.710,81.475,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.584 | Acc: 51.705,81.489,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.583 | Acc: 51.772,81.457,93.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.583 | Acc: 51.718,81.530,93.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.583 | Acc: 51.621,81.553,93.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.581 | Acc: 51.692,81.584,94.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 46.094,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.511 | Acc: 46.652,66.481,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.562 | Acc: 46.341,65.434,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.618 | Acc: 46.260,64.780,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.227 | Acc: 56.250,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 53.274,83.259,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.570 | Acc: 51.296,81.955,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.573 | Acc: 51.332,81.865,94.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.569 | Acc: 51.591,82.118,94.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.580 | Acc: 51.485,81.637,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.579 | Acc: 51.634,81.870,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.584 | Acc: 51.568,81.704,93.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.589 | Acc: 51.495,81.711,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.594 | Acc: 51.601,81.578,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.590 | Acc: 51.737,81.565,93.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.586 | Acc: 51.743,81.561,93.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.579 | Acc: 51.828,81.629,94.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.580 | Acc: 51.829,81.636,94.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.580 | Acc: 51.913,81.564,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.583 | Acc: 51.903,81.528,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.584 | Acc: 51.823,81.515,94.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.582 | Acc: 51.863,81.562,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.580 | Acc: 51.829,81.590,94.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.579 | Acc: 51.845,81.623,94.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.294 | Acc: 46.094,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.502 | Acc: 47.024,66.369,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.549 | Acc: 46.799,65.587,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 46.696,65.049,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.303 | Acc: 55.469,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 51.972,81.808,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 52.077,81.479,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 51.934,81.570,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.588 | Acc: 51.292,81.076,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.597 | Acc: 51.238,81.149,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.588 | Acc: 51.214,81.269,94.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.575 | Acc: 51.485,81.510,94.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.572 | Acc: 51.616,81.643,94.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.584 | Acc: 51.468,81.522,94.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.589 | Acc: 51.438,81.549,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.586 | Acc: 51.531,81.582,94.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.582 | Acc: 51.566,81.535,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.576 | Acc: 51.646,81.666,94.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.574 | Acc: 51.599,81.636,94.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.575 | Acc: 51.568,81.639,94.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.573 | Acc: 51.589,81.647,94.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.571 | Acc: 51.638,81.713,94.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.569 | Acc: 51.658,81.739,94.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.573 | Acc: 51.601,81.689,94.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.302 | Acc: 45.312,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.528 | Acc: 46.987,66.964,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 46.570,65.682,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 46.580,64.997,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.786 | Acc: 51.562,81.250,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.605 | Acc: 51.711,81.734,93.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.559 | Acc: 52.115,82.527,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.566 | Acc: 51.857,81.865,93.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.560 | Acc: 51.842,81.838,94.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.563 | Acc: 52.135,81.683,94.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.553 | Acc: 52.021,81.857,94.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.547 | Acc: 52.233,81.948,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.550 | Acc: 52.281,81.837,94.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.551 | Acc: 52.279,81.841,94.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.557 | Acc: 52.126,81.740,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.564 | Acc: 51.983,81.625,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.566 | Acc: 51.854,81.639,94.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.569 | Acc: 51.808,81.657,94.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.575 | Acc: 51.721,81.614,94.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.573 | Acc: 51.768,81.533,94.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.575 | Acc: 51.726,81.542,94.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.575 | Acc: 51.762,81.523,94.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 51.755,81.529,94.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.573 | Acc: 51.794,81.564,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.305 | Acc: 46.094,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.542 | Acc: 46.838,66.183,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 46.322,65.282,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 46.209,64.857,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.158 | Acc: 59.375,86.719,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 52.307,81.845,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 52.248,81.955,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.563 | Acc: 51.921,81.788,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.544 | Acc: 52.363,82.128,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.566 | Acc: 52.011,81.815,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.568 | Acc: 52.002,81.689,94.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.572 | Acc: 52.056,81.693,94.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.571 | Acc: 51.990,81.643,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.569 | Acc: 51.938,81.682,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.571 | Acc: 51.963,81.600,94.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.574 | Acc: 52.004,81.604,94.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.576 | Acc: 51.848,81.652,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.578 | Acc: 51.886,81.684,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.571 | Acc: 51.949,81.798,94.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.575 | Acc: 51.962,81.738,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.569 | Acc: 51.964,81.781,94.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.566 | Acc: 51.924,81.779,94.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.566 | Acc: 51.937,81.756,94.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.563 | Acc: 51.911,81.777,94.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.315 | Acc: 47.656,73.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.526 | Acc: 46.689,66.667,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 46.551,65.758,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 46.465,65.151,67.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.639 | Acc: 42.969,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 52.381,81.548,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.538 | Acc: 52.534,81.917,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.529 | Acc: 52.228,82.031,94.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.523 | Acc: 52.054,82.031,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 52.096,82.163,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 52.008,81.870,94.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 51.906,81.732,94.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.554 | Acc: 51.800,81.847,94.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.548 | Acc: 51.878,81.867,94.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.548 | Acc: 52.064,81.876,94.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.548 | Acc: 52.079,81.911,94.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.554 | Acc: 51.987,81.795,94.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.556 | Acc: 51.985,81.822,94.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.553 | Acc: 52.082,81.864,94.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.556 | Acc: 52.014,81.824,94.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.557 | Acc: 51.991,81.771,94.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.559 | Acc: 51.890,81.701,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.562 | Acc: 51.904,81.691,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.559 | Acc: 51.999,81.677,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 46.094,71.875,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.519 | Acc: 46.801,66.071,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.567 | Acc: 46.475,65.339,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.618 | Acc: 46.452,64.716,67.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.404 | Acc: 57.812,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.572 | Acc: 52.009,81.101,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.538 | Acc: 52.191,81.536,94.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 52.049,81.532,94.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.526 | Acc: 52.296,81.723,94.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.550 | Acc: 51.787,81.753,94.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.559 | Acc: 51.692,81.721,94.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.564 | Acc: 51.668,81.749,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.569 | Acc: 51.679,81.687,94.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.577 | Acc: 51.709,81.548,94.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.584 | Acc: 51.656,81.425,94.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.579 | Acc: 51.711,81.423,94.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.572 | Acc: 51.799,81.555,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.570 | Acc: 51.844,81.624,94.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.567 | Acc: 51.860,81.742,94.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.566 | Acc: 51.804,81.779,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.565 | Acc: 51.808,81.837,94.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.559 | Acc: 51.883,81.940,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.558 | Acc: 51.846,81.912,94.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.558 | Acc: 51.829,81.957,94.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.215 | Acc: 46.094,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 46.466,66.183,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 46.303,65.358,67.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 46.376,64.767,67.239,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.939 | Acc: 51.562,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.618 | Acc: 50.856,81.771,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.569 | Acc: 51.696,82.050,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.545 | Acc: 52.152,82.211,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.540 | Acc: 52.276,82.186,94.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.548 | Acc: 52.166,82.101,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.532 | Acc: 52.550,82.302,94.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 52.283,82.153,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.547 | Acc: 52.417,82.080,94.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.549 | Acc: 52.370,82.061,94.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.554 | Acc: 52.239,81.992,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.555 | Acc: 52.241,81.883,94.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.553 | Acc: 52.266,81.814,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.555 | Acc: 52.158,81.762,94.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.557 | Acc: 52.080,81.753,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.560 | Acc: 51.931,81.728,94.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.560 | Acc: 51.935,81.715,94.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 51.961,81.761,94.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.557 | Acc: 51.935,81.774,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.561 | Acc: 51.850,81.724,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 45.312,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.530 | Acc: 46.912,66.332,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 46.608,65.282,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.642 | Acc: 46.504,64.805,67.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.646 | Acc: 46.094,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 52.307,81.473,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.532 | Acc: 52.344,82.107,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 52.728,82.684,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.534 | Acc: 52.344,82.282,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.543 | Acc: 51.926,82.170,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.531 | Acc: 52.221,82.038,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 52.371,82.142,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 52.198,82.235,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 52.072,82.213,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.529 | Acc: 52.091,82.132,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.532 | Acc: 51.969,82.162,94.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.531 | Acc: 51.977,82.197,94.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.535 | Acc: 51.910,82.133,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.535 | Acc: 51.929,82.156,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.536 | Acc: 51.986,82.161,94.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.543 | Acc: 51.835,82.116,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.544 | Acc: 51.773,82.157,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 51.803,82.139,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.548 | Acc: 51.804,82.054,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.298 | Acc: 46.875,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.541 | Acc: 46.801,66.295,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 46.456,65.111,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 46.414,64.613,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.433 | Acc: 54.688,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.546 | Acc: 51.749,81.287,94.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.539 | Acc: 52.306,81.536,94.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.532 | Acc: 51.985,81.404,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.541 | Acc: 51.562,81.588,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.526 | Acc: 51.988,81.822,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.521 | Acc: 52.079,82.089,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 52.072,82.292,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.518 | Acc: 52.121,82.264,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.529 | Acc: 52.072,82.070,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.524 | Acc: 52.223,82.210,94.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.524 | Acc: 52.368,82.180,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.526 | Acc: 52.308,82.106,94.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.535 | Acc: 52.197,81.995,94.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 52.121,81.940,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.548 | Acc: 52.108,81.876,94.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.549 | Acc: 52.113,81.817,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.549 | Acc: 52.064,81.825,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.551 | Acc: 52.002,81.873,94.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 52.071,81.857,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 46.875,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 46.801,66.443,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 46.456,65.244,67.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 46.440,64.728,67.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.642 | Acc: 48.438,75.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.476 | Acc: 52.679,83.594,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.487 | Acc: 52.954,83.003,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 52.382,82.544,94.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.521 | Acc: 52.199,82.427,94.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.546 | Acc: 51.709,82.232,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.556 | Acc: 51.569,82.154,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.559 | Acc: 51.801,81.976,94.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.563 | Acc: 51.553,81.920,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.561 | Acc: 51.528,81.971,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.559 | Acc: 51.535,81.903,94.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.551 | Acc: 51.715,82.021,94.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.552 | Acc: 51.611,81.989,94.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.551 | Acc: 51.682,82.010,94.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.550 | Acc: 51.607,82.087,94.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.552 | Acc: 51.583,82.036,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.549 | Acc: 51.657,82.041,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.545 | Acc: 51.766,82.050,94.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.805,82.014,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.544 | Acc: 51.837,82.031,94.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.314 | Acc: 46.094,71.875,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 47.210,66.369,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 46.684,65.187,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.657 | Acc: 46.670,64.716,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.989 | Acc: 43.750,77.344,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 53.051,81.510,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.566 | Acc: 52.801,81.650,94.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.558 | Acc: 52.254,81.890,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.573 | Acc: 51.890,81.684,94.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.578 | Acc: 51.686,81.436,94.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.571 | Acc: 51.931,81.431,94.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.570 | Acc: 51.756,81.461,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.559 | Acc: 51.839,81.614,94.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.554 | Acc: 52.003,81.669,94.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.558 | Acc: 51.838,81.790,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.554 | Acc: 51.898,81.812,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.553 | Acc: 51.870,81.843,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.550 | Acc: 51.910,81.912,94.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.548 | Acc: 51.974,81.864,94.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.544 | Acc: 51.913,81.829,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 51.915,81.795,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.548 | Acc: 51.954,81.793,94.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.928,81.819,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.550 | Acc: 51.889,81.841,94.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.341 | Acc: 46.875,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.098,66.927,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 46.704,65.473,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 46.440,64.818,67.239,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.298 | Acc: 53.125,85.156,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 53.460,82.812,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.540 | Acc: 52.382,81.803,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.556 | Acc: 51.588,81.749,94.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.563 | Acc: 51.399,81.694,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.556 | Acc: 51.632,81.761,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.559 | Acc: 51.666,81.708,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.553 | Acc: 51.961,81.821,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.546 | Acc: 52.043,81.900,94.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.553 | Acc: 51.938,81.928,94.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.556 | Acc: 51.943,81.837,94.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.553 | Acc: 52.107,81.809,94.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.549 | Acc: 52.127,81.931,94.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.550 | Acc: 52.086,81.926,94.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.550 | Acc: 52.049,81.937,94.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 52.053,81.979,94.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.548 | Acc: 51.993,81.963,94.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.547 | Acc: 52.080,81.988,94.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 52.045,82.014,94.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.553 | Acc: 52.022,81.923,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.299 | Acc: 47.656,71.875,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.098,66.071,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 46.551,64.996,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.660 | Acc: 46.440,64.652,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.539 | Acc: 51.562,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.557 | Acc: 51.451,82.180,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.554 | Acc: 51.048,81.307,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.531 | Acc: 51.434,81.493,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.539 | Acc: 51.350,81.510,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 51.671,81.753,94.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.552 | Acc: 51.472,81.624,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.547 | Acc: 51.723,81.821,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.543 | Acc: 51.941,81.735,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.540 | Acc: 51.921,81.811,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.540 | Acc: 51.928,81.740,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.983,81.840,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.536 | Acc: 51.906,81.931,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.539 | Acc: 51.832,81.903,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.546 | Acc: 51.799,81.837,94.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.542 | Acc: 51.866,81.899,94.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.547 | Acc: 51.867,81.832,94.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.551 | Acc: 51.844,81.768,94.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.547 | Acc: 51.930,81.826,94.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.547 | Acc: 51.813,81.820,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.324 | Acc: 46.875,71.875,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 46.577,65.960,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.625 | Acc: 46.227,64.863,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.676 | Acc: 46.299,64.421,67.303,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.481 | Acc: 54.688,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 52.344,82.143,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.518 | Acc: 52.973,82.222,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.522 | Acc: 52.472,82.403,94.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.527 | Acc: 52.421,82.292,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.539 | Acc: 52.019,82.186,94.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.546 | Acc: 51.834,81.902,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.541 | Acc: 51.806,81.970,94.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 51.800,81.924,94.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.540 | Acc: 51.899,81.945,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 52.064,81.996,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.990,82.028,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.535 | Acc: 51.952,82.034,94.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.537 | Acc: 51.928,81.950,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.536 | Acc: 51.899,81.948,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 51.931,81.901,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.540 | Acc: 51.867,81.927,94.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.543 | Acc: 51.808,81.901,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 51.822,81.932,94.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.543 | Acc: 51.848,81.941,94.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 45.312,71.875,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.540 | Acc: 47.359,66.592,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 46.723,65.358,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 46.568,64.728,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.487 | Acc: 56.250,83.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.488 | Acc: 52.641,82.812,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.549 | Acc: 51.677,82.184,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.532 | Acc: 52.152,82.057,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.525 | Acc: 52.228,82.089,94.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 52.375,82.155,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.518 | Acc: 52.111,81.947,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 51.973,81.981,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.521 | Acc: 51.941,82.070,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 51.916,81.954,94.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.527 | Acc: 51.951,81.938,94.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 51.934,81.840,94.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 51.874,81.795,94.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.536 | Acc: 52.003,81.783,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.536 | Acc: 52.024,81.770,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.535 | Acc: 52.056,81.808,94.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.959,81.761,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.546 | Acc: 51.892,81.727,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.545 | Acc: 51.898,81.739,94.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.545 | Acc: 51.907,81.748,94.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.336 | Acc: 46.875,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.507,66.704,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 46.894,65.530,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.659 | Acc: 46.734,64.921,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.443 | Acc: 50.781,85.156,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.526 | Acc: 51.860,81.771,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.530 | Acc: 52.115,81.688,94.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.532 | Acc: 52.126,81.506,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.535 | Acc: 52.035,81.414,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.528 | Acc: 52.119,81.536,94.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.544 | Acc: 51.834,81.521,94.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.547 | Acc: 51.768,81.643,94.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.544 | Acc: 51.771,81.633,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.547 | Acc: 51.774,81.630,94.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.543 | Acc: 51.873,81.759,94.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 51.980,81.816,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.545 | Acc: 51.942,81.730,94.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.541 | Acc: 52.071,81.756,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 52.060,81.778,94.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.537 | Acc: 51.986,81.894,94.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 51.974,81.895,94.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.541 | Acc: 51.890,81.878,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.538 | Acc: 51.976,81.945,94.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.537 | Acc: 51.983,81.966,94.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.308 | Acc: 46.094,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 47.173,66.295,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 46.456,65.511,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.675 | Acc: 46.401,64.754,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.478 | Acc: 50.781,88.281,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 51.711,83.557,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 51.562,83.041,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.520 | Acc: 51.601,82.428,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.525 | Acc: 51.389,82.581,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.292,82.526,94.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.533 | Acc: 51.575,82.509,94.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.529 | Acc: 51.690,82.430,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.522 | Acc: 51.931,82.366,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 51.886,82.415,94.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 52.013,82.389,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.522 | Acc: 52.040,82.311,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.523 | Acc: 52.039,82.375,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.530 | Acc: 51.877,82.349,94.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.530 | Acc: 51.924,82.287,94.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.534 | Acc: 51.819,82.239,94.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.536 | Acc: 51.740,82.189,94.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 51.757,82.141,94.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.540 | Acc: 51.835,82.152,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.540 | Acc: 51.854,82.113,94.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.375 | Acc: 44.531,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.210,66.778,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 46.608,65.682,67.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.668 | Acc: 46.632,65.023,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.105 | Acc: 60.938,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.498 | Acc: 52.753,81.176,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.517 | Acc: 52.363,81.250,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.524 | Acc: 52.164,81.340,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.529 | Acc: 51.948,81.481,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.539 | Acc: 51.818,81.745,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.544 | Acc: 51.827,81.805,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 52.072,81.754,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.552 | Acc: 51.970,81.653,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.548 | Acc: 52.037,81.751,94.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.548 | Acc: 51.982,81.748,94.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.545 | Acc: 51.987,81.816,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.540 | Acc: 52.107,81.928,94.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.536 | Acc: 52.059,81.992,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.538 | Acc: 51.980,81.967,94.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.537 | Acc: 52.001,82.005,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 52.018,81.992,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.539 | Acc: 52.050,82.008,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.543 | Acc: 52.002,82.040,94.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.541 | Acc: 52.057,82.035,94.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.294 | Acc: 46.875,71.094,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.513 | Acc: 47.024,66.369,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 46.704,65.625,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 46.593,64.844,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.887 | Acc: 45.312,75.781,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.543 | Acc: 52.604,82.515,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.532 | Acc: 53.030,82.584,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 52.728,82.441,95.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.519 | Acc: 52.373,82.465,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.542 | Acc: 52.274,81.946,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.534 | Acc: 52.505,82.064,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.538 | Acc: 52.366,82.197,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.528 | Acc: 52.475,82.313,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 52.512,82.459,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 52.491,82.358,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.527 | Acc: 52.439,82.289,94.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.527 | Acc: 52.512,82.265,95.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.530 | Acc: 52.422,82.208,95.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 52.372,82.156,95.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 52.448,82.218,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.523 | Acc: 52.446,82.168,95.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 52.408,82.166,94.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.532 | Acc: 52.311,82.111,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 52.319,82.140,94.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.311 | Acc: 46.094,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.539 | Acc: 47.061,65.997,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 46.475,65.149,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.655 | Acc: 46.452,64.600,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.678 | Acc: 53.125,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.490 | Acc: 51.228,82.440,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.477 | Acc: 51.696,82.908,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 51.716,82.928,94.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.500 | Acc: 51.669,82.726,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.521 | Acc: 51.655,82.403,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.526 | Acc: 51.569,82.277,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 51.485,82.148,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.536 | Acc: 51.407,82.056,94.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.530 | Acc: 51.537,82.049,94.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.527 | Acc: 51.625,82.097,94.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.533 | Acc: 51.566,82.031,94.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.537 | Acc: 51.533,81.966,94.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.541 | Acc: 51.500,81.932,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 51.507,81.951,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.540 | Acc: 51.620,81.922,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 51.701,82.004,94.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.537 | Acc: 51.682,81.937,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.537 | Acc: 51.688,81.960,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 51.780,81.957,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.332 | Acc: 46.094,71.094,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 47.210,66.443,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 46.532,65.396,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.414,64.780,67.239,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.269 | Acc: 56.250,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.523 | Acc: 51.190,82.106,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.537 | Acc: 51.315,82.203,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 51.883,81.749,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 52.103,81.752,94.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 52.197,81.962,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.521 | Acc: 52.098,82.076,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.514 | Acc: 52.189,82.059,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.517 | Acc: 52.184,82.031,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.514 | Acc: 52.275,82.066,94.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.512 | Acc: 52.387,82.109,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 52.333,82.176,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 52.305,82.106,94.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 52.278,82.085,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.532 | Acc: 52.085,82.037,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 52.014,82.055,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.533 | Acc: 51.969,82.104,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.531 | Acc: 51.977,82.116,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.532 | Acc: 51.980,82.077,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 52.026,82.048,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 47.656,71.875,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 47.545,66.369,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 46.913,65.206,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.652 | Acc: 46.747,64.754,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.075 | Acc: 59.375,90.625,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.545 | Acc: 52.567,82.143,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.585 | Acc: 51.391,81.574,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 51.550,82.018,94.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.548 | Acc: 51.524,81.944,94.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.545 | Acc: 51.648,82.155,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.535 | Acc: 51.801,82.290,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.540 | Acc: 51.684,82.281,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.540 | Acc: 51.708,82.269,94.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.531 | Acc: 51.981,82.381,94.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 52.083,82.311,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.532 | Acc: 52.001,82.353,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.531 | Acc: 51.968,82.352,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.530 | Acc: 51.886,82.346,95.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 52.024,82.340,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 52.079,82.327,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.526 | Acc: 52.086,82.292,95.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 52.126,82.281,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.526 | Acc: 52.032,82.224,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.527 | Acc: 52.079,82.187,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.363 | Acc: 46.875,70.312,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.061,66.257,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 46.532,65.130,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.678 | Acc: 46.465,64.600,67.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.605 | Acc: 46.094,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.508 | Acc: 52.493,82.217,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 52.973,82.203,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 52.536,81.890,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.511 | Acc: 52.595,81.877,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 52.143,81.969,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.521 | Acc: 52.118,81.896,94.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.525 | Acc: 52.133,81.915,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.532 | Acc: 52.048,81.852,94.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.531 | Acc: 52.266,81.846,94.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 52.293,81.779,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 52.252,81.925,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 52.259,82.012,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.530 | Acc: 52.311,81.959,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 52.302,81.970,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.531 | Acc: 52.245,81.951,94.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.531 | Acc: 52.227,81.973,94.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 52.229,82.024,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.526 | Acc: 52.244,82.079,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 52.235,82.136,94.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.339 | Acc: 45.312,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.321,66.406,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.608 | Acc: 46.970,65.396,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.709,64.741,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.779 | Acc: 49.219,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.528 | Acc: 51.562,81.882,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 52.268,81.841,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 52.600,81.698,95.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 51.919,81.588,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 52.003,81.590,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 51.963,81.579,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.543 | Acc: 51.917,81.616,94.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 52.048,81.784,94.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 52.184,81.751,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.542 | Acc: 52.099,81.759,94.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.547 | Acc: 52.146,81.667,94.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.542 | Acc: 52.133,81.707,94.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.539 | Acc: 52.104,81.723,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.540 | Acc: 52.043,81.775,94.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.536 | Acc: 52.017,81.888,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 52.098,81.849,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.540 | Acc: 52.044,81.807,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.541 | Acc: 52.000,81.823,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.541 | Acc: 52.010,81.822,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.399 | Acc: 46.094,71.875,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 46.801,66.369,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.635 | Acc: 46.227,65.244,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 46.235,64.703,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.938 | Acc: 46.094,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.572 | Acc: 50.893,81.250,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.588 | Acc: 51.315,81.326,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.560 | Acc: 51.806,81.673,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.561 | Acc: 51.813,81.559,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 52.096,81.915,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.537 | Acc: 52.299,81.921,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.530 | Acc: 52.427,82.026,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.526 | Acc: 52.300,81.968,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 52.219,81.932,94.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.531 | Acc: 52.215,81.872,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.528 | Acc: 52.202,81.946,94.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.526 | Acc: 52.201,81.992,94.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 52.278,82.016,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.530 | Acc: 52.202,81.959,94.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 52.144,81.881,94.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 52.049,81.910,94.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 52.016,81.869,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.534 | Acc: 51.974,81.854,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.533 | Acc: 51.969,81.843,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.359 | Acc: 43.750,71.875,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 46.763,66.518,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 46.475,65.282,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.679 | Acc: 46.491,64.805,67.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.165 | Acc: 60.156,87.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.525 | Acc: 52.195,81.808,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.549 | Acc: 52.287,81.136,94.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.564 | Acc: 51.934,81.340,94.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.544 | Acc: 52.083,81.472,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.549 | Acc: 52.166,81.320,94.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 52.215,81.437,94.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 52.105,81.588,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 52.324,81.769,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.532 | Acc: 52.374,81.781,94.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.532 | Acc: 52.289,81.751,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 52.365,81.798,94.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.522 | Acc: 52.532,81.798,94.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.521 | Acc: 52.496,81.810,94.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.519 | Acc: 52.513,81.853,94.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.516 | Acc: 52.580,81.876,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 52.531,81.878,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 52.451,81.850,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 52.378,81.910,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 52.372,81.882,94.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.362 | Acc: 45.312,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 46.949,66.443,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 46.513,65.415,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 46.491,64.831,67.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.523 | Acc: 47.656,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.567 | Acc: 50.372,80.618,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.571 | Acc: 50.629,81.079,94.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.565 | Acc: 50.717,81.045,94.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.567 | Acc: 50.810,81.125,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 51.106,81.296,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.542 | Acc: 51.491,81.476,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.533 | Acc: 51.612,81.688,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.535 | Acc: 51.820,81.730,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.538 | Acc: 51.804,81.699,94.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.535 | Acc: 51.835,81.748,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.532 | Acc: 51.845,81.784,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 51.935,81.782,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 51.964,81.909,94.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 51.938,81.917,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.531 | Acc: 51.877,81.876,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 51.893,81.907,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.526 | Acc: 51.998,82.004,94.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 52.006,82.044,94.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 52.012,82.101,94.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 45.312,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 47.210,66.332,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.623 | Acc: 46.894,65.225,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 46.721,64.703,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.273 | Acc: 57.812,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 53.051,82.106,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.528 | Acc: 52.477,81.974,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.500 | Acc: 52.613,82.441,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.469,82.523,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.382,82.681,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 52.234,82.864,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 52.166,82.569,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.500 | Acc: 52.125,82.531,95.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 52.098,82.709,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.173,82.564,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.354,82.611,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.224,82.556,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.497 | Acc: 52.332,82.540,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.501 | Acc: 52.291,82.501,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 52.289,82.467,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 52.263,82.467,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 52.234,82.393,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.513 | Acc: 52.194,82.358,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 52.221,82.318,95.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 45.312,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 46.726,66.183,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.638 | Acc: 46.494,65.187,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.695 | Acc: 46.350,64.690,67.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.414 | Acc: 59.375,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.513 | Acc: 52.344,83.110,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 52.325,82.603,95.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 52.190,82.467,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 52.247,82.533,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 52.290,82.341,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.526 | Acc: 52.047,82.147,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 51.984,82.297,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.514 | Acc: 52.057,82.395,94.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 52.141,82.342,94.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 52.157,82.323,94.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 52.213,82.272,94.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 52.130,82.154,94.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.522 | Acc: 52.056,82.061,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 51.935,82.015,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 52.009,82.031,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 51.935,82.077,94.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 51.947,82.125,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.518 | Acc: 51.939,82.170,94.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.522 | Acc: 51.983,82.107,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.352 | Acc: 45.312,69.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 46.987,66.555,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 46.494,65.244,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 46.376,64.690,67.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.783 | Acc: 45.312,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.459 | Acc: 51.265,83.705,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.498 | Acc: 51.372,83.346,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 51.550,82.748,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 51.698,82.456,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.519 | Acc: 51.880,82.565,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.995,82.373,94.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 52.100,82.447,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 52.227,82.516,94.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 52.387,82.575,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 52.352,82.552,95.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.505 | Acc: 52.365,82.586,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 52.305,82.404,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 52.284,82.396,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.509 | Acc: 52.322,82.295,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.505 | Acc: 52.375,82.322,95.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.507 | Acc: 52.319,82.262,95.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.506 | Acc: 52.298,82.299,95.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.508 | Acc: 52.277,82.284,95.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 52.174,82.263,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.412 | Acc: 45.312,67.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 47.061,66.034,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.623 | Acc: 46.913,65.282,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.686 | Acc: 46.734,64.652,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.577 | Acc: 50.781,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.552 | Acc: 50.372,81.808,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.555 | Acc: 51.105,81.631,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.557 | Acc: 51.486,81.455,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.545 | Acc: 51.775,81.578,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 52.112,81.668,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.550 | Acc: 52.002,81.534,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.554 | Acc: 51.900,81.505,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.552 | Acc: 51.863,81.614,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.535 | Acc: 52.080,81.846,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 51.947,81.864,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.539 | Acc: 51.909,81.890,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.543 | Acc: 51.864,81.782,94.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.543 | Acc: 51.817,81.792,94.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.539 | Acc: 51.863,81.862,94.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 51.947,81.891,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.528 | Acc: 52.001,81.961,94.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 52.067,81.969,94.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.526 | Acc: 52.036,81.992,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.525 | Acc: 52.059,82.013,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.410 | Acc: 46.094,69.531,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.542 | Acc: 47.582,66.332,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 46.932,65.492,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 46.747,64.972,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.484 | Acc: 55.469,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.570 | Acc: 51.042,81.473,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.540 | Acc: 51.944,81.917,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 52.049,82.300,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.502 | Acc: 52.257,82.369,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.511 | Acc: 51.949,82.263,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.497 | Acc: 52.111,82.470,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.496 | Acc: 52.227,82.502,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.495 | Acc: 52.193,82.497,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 52.404,82.459,95.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.215,82.397,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 52.199,82.311,95.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.321,82.342,95.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 52.365,82.325,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.504 | Acc: 52.244,82.348,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 52.268,82.353,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 52.205,82.314,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.505 | Acc: 52.160,82.260,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 52.168,82.252,95.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.506 | Acc: 52.133,82.283,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.419 | Acc: 46.094,70.312,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 47.098,66.295,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.632 | Acc: 46.627,65.434,67.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 46.542,64.703,66.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.682 | Acc: 54.688,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 54.278,81.808,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.492 | Acc: 53.239,81.955,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 53.048,82.172,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.472 | Acc: 53.231,82.350,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.469 | Acc: 53.009,82.387,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 52.905,82.690,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 52.909,82.591,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.475 | Acc: 52.766,82.788,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.482 | Acc: 52.598,82.670,95.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.479 | Acc: 52.662,82.754,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.483 | Acc: 52.619,82.717,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.590,82.761,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.475,82.669,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 52.408,82.635,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.502 | Acc: 52.445,82.501,95.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.505 | Acc: 52.383,82.474,95.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.424,82.508,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.501 | Acc: 52.391,82.559,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.508 | Acc: 52.217,82.460,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 46.875,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 47.135,66.295,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.623 | Acc: 46.780,65.187,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 46.734,64.626,67.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.281 | Acc: 57.031,86.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.428 | Acc: 53.125,82.626,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.444 | Acc: 53.163,82.717,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.465 | Acc: 52.715,82.608,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 52.633,82.523,94.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.469 | Acc: 52.932,82.534,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.712,82.515,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 52.698,82.336,95.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.491 | Acc: 52.538,82.245,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.494 | Acc: 52.529,82.247,95.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 52.558,82.222,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.495 | Acc: 52.591,82.296,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.500 | Acc: 52.412,82.255,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.501 | Acc: 52.218,82.349,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.506 | Acc: 52.219,82.276,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.511 | Acc: 52.170,82.249,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.512 | Acc: 52.110,82.236,95.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.510 | Acc: 52.147,82.265,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.181,82.267,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.508 | Acc: 52.196,82.335,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.372 | Acc: 46.094,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 47.024,66.146,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.625 | Acc: 46.608,65.149,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 46.478,64.639,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.460 | Acc: 53.125,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.527 | Acc: 51.674,82.254,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 51.696,82.565,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.480 | Acc: 52.293,83.094,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 52.228,83.063,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 52.181,82.944,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.492 | Acc: 52.234,82.806,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 52.017,82.812,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 52.116,83.007,95.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.491 | Acc: 52.141,82.964,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.493 | Acc: 52.149,82.984,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.121,82.954,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 51.968,82.936,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.083,82.935,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.499 | Acc: 51.966,82.807,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 51.926,82.849,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 52.005,82.776,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 51.993,82.783,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.498 | Acc: 52.032,82.732,95.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.496 | Acc: 52.022,82.755,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.379 | Acc: 45.312,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 47.247,66.146,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 46.951,65.415,67.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.674 | Acc: 46.824,64.664,67.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.098 | Acc: 58.594,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.528 | Acc: 52.269,82.552,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 52.744,82.012,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 52.293,81.852,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.516 | Acc: 52.710,82.186,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 52.359,82.024,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 52.331,82.218,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.519 | Acc: 52.277,82.336,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.513 | Acc: 52.378,82.366,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 52.391,82.351,95.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.505 | Acc: 52.433,82.389,95.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.507 | Acc: 52.344,82.318,95.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.510 | Acc: 52.285,82.229,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.383,82.286,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.504 | Acc: 52.416,82.332,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.501 | Acc: 52.440,82.397,95.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 52.332,82.394,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.504 | Acc: 52.305,82.379,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.503 | Acc: 52.290,82.397,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.500 | Acc: 52.249,82.396,95.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.381 | Acc: 44.531,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 47.247,66.220,67.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 46.742,65.244,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.663 | Acc: 46.657,64.703,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.484 | Acc: 52.344,79.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.484 | Acc: 52.195,82.589,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 52.229,82.622,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 52.088,82.121,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.238,82.224,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.503 | Acc: 51.787,82.178,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.496 | Acc: 52.111,82.386,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 52.122,82.375,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.023,82.419,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.500 | Acc: 51.994,82.476,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.501 | Acc: 51.943,82.373,95.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 52.061,82.410,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.501 | Acc: 52.117,82.352,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 51.970,82.393,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.506 | Acc: 52.010,82.420,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 51.973,82.434,95.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 51.952,82.413,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.966,82.366,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.509 | Acc: 51.991,82.347,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.506 | Acc: 52.081,82.310,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.382 | Acc: 46.875,69.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 47.024,66.369,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 46.627,65.206,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.681 | Acc: 46.580,64.600,67.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.197 | Acc: 54.688,90.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.490 | Acc: 52.455,83.445,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.520 | Acc: 52.077,82.393,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.506 | Acc: 51.883,82.659,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.987,82.388,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.497 | Acc: 52.150,82.495,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 52.008,82.393,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.498 | Acc: 52.133,82.364,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.500 | Acc: 52.208,82.458,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 52.249,82.407,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.500 | Acc: 52.219,82.432,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.506 | Acc: 52.206,82.367,95.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.504 | Acc: 52.159,82.436,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.504 | Acc: 52.011,82.465,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.505 | Acc: 52.027,82.479,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 52.040,82.498,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 52.081,82.460,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 52.053,82.398,95.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.502 | Acc: 52.162,82.408,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.194,82.454,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.322 | Acc: 46.094,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 47.470,66.146,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 47.008,65.396,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 46.875,64.818,66.931,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.291 | Acc: 56.250,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.443 | Acc: 53.981,82.589,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.438 | Acc: 53.373,82.698,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 52.818,82.454,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.720,82.272,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.375,82.472,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.497 | Acc: 52.157,82.432,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 52.072,82.624,95.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.501 | Acc: 52.237,82.604,95.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.499 | Acc: 52.210,82.605,95.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 51.994,82.610,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.507 | Acc: 51.927,82.583,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 52.003,82.553,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.009,82.513,95.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 52.032,82.446,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 51.900,82.511,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.505 | Acc: 51.974,82.542,95.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.094,82.597,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.499 | Acc: 52.151,82.559,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.118,82.593,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 44.531,69.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 47.656,66.481,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 47.123,65.434,67.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 46.926,64.831,67.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.528 | Acc: 57.031,85.156,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.453 | Acc: 52.158,83.147,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 52.268,82.565,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 52.190,82.877,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.492 | Acc: 52.296,82.706,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.996,82.619,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.504 | Acc: 52.111,82.548,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.493 | Acc: 52.166,82.524,95.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 52.290,82.628,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.214,82.648,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.485 | Acc: 52.223,82.692,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 52.312,82.728,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.198,82.825,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.218,82.801,95.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 52.185,82.735,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.496 | Acc: 52.063,82.636,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.052,82.664,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.495 | Acc: 52.133,82.654,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.088,82.598,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 52.155,82.616,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 45.312,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 47.433,66.406,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.625 | Acc: 46.951,65.358,67.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 46.760,64.767,66.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.437 | Acc: 51.562,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 51.600,83.408,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 51.372,83.155,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 52.024,83.030,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.512 | Acc: 51.813,82.706,95.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.514 | Acc: 51.965,82.480,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 51.898,82.477,95.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.528 | Acc: 51.707,82.275,95.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.528 | Acc: 51.878,82.245,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.524 | Acc: 51.804,82.390,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.518 | Acc: 51.951,82.447,94.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.508 | Acc: 52.057,82.604,95.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 52.058,82.501,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.508 | Acc: 52.122,82.507,95.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.511 | Acc: 52.035,82.532,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.509 | Acc: 52.141,82.581,95.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 52.156,82.525,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 52.128,82.489,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 52.153,82.449,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 52.133,82.396,95.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.333 | Acc: 46.875,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 47.247,66.295,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 47.027,65.282,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.673 | Acc: 46.824,64.741,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.677 | Acc: 48.438,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.470 | Acc: 52.269,82.924,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 52.572,82.470,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 52.677,82.646,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.492 | Acc: 52.633,82.427,95.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 52.228,82.426,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.496 | Acc: 52.266,82.444,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 52.194,82.325,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 52.286,82.444,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.502 | Acc: 52.270,82.424,95.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 52.332,82.482,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.333,82.519,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 52.376,82.514,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.338,82.489,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 52.277,82.443,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.496 | Acc: 52.253,82.418,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 52.234,82.357,95.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 52.193,82.336,95.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.498 | Acc: 52.184,82.336,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.500 | Acc: 52.116,82.316,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.374 | Acc: 44.531,71.875,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 47.396,66.406,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.617 | Acc: 46.894,65.282,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 46.773,64.728,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.488 | Acc: 50.000,88.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 53.423,81.659,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.525 | Acc: 52.668,81.841,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.503 | Acc: 52.446,82.121,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.525 | Acc: 52.035,81.916,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 51.949,81.799,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 51.692,81.857,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 51.618,82.148,95.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.527 | Acc: 51.601,82.128,95.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.520 | Acc: 51.696,82.174,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.772,82.229,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 51.768,82.272,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 51.721,82.232,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 51.601,82.241,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 51.654,82.276,95.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.512 | Acc: 51.840,82.369,95.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.507 | Acc: 51.913,82.387,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.507 | Acc: 51.989,82.373,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 51.950,82.371,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.504 | Acc: 52.028,82.390,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.345 | Acc: 45.312,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 47.359,66.034,68.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 47.104,65.130,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.682 | Acc: 46.913,64.536,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.527 | Acc: 50.781,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.526 | Acc: 52.083,83.036,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 52.306,82.851,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.531 | Acc: 51.652,82.236,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.360,81.809,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.431,81.853,95.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.534 | Acc: 51.343,81.889,95.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.521 | Acc: 51.646,81.865,95.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 51.757,81.760,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.520 | Acc: 51.718,82.070,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.827,82.148,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.852,82.105,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 52.062,82.235,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 52.224,82.322,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.511 | Acc: 52.096,82.281,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.511 | Acc: 52.074,82.306,95.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.507 | Acc: 52.113,82.374,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.503 | Acc: 52.222,82.379,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.503 | Acc: 52.160,82.373,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.502 | Acc: 52.145,82.390,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 46.094,71.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 46.987,66.406,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.622 | Acc: 46.589,65.511,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.679 | Acc: 46.644,64.818,66.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.627 | Acc: 53.125,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.443 | Acc: 53.051,84.189,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 52.001,82.736,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.503 | Acc: 51.895,82.480,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.501 | Acc: 51.890,82.861,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.918,82.619,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 52.073,82.561,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 51.989,82.469,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.500 | Acc: 52.019,82.541,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 52.171,82.670,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.490 | Acc: 52.118,82.727,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.135,82.629,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.214,82.631,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 52.251,82.639,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.493 | Acc: 52.280,82.596,95.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.490 | Acc: 52.315,82.584,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 52.254,82.562,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.243,82.560,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 52.242,82.471,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 52.221,82.470,95.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.340 | Acc: 44.531,72.656,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.561 | Acc: 47.359,66.295,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 46.780,65.396,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.673 | Acc: 46.632,64.728,67.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.800 | Acc: 42.188,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.470 | Acc: 52.753,82.738,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.464 | Acc: 52.954,83.003,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 52.626,82.812,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.484 | Acc: 52.556,82.735,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.514,82.666,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.497 | Acc: 52.460,82.503,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 52.571,82.657,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 52.465,82.507,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.481 | Acc: 52.629,82.502,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.480 | Acc: 52.655,82.579,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 52.542,82.576,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.493,82.521,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.475,82.555,95.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.524,82.529,95.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 52.624,82.485,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 52.650,82.482,95.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.495 | Acc: 52.561,82.425,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 52.515,82.462,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 52.465,82.482,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 45.312,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 47.545,66.183,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 47.123,65.301,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 46.875,64.600,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.425 | Acc: 48.438,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.503 | Acc: 51.897,82.180,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 51.925,82.279,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 51.703,82.608,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 51.630,82.504,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 51.949,82.550,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 51.931,82.419,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.496 | Acc: 51.906,82.402,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.507 | Acc: 51.752,82.288,95.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 51.627,82.446,95.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 51.866,82.470,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.503 | Acc: 51.859,82.459,95.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.500 | Acc: 52.033,82.475,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.284,82.654,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 52.144,82.618,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.183,82.615,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 52.207,82.657,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 52.154,82.634,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.487 | Acc: 52.155,82.650,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 52.130,82.632,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 45.312,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.554 | Acc: 47.507,66.443,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 47.046,65.587,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.939,64.997,67.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 3.073 | Acc: 46.875,77.344,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.563 | Acc: 52.753,81.436,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.526 | Acc: 52.268,82.431,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 52.293,82.364,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.497 | Acc: 52.556,82.427,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.502 | Acc: 52.522,82.488,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 52.299,82.354,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.511 | Acc: 52.477,82.441,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 52.344,82.356,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 52.482,82.402,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 52.472,82.373,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 52.563,82.402,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 52.564,82.300,95.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 52.484,82.289,95.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 52.449,82.243,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.497 | Acc: 52.487,82.317,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.502 | Acc: 52.436,82.260,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.502 | Acc: 52.390,82.347,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 52.389,82.291,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.504 | Acc: 52.348,82.370,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 45.312,69.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 47.173,65.997,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 46.837,65.034,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 46.760,64.447,67.239,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.384 | Acc: 50.781,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.551 | Acc: 52.679,82.217,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.518 | Acc: 52.458,82.165,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.505 | Acc: 52.369,82.454,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 52.537,82.649,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 52.375,82.565,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 52.537,82.696,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 52.571,82.824,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.476 | Acc: 52.315,82.754,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.477 | Acc: 52.335,82.700,95.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 52.258,82.688,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 52.146,82.629,95.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 52.104,82.582,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 52.104,82.534,95.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 52.069,82.551,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.502 | Acc: 52.004,82.537,95.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 52.013,82.503,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 52.060,82.512,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.492 | Acc: 52.192,82.607,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 52.163,82.573,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.397 | Acc: 45.312,70.312,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.558 | Acc: 47.247,66.257,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 46.875,65.282,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 46.785,64.664,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.494 | Acc: 50.781,85.938,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.499 | Acc: 52.418,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 51.982,82.641,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.500 | Acc: 51.895,82.403,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 52.411,82.687,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.328,82.426,95.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.490 | Acc: 52.240,82.425,95.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.377,82.391,95.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.492 | Acc: 52.310,82.313,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 52.314,82.407,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.184,82.389,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 52.068,82.378,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 51.977,82.346,95.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.509 | Acc: 51.895,82.337,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.507 | Acc: 51.977,82.370,95.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.506 | Acc: 51.931,82.335,95.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 52.022,82.345,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.000,82.370,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 51.978,82.477,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 52.016,82.505,95.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 46.094,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.559 | Acc: 47.656,66.220,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.612 | Acc: 47.199,65.396,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.675 | Acc: 46.990,64.639,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.291 | Acc: 46.875,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 53.013,82.738,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.484 | Acc: 53.049,82.698,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 52.946,82.544,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 52.951,82.764,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 52.607,82.735,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 52.634,82.664,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.503 | Acc: 52.333,82.724,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.504 | Acc: 52.218,82.652,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.498 | Acc: 52.331,82.705,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 52.421,82.739,95.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.393,82.735,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.259,82.712,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.487 | Acc: 52.332,82.579,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.208,82.562,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.250,82.535,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.293,82.450,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 52.218,82.418,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 52.223,82.334,95.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 52.186,82.314,95.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 45.312,71.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.396,66.109,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.615 | Acc: 47.066,65.244,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.676 | Acc: 46.913,64.664,67.188,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.484 | Acc: 52.344,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.459 | Acc: 53.125,83.668,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.462 | Acc: 52.782,83.518,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 52.779,83.158,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.296,82.639,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 52.382,82.480,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.492 | Acc: 52.492,82.490,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 52.344,82.353,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.281,82.225,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 52.288,82.109,95.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 52.278,82.156,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.502 | Acc: 52.287,82.169,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 52.373,82.197,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.335,82.280,95.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 52.352,82.368,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.492 | Acc: 52.336,82.428,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 52.312,82.435,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.321,82.476,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.491 | Acc: 52.300,82.434,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 52.295,82.425,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.406 | Acc: 46.094,72.656,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 47.247,66.369,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.638 | Acc: 46.951,65.396,67.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.697 | Acc: 46.785,64.690,66.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.651 | Acc: 48.438,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.604 | Acc: 51.116,80.729,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.561 | Acc: 51.772,81.383,94.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.549 | Acc: 51.562,81.724,94.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 52.276,82.089,94.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.505 | Acc: 52.305,82.178,94.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.503 | Acc: 52.421,82.277,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 52.521,82.197,95.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.514 | Acc: 52.145,82.245,94.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.518 | Acc: 52.106,82.256,94.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 52.122,82.253,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.511 | Acc: 52.064,82.229,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 51.981,82.148,95.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.513 | Acc: 51.964,82.163,95.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 51.916,82.209,95.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 51.900,82.252,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 51.959,82.292,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.502 | Acc: 52.018,82.320,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 52.062,82.360,95.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 52.044,82.347,95.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.371 | Acc: 45.312,71.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.567 | Acc: 47.396,66.295,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 46.627,65.320,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 46.376,64.652,66.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.377 | Acc: 54.688,84.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.460 | Acc: 53.162,83.147,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.460 | Acc: 52.877,83.136,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 52.177,82.902,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 52.411,82.957,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 52.297,82.681,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.182,82.587,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.496 | Acc: 52.155,82.447,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 51.970,82.473,95.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.506 | Acc: 51.934,82.484,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 51.955,82.381,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 52.011,82.420,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 52.023,82.414,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.089,82.408,95.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 52.060,82.459,95.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 52.027,82.444,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.018,82.489,95.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.495 | Acc: 52.064,82.471,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 52.039,82.499,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.040,82.495,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 46.094,73.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 47.284,66.332,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.640 | Acc: 46.646,65.168,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.702 | Acc: 46.337,64.664,67.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.700 | Acc: 52.344,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 52.827,82.329,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.494 | Acc: 52.858,82.698,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.481 | Acc: 52.856,83.043,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.392,82.832,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.500 | Acc: 52.189,82.712,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.507 | Acc: 52.228,82.503,95.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.506 | Acc: 52.355,82.619,95.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.516 | Acc: 52.121,82.468,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.520 | Acc: 51.856,82.502,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 51.835,82.408,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 52.008,82.480,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.515 | Acc: 52.020,82.391,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 52.146,82.334,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.509 | Acc: 52.144,82.379,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.501 | Acc: 52.219,82.392,95.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 52.237,82.440,95.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 52.300,82.535,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.303,82.486,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 52.290,82.515,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 46.875,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.546 | Acc: 47.470,66.518,68.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 47.161,65.434,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.675 | Acc: 46.952,64.741,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.685 | Acc: 49.219,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 52.344,81.771,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.484 | Acc: 52.439,81.860,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 52.818,82.415,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.471 | Acc: 52.431,82.417,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 52.483,82.542,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 52.434,82.561,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 52.366,82.463,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.281,82.284,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.473,82.390,95.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 52.624,82.381,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 52.524,82.360,95.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 52.353,82.297,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.290,82.322,95.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.313,82.337,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 52.377,82.309,95.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.431,82.340,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.412,82.366,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.394,82.347,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.370,82.312,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.346 | Acc: 45.312,72.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 47.396,66.295,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 46.856,65.415,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 46.709,64.741,67.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.534 | Acc: 46.094,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 51.823,82.589,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 52.191,82.203,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 51.947,82.889,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 51.968,82.350,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.494 | Acc: 51.957,82.333,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 52.014,82.406,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 52.144,82.502,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 52.256,82.424,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.322,82.385,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.491 | Acc: 52.355,82.331,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 52.308,82.353,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.491 | Acc: 52.305,82.398,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.323,82.378,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 52.330,82.354,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.500 | Acc: 52.354,82.389,95.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.351,82.501,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.314,82.455,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 52.376,82.490,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.350,82.497,95.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.387 | Acc: 45.312,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 47.247,66.629,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 46.761,65.473,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.677 | Acc: 46.580,64.933,67.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.650 | Acc: 50.781,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 53.051,82.366,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.437 | Acc: 53.011,83.194,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.465 | Acc: 52.318,82.633,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.473 | Acc: 52.546,82.359,95.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.475 | Acc: 52.823,82.232,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 52.847,82.277,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.538,82.402,95.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 52.620,82.400,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.491,82.333,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 52.655,82.416,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 52.485,82.169,95.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.489 | Acc: 52.418,82.197,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 52.350,82.247,95.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.363,82.304,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.492 | Acc: 52.346,82.376,95.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 52.293,82.343,95.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.371,82.322,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.320,82.252,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.496 | Acc: 52.284,82.292,95.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.353 | Acc: 45.312,70.312,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.570 | Acc: 47.284,66.183,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 46.684,65.130,67.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 46.542,64.472,66.931,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.352 | Acc: 51.562,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.498 | Acc: 51.674,81.920,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 51.620,83.003,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.511 | Acc: 51.396,82.556,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 51.707,82.282,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.532 | Acc: 51.756,82.016,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.528 | Acc: 51.853,82.012,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.530 | Acc: 51.884,81.992,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 52.043,82.128,95.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.521 | Acc: 51.973,82.221,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 52.126,82.276,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.511 | Acc: 52.110,82.353,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.514 | Acc: 52.026,82.304,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.512 | Acc: 52.009,82.316,95.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 52.032,82.343,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 52.009,82.384,95.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 52.142,82.496,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 52.108,82.542,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 52.171,82.616,95.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 52.229,82.599,95.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.360 | Acc: 45.312,71.875,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 47.507,66.629,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 47.027,65.530,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 46.734,64.857,67.123,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.873 | Acc: 48.438,78.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.538 | Acc: 51.935,81.064,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.515 | Acc: 52.039,81.726,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 52.549,81.916,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.524 | Acc: 51.813,81.954,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.511 | Acc: 51.825,82.418,95.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.506 | Acc: 51.834,82.477,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.504 | Acc: 51.973,82.425,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 52.009,82.502,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 52.033,82.489,95.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.502 | Acc: 52.118,82.486,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.132,82.530,95.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.503 | Acc: 52.049,82.462,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.504 | Acc: 52.050,82.480,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.063,82.504,95.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.502 | Acc: 52.141,82.434,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.502 | Acc: 52.086,82.523,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.167,82.538,95.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.503 | Acc: 52.119,82.518,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 52.102,82.445,95.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 46.094,71.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.284,66.406,67.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 47.104,65.396,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.674 | Acc: 46.849,64.793,67.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.499 | Acc: 53.125,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 53.125,82.515,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.452 | Acc: 52.344,82.889,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.468 | Acc: 52.177,82.672,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.485 | Acc: 52.238,82.494,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.494 | Acc: 52.212,82.658,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 52.260,82.709,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.491 | Acc: 52.189,82.713,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 52.300,82.774,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.296,82.800,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.491 | Acc: 52.278,82.684,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.135,82.650,95.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.178,82.637,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.116,82.507,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 52.132,82.540,95.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.497 | Acc: 52.108,82.491,95.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 52.110,82.428,95.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.496 | Acc: 52.177,82.464,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.499 | Acc: 52.184,82.416,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.500 | Acc: 52.198,82.392,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 45.312,73.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 47.173,66.146,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.627 | Acc: 46.742,65.149,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 46.632,64.524,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.571 | Acc: 51.562,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 52.307,83.371,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 52.382,83.136,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.452 | Acc: 52.600,82.736,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.461 | Acc: 52.363,82.812,95.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 52.638,82.898,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.459 | Acc: 52.705,82.864,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 52.582,82.779,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 52.586,82.672,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.352,82.433,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 52.379,82.369,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 52.315,82.339,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.486 | Acc: 52.315,82.381,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 52.332,82.426,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 52.349,82.429,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 52.398,82.447,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 52.315,82.489,95.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 52.220,82.453,95.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.490 | Acc: 52.171,82.471,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.260,82.521,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.345 | Acc: 46.094,73.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.564 | Acc: 47.210,66.481,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 46.970,65.454,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.689 | Acc: 46.747,64.703,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.696 | Acc: 53.906,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.543 | Acc: 52.344,81.920,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.508 | Acc: 52.439,82.660,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.510 | Acc: 52.344,82.351,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.500 | Acc: 52.720,82.581,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 52.506,82.372,95.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.512 | Acc: 52.512,82.593,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 52.571,82.796,95.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.497 | Acc: 52.586,82.793,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 52.391,82.730,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.484,82.746,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.501 | Acc: 52.446,82.657,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.504 | Acc: 52.454,82.569,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.501 | Acc: 52.544,82.651,95.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.488,82.637,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 52.512,82.696,95.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.495 | Acc: 52.487,82.730,95.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 52.433,82.654,95.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 52.426,82.600,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 52.327,82.552,95.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.434 | Acc: 46.094,71.875,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 47.061,66.555,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 46.589,65.396,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 46.516,64.703,67.136,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.854 | Acc: 47.656,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.561 | Acc: 51.972,81.808,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.542 | Acc: 52.363,81.784,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 52.126,81.903,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.491 | Acc: 52.296,82.591,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.499 | Acc: 52.421,82.457,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.486 | Acc: 52.486,82.780,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.491 | Acc: 52.443,82.547,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.353,82.691,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 52.387,82.700,95.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.320,82.641,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.383,82.629,95.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.396,82.608,95.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.500 | Acc: 52.422,82.618,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.313,82.632,95.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.499 | Acc: 52.341,82.659,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 52.229,82.718,95.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.502 | Acc: 52.142,82.696,95.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.501 | Acc: 52.192,82.724,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.503 | Acc: 52.155,82.671,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 46.094,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 47.210,66.295,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 46.780,65.320,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 46.670,64.677,67.111,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.563 | Acc: 46.875,86.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.508 | Acc: 51.525,82.664,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 52.039,82.832,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.488 | Acc: 51.947,82.761,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.511 | Acc: 51.775,82.591,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.511 | Acc: 51.709,82.588,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 52.008,82.729,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.506 | Acc: 52.083,82.574,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 52.048,82.599,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.506 | Acc: 51.873,82.631,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 51.978,82.708,95.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.114,82.692,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 52.110,82.702,95.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.497 | Acc: 52.203,82.633,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 52.238,82.626,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.496 | Acc: 52.092,82.558,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.078,82.550,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 52.057,82.512,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.498 | Acc: 52.058,82.484,95.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.500 | Acc: 51.995,82.456,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.406 | Acc: 45.312,70.312,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.574 | Acc: 46.912,66.369,67.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.632 | Acc: 46.761,65.415,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.691 | Acc: 46.619,64.741,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.384 | Acc: 51.562,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.491 | Acc: 51.897,82.775,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.506 | Acc: 51.543,82.527,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.500 | Acc: 51.550,82.467,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.498 | Acc: 51.958,82.571,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.494 | Acc: 52.081,82.565,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 51.963,82.541,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.499 | Acc: 51.762,82.524,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 51.761,82.483,95.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.796,82.627,95.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 51.994,82.649,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.036,82.802,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.052,82.715,95.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.062,82.699,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 52.124,82.612,95.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.198,82.594,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 52.290,82.696,95.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.215,82.629,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 52.246,82.629,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.494 | Acc: 52.268,82.624,95.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 46.094,70.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.562 | Acc: 46.912,66.332,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 46.532,65.320,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 46.491,64.754,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.504 | Acc: 57.812,82.812,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 51.451,82.812,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 52.001,82.508,94.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 51.601,82.595,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.804,82.677,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 51.779,82.580,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.509 | Acc: 51.840,82.574,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 51.745,82.475,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.513 | Acc: 51.873,82.526,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 52.046,82.545,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.505 | Acc: 52.079,82.560,95.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.503 | Acc: 52.125,82.505,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 52.208,82.479,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 52.284,82.483,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.506 | Acc: 52.324,82.407,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 52.442,82.452,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.500 | Acc: 52.310,82.506,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.494 | Acc: 52.364,82.522,95.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.494 | Acc: 52.415,82.464,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 52.346,82.456,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.392 | Acc: 45.312,71.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 47.321,66.443,67.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.632 | Acc: 46.932,65.301,67.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.691 | Acc: 46.837,64.703,67.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 3.018 | Acc: 51.562,75.000,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 52.232,81.920,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 52.096,82.279,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.512 | Acc: 52.075,82.351,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.513 | Acc: 52.045,82.137,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 52.119,82.287,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.515 | Acc: 52.176,82.251,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 52.033,82.281,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.511 | Acc: 52.203,82.337,95.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 52.227,82.390,95.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 52.317,82.389,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.499 | Acc: 52.351,82.427,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.500 | Acc: 52.341,82.394,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.499 | Acc: 52.281,82.417,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 52.291,82.443,95.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.258,82.491,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 52.239,82.516,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 52.259,82.524,95.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 52.307,82.520,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 52.245,82.540,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 44.531,71.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 47.507,66.109,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 46.894,65.187,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 46.824,64.549,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.546 | Acc: 51.562,78.125,93.750,% | Adaptive Acc: 83.594% | clf_exit: 0.367 0.477 0.156
Batch: 20 | Loss: 2.489 | Acc: 51.042,81.771,95.312,% | Adaptive Acc: 85.714% | clf_exit: 0.374 0.431 0.196
Batch: 40 | Loss: 2.503 | Acc: 50.819,82.088,95.408,% | Adaptive Acc: 86.052% | clf_exit: 0.362 0.443 0.195
Batch: 60 | Loss: 2.493 | Acc: 51.460,82.198,95.517,% | Adaptive Acc: 86.219% | clf_exit: 0.360 0.446 0.194
Batch: 80 | Loss: 2.484 | Acc: 51.919,82.186,95.592,% | Adaptive Acc: 86.343% | clf_exit: 0.360 0.444 0.196
Batch: 100 | Loss: 2.499 | Acc: 52.065,82.078,95.459,% | Adaptive Acc: 86.402% | clf_exit: 0.362 0.442 0.196
Batch: 120 | Loss: 2.500 | Acc: 51.872,81.973,95.416,% | Adaptive Acc: 86.331% | clf_exit: 0.362 0.442 0.196
Batch: 140 | Loss: 2.495 | Acc: 51.851,82.170,95.434,% | Adaptive Acc: 86.425% | clf_exit: 0.360 0.444 0.196
Batch: 160 | Loss: 2.498 | Acc: 51.975,82.308,95.322,% | Adaptive Acc: 86.520% | clf_exit: 0.361 0.445 0.194
Batch: 180 | Loss: 2.499 | Acc: 52.093,82.316,95.278,% | Adaptive Acc: 86.438% | clf_exit: 0.360 0.446 0.194
Batch: 200 | Loss: 2.498 | Acc: 51.990,82.369,95.312,% | Adaptive Acc: 86.423% | clf_exit: 0.361 0.446 0.193
Batch: 220 | Loss: 2.499 | Acc: 51.980,82.392,95.305,% | Adaptive Acc: 86.510% | clf_exit: 0.360 0.447 0.193
Batch: 240 | Loss: 2.497 | Acc: 52.058,82.391,95.293,% | Adaptive Acc: 86.508% | clf_exit: 0.360 0.447 0.193
Batch: 260 | Loss: 2.503 | Acc: 52.029,82.340,95.295,% | Adaptive Acc: 86.467% | clf_exit: 0.360 0.446 0.194
Batch: 280 | Loss: 2.503 | Acc: 52.049,82.418,95.287,% | Adaptive Acc: 86.510% | clf_exit: 0.359 0.448 0.193
Batch: 300 | Loss: 2.500 | Acc: 52.043,82.472,95.287,% | Adaptive Acc: 86.480% | clf_exit: 0.360 0.447 0.193
Batch: 320 | Loss: 2.500 | Acc: 52.035,82.447,95.274,% | Adaptive Acc: 86.451% | clf_exit: 0.360 0.446 0.193
Batch: 340 | Loss: 2.503 | Acc: 52.062,82.460,95.267,% | Adaptive Acc: 86.425% | clf_exit: 0.360 0.446 0.193
Batch: 360 | Loss: 2.505 | Acc: 52.106,82.408,95.280,% | Adaptive Acc: 86.405% | clf_exit: 0.359 0.447 0.193
Batch: 380 | Loss: 2.500 | Acc: 52.174,82.470,95.333,% | Adaptive Acc: 86.501% | clf_exit: 0.360 0.448 0.193
Batch: 0 | Loss: 4.358 | Acc: 46.094,71.094,68.750,% | Adaptive Acc: 66.406% | clf_exit: 0.430 0.398 0.172
Batch: 20 | Loss: 4.582 | Acc: 46.949,66.555,68.006,% | Adaptive Acc: 64.211% | clf_exit: 0.414 0.376 0.209
Batch: 40 | Loss: 4.641 | Acc: 46.723,65.492,67.416,% | Adaptive Acc: 63.338% | clf_exit: 0.410 0.373 0.217
Batch: 60 | Loss: 4.701 | Acc: 46.670,64.831,67.072,% | Adaptive Acc: 63.012% | clf_exit: 0.405 0.375 0.220
model is save as models/resnet56_h12_cifar100_adaptive0_circles6_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 67.109 | Acc: 0.781,0.000,1.562,% | Adaptive Acc: 0.781% | clf_exit: 0.961 0.031 0.008
Batch: 20 | Loss: 64.328 | Acc: 2.232,2.232,1.228,% | Adaptive Acc: 2.195% | clf_exit: 0.977 0.021 0.002
Batch: 40 | Loss: 64.624 | Acc: 2.191,2.134,1.143,% | Adaptive Acc: 2.191% | clf_exit: 0.977 0.019 0.004
Batch: 60 | Loss: 64.547 | Acc: 2.100,2.075,1.089,% | Adaptive Acc: 2.113% | clf_exit: 0.975 0.022 0.003
Batch: 0 | Loss: 44.128 | Acc: 3.906,2.344,3.125,% | Adaptive Acc: 3.906% | clf_exit: 0.742 0.250 0.008
Batch: 20 | Loss: 42.756 | Acc: 4.911,3.237,4.315,% | Adaptive Acc: 5.208% | clf_exit: 0.809 0.183 0.007
Batch: 40 | Loss: 43.017 | Acc: 4.745,3.106,4.535,% | Adaptive Acc: 4.916% | clf_exit: 0.820 0.172 0.007
Batch: 60 | Loss: 42.877 | Acc: 4.623,3.138,4.444,% | Adaptive Acc: 4.790% | clf_exit: 0.822 0.170 0.008
Batch: 0 | Loss: 40.777 | Acc: 3.125,2.344,1.562,% | Adaptive Acc: 3.906% | clf_exit: 0.844 0.141 0.016
Batch: 20 | Loss: 39.840 | Acc: 5.022,3.832,3.683,% | Adaptive Acc: 5.543% | clf_exit: 0.799 0.183 0.017
Batch: 40 | Loss: 40.032 | Acc: 4.878,3.830,3.963,% | Adaptive Acc: 5.316% | clf_exit: 0.790 0.195 0.016
Batch: 60 | Loss: 39.971 | Acc: 4.790,3.637,3.893,% | Adaptive Acc: 5.072% | clf_exit: 0.786 0.199 0.014
Batch: 0 | Loss: 33.573 | Acc: 7.031,3.906,3.125,% | Adaptive Acc: 7.812% | clf_exit: 0.719 0.266 0.016
Batch: 20 | Loss: 32.830 | Acc: 6.064,5.766,5.283,% | Adaptive Acc: 6.994% | clf_exit: 0.747 0.213 0.040
Batch: 40 | Loss: 33.007 | Acc: 5.945,5.564,5.450,% | Adaptive Acc: 6.803% | clf_exit: 0.743 0.221 0.036
Batch: 60 | Loss: 32.985 | Acc: 6.045,5.353,5.277,% | Adaptive Acc: 6.673% | clf_exit: 0.738 0.225 0.036
Batch: 0 | Loss: 20.341 | Acc: 7.812,12.500,17.969,% | Adaptive Acc: 16.406% | clf_exit: 0.586 0.250 0.164
Batch: 20 | Loss: 20.063 | Acc: 10.082,13.876,15.848,% | Adaptive Acc: 13.728% | clf_exit: 0.616 0.250 0.135
Batch: 40 | Loss: 20.216 | Acc: 9.928,13.262,15.301,% | Adaptive Acc: 13.338% | clf_exit: 0.605 0.263 0.133
Batch: 60 | Loss: 20.211 | Acc: 10.233,13.204,15.356,% | Adaptive Acc: 13.473% | clf_exit: 0.600 0.268 0.132
Batch: 0 | Loss: 8.150 | Acc: 25.000,47.656,61.719,% | Adaptive Acc: 45.312% | clf_exit: 0.469 0.336 0.195
Batch: 20 | Loss: 7.841 | Acc: 25.632,46.726,55.208,% | Adaptive Acc: 43.192% | clf_exit: 0.461 0.311 0.228
Batch: 40 | Loss: 7.924 | Acc: 24.600,46.132,55.107,% | Adaptive Acc: 42.111% | clf_exit: 0.462 0.300 0.237
Batch: 60 | Loss: 7.976 | Acc: 24.385,45.428,54.457,% | Adaptive Acc: 41.726% | clf_exit: 0.458 0.308 0.234
Batch: 0 | Loss: 4.358 | Acc: 46.094,71.094,68.750,% | Adaptive Acc: 66.406% | clf_exit: 0.430 0.398 0.172
Batch: 20 | Loss: 4.582 | Acc: 46.949,66.555,68.006,% | Adaptive Acc: 64.211% | clf_exit: 0.414 0.376 0.209
Batch: 40 | Loss: 4.641 | Acc: 46.723,65.492,67.416,% | Adaptive Acc: 63.338% | clf_exit: 0.410 0.373 0.217
Batch: 60 | Loss: 4.701 | Acc: 46.670,64.831,67.072,% | Adaptive Acc: 63.012% | clf_exit: 0.405 0.375 0.220







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.886 |  Acc: 1.594,1.926,1.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 14.529 |  Acc: 2.000,2.050,1.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 13.467 |  Acc: 2.136,2.958,1.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 13.535 |  Acc: 2.130,3.190,1.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 13.098 |  Acc: 2.640,5.444,1.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 13.058 |  Acc: 2.170,6.380,1.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 12.778 |  Acc: 2.842,8.310,1.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 12.836 |  Acc: 2.590,7.060,2.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 12.510 |  Acc: 3.634,10.412,1.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 12.591 |  Acc: 2.460,10.200,1.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 12.225 |  Acc: 5.092,11.926,1.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 12.840 |  Acc: 5.150,6.980,1.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 11.970 |  Acc: 6.956,13.646,2.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 12.077 |  Acc: 7.390,11.770,2.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 11.767 |  Acc: 8.580,15.754,2.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 12.203 |  Acc: 7.870,12.170,2.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 11.421 |  Acc: 9.944,18.162,2.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 11.887 |  Acc: 9.000,13.100,2.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 11.173 |  Acc: 11.050,20.014,2.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 11.440 |  Acc: 8.810,17.950,2.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 10.952 |  Acc: 12.262,21.728,2.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 11.133 |  Acc: 12.790,19.180,2.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 10.733 |  Acc: 14.082,23.926,2.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 11.147 |  Acc: 11.780,20.030,2.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 10.524 |  Acc: 16.014,25.382,2.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 11.651 |  Acc: 9.680,17.390,2.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 10.345 |  Acc: 17.334,26.910,2.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 10.788 |  Acc: 14.630,22.190,2.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 10.239 |  Acc: 18.398,28.138,2.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 11.719 |  Acc: 11.440,23.470,1.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 10.267 |  Acc: 19.634,29.804,2.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 10.861 |  Acc: 15.950,24.860,2.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 10.083 |  Acc: 21.066,30.700,2.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 11.307 |  Acc: 13.970,22.590,2.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 9.897 |  Acc: 22.868,32.820,2.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 10.299 |  Acc: 19.200,29.720,2.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 9.726 |  Acc: 24.430,34.332,2.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 10.458 |  Acc: 17.660,29.330,2.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 9.584 |  Acc: 25.506,35.926,2.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 12.659 |  Acc: 10.040,22.240,2.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 9.424 |  Acc: 26.708,37.206,4.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 11.117 |  Acc: 17.520,24.980,5.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 8.937 |  Acc: 28.018,38.654,10.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 10.975 |  Acc: 16.240,24.800,7.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 8.614 |  Acc: 29.092,40.010,12.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 9.342 |  Acc: 22.970,35.150,9.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 8.401 |  Acc: 29.726,40.358,13.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 10.017 |  Acc: 20.760,28.460,10.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 8.188 |  Acc: 29.974,41.760,15.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 9.177 |  Acc: 22.580,34.180,13.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 7.924 |  Acc: 30.666,42.314,20.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 9.678 |  Acc: 19.440,32.410,18.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 7.310 |  Acc: 31.172,43.048,33.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 8.961 |  Acc: 19.110,32.280,30.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 6.959 |  Acc: 31.722,43.548,39.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 7.958 |  Acc: 25.240,33.280,33.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 6.727 |  Acc: 31.752,44.822,42.952,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.549 |  Acc: 26.640,38.300,39.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 6.593 |  Acc: 32.326,45.634,44.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.791 |  Acc: 23.500,37.500,37.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 6.430 |  Acc: 32.738,46.948,46.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 8.585 |  Acc: 20.820,33.810,36.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 6.356 |  Acc: 32.944,47.816,47.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 7.895 |  Acc: 25.510,37.060,39.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 6.231 |  Acc: 33.546,48.758,48.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 9.420 |  Acc: 16.860,31.850,34.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 6.129 |  Acc: 34.166,49.634,50.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.454 |  Acc: 27.510,39.820,41.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 6.057 |  Acc: 34.188,50.124,50.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 7.835 |  Acc: 23.050,38.120,41.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.972 |  Acc: 34.692,51.054,51.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 6.708 |  Acc: 28.380,43.960,47.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.899 |  Acc: 34.974,51.668,52.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.809 |  Acc: 23.530,40.700,43.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.818 |  Acc: 35.442,52.254,53.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 7.836 |  Acc: 22.870,40.990,43.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.788 |  Acc: 35.360,52.608,53.726,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 6.512 |  Acc: 30.850,47.180,49.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.725 |  Acc: 35.752,53.044,54.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 7.244 |  Acc: 27.450,40.680,45.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.669 |  Acc: 36.180,53.640,54.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 8.238 |  Acc: 21.880,34.840,39.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.618 |  Acc: 36.286,53.896,55.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 7.016 |  Acc: 29.150,43.090,45.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.572 |  Acc: 36.608,54.342,55.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 6.678 |  Acc: 28.970,45.630,49.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.531 |  Acc: 36.834,54.698,56.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 7.405 |  Acc: 23.630,42.490,46.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.497 |  Acc: 37.074,55.238,57.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 6.779 |  Acc: 28.720,44.810,48.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.438 |  Acc: 37.142,55.700,57.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.433 |  Acc: 25.760,43.470,46.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.423 |  Acc: 37.156,55.702,57.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 7.922 |  Acc: 21.450,39.550,44.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.381 |  Acc: 37.472,56.070,57.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.759 |  Acc: 27.820,47.230,50.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.334 |  Acc: 37.394,56.606,58.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.361 |  Acc: 31.040,48.610,52.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.315 |  Acc: 37.830,56.766,58.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 7.805 |  Acc: 21.550,40.390,45.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.275 |  Acc: 37.984,57.188,59.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 6.613 |  Acc: 30.140,47.410,51.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.247 |  Acc: 38.228,57.328,60.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 7.417 |  Acc: 25.580,41.470,44.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 5.217 |  Acc: 38.300,57.668,60.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 7.550 |  Acc: 24.050,43.240,47.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 5.193 |  Acc: 38.638,57.730,60.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 7.753 |  Acc: 21.440,43.380,47.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 5.155 |  Acc: 38.556,58.226,60.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.652 |  Acc: 28.850,47.210,51.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 5.139 |  Acc: 38.558,58.304,60.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 6.687 |  Acc: 28.300,46.460,49.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 5.116 |  Acc: 39.048,58.124,60.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.417 |  Acc: 30.840,49.280,52.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 5.080 |  Acc: 39.004,58.544,61.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.539 |  Acc: 31.020,46.870,50.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 5.052 |  Acc: 39.158,59.072,61.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 6.347 |  Acc: 31.610,48.270,51.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 5.043 |  Acc: 39.186,59.138,61.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 7.362 |  Acc: 24.620,43.590,49.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 5.006 |  Acc: 39.642,59.368,62.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 6.384 |  Acc: 30.550,48.720,52.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.987 |  Acc: 39.618,59.744,62.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.306 |  Acc: 31.940,48.740,53.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.978 |  Acc: 39.548,59.540,62.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 8.487 |  Acc: 23.010,38.390,44.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.953 |  Acc: 39.510,59.784,62.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.769 |  Acc: 28.600,47.620,51.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.949 |  Acc: 39.888,59.860,63.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 7.430 |  Acc: 25.110,44.730,50.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.929 |  Acc: 39.744,60.042,63.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 6.236 |  Acc: 32.920,48.880,52.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.906 |  Acc: 39.840,60.108,63.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 6.389 |  Acc: 31.050,47.870,53.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.918 |  Acc: 39.834,60.002,63.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.698 |  Acc: 31.680,46.700,50.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.889 |  Acc: 40.016,60.180,63.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 6.276 |  Acc: 32.850,48.710,53.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.850 |  Acc: 40.262,60.430,64.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.610 |  Acc: 28.600,47.980,52.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.846 |  Acc: 40.398,60.450,64.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.627 |  Acc: 30.900,46.090,51.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.828 |  Acc: 40.330,60.802,64.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 6.229 |  Acc: 32.720,49.530,54.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.813 |  Acc: 40.412,60.758,64.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.504 |  Acc: 30.450,47.390,52.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.808 |  Acc: 40.274,61.012,64.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.970 |  Acc: 26.360,45.710,51.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.772 |  Acc: 40.484,61.204,65.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 7.032 |  Acc: 28.940,47.700,50.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.779 |  Acc: 40.420,61.098,65.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 7.421 |  Acc: 25.250,44.130,48.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.752 |  Acc: 40.570,61.210,65.006,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.341 |  Acc: 31.250,48.310,52.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.767 |  Acc: 40.452,61.238,65.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.746 |  Acc: 30.630,47.340,53.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.743 |  Acc: 40.450,61.584,65.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 7.596 |  Acc: 26.220,43.440,47.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.720 |  Acc: 40.590,61.800,65.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.211 |  Acc: 33.630,50.110,54.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.709 |  Acc: 40.816,61.758,65.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 6.207 |  Acc: 30.300,50.930,56.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.729 |  Acc: 40.676,61.230,65.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.882 |  Acc: 29.460,46.220,51.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.716 |  Acc: 40.604,61.700,65.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 7.017 |  Acc: 25.780,46.420,52.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.685 |  Acc: 40.852,62.092,66.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 7.020 |  Acc: 28.000,45.830,51.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.659 |  Acc: 41.076,62.090,66.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 6.720 |  Acc: 26.330,49.060,54.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.672 |  Acc: 40.818,62.048,66.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.190 |  Acc: 32.160,50.740,55.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.660 |  Acc: 40.902,62.026,66.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.320 |  Acc: 29.020,49.340,55.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.631 |  Acc: 41.358,62.234,66.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.660 |  Acc: 30.900,47.410,51.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.647 |  Acc: 40.856,62.182,66.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 7.325 |  Acc: 27.370,43.350,50.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.629 |  Acc: 41.176,62.308,66.728,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 7.075 |  Acc: 25.100,45.640,52.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.630 |  Acc: 41.180,62.342,66.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 6.905 |  Acc: 29.940,45.760,52.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.602 |  Acc: 41.452,62.496,67.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 6.800 |  Acc: 29.410,46.450,52.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.597 |  Acc: 41.466,62.632,67.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 6.213 |  Acc: 32.760,50.260,55.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.590 |  Acc: 41.500,62.422,67.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 6.296 |  Acc: 29.420,50.780,55.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.596 |  Acc: 41.486,62.406,67.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 5.810 |  Acc: 35.820,52.540,56.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.584 |  Acc: 41.298,62.616,67.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 7.300 |  Acc: 26.530,44.290,49.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.573 |  Acc: 41.386,63.028,67.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 5.956 |  Acc: 34.130,52.200,57.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.576 |  Acc: 41.452,62.842,67.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 5.816 |  Acc: 33.930,53.300,57.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.549 |  Acc: 41.682,63.122,67.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.107 |  Acc: 33.060,50.990,54.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.539 |  Acc: 41.772,63.014,68.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.208 |  Acc: 33.120,50.290,56.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.525 |  Acc: 41.456,63.356,68.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.131 |  Acc: 31.550,50.410,55.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.529 |  Acc: 41.776,63.140,67.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.268 |  Acc: 29.950,48.960,56.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.509 |  Acc: 41.694,63.294,68.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.069 |  Acc: 33.070,51.620,56.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.518 |  Acc: 41.720,63.340,68.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 7.028 |  Acc: 24.540,46.530,52.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.519 |  Acc: 41.618,63.500,68.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.723 |  Acc: 29.160,48.040,52.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.487 |  Acc: 41.708,63.740,68.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 6.449 |  Acc: 31.130,48.480,54.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.507 |  Acc: 41.634,63.412,68.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 5.972 |  Acc: 33.360,52.390,56.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.483 |  Acc: 41.754,63.394,68.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.931 |  Acc: 26.810,47.710,53.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.473 |  Acc: 41.742,63.808,68.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 6.241 |  Acc: 33.240,49.850,53.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.465 |  Acc: 41.846,63.874,68.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.077 |  Acc: 32.890,50.730,55.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.472 |  Acc: 41.984,63.674,68.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 5.859 |  Acc: 35.090,53.280,57.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.470 |  Acc: 41.908,63.722,68.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.498 |  Acc: 31.410,46.850,51.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.462 |  Acc: 42.044,63.752,68.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.965 |  Acc: 24.070,47.110,55.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.453 |  Acc: 42.030,63.750,69.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 8.723 |  Acc: 18.580,35.550,45.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.472 |  Acc: 42.004,63.564,68.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 6.243 |  Acc: 30.160,50.240,55.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.440 |  Acc: 41.954,63.830,69.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.534 |  Acc: 32.940,47.830,53.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.445 |  Acc: 42.170,64.066,69.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 6.379 |  Acc: 29.820,50.370,55.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.424 |  Acc: 42.106,63.970,69.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.440 |  Acc: 32.440,49.750,53.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.437 |  Acc: 41.920,63.912,69.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.006 |  Acc: 33.290,51.860,57.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.427 |  Acc: 42.018,63.934,69.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 7.080 |  Acc: 26.600,46.660,54.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.407 |  Acc: 42.302,64.484,69.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 6.631 |  Acc: 29.300,48.260,52.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.398 |  Acc: 42.722,64.400,69.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 6.862 |  Acc: 27.910,47.120,53.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.400 |  Acc: 42.156,63.988,69.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 6.975 |  Acc: 29.870,45.080,52.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.415 |  Acc: 42.216,64.106,69.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 6.824 |  Acc: 29.760,48.200,50.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.405 |  Acc: 42.212,64.230,69.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 7.484 |  Acc: 24.650,44.280,51.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.400 |  Acc: 42.216,64.124,69.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 6.214 |  Acc: 31.740,50.870,55.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.390 |  Acc: 42.114,64.282,69.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 6.637 |  Acc: 29.590,49.470,53.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.374 |  Acc: 42.414,64.556,69.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 5.801 |  Acc: 34.830,53.100,57.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.361 |  Acc: 42.486,64.530,70.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 6.117 |  Acc: 33.890,50.860,54.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.380 |  Acc: 42.192,64.066,70.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.583 |  Acc: 29.120,48.910,55.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.374 |  Acc: 42.440,64.240,70.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.819 |  Acc: 29.260,47.050,52.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.386 |  Acc: 42.476,64.320,69.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.706 |  Acc: 29.250,47.820,52.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.366 |  Acc: 42.432,64.396,69.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 7.450 |  Acc: 19.440,46.710,52.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.366 |  Acc: 42.236,64.548,70.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 6.737 |  Acc: 29.010,48.860,55.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.339 |  Acc: 42.498,64.682,70.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 7.180 |  Acc: 24.030,45.990,53.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.366 |  Acc: 42.452,64.370,70.494,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.417 |  Acc: 29.490,49.890,55.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.351 |  Acc: 42.550,64.672,70.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 6.730 |  Acc: 30.870,48.210,53.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.350 |  Acc: 42.496,64.816,70.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 6.596 |  Acc: 29.370,48.380,54.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.339 |  Acc: 42.754,64.504,70.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.484 |  Acc: 29.990,49.650,54.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.351 |  Acc: 42.312,64.520,70.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 5.985 |  Acc: 32.410,53.510,59.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.335 |  Acc: 42.742,64.692,70.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.616 |  Acc: 28.920,48.220,54.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.322 |  Acc: 42.700,64.800,70.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 6.030 |  Acc: 35.080,52.270,55.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.333 |  Acc: 42.528,64.574,70.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 6.437 |  Acc: 32.110,49.990,53.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.338 |  Acc: 42.632,64.660,70.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.837 |  Acc: 27.290,48.350,54.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.323 |  Acc: 42.628,64.796,70.636,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.553 |  Acc: 27.220,48.920,56.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.311 |  Acc: 42.504,64.930,70.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 6.580 |  Acc: 28.260,49.110,55.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.319 |  Acc: 42.836,64.980,70.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.183 |  Acc: 34.300,50.610,55.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.297 |  Acc: 42.902,64.818,70.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.941 |  Acc: 26.600,46.830,54.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.302 |  Acc: 42.842,64.822,71.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.499 |  Acc: 32.640,47.910,53.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.292 |  Acc: 43.108,64.872,70.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 7.329 |  Acc: 24.730,43.900,51.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.646 |  Acc: 46.852,71.620,78.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.464 |  Acc: 43.940,63.950,68.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.436 |  Acc: 48.086,73.936,81.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.436 |  Acc: 43.750,64.620,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.382 |  Acc: 48.174,74.344,82.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.375 |  Acc: 44.890,64.650,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.347 |  Acc: 48.304,74.606,82.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.400 |  Acc: 44.540,64.910,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.296 |  Acc: 48.744,74.906,83.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.368 |  Acc: 44.760,64.820,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.268 |  Acc: 48.644,75.344,84.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.386 |  Acc: 45.000,64.860,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.242 |  Acc: 49.016,75.430,84.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.375 |  Acc: 45.090,64.980,69.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.223 |  Acc: 48.618,75.638,84.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.403 |  Acc: 44.910,64.660,69.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.201 |  Acc: 48.870,75.872,84.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.447 |  Acc: 44.550,64.860,69.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.192 |  Acc: 49.144,75.820,85.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.391 |  Acc: 45.260,64.780,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.169 |  Acc: 49.172,75.924,85.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.382 |  Acc: 45.330,65.040,69.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.156 |  Acc: 48.990,75.918,85.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.410 |  Acc: 45.380,64.430,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.138 |  Acc: 49.058,76.224,86.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.411 |  Acc: 45.120,65.050,69.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.122 |  Acc: 49.272,76.458,86.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.429 |  Acc: 45.200,64.780,68.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.107 |  Acc: 49.518,76.560,86.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.586 |  Acc: 43.390,64.270,68.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.098 |  Acc: 49.334,76.572,86.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.453 |  Acc: 44.780,65.120,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.079 |  Acc: 49.324,76.596,86.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.493 |  Acc: 44.810,64.830,68.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.066 |  Acc: 49.438,76.646,87.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.449 |  Acc: 45.380,64.970,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.055 |  Acc: 49.560,76.998,87.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.490 |  Acc: 44.770,64.330,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.050 |  Acc: 49.616,77.078,87.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.492 |  Acc: 45.090,64.510,68.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.049 |  Acc: 49.712,76.698,87.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.557 |  Acc: 44.670,64.520,68.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 3.034 |  Acc: 49.672,77.050,87.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.495 |  Acc: 45.220,64.920,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 3.023 |  Acc: 49.602,77.094,87.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.538 |  Acc: 44.990,64.290,68.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 3.021 |  Acc: 49.616,77.184,87.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.530 |  Acc: 45.270,64.180,68.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 3.007 |  Acc: 49.758,77.208,87.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.487 |  Acc: 45.450,64.750,68.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 3.003 |  Acc: 49.916,77.286,87.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.527 |  Acc: 45.120,65.160,68.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.993 |  Acc: 49.670,77.524,88.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.558 |  Acc: 44.650,64.310,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.993 |  Acc: 49.596,77.348,88.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.521 |  Acc: 45.190,64.630,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.975 |  Acc: 49.984,77.460,88.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.546 |  Acc: 45.180,64.910,68.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.972 |  Acc: 49.802,77.618,88.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.489 |  Acc: 45.440,64.800,68.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.973 |  Acc: 49.744,77.332,88.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.512 |  Acc: 45.570,64.600,68.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.958 |  Acc: 49.948,77.526,88.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.508 |  Acc: 45.680,64.650,68.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.962 |  Acc: 49.934,77.530,88.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.576 |  Acc: 45.600,64.280,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.940 |  Acc: 50.128,77.854,88.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.660 |  Acc: 44.520,64.040,67.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.937 |  Acc: 49.958,77.756,88.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.635 |  Acc: 44.970,64.340,68.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.933 |  Acc: 49.896,77.734,88.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.603 |  Acc: 45.400,64.190,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.936 |  Acc: 49.962,77.866,88.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.607 |  Acc: 45.020,63.930,68.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.930 |  Acc: 49.844,77.802,88.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.579 |  Acc: 46.020,64.300,67.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.919 |  Acc: 50.086,77.962,88.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.697 |  Acc: 44.450,63.880,67.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.913 |  Acc: 50.250,78.016,89.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.565 |  Acc: 45.610,64.810,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.906 |  Acc: 50.406,78.054,89.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.677 |  Acc: 44.370,63.930,67.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.912 |  Acc: 49.968,77.710,89.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.668 |  Acc: 45.280,64.170,67.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.899 |  Acc: 50.200,77.988,89.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.782 |  Acc: 43.470,63.600,67.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.902 |  Acc: 50.310,77.866,89.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.706 |  Acc: 44.710,63.950,67.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.894 |  Acc: 50.034,78.202,89.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.721 |  Acc: 44.760,63.660,67.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.884 |  Acc: 50.082,78.158,89.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.722 |  Acc: 44.070,64.280,66.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.880 |  Acc: 50.232,78.222,89.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.703 |  Acc: 44.980,64.350,67.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.888 |  Acc: 50.202,78.098,89.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.721 |  Acc: 44.810,63.980,66.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.874 |  Acc: 50.034,78.454,89.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.758 |  Acc: 44.700,63.330,66.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.880 |  Acc: 50.142,78.200,89.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.754 |  Acc: 44.020,63.900,67.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.869 |  Acc: 50.282,78.290,89.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.757 |  Acc: 44.250,63.630,66.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.857 |  Acc: 50.488,78.500,89.822,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.668 |  Acc: 45.050,64.730,67.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.866 |  Acc: 50.232,78.348,89.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.867 |  Acc: 43.530,63.230,66.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.866 |  Acc: 50.272,78.162,89.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.738 |  Acc: 44.790,63.920,67.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.861 |  Acc: 50.194,78.170,89.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.749 |  Acc: 44.440,63.690,67.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.850 |  Acc: 50.252,78.530,90.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.786 |  Acc: 44.780,63.530,66.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.847 |  Acc: 50.620,78.564,89.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.773 |  Acc: 45.280,63.600,66.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.845 |  Acc: 50.458,78.544,90.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.862 |  Acc: 43.450,63.310,66.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.854 |  Acc: 50.332,78.400,89.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.730 |  Acc: 45.420,63.960,66.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.841 |  Acc: 50.370,78.758,89.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.739 |  Acc: 44.550,64.210,67.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.838 |  Acc: 50.316,78.688,90.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.829 |  Acc: 43.130,63.450,66.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.836 |  Acc: 50.358,78.382,89.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.823 |  Acc: 44.390,63.080,66.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.847 |  Acc: 50.312,78.362,90.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 5.000 |  Acc: 42.160,62.210,66.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.835 |  Acc: 50.464,78.670,90.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.819 |  Acc: 44.910,63.660,66.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.837 |  Acc: 50.436,78.654,90.278,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.797 |  Acc: 44.150,63.450,66.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.827 |  Acc: 50.446,78.618,90.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.692 |  Acc: 44.960,63.970,67.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.830 |  Acc: 50.640,78.640,90.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.869 |  Acc: 44.180,63.630,66.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.835 |  Acc: 50.246,78.384,90.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.775 |  Acc: 44.340,63.620,66.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.816 |  Acc: 50.162,78.872,90.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 5.009 |  Acc: 42.600,62.950,65.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.816 |  Acc: 50.416,78.700,90.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.810 |  Acc: 44.330,63.340,66.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.821 |  Acc: 50.540,78.864,90.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.808 |  Acc: 44.930,63.330,66.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.818 |  Acc: 50.432,78.924,90.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 5.026 |  Acc: 42.280,62.730,65.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.818 |  Acc: 50.598,78.788,90.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.776 |  Acc: 45.030,63.880,66.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.813 |  Acc: 50.360,78.784,90.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.910 |  Acc: 43.040,63.120,66.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.814 |  Acc: 50.718,78.824,90.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.843 |  Acc: 44.430,63.580,66.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.664 |  Acc: 51.390,80.554,92.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.584 |  Acc: 45.830,65.000,68.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.621 |  Acc: 51.618,81.236,93.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.568 |  Acc: 46.150,65.250,68.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.602 |  Acc: 51.620,81.310,93.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.591 |  Acc: 46.190,65.220,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.599 |  Acc: 51.418,81.166,93.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.567 |  Acc: 46.250,65.310,68.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.579 |  Acc: 51.698,81.560,94.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.577 |  Acc: 46.450,64.960,67.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.581 |  Acc: 51.712,81.574,93.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.588 |  Acc: 46.210,65.190,68.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.579 |  Acc: 51.912,81.650,94.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.574 |  Acc: 46.650,65.390,68.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.572 |  Acc: 51.624,81.718,94.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.598 |  Acc: 46.600,65.340,68.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.576 |  Acc: 51.772,81.536,94.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.612 |  Acc: 46.300,65.240,67.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.561 |  Acc: 51.940,81.816,94.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.608 |  Acc: 46.370,65.530,67.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.560 |  Acc: 52.040,81.672,94.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.592 |  Acc: 46.400,65.110,67.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.555 |  Acc: 51.852,81.984,94.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.612 |  Acc: 46.410,65.190,67.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.562 |  Acc: 51.824,81.740,94.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.615 |  Acc: 46.560,65.220,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.551 |  Acc: 51.760,82.018,94.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.624 |  Acc: 46.460,65.090,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.556 |  Acc: 52.052,81.814,94.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.599 |  Acc: 46.450,65.080,67.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.547 |  Acc: 51.766,82.002,94.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.625 |  Acc: 46.650,65.140,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.548 |  Acc: 51.922,81.860,94.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.626 |  Acc: 46.540,65.100,67.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.553 |  Acc: 52.010,81.954,94.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.622 |  Acc: 46.460,65.070,67.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.548 |  Acc: 51.800,81.814,94.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.640 |  Acc: 46.380,64.850,67.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.541 |  Acc: 51.904,81.978,94.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.615 |  Acc: 46.530,65.110,67.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.543 |  Acc: 51.944,81.764,94.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.626 |  Acc: 46.690,65.180,67.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.538 |  Acc: 51.936,81.954,94.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.644 |  Acc: 46.400,65.130,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.536 |  Acc: 51.918,82.134,94.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.638 |  Acc: 46.610,65.340,67.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.542 |  Acc: 51.980,81.990,94.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.610 |  Acc: 46.610,65.160,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.531 |  Acc: 52.278,82.152,94.976,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.630 |  Acc: 46.500,64.890,68.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.534 |  Acc: 51.816,81.994,94.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.632 |  Acc: 46.420,65.260,67.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.530 |  Acc: 52.064,82.062,94.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.622 |  Acc: 46.670,65.140,67.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.528 |  Acc: 52.096,82.196,94.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.646 |  Acc: 46.420,65.000,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.524 |  Acc: 52.184,82.134,94.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.631 |  Acc: 46.660,65.110,67.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.540 |  Acc: 51.972,81.836,94.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.650 |  Acc: 46.250,65.160,67.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.532 |  Acc: 51.986,81.858,94.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.650 |  Acc: 46.510,65.080,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.527 |  Acc: 52.390,81.902,94.854,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.646 |  Acc: 46.520,65.080,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.525 |  Acc: 51.960,82.092,94.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.648 |  Acc: 46.630,65.080,67.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.512 |  Acc: 52.228,82.302,95.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.664 |  Acc: 46.320,65.010,67.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.525 |  Acc: 51.990,82.078,94.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.648 |  Acc: 46.370,65.090,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.513 |  Acc: 52.128,82.260,95.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.653 |  Acc: 46.630,64.940,67.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.525 |  Acc: 52.006,82.030,94.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.634 |  Acc: 46.770,65.220,67.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.507 |  Acc: 52.078,82.288,95.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.659 |  Acc: 46.600,64.980,67.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.511 |  Acc: 52.184,82.452,95.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.652 |  Acc: 46.610,64.930,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.508 |  Acc: 52.166,82.304,95.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.648 |  Acc: 46.550,64.980,67.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.497 |  Acc: 52.050,82.736,95.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.640 |  Acc: 46.760,64.980,67.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.502 |  Acc: 52.228,82.396,95.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.628 |  Acc: 46.630,65.020,67.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.505 |  Acc: 52.116,82.300,95.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.648 |  Acc: 46.520,64.990,67.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.498 |  Acc: 52.166,82.434,95.270,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.630 |  Acc: 46.920,65.150,67.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.500 |  Acc: 52.052,82.580,95.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.629 |  Acc: 46.870,65.150,67.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.495 |  Acc: 52.098,82.638,95.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.653 |  Acc: 46.790,65.050,67.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.509 |  Acc: 52.112,82.346,95.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.642 |  Acc: 46.700,65.110,67.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.501 |  Acc: 52.096,82.308,95.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.645 |  Acc: 46.790,65.070,67.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.505 |  Acc: 52.052,82.354,95.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.650 |  Acc: 46.730,64.910,67.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.502 |  Acc: 52.116,82.366,95.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.647 |  Acc: 46.610,65.110,67.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.497 |  Acc: 52.222,82.512,95.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.644 |  Acc: 46.600,65.040,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.496 |  Acc: 52.436,82.470,95.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.652 |  Acc: 46.830,64.900,67.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.492 |  Acc: 52.118,82.664,95.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.629 |  Acc: 46.850,65.350,67.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.502 |  Acc: 52.384,82.386,95.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.657 |  Acc: 46.710,64.750,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.496 |  Acc: 52.140,82.564,95.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.651 |  Acc: 46.800,64.990,67.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.498 |  Acc: 52.058,82.488,95.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.644 |  Acc: 46.890,64.950,67.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.502 |  Acc: 52.124,82.304,95.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.644 |  Acc: 46.810,64.930,67.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.495 |  Acc: 52.300,82.366,95.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.663 |  Acc: 46.800,64.930,67.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.501 |  Acc: 52.038,82.316,95.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.648 |  Acc: 46.400,64.930,67.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.498 |  Acc: 52.034,82.546,95.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.669 |  Acc: 46.330,64.980,67.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.496 |  Acc: 52.266,82.490,95.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.644 |  Acc: 46.800,65.050,67.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.497 |  Acc: 52.342,82.316,95.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.659 |  Acc: 46.640,65.080,67.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.497 |  Acc: 52.348,82.472,95.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.644 |  Acc: 46.610,65.120,67.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.497 |  Acc: 52.246,82.346,95.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.662 |  Acc: 46.590,64.870,67.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.497 |  Acc: 52.236,82.572,95.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.651 |  Acc: 46.690,65.120,67.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.506 |  Acc: 52.142,82.454,95.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.642 |  Acc: 46.780,65.120,67.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.500 |  Acc: 52.202,82.420,95.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.652 |  Acc: 46.420,64.800,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.489 |  Acc: 52.254,82.514,95.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.659 |  Acc: 46.660,64.960,67.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.499 |  Acc: 52.328,82.536,95.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.651 |  Acc: 46.530,65.000,67.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.504 |  Acc: 52.188,82.618,95.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.654 |  Acc: 46.660,65.000,67.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.500 |  Acc: 51.988,82.464,95.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.658 |  Acc: 46.570,64.990,67.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.498 |  Acc: 52.256,82.562,95.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.642 |  Acc: 46.530,65.050,67.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.495 |  Acc: 52.328,82.468,95.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.655 |  Acc: 46.690,64.980,67.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.490 |  Acc: 52.252,82.544,95.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.649 |  Acc: 46.750,64.950,67.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=6, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.499 |  Acc: 52.192,82.472,95.310,% | Adaptive Acc:86.496% | clf_exit: 0.360 0.448 0.192
Testing: Epoch=299 | Loss: 4.665 |  Acc: 46.590,65.030,67.640,% | Adaptive Acc:63.490% | clf_exit: 0.404 0.379 0.217

circles: 0
Testing: Epoch=299 | Loss: 64.551 |  Acc: 2.060,2.070,1.000,% | Adaptive Acc:2.080% | clf_exit: 0.975 0.022 0.003
circles: 1
Testing: Epoch=299 | Loss: 42.865 |  Acc: 4.480,2.950,4.310,% | Adaptive Acc:4.690% | clf_exit: 0.821 0.171 0.008
circles: 2
Testing: Epoch=299 | Loss: 39.936 |  Acc: 4.650,3.560,3.820,% | Adaptive Acc:4.960% | clf_exit: 0.785 0.200 0.015
circles: 3
Testing: Epoch=299 | Loss: 32.925 |  Acc: 5.970,5.260,5.240,% | Adaptive Acc:6.640% | clf_exit: 0.738 0.225 0.037
circles: 4
Testing: Epoch=299 | Loss: 20.133 |  Acc: 10.140,13.070,15.780,% | Adaptive Acc:13.340% | clf_exit: 0.599 0.268 0.132
circles: 5
Testing: Epoch=299 | Loss: 7.937 |  Acc: 24.450,45.920,54.880,% | Adaptive Acc:41.880% | clf_exit: 0.460 0.310 0.230
circles: 6
Testing: Epoch=299 | Loss: 4.665 |  Acc: 46.590,65.030,67.640,% | Adaptive Acc:63.490% | clf_exit: 0.404 0.379 0.217
