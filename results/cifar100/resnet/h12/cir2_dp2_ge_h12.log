==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=16, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=64, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=64, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule2(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.351 | Acc: 2.344,0.000,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.630 | Acc: 1.488,1.190,1.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.408 | Acc: 1.753,1.734,1.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.262 | Acc: 1.895,2.152,1.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.146 | Acc: 1.968,2.431,2.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.048 | Acc: 2.135,2.653,2.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.957 | Acc: 2.389,2.834,2.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.860 | Acc: 2.549,3.136,2.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.764 | Acc: 2.742,3.300,3.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.679 | Acc: 2.793,3.440,3.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.604 | Acc: 2.880,3.572,4.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.525 | Acc: 2.977,3.864,4.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.454 | Acc: 3.057,4.052,4.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.392 | Acc: 3.149,4.209,5.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.331 | Acc: 3.239,4.465,5.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.277 | Acc: 3.330,4.591,5.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.222 | Acc: 3.429,4.746,5.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.164 | Acc: 3.526,4.923,6.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.108 | Acc: 3.586,5.081,6.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.058 | Acc: 3.683,5.255,6.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.015 | Acc: 8.594,8.594,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.225 | Acc: 5.171,7.292,9.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.214 | Acc: 5.297,7.050,9.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.204 | Acc: 5.341,7.082,9.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 11.924 | Acc: 4.688,10.156,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.048 | Acc: 6.101,9.487,11.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.022 | Acc: 5.716,9.870,11.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.013 | Acc: 5.917,9.541,11.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.017 | Acc: 5.575,9.201,11.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.994 | Acc: 5.608,9.205,11.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.983 | Acc: 5.579,9.214,11.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.964 | Acc: 5.690,9.336,11.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.947 | Acc: 5.682,9.496,12.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.922 | Acc: 5.723,9.599,12.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.907 | Acc: 5.865,9.659,12.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.885 | Acc: 5.928,9.661,12.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.866 | Acc: 5.932,9.774,12.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.838 | Acc: 6.133,9.878,12.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.825 | Acc: 6.253,9.889,12.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.801 | Acc: 6.351,9.972,13.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.782 | Acc: 6.386,10.054,13.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.760 | Acc: 6.424,10.120,13.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.740 | Acc: 6.479,10.137,13.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.717 | Acc: 6.543,10.263,13.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.474 | Acc: 6.250,10.938,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.576 | Acc: 6.808,10.565,15.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.540 | Acc: 6.307,10.785,15.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.540 | Acc: 6.237,10.515,14.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 11.714 | Acc: 10.156,11.719,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.352 | Acc: 9.003,11.942,16.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.285 | Acc: 8.899,12.462,16.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.307 | Acc: 8.389,12.218,16.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.308 | Acc: 8.314,12.269,15.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.263 | Acc: 8.462,12.809,16.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.235 | Acc: 8.484,12.926,16.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.218 | Acc: 8.477,12.844,16.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.192 | Acc: 8.579,12.878,16.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.174 | Acc: 8.680,12.983,16.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.158 | Acc: 8.835,13.056,16.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.143 | Acc: 8.862,13.083,16.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.127 | Acc: 8.957,13.168,16.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.099 | Acc: 9.040,13.284,17.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.085 | Acc: 9.050,13.345,17.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.070 | Acc: 9.074,13.419,17.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.057 | Acc: 9.063,13.495,17.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.042 | Acc: 9.102,13.613,17.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.027 | Acc: 9.152,13.658,17.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.011 | Acc: 9.186,13.710,17.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.456 | Acc: 14.844,18.750,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.738 | Acc: 10.863,13.616,18.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.740 | Acc: 10.366,14.367,18.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.751 | Acc: 10.656,14.447,18.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 10.805 | Acc: 8.594,7.031,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.629 | Acc: 9.859,15.588,19.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.662 | Acc: 10.652,15.187,19.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.643 | Acc: 10.156,15.190,19.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.609 | Acc: 10.253,15.345,19.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.590 | Acc: 10.450,15.401,20.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.577 | Acc: 10.453,15.541,20.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.565 | Acc: 10.611,15.686,20.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.550 | Acc: 10.719,15.785,20.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.550 | Acc: 10.812,15.940,20.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.545 | Acc: 10.879,15.924,20.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.532 | Acc: 10.983,15.961,20.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.514 | Acc: 11.041,16.121,20.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.492 | Acc: 11.123,16.284,21.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.479 | Acc: 11.185,16.348,21.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.470 | Acc: 11.272,16.352,21.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.454 | Acc: 11.395,16.421,21.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.441 | Acc: 11.467,16.450,21.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.426 | Acc: 11.457,16.560,21.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.422 | Acc: 11.452,16.609,21.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.309 | Acc: 9.375,20.312,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.547 | Acc: 9.859,16.257,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.516 | Acc: 10.118,16.654,22.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.516 | Acc: 10.195,16.752,21.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 9.741 | Acc: 10.156,19.531,23.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.129 | Acc: 12.314,19.048,23.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.148 | Acc: 12.309,18.236,23.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.125 | Acc: 12.782,18.468,23.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.082 | Acc: 12.963,18.634,23.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.058 | Acc: 13.049,18.634,23.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.053 | Acc: 13.113,18.653,23.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.041 | Acc: 13.303,18.617,23.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.021 | Acc: 13.587,18.755,24.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.004 | Acc: 13.627,18.923,24.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.982 | Acc: 13.767,19.181,24.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.970 | Acc: 13.843,19.443,24.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.954 | Acc: 13.862,19.544,24.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.947 | Acc: 13.883,19.597,24.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.932 | Acc: 13.990,19.756,24.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.914 | Acc: 14.037,19.908,24.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.910 | Acc: 14.084,19.877,24.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.894 | Acc: 14.136,19.960,24.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.877 | Acc: 14.212,20.100,25.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.872 | Acc: 14.255,20.161,25.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.668 | Acc: 10.156,18.750,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.220 | Acc: 12.649,17.746,23.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.241 | Acc: 12.691,17.873,23.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.218 | Acc: 13.140,17.572,22.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.345 | Acc: 17.969,23.438,27.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.589 | Acc: 15.104,21.689,27.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.609 | Acc: 15.758,22.123,26.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.628 | Acc: 15.330,21.798,26.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.611 | Acc: 15.355,21.759,26.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.559 | Acc: 15.439,21.898,27.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.542 | Acc: 15.657,22.095,27.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.535 | Acc: 15.736,22.141,27.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.514 | Acc: 15.853,22.346,27.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.503 | Acc: 15.975,22.579,27.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.499 | Acc: 15.920,22.579,27.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.506 | Acc: 15.894,22.522,27.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.490 | Acc: 15.991,22.536,27.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.474 | Acc: 16.068,22.653,27.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.465 | Acc: 16.100,22.653,27.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.459 | Acc: 16.136,22.661,27.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.450 | Acc: 16.202,22.656,27.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.438 | Acc: 16.157,22.789,27.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.426 | Acc: 16.190,22.864,27.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.412 | Acc: 16.244,22.929,27.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.571 | Acc: 18.750,23.438,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.637 | Acc: 15.327,21.057,27.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.683 | Acc: 14.882,21.170,26.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.667 | Acc: 15.087,21.107,26.178,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 8.311 | Acc: 17.188,28.125,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.144 | Acc: 16.853,24.665,30.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.101 | Acc: 17.588,25.038,31.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.046 | Acc: 18.110,25.538,31.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.051 | Acc: 18.142,25.473,31.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.054 | Acc: 17.938,25.170,31.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.056 | Acc: 17.975,25.123,30.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.051 | Acc: 18.074,25.144,30.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.051 | Acc: 18.071,25.063,30.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.040 | Acc: 18.146,25.082,30.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.025 | Acc: 18.198,25.144,31.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.025 | Acc: 18.170,25.138,31.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.012 | Acc: 18.244,25.188,31.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.019 | Acc: 18.262,25.174,31.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.025 | Acc: 18.269,25.131,30.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.006 | Acc: 18.343,25.241,31.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.000 | Acc: 18.404,25.292,31.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.994 | Acc: 18.340,25.284,31.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.992 | Acc: 18.293,25.294,31.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.979 | Acc: 18.373,25.385,31.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.181 | Acc: 20.312,25.000,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.181 | Acc: 16.927,23.363,31.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.210 | Acc: 16.063,23.285,31.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.220 | Acc: 16.227,22.964,31.148,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.198 | Acc: 13.281,26.562,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.715 | Acc: 19.531,28.311,34.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.666 | Acc: 19.722,27.992,34.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.703 | Acc: 19.249,27.587,33.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.682 | Acc: 19.579,27.517,33.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.680 | Acc: 19.585,27.529,33.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.671 | Acc: 19.628,27.460,33.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.655 | Acc: 19.598,27.610,34.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.650 | Acc: 19.662,27.747,34.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.656 | Acc: 19.613,27.698,34.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.668 | Acc: 19.551,27.740,34.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.668 | Acc: 19.690,27.708,34.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.657 | Acc: 19.667,27.720,34.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.655 | Acc: 19.708,27.658,34.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.642 | Acc: 19.812,27.752,34.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.640 | Acc: 19.822,27.824,34.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.638 | Acc: 19.782,27.828,34.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.631 | Acc: 19.841,27.896,34.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.618 | Acc: 19.938,27.954,34.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.608 | Acc: 19.995,28.010,34.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.255 | Acc: 17.188,19.531,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.488 | Acc: 15.365,20.461,29.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.533 | Acc: 14.405,19.360,29.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.518 | Acc: 14.639,19.454,29.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 7.905 | Acc: 21.875,29.688,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.287 | Acc: 21.689,30.060,36.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.286 | Acc: 21.723,30.507,36.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.309 | Acc: 21.734,30.149,36.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.357 | Acc: 21.508,29.524,36.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.367 | Acc: 21.457,29.301,35.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.350 | Acc: 21.352,29.242,35.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.338 | Acc: 21.410,29.399,35.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.330 | Acc: 21.545,29.377,35.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.297 | Acc: 21.780,29.631,36.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.298 | Acc: 21.673,29.668,36.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.308 | Acc: 21.656,29.581,36.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.302 | Acc: 21.677,29.626,36.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.306 | Acc: 21.594,29.583,36.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.299 | Acc: 21.578,29.587,36.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.296 | Acc: 21.613,29.643,36.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.287 | Acc: 21.673,29.717,36.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.274 | Acc: 21.747,29.756,36.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.269 | Acc: 21.773,29.874,36.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.268 | Acc: 21.779,29.878,36.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.696 | Acc: 23.438,30.469,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.968 | Acc: 17.708,24.888,32.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.958 | Acc: 17.245,25.476,32.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.938 | Acc: 17.162,25.538,33.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.347 | Acc: 21.875,31.250,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.104 | Acc: 22.954,30.766,38.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.029 | Acc: 23.133,31.898,38.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.040 | Acc: 23.271,31.749,38.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.058 | Acc: 22.695,31.626,38.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.058 | Acc: 22.904,31.490,38.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.042 | Acc: 22.856,31.857,38.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.049 | Acc: 22.883,31.704,38.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.045 | Acc: 22.879,31.682,38.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.056 | Acc: 22.932,31.500,38.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.033 | Acc: 23.092,31.689,38.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.018 | Acc: 23.236,31.922,38.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.012 | Acc: 23.295,32.028,38.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.020 | Acc: 23.279,31.918,38.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.016 | Acc: 23.171,31.864,38.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.000 | Acc: 23.196,31.912,38.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.001 | Acc: 23.211,31.866,38.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.999 | Acc: 23.172,31.869,38.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.997 | Acc: 23.189,31.862,38.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.997 | Acc: 23.202,31.851,38.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.818 | Acc: 28.125,37.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.372 | Acc: 20.833,28.162,39.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.403 | Acc: 20.598,28.258,38.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.377 | Acc: 20.415,28.394,38.678,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 7.401 | Acc: 24.219,33.594,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.607 | Acc: 24.926,33.966,40.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.740 | Acc: 25.248,33.460,40.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.718 | Acc: 25.026,33.824,40.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.760 | Acc: 24.595,33.613,40.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.749 | Acc: 24.528,33.656,40.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.738 | Acc: 24.458,33.891,41.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.761 | Acc: 24.307,33.660,40.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.772 | Acc: 24.248,33.628,40.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.774 | Acc: 24.396,33.676,40.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.775 | Acc: 24.328,33.574,40.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.775 | Acc: 24.378,33.587,40.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.777 | Acc: 24.306,33.532,40.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.768 | Acc: 24.332,33.576,40.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.757 | Acc: 24.394,33.610,40.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.761 | Acc: 24.346,33.537,40.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.766 | Acc: 24.287,33.489,40.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.759 | Acc: 24.299,33.541,40.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.754 | Acc: 24.366,33.613,40.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.756 | Acc: 24.336,33.581,40.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.198 | Acc: 25.781,35.156,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.171 | Acc: 21.577,30.283,39.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.215 | Acc: 20.979,30.145,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.219 | Acc: 21.145,29.905,38.909,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 7.445 | Acc: 32.031,42.188,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.469 | Acc: 26.488,36.496,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.501 | Acc: 25.591,35.595,43.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.491 | Acc: 25.346,35.707,43.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.490 | Acc: 25.328,35.542,43.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.495 | Acc: 25.294,35.419,42.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.516 | Acc: 25.187,35.150,42.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.506 | Acc: 25.249,35.239,42.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.515 | Acc: 25.325,35.142,42.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.533 | Acc: 25.306,35.009,42.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.525 | Acc: 25.342,35.145,42.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.526 | Acc: 25.343,35.139,42.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.525 | Acc: 25.389,35.179,42.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.532 | Acc: 25.284,35.093,42.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.535 | Acc: 25.250,35.084,42.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.532 | Acc: 25.189,35.130,42.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.527 | Acc: 25.297,35.183,42.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.522 | Acc: 25.344,35.218,42.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.522 | Acc: 25.288,35.230,42.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.511 | Acc: 25.361,35.355,42.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.350 | Acc: 17.969,32.031,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.423 | Acc: 20.015,27.790,38.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.487 | Acc: 19.150,27.229,37.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.470 | Acc: 19.416,27.677,37.602,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 7.806 | Acc: 26.562,35.156,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.190 | Acc: 26.935,37.723,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.197 | Acc: 26.486,37.938,46.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.223 | Acc: 26.627,37.807,45.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.260 | Acc: 26.466,37.490,45.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.291 | Acc: 26.269,37.198,44.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.307 | Acc: 26.337,37.100,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.325 | Acc: 26.164,37.112,44.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.331 | Acc: 26.087,36.826,44.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.334 | Acc: 26.135,36.900,44.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.329 | Acc: 26.170,36.987,44.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.327 | Acc: 26.156,37.009,44.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.336 | Acc: 26.186,36.865,44.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.339 | Acc: 26.167,36.868,44.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.340 | Acc: 26.179,36.838,44.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.333 | Acc: 26.298,36.890,44.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.338 | Acc: 26.258,36.862,44.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.338 | Acc: 26.244,36.804,44.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.338 | Acc: 26.255,36.762,44.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.337 | Acc: 26.275,36.801,44.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.344 | Acc: 25.781,37.500,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.721 | Acc: 16.778,31.027,40.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.709 | Acc: 16.673,30.774,39.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.648 | Acc: 16.790,30.315,40.215,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.342 | Acc: 26.562,39.844,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.123 | Acc: 26.451,39.174,45.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.189 | Acc: 26.067,38.567,45.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.161 | Acc: 26.140,38.678,45.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.157 | Acc: 26.437,38.387,46.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.165 | Acc: 26.377,38.235,45.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.155 | Acc: 26.414,38.372,45.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.158 | Acc: 26.684,38.364,45.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.164 | Acc: 26.766,38.310,45.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.167 | Acc: 26.593,38.234,45.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.165 | Acc: 26.609,38.207,45.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.160 | Acc: 26.623,38.200,45.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.167 | Acc: 26.705,38.223,45.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.168 | Acc: 26.700,38.147,45.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.165 | Acc: 26.746,38.181,45.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.154 | Acc: 26.791,38.224,45.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.155 | Acc: 26.847,38.228,45.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.155 | Acc: 26.837,38.148,45.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.162 | Acc: 26.807,38.136,45.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.157 | Acc: 26.786,38.179,45.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.163 | Acc: 28.125,34.375,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.196 | Acc: 21.838,33.668,42.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.266 | Acc: 20.903,32.755,41.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.274 | Acc: 20.850,32.595,41.329,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 6.573 | Acc: 30.469,41.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.931 | Acc: 27.121,40.476,47.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.937 | Acc: 27.496,40.263,47.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.998 | Acc: 27.241,39.652,47.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.026 | Acc: 27.074,39.381,46.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.010 | Acc: 27.112,39.542,47.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.005 | Acc: 27.002,39.411,47.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.010 | Acc: 27.039,39.484,46.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.014 | Acc: 27.242,39.621,47.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.006 | Acc: 27.236,39.576,47.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.007 | Acc: 27.254,39.509,47.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.006 | Acc: 27.323,39.635,47.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.006 | Acc: 27.276,39.581,47.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.998 | Acc: 27.347,39.664,47.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.002 | Acc: 27.310,39.607,46.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.999 | Acc: 27.414,39.709,47.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.993 | Acc: 27.456,39.780,47.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.993 | Acc: 27.467,39.807,47.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.998 | Acc: 27.456,39.757,47.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.987 | Acc: 27.508,39.842,47.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.266 | Acc: 19.531,31.250,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.433 | Acc: 19.680,30.320,39.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.472 | Acc: 18.883,29.611,39.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.463 | Acc: 18.904,29.700,39.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 6.125 | Acc: 33.594,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.724 | Acc: 28.869,42.001,49.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.738 | Acc: 28.582,41.616,49.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.785 | Acc: 28.381,41.368,49.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.805 | Acc: 28.144,40.992,48.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.809 | Acc: 28.164,40.896,49.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.791 | Acc: 28.325,40.999,49.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.827 | Acc: 28.275,40.858,48.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.829 | Acc: 28.256,40.940,48.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.831 | Acc: 28.336,40.893,48.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.829 | Acc: 28.226,40.944,48.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.832 | Acc: 28.196,40.805,48.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.837 | Acc: 28.203,40.781,48.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.841 | Acc: 28.191,40.781,48.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.835 | Acc: 28.236,40.772,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.837 | Acc: 28.260,40.716,48.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.843 | Acc: 28.191,40.705,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.844 | Acc: 28.203,40.691,48.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.845 | Acc: 28.212,40.714,48.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.847 | Acc: 28.236,40.723,48.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.722 | Acc: 25.781,33.594,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.861 | Acc: 23.661,35.417,42.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.878 | Acc: 23.228,34.127,41.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.893 | Acc: 23.130,33.837,42.085,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.893 | Acc: 26.562,39.062,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.693 | Acc: 29.129,41.927,49.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.730 | Acc: 28.887,42.530,49.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.747 | Acc: 28.496,42.444,49.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.741 | Acc: 28.800,42.564,49.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.723 | Acc: 28.976,42.574,49.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.712 | Acc: 29.145,42.588,49.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.725 | Acc: 29.045,42.420,49.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.713 | Acc: 29.047,42.513,50.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.714 | Acc: 28.993,42.528,49.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.714 | Acc: 28.988,42.331,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.722 | Acc: 29.026,42.255,49.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.719 | Acc: 29.098,42.220,49.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.721 | Acc: 29.125,42.205,49.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.720 | Acc: 29.073,42.201,49.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.719 | Acc: 29.018,42.226,49.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.720 | Acc: 28.918,42.144,49.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.723 | Acc: 28.945,42.142,49.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.714 | Acc: 28.967,42.142,49.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.709 | Acc: 28.970,42.142,49.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.741 | Acc: 15.625,27.344,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.788 | Acc: 14.769,26.079,36.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.735 | Acc: 14.444,26.391,36.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.707 | Acc: 14.088,26.050,36.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 6.288 | Acc: 32.812,46.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.579 | Acc: 28.981,43.192,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.630 | Acc: 29.002,42.111,50.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.573 | Acc: 29.547,42.905,50.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.584 | Acc: 29.398,42.631,50.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.615 | Acc: 29.216,42.536,50.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.606 | Acc: 29.268,42.730,50.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.593 | Acc: 29.444,42.675,50.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.591 | Acc: 29.552,42.678,50.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.594 | Acc: 29.472,42.615,50.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.601 | Acc: 29.544,42.580,50.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.601 | Acc: 29.479,42.590,50.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.596 | Acc: 29.626,42.693,50.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.594 | Acc: 29.565,42.780,50.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.593 | Acc: 29.604,42.757,50.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.604 | Acc: 29.560,42.714,50.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.592 | Acc: 29.651,42.781,50.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.597 | Acc: 29.578,42.795,50.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.596 | Acc: 29.590,42.791,50.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.598 | Acc: 29.530,42.819,50.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.937 | Acc: 17.969,30.469,33.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.842 | Acc: 16.481,31.138,41.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.924 | Acc: 16.521,30.907,40.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.969 | Acc: 16.176,30.507,40.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.469 | Acc: 36.719,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.450 | Acc: 29.018,44.792,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.549 | Acc: 28.811,43.559,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.531 | Acc: 28.791,43.981,51.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.508 | Acc: 29.360,43.972,51.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.512 | Acc: 29.448,43.796,51.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.520 | Acc: 29.610,43.886,51.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.512 | Acc: 29.715,43.822,51.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.520 | Acc: 29.658,43.784,51.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.519 | Acc: 29.739,43.823,51.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.504 | Acc: 29.800,44.061,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.500 | Acc: 29.974,44.125,51.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.498 | Acc: 30.025,44.175,51.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.511 | Acc: 29.930,44.025,51.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.508 | Acc: 29.999,44.114,51.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.515 | Acc: 30.015,44.004,51.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.514 | Acc: 30.011,44.047,51.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.511 | Acc: 30.086,44.004,51.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.514 | Acc: 30.127,43.958,51.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.508 | Acc: 30.079,43.941,51.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.719 | Acc: 29.688,36.719,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.372 | Acc: 27.344,37.872,47.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.511 | Acc: 26.715,35.690,45.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.512 | Acc: 26.998,35.528,44.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.020 | Acc: 35.156,53.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.358 | Acc: 31.399,45.499,52.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.419 | Acc: 30.602,44.055,52.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.348 | Acc: 31.058,44.890,53.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.361 | Acc: 30.748,44.811,52.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.375 | Acc: 30.647,44.485,52.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.383 | Acc: 30.746,44.518,52.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.363 | Acc: 30.718,44.731,52.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.365 | Acc: 30.765,44.827,52.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.341 | Acc: 30.969,45.179,52.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.354 | Acc: 30.900,45.110,52.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.372 | Acc: 30.840,44.941,52.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.366 | Acc: 30.829,45.141,52.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.359 | Acc: 30.822,45.220,52.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.366 | Acc: 30.752,45.173,52.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.365 | Acc: 30.728,45.105,52.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.378 | Acc: 30.698,44.996,52.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.375 | Acc: 30.762,45.001,52.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.367 | Acc: 30.852,45.020,52.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.368 | Acc: 30.893,44.999,52.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.249 | Acc: 29.688,37.500,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.237 | Acc: 26.860,38.430,46.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.255 | Acc: 26.620,38.357,46.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.238 | Acc: 26.473,38.486,46.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.573 | Acc: 23.438,38.281,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.312 | Acc: 30.283,45.238,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.228 | Acc: 30.964,45.827,54.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.233 | Acc: 31.186,45.940,55.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.237 | Acc: 31.289,46.007,54.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.240 | Acc: 31.358,45.985,54.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.235 | Acc: 31.334,46.055,54.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.250 | Acc: 31.161,45.806,54.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.258 | Acc: 31.299,45.676,54.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.269 | Acc: 31.207,45.619,53.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.271 | Acc: 31.219,45.612,53.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.279 | Acc: 31.102,45.521,53.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.278 | Acc: 31.020,45.604,53.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.282 | Acc: 31.052,45.555,53.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.292 | Acc: 30.941,45.499,53.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.291 | Acc: 30.967,45.608,53.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.279 | Acc: 31.082,45.712,53.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.287 | Acc: 31.071,45.649,53.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.279 | Acc: 31.161,45.745,53.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.277 | Acc: 31.158,45.784,53.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.609 | Acc: 27.344,36.719,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.564 | Acc: 23.661,38.504,46.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.581 | Acc: 24.162,38.072,45.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.581 | Acc: 24.155,37.987,45.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 5.848 | Acc: 38.281,47.656,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.127 | Acc: 31.882,46.317,55.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.162 | Acc: 32.031,46.684,54.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.164 | Acc: 32.108,46.875,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.168 | Acc: 31.867,46.836,54.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.162 | Acc: 32.109,47.030,54.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.165 | Acc: 32.199,47.095,54.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.163 | Acc: 32.192,47.102,54.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.165 | Acc: 31.992,47.006,54.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.171 | Acc: 32.010,46.840,54.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.173 | Acc: 31.868,46.840,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.180 | Acc: 31.809,46.815,54.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.194 | Acc: 31.762,46.758,54.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.182 | Acc: 31.825,46.821,54.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.177 | Acc: 31.845,46.814,54.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.175 | Acc: 31.870,46.844,54.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.170 | Acc: 31.917,46.885,54.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.178 | Acc: 31.871,46.820,54.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.181 | Acc: 31.901,46.728,54.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.185 | Acc: 31.894,46.672,54.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.980 | Acc: 25.781,35.156,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.547 | Acc: 23.735,37.649,48.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.610 | Acc: 23.514,37.462,47.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.609 | Acc: 23.540,37.782,47.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 5.655 | Acc: 41.406,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.940 | Acc: 33.519,48.661,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.002 | Acc: 33.746,48.190,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.035 | Acc: 33.517,48.181,56.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.041 | Acc: 33.304,48.486,56.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.058 | Acc: 33.253,48.105,56.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.070 | Acc: 32.922,47.772,55.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.060 | Acc: 33.056,47.889,55.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.063 | Acc: 33.079,47.928,55.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.065 | Acc: 32.873,47.738,55.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.080 | Acc: 32.622,47.485,55.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.084 | Acc: 32.526,47.462,55.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.078 | Acc: 32.524,47.390,55.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.079 | Acc: 32.582,47.366,55.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.091 | Acc: 32.557,47.250,55.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.103 | Acc: 32.540,47.179,55.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.100 | Acc: 32.601,47.347,55.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.106 | Acc: 32.606,47.379,55.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.109 | Acc: 32.592,47.386,55.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.110 | Acc: 32.530,47.338,54.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.670 | Acc: 24.219,39.844,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.447 | Acc: 23.996,38.951,47.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.424 | Acc: 23.685,38.796,47.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.418 | Acc: 23.847,39.191,46.939,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 6.552 | Acc: 25.781,46.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.079 | Acc: 32.738,46.838,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.002 | Acc: 32.793,48.056,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.949 | Acc: 33.043,48.425,57.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.958 | Acc: 33.102,48.765,57.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.983 | Acc: 33.168,48.677,56.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.980 | Acc: 33.064,48.722,56.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.965 | Acc: 33.150,48.897,56.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.973 | Acc: 33.235,48.865,56.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.988 | Acc: 33.162,48.688,56.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.986 | Acc: 33.193,48.644,56.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.012 | Acc: 33.053,48.491,56.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.998 | Acc: 33.270,48.528,56.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.010 | Acc: 33.256,48.363,56.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.020 | Acc: 33.207,48.273,56.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.030 | Acc: 33.072,48.188,56.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.034 | Acc: 32.954,48.043,55.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.038 | Acc: 32.856,48.018,55.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.039 | Acc: 32.819,48.013,55.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.039 | Acc: 32.765,48.029,55.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.334 | Acc: 29.688,40.625,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.124 | Acc: 27.790,41.629,48.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.161 | Acc: 27.058,41.120,47.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.212 | Acc: 26.588,41.227,47.976,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 5.313 | Acc: 38.281,56.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.809 | Acc: 34.784,48.772,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.833 | Acc: 34.184,48.876,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.843 | Acc: 33.504,49.065,57.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.890 | Acc: 33.459,48.592,56.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.930 | Acc: 33.400,48.530,56.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.945 | Acc: 33.329,48.489,56.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.939 | Acc: 33.295,48.715,56.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.949 | Acc: 33.269,48.690,56.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.943 | Acc: 33.382,48.692,56.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.948 | Acc: 33.298,48.725,56.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.952 | Acc: 33.364,48.766,56.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.950 | Acc: 33.399,48.645,56.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.950 | Acc: 33.492,48.617,56.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.951 | Acc: 33.466,48.618,56.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.943 | Acc: 33.493,48.705,56.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.938 | Acc: 33.535,48.717,56.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.940 | Acc: 33.518,48.719,56.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.946 | Acc: 33.436,48.665,56.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.946 | Acc: 33.405,48.741,56.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.897 | Acc: 21.875,39.844,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.782 | Acc: 19.494,34.152,43.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.793 | Acc: 18.883,34.204,42.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.766 | Acc: 18.955,34.388,42.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 5.674 | Acc: 30.469,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.882 | Acc: 32.812,48.772,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.887 | Acc: 33.365,49.371,57.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.950 | Acc: 33.299,48.386,56.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.962 | Acc: 33.227,48.669,56.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.956 | Acc: 33.099,48.786,56.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.934 | Acc: 33.271,49.186,56.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.924 | Acc: 33.278,49.269,56.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.912 | Acc: 33.511,49.393,56.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.893 | Acc: 33.585,49.387,57.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.888 | Acc: 33.609,49.479,57.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.895 | Acc: 33.548,49.371,57.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.903 | Acc: 33.509,49.332,57.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.902 | Acc: 33.519,49.255,57.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.894 | Acc: 33.594,49.316,57.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.898 | Acc: 33.578,49.273,57.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.899 | Acc: 33.509,49.297,57.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.905 | Acc: 33.553,49.281,57.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.903 | Acc: 33.559,49.221,56.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.902 | Acc: 33.573,49.198,56.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.722 | Acc: 20.312,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.537 | Acc: 18.229,36.458,46.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.548 | Acc: 17.340,36.471,45.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.499 | Acc: 17.380,36.066,45.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 5.279 | Acc: 39.062,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.795 | Acc: 34.003,50.000,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.760 | Acc: 33.918,50.534,58.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.797 | Acc: 33.466,50.179,58.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.784 | Acc: 33.497,50.357,57.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.777 | Acc: 33.702,50.557,58.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.786 | Acc: 33.697,50.278,58.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.794 | Acc: 33.583,50.094,58.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.814 | Acc: 33.647,49.922,57.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.813 | Acc: 33.633,49.978,57.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.811 | Acc: 33.706,50.062,57.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.815 | Acc: 33.664,50.011,57.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.816 | Acc: 33.513,49.977,57.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.810 | Acc: 33.621,49.988,57.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.813 | Acc: 33.627,49.967,57.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.805 | Acc: 33.770,50.062,57.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.809 | Acc: 33.779,50.066,57.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.815 | Acc: 33.761,49.927,57.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.814 | Acc: 33.851,49.985,57.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.817 | Acc: 33.912,49.932,57.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.017 | Acc: 18.750,37.500,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.373 | Acc: 23.958,39.397,48.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.357 | Acc: 23.438,39.196,47.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.372 | Acc: 23.335,39.050,47.503,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 5.514 | Acc: 38.281,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.753 | Acc: 33.854,49.368,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.747 | Acc: 34.508,49.371,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.721 | Acc: 34.529,50.013,58.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.699 | Acc: 34.857,50.550,58.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.734 | Acc: 34.615,50.650,58.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.725 | Acc: 34.853,50.652,58.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.724 | Acc: 34.724,50.515,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.725 | Acc: 34.705,50.505,58.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.741 | Acc: 34.556,50.367,58.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.732 | Acc: 34.499,50.532,58.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.739 | Acc: 34.407,50.506,58.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.742 | Acc: 34.398,50.515,58.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.743 | Acc: 34.381,50.515,58.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.747 | Acc: 34.361,50.470,58.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.748 | Acc: 34.308,50.441,58.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.753 | Acc: 34.317,50.436,58.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.764 | Acc: 34.141,50.357,58.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.766 | Acc: 34.107,50.327,58.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.770 | Acc: 34.047,50.258,58.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.746 | Acc: 25.000,38.281,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.241 | Acc: 26.674,38.876,47.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.375 | Acc: 25.495,38.205,46.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.383 | Acc: 25.692,38.166,46.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 5.981 | Acc: 32.812,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.654 | Acc: 36.421,50.409,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.620 | Acc: 34.794,51.639,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.618 | Acc: 34.810,51.460,59.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.643 | Acc: 34.529,51.177,59.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.649 | Acc: 34.452,51.361,59.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.661 | Acc: 34.285,51.349,59.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.658 | Acc: 34.475,51.236,59.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.688 | Acc: 34.195,50.932,58.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.687 | Acc: 34.306,50.881,58.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.689 | Acc: 34.301,50.777,58.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.691 | Acc: 34.379,50.838,58.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.692 | Acc: 34.281,50.859,58.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.688 | Acc: 34.285,50.934,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.686 | Acc: 34.411,51.062,59.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.681 | Acc: 34.502,51.212,59.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.689 | Acc: 34.463,51.146,58.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.694 | Acc: 34.416,51.070,58.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.690 | Acc: 34.475,51.071,58.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.695 | Acc: 34.455,50.995,58.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.586 | Acc: 25.000,41.406,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.107 | Acc: 26.042,42.522,50.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.102 | Acc: 26.277,41.902,49.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.096 | Acc: 25.717,41.637,49.590,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 6.018 | Acc: 30.469,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.651 | Acc: 34.338,51.376,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.586 | Acc: 34.947,52.115,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.596 | Acc: 34.823,51.742,59.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.636 | Acc: 34.404,51.601,59.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.647 | Acc: 34.638,51.547,59.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.638 | Acc: 34.943,51.588,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.623 | Acc: 34.957,51.585,59.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.618 | Acc: 35.040,51.829,59.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.625 | Acc: 34.936,51.675,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.633 | Acc: 34.915,51.613,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.641 | Acc: 34.849,51.513,59.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.655 | Acc: 34.664,51.387,59.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.662 | Acc: 34.683,51.392,59.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.660 | Acc: 34.656,51.443,59.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.653 | Acc: 34.671,51.487,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.655 | Acc: 34.640,51.499,59.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.650 | Acc: 34.732,51.549,59.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.647 | Acc: 34.814,51.634,59.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.640 | Acc: 34.900,51.575,59.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.084 | Acc: 29.688,35.938,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.851 | Acc: 27.381,33.966,42.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.838 | Acc: 26.905,34.527,42.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.877 | Acc: 26.498,34.311,41.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 5.593 | Acc: 32.812,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.461 | Acc: 37.016,52.269,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.470 | Acc: 36.757,52.325,60.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.513 | Acc: 36.066,52.241,60.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.522 | Acc: 35.706,52.170,60.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.514 | Acc: 35.852,52.290,60.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.542 | Acc: 35.705,52.144,60.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.552 | Acc: 35.710,52.150,60.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.570 | Acc: 35.569,52.072,60.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.584 | Acc: 35.597,51.998,59.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.584 | Acc: 35.553,52.025,59.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.602 | Acc: 35.432,51.870,59.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.610 | Acc: 35.325,51.841,59.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.615 | Acc: 35.228,51.808,59.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.615 | Acc: 35.254,51.838,59.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.615 | Acc: 35.208,51.799,59.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.611 | Acc: 35.293,51.806,59.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.610 | Acc: 35.257,51.730,59.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.608 | Acc: 35.241,51.770,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.611 | Acc: 35.179,51.749,59.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.966 | Acc: 29.688,46.875,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.795 | Acc: 30.246,43.080,51.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.912 | Acc: 29.516,42.569,50.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.946 | Acc: 29.060,42.200,49.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 5.857 | Acc: 28.125,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.539 | Acc: 34.635,52.939,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.493 | Acc: 35.061,53.030,61.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.537 | Acc: 34.631,52.331,60.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.540 | Acc: 34.539,52.344,60.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.573 | Acc: 34.468,52.104,60.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.541 | Acc: 34.846,52.337,60.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.544 | Acc: 34.968,52.394,60.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.539 | Acc: 34.739,52.451,60.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.524 | Acc: 34.876,52.655,60.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.516 | Acc: 35.059,52.787,60.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.510 | Acc: 35.160,52.934,61.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.516 | Acc: 35.059,52.836,60.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.521 | Acc: 34.998,52.799,60.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.535 | Acc: 34.962,52.663,60.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.541 | Acc: 35.063,52.650,60.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.547 | Acc: 35.049,52.570,60.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.542 | Acc: 35.076,52.568,60.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.537 | Acc: 35.191,52.632,60.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.545 | Acc: 35.121,52.522,60.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.648 | Acc: 28.906,42.188,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.458 | Acc: 26.153,39.509,49.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.540 | Acc: 25.419,38.567,47.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.488 | Acc: 25.295,38.781,48.412,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.437 | Acc: 35.938,56.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.549 | Acc: 34.152,52.269,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.531 | Acc: 35.099,52.344,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.537 | Acc: 34.477,52.369,61.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.497 | Acc: 34.684,52.614,61.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.492 | Acc: 34.862,52.723,60.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.488 | Acc: 34.963,52.628,60.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.478 | Acc: 34.973,52.687,60.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.475 | Acc: 35.020,52.717,60.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.481 | Acc: 35.225,52.667,60.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.469 | Acc: 35.308,52.779,60.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.463 | Acc: 35.563,52.899,60.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.465 | Acc: 35.523,52.953,60.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.466 | Acc: 35.477,52.921,60.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.471 | Acc: 35.373,52.872,60.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.473 | Acc: 35.387,52.878,60.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.473 | Acc: 35.451,52.879,60.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.480 | Acc: 35.475,52.786,60.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.490 | Acc: 35.509,52.746,60.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.493 | Acc: 35.470,52.647,60.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.605 | Acc: 16.406,36.719,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.552 | Acc: 19.903,33.222,46.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.714 | Acc: 19.836,32.984,45.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.705 | Acc: 19.723,33.069,45.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 6.241 | Acc: 28.125,49.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.415 | Acc: 36.049,53.683,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.403 | Acc: 36.566,53.449,61.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.431 | Acc: 36.450,52.830,61.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.423 | Acc: 36.150,52.971,61.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.414 | Acc: 35.914,52.986,61.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.425 | Acc: 35.938,52.970,61.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.440 | Acc: 35.965,52.881,61.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.440 | Acc: 36.039,52.970,61.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.435 | Acc: 36.093,52.983,61.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.438 | Acc: 35.996,53.012,61.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.434 | Acc: 36.047,53.164,61.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.434 | Acc: 36.044,53.255,61.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.430 | Acc: 36.096,53.320,61.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.441 | Acc: 36.090,53.214,61.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.452 | Acc: 36.124,53.107,61.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.456 | Acc: 36.166,53.200,61.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.458 | Acc: 36.148,53.173,61.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.464 | Acc: 36.132,53.196,61.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.466 | Acc: 36.085,53.176,61.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.531 | Acc: 26.562,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.613 | Acc: 23.996,38.988,48.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.633 | Acc: 23.571,39.634,47.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.628 | Acc: 23.527,39.152,47.784,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.395 | Acc: 36.719,57.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.301 | Acc: 35.938,55.394,63.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.254 | Acc: 36.833,55.640,64.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.264 | Acc: 37.218,55.443,63.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.311 | Acc: 36.844,54.890,63.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.347 | Acc: 36.665,54.602,62.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.350 | Acc: 36.583,54.410,62.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.355 | Acc: 36.464,54.277,62.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.372 | Acc: 36.466,54.032,62.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.393 | Acc: 36.473,53.798,62.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.394 | Acc: 36.594,53.887,61.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.394 | Acc: 36.637,53.938,61.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.406 | Acc: 36.553,53.815,61.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.406 | Acc: 36.623,53.703,61.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.413 | Acc: 36.527,53.645,61.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.417 | Acc: 36.496,53.584,61.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.419 | Acc: 36.415,53.502,61.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.419 | Acc: 36.414,53.510,61.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.431 | Acc: 36.334,53.391,61.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.434 | Acc: 36.358,53.385,61.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.115 | Acc: 31.250,41.406,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.845 | Acc: 28.571,41.815,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.955 | Acc: 28.087,41.139,50.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.925 | Acc: 28.138,40.894,50.820,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 4.809 | Acc: 35.938,57.031,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.381 | Acc: 35.938,53.534,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.388 | Acc: 35.690,53.982,61.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.407 | Acc: 35.617,53.765,61.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.383 | Acc: 36.082,53.848,61.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.364 | Acc: 36.286,54.092,62.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.347 | Acc: 36.641,54.132,62.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.350 | Acc: 36.353,54.056,62.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.355 | Acc: 36.350,54.178,62.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.358 | Acc: 36.296,54.118,62.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.366 | Acc: 36.350,54.081,62.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.370 | Acc: 36.397,54.030,62.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.367 | Acc: 36.492,54.055,62.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.374 | Acc: 36.515,53.924,62.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.391 | Acc: 36.477,53.837,61.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.392 | Acc: 36.462,53.818,61.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.382 | Acc: 36.570,53.943,61.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.377 | Acc: 36.590,53.950,61.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.376 | Acc: 36.578,53.934,61.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.392 | Acc: 36.382,53.732,61.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.846 | Acc: 17.188,37.500,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.412 | Acc: 19.457,35.565,46.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.508 | Acc: 19.245,35.347,46.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.572 | Acc: 18.763,35.336,46.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 5.448 | Acc: 36.719,57.031,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.298 | Acc: 37.798,54.985,63.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.243 | Acc: 37.500,55.507,63.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.288 | Acc: 37.167,54.892,63.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.317 | Acc: 36.719,54.581,62.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.304 | Acc: 36.734,54.626,62.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.310 | Acc: 36.790,54.462,62.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.325 | Acc: 36.680,54.338,62.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.339 | Acc: 36.617,54.159,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.323 | Acc: 36.607,54.355,62.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.310 | Acc: 36.707,54.419,62.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.314 | Acc: 36.666,54.323,62.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.315 | Acc: 36.716,54.315,62.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.318 | Acc: 36.620,54.319,62.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.326 | Acc: 36.516,54.293,62.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.331 | Acc: 36.436,54.207,62.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.332 | Acc: 36.402,54.206,62.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.332 | Acc: 36.494,54.287,62.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.333 | Acc: 36.505,54.268,62.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.344 | Acc: 36.469,54.169,62.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.095 | Acc: 29.688,35.938,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.551 | Acc: 23.847,39.732,48.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.604 | Acc: 23.152,39.082,47.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.558 | Acc: 23.322,39.331,47.964,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 5.782 | Acc: 34.375,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.139 | Acc: 37.388,55.729,64.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.150 | Acc: 37.195,55.678,64.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.185 | Acc: 37.013,55.712,64.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.205 | Acc: 36.767,55.411,64.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.227 | Acc: 36.595,55.028,63.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.211 | Acc: 36.757,55.081,63.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.222 | Acc: 36.846,54.859,63.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.232 | Acc: 36.607,54.780,63.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.233 | Acc: 36.632,54.938,63.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.240 | Acc: 36.676,54.847,62.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.254 | Acc: 36.567,54.790,62.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.255 | Acc: 36.667,54.759,62.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.254 | Acc: 36.847,54.885,62.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.264 | Acc: 36.769,54.818,62.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.272 | Acc: 36.791,54.763,62.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.284 | Acc: 36.755,54.636,62.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.291 | Acc: 36.792,54.589,62.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.302 | Acc: 36.667,54.508,62.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.312 | Acc: 36.585,54.388,62.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.928 | Acc: 30.469,48.438,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.403 | Acc: 24.814,40.848,48.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.359 | Acc: 25.057,40.168,48.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.364 | Acc: 24.436,40.074,48.079,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.143 | Acc: 38.281,53.125,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.266 | Acc: 37.351,55.060,63.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.267 | Acc: 37.043,55.030,63.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.292 | Acc: 36.770,54.931,63.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.281 | Acc: 36.487,54.803,63.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.293 | Acc: 36.448,54.780,62.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.279 | Acc: 36.525,54.913,63.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.270 | Acc: 36.680,54.793,63.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.259 | Acc: 36.923,54.959,63.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.257 | Acc: 37.042,54.821,63.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.261 | Acc: 37.185,54.862,63.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.266 | Acc: 37.256,54.776,63.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.270 | Acc: 37.173,54.652,62.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.275 | Acc: 37.162,54.598,62.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.277 | Acc: 37.214,54.562,62.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.277 | Acc: 37.191,54.542,62.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.283 | Acc: 37.101,54.493,62.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.280 | Acc: 37.097,54.474,62.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.282 | Acc: 37.004,54.471,62.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.283 | Acc: 37.030,54.466,62.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.617 | Acc: 28.906,34.375,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.402 | Acc: 26.972,40.402,48.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.412 | Acc: 26.239,39.863,48.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.411 | Acc: 26.204,39.460,48.284,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 5.116 | Acc: 32.031,58.594,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.259 | Acc: 36.719,54.799,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.240 | Acc: 36.966,55.011,63.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.252 | Acc: 36.885,54.777,63.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.236 | Acc: 36.902,54.977,63.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.231 | Acc: 36.997,55.159,63.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.244 | Acc: 36.764,55.127,63.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.229 | Acc: 37.073,55.269,63.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.232 | Acc: 37.024,55.270,63.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.236 | Acc: 36.948,55.214,63.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.229 | Acc: 36.999,55.232,63.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.237 | Acc: 36.931,55.158,63.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.247 | Acc: 36.959,55.044,63.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.253 | Acc: 36.979,54.999,63.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.249 | Acc: 37.075,55.035,63.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.240 | Acc: 37.108,55.118,63.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.246 | Acc: 37.096,55.028,63.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.251 | Acc: 37.072,54.928,63.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.245 | Acc: 37.173,54.984,63.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.254 | Acc: 37.135,54.942,63.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.982 | Acc: 31.250,43.750,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.806 | Acc: 26.972,44.792,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.869 | Acc: 25.762,44.855,53.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.837 | Acc: 25.730,45.261,53.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.485 | Acc: 32.812,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.316 | Acc: 35.789,54.688,63.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.143 | Acc: 37.176,56.650,64.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.111 | Acc: 37.359,56.762,64.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.118 | Acc: 37.375,56.395,64.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.140 | Acc: 37.098,56.265,64.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.157 | Acc: 37.009,55.914,63.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.145 | Acc: 37.007,56.051,64.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.160 | Acc: 36.923,55.794,63.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.185 | Acc: 36.723,55.512,63.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.176 | Acc: 36.762,55.562,63.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.200 | Acc: 36.577,55.384,63.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.209 | Acc: 36.579,55.359,63.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.216 | Acc: 36.686,55.295,63.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.217 | Acc: 36.591,55.335,63.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.219 | Acc: 36.745,55.300,63.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.219 | Acc: 36.816,55.247,63.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.219 | Acc: 36.893,55.226,63.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.223 | Acc: 36.909,55.185,63.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.224 | Acc: 36.916,55.212,63.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.005 | Acc: 35.938,39.062,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.978 | Acc: 29.278,42.708,50.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.955 | Acc: 29.325,42.607,51.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.928 | Acc: 29.355,42.918,51.665,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 4.709 | Acc: 36.719,57.031,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.066 | Acc: 37.128,55.506,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.124 | Acc: 36.700,55.316,64.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.110 | Acc: 36.872,55.904,64.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.148 | Acc: 36.989,55.806,64.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.152 | Acc: 36.812,55.863,64.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.169 | Acc: 36.822,55.675,64.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.169 | Acc: 36.868,55.796,64.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.180 | Acc: 36.903,55.804,64.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.176 | Acc: 36.896,55.874,64.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.173 | Acc: 37.030,55.916,64.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.178 | Acc: 37.079,55.762,64.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.186 | Acc: 37.082,55.647,63.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.187 | Acc: 37.144,55.553,63.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.185 | Acc: 37.122,55.563,63.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.178 | Acc: 37.303,55.599,63.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.186 | Acc: 37.252,55.510,63.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.179 | Acc: 37.278,55.604,63.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.184 | Acc: 37.307,55.638,63.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.184 | Acc: 37.297,55.612,63.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.884 | Acc: 28.125,39.062,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.907 | Acc: 22.507,37.388,48.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.918 | Acc: 22.085,37.290,47.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.884 | Acc: 22.234,37.180,48.028,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 4.980 | Acc: 42.188,55.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.157 | Acc: 37.240,54.874,64.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.174 | Acc: 36.871,55.488,64.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.120 | Acc: 37.577,56.327,64.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.077 | Acc: 37.789,56.954,64.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.074 | Acc: 37.740,56.954,65.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.092 | Acc: 37.455,56.812,65.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.088 | Acc: 37.445,56.776,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.103 | Acc: 37.553,56.662,64.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.113 | Acc: 37.543,56.487,64.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.112 | Acc: 37.442,56.452,64.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.129 | Acc: 37.306,56.215,64.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.133 | Acc: 37.293,56.244,64.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.140 | Acc: 37.317,56.205,64.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.152 | Acc: 37.250,56.044,64.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.155 | Acc: 37.355,55.957,64.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.167 | Acc: 37.286,55.921,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.169 | Acc: 37.296,55.964,63.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.170 | Acc: 37.305,55.971,63.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.170 | Acc: 37.264,55.926,63.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.908 | Acc: 24.219,44.531,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.980 | Acc: 27.679,44.308,51.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.950 | Acc: 27.229,44.074,51.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.970 | Acc: 26.960,44.045,51.037,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 4.943 | Acc: 40.625,60.156,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.972 | Acc: 38.876,57.999,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.937 | Acc: 39.158,58.784,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.031 | Acc: 38.307,57.518,65.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.047 | Acc: 38.667,57.060,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.068 | Acc: 38.351,56.706,65.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.073 | Acc: 38.120,56.670,65.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.085 | Acc: 37.849,56.555,65.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.093 | Acc: 37.849,56.362,64.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.091 | Acc: 37.975,56.323,64.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.101 | Acc: 38.099,56.227,64.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.094 | Acc: 38.193,56.360,64.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.099 | Acc: 38.038,56.289,64.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.103 | Acc: 38.051,56.226,64.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.103 | Acc: 38.000,56.244,64.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.104 | Acc: 37.967,56.245,64.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.110 | Acc: 37.858,56.204,64.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.119 | Acc: 37.786,56.122,64.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.126 | Acc: 37.662,56.044,64.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.139 | Acc: 37.562,55.965,64.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.954 | Acc: 28.125,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.084 | Acc: 32.292,48.996,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.124 | Acc: 31.974,48.457,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.162 | Acc: 31.404,48.066,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 4.181 | Acc: 46.094,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.964 | Acc: 38.132,57.478,66.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.025 | Acc: 37.576,56.612,65.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.029 | Acc: 37.782,56.532,65.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.048 | Acc: 37.703,56.318,65.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.050 | Acc: 37.786,56.374,65.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.070 | Acc: 37.778,56.295,64.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.094 | Acc: 37.578,56.073,64.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.095 | Acc: 37.636,56.095,64.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.083 | Acc: 37.634,56.306,64.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.080 | Acc: 37.671,56.254,64.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.086 | Acc: 37.585,56.204,64.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.090 | Acc: 37.740,56.253,64.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.087 | Acc: 37.871,56.277,64.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.093 | Acc: 37.803,56.286,64.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.088 | Acc: 37.843,56.292,64.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.092 | Acc: 37.802,56.296,64.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.104 | Acc: 37.718,56.200,64.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.107 | Acc: 37.714,56.196,64.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.112 | Acc: 37.771,56.225,64.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.709 | Acc: 17.969,35.938,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.198 | Acc: 18.527,38.467,49.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.317 | Acc: 18.674,38.034,48.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.289 | Acc: 18.622,38.537,48.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 4.437 | Acc: 36.719,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.850 | Acc: 37.760,57.961,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.971 | Acc: 37.309,57.565,66.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.007 | Acc: 37.116,57.031,66.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.009 | Acc: 37.162,57.099,65.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.011 | Acc: 37.369,57.155,65.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.004 | Acc: 37.629,57.380,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.001 | Acc: 37.500,57.353,65.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.998 | Acc: 37.781,57.381,65.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.003 | Acc: 37.897,57.295,65.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.009 | Acc: 37.959,57.296,65.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.035 | Acc: 37.868,57.088,65.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.046 | Acc: 37.827,56.918,65.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.054 | Acc: 37.727,56.765,65.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.063 | Acc: 37.759,56.706,65.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.071 | Acc: 37.765,56.655,64.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.081 | Acc: 37.741,56.647,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.089 | Acc: 37.674,56.564,64.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.090 | Acc: 37.647,56.531,64.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.093 | Acc: 37.689,56.494,64.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.943 | Acc: 23.438,35.156,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.677 | Acc: 23.624,37.798,48.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.773 | Acc: 22.904,37.157,47.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.708 | Acc: 23.002,37.577,47.631,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 4.688 | Acc: 42.969,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.880 | Acc: 39.100,58.594,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.943 | Acc: 38.758,56.593,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.957 | Acc: 38.601,56.980,66.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.969 | Acc: 38.580,57.070,66.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.994 | Acc: 38.266,56.985,66.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.027 | Acc: 37.965,56.708,65.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.034 | Acc: 38.115,56.699,65.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.039 | Acc: 38.058,56.648,65.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.043 | Acc: 38.117,56.798,65.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.040 | Acc: 38.289,56.977,65.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.038 | Acc: 38.366,56.872,65.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.041 | Acc: 38.343,56.859,65.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.045 | Acc: 38.254,56.825,65.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.058 | Acc: 38.117,56.792,65.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.062 | Acc: 38.055,56.779,65.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.064 | Acc: 37.979,56.717,65.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.067 | Acc: 38.020,56.692,65.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.067 | Acc: 38.004,56.648,65.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.070 | Acc: 37.974,56.599,65.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.935 | Acc: 25.781,43.750,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.729 | Acc: 28.125,43.973,53.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.755 | Acc: 28.468,43.998,53.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.713 | Acc: 28.804,44.147,53.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 5.047 | Acc: 36.719,53.125,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.880 | Acc: 39.062,58.631,66.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.879 | Acc: 38.948,59.242,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.920 | Acc: 38.614,58.145,65.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.955 | Acc: 38.349,57.504,65.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.975 | Acc: 38.219,57.472,65.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.950 | Acc: 38.481,57.851,66.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.949 | Acc: 38.597,57.918,65.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.955 | Acc: 38.393,57.779,65.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.967 | Acc: 38.260,57.713,65.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.965 | Acc: 38.328,57.816,65.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.975 | Acc: 38.221,57.600,65.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.987 | Acc: 38.006,57.518,65.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.998 | Acc: 38.036,57.438,65.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.006 | Acc: 38.037,57.418,65.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.020 | Acc: 37.980,57.335,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.034 | Acc: 38.028,57.219,65.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.030 | Acc: 38.100,57.260,65.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.042 | Acc: 38.006,57.090,65.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.045 | Acc: 38.074,57.097,65.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.435 | Acc: 24.219,46.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.903 | Acc: 26.860,44.308,52.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.015 | Acc: 26.239,43.693,51.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.988 | Acc: 25.845,43.955,52.331,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.273 | Acc: 34.375,51.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.972 | Acc: 37.872,57.775,66.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.961 | Acc: 37.424,57.946,66.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.905 | Acc: 38.409,58.760,67.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.920 | Acc: 38.580,58.304,66.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.942 | Acc: 38.614,58.075,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.951 | Acc: 38.669,58.038,66.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.967 | Acc: 38.520,57.901,66.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.979 | Acc: 38.577,57.842,65.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.981 | Acc: 38.579,57.756,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.983 | Acc: 38.557,57.634,65.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.995 | Acc: 38.476,57.466,65.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.006 | Acc: 38.375,57.359,65.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.032 | Acc: 38.335,57.091,65.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.031 | Acc: 38.184,57.187,65.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.028 | Acc: 38.180,57.234,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.025 | Acc: 38.201,57.272,65.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.016 | Acc: 38.318,57.359,65.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.017 | Acc: 38.255,57.300,65.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.023 | Acc: 38.121,57.236,65.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.256 | Acc: 28.906,43.750,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.954 | Acc: 27.790,44.085,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.017 | Acc: 28.106,43.655,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.989 | Acc: 27.690,43.993,52.152,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 5.407 | Acc: 30.469,50.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.916 | Acc: 37.351,57.403,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.963 | Acc: 38.243,57.050,66.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.955 | Acc: 38.281,57.582,66.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.947 | Acc: 38.329,57.600,66.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.953 | Acc: 38.374,57.488,66.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.956 | Acc: 38.217,57.483,66.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.950 | Acc: 38.370,57.330,66.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.941 | Acc: 38.403,57.410,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.934 | Acc: 38.557,57.610,66.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.933 | Acc: 38.790,57.711,66.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.949 | Acc: 38.589,57.554,66.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.957 | Acc: 38.563,57.540,65.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.962 | Acc: 38.649,57.591,65.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.966 | Acc: 38.721,57.557,65.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.974 | Acc: 38.634,57.483,65.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.980 | Acc: 38.534,57.406,65.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.988 | Acc: 38.549,57.320,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.989 | Acc: 38.487,57.334,65.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.992 | Acc: 38.433,57.351,65.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.511 | Acc: 32.031,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.535 | Acc: 27.939,46.205,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.618 | Acc: 27.668,45.027,55.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.565 | Acc: 27.805,45.761,55.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.841 | Acc: 39.062,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.792 | Acc: 39.546,60.417,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.809 | Acc: 39.082,59.623,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.835 | Acc: 38.832,58.811,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.829 | Acc: 39.207,58.594,67.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.851 | Acc: 38.877,58.238,67.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.870 | Acc: 38.688,57.935,67.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.884 | Acc: 38.564,57.945,67.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.896 | Acc: 38.742,57.929,67.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.914 | Acc: 38.670,57.623,66.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.918 | Acc: 38.771,57.533,66.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.928 | Acc: 38.660,57.533,66.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.929 | Acc: 38.696,57.569,66.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.947 | Acc: 38.569,57.417,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.945 | Acc: 38.565,57.546,66.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.953 | Acc: 38.541,57.400,66.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.972 | Acc: 38.332,57.243,66.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.978 | Acc: 38.297,57.162,65.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.980 | Acc: 38.340,57.142,65.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.982 | Acc: 38.392,57.144,65.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.138 | Acc: 35.938,47.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.313 | Acc: 32.217,45.499,55.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.330 | Acc: 32.393,45.675,54.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.327 | Acc: 32.300,45.710,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 5.390 | Acc: 39.844,53.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.885 | Acc: 37.426,57.961,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.867 | Acc: 38.034,58.251,67.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.894 | Acc: 38.179,58.325,66.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.862 | Acc: 38.744,58.536,67.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.864 | Acc: 39.047,58.601,67.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.894 | Acc: 38.856,58.549,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.912 | Acc: 38.763,58.416,66.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.911 | Acc: 38.723,58.366,66.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.929 | Acc: 38.562,58.244,66.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.941 | Acc: 38.491,58.182,66.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.948 | Acc: 38.401,58.226,66.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.960 | Acc: 38.278,58.007,66.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.968 | Acc: 38.263,58.007,66.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.975 | Acc: 38.248,57.963,66.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.973 | Acc: 38.255,57.893,66.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.969 | Acc: 38.303,57.837,66.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.968 | Acc: 38.419,57.796,66.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.958 | Acc: 38.563,57.867,66.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.958 | Acc: 38.611,57.817,66.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.212 | Acc: 29.688,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.252 | Acc: 29.985,49.442,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.246 | Acc: 30.583,48.857,56.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.290 | Acc: 30.328,48.412,56.250,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 5.233 | Acc: 32.031,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.905 | Acc: 39.844,58.259,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.900 | Acc: 39.348,57.984,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.914 | Acc: 39.216,58.017,67.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.906 | Acc: 38.927,58.218,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.896 | Acc: 38.900,58.021,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.886 | Acc: 38.727,58.090,67.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.921 | Acc: 38.542,57.857,66.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.926 | Acc: 38.534,57.885,66.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.925 | Acc: 38.540,57.869,66.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.933 | Acc: 38.674,57.665,66.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.938 | Acc: 38.614,57.604,66.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.938 | Acc: 38.567,57.676,66.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.938 | Acc: 38.530,57.714,66.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.936 | Acc: 38.523,57.721,66.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.932 | Acc: 38.585,57.792,66.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.925 | Acc: 38.515,57.859,66.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.934 | Acc: 38.483,57.778,66.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.939 | Acc: 38.459,57.771,66.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.940 | Acc: 38.523,57.798,66.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.271 | Acc: 27.344,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.410 | Acc: 30.952,47.210,54.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.401 | Acc: 30.221,47.256,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.450 | Acc: 29.559,46.888,54.662,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.644 | Acc: 41.406,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.839 | Acc: 38.653,59.152,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.808 | Acc: 39.082,59.280,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.822 | Acc: 38.922,59.119,67.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.847 | Acc: 38.860,58.864,67.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.860 | Acc: 38.769,58.787,67.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.878 | Acc: 38.598,58.452,66.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.858 | Acc: 38.852,58.727,67.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.850 | Acc: 38.936,58.880,67.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.863 | Acc: 38.765,58.805,67.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.865 | Acc: 38.864,58.796,67.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.866 | Acc: 39.013,58.742,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.868 | Acc: 39.033,58.697,67.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.878 | Acc: 39.000,58.591,66.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.884 | Acc: 38.968,58.519,66.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.884 | Acc: 38.998,58.513,66.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.883 | Acc: 38.972,58.523,66.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.893 | Acc: 38.843,58.433,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.902 | Acc: 38.840,58.356,66.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.910 | Acc: 38.825,58.272,66.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.556 | Acc: 31.250,48.438,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.536 | Acc: 30.729,47.247,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.646 | Acc: 29.287,45.598,51.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.666 | Acc: 29.034,45.377,51.383,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.914 | Acc: 38.281,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.921 | Acc: 38.504,57.254,67.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.913 | Acc: 37.729,57.698,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.912 | Acc: 37.782,58.120,66.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.930 | Acc: 37.963,58.063,66.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.919 | Acc: 37.755,58.431,66.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.932 | Acc: 37.907,58.187,66.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.933 | Acc: 37.927,58.139,66.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.906 | Acc: 38.218,58.380,66.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.900 | Acc: 38.311,58.473,66.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.893 | Acc: 38.437,58.497,66.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.887 | Acc: 38.536,58.523,66.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.888 | Acc: 38.502,58.542,67.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.895 | Acc: 38.563,58.501,66.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.894 | Acc: 38.534,58.441,66.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.892 | Acc: 38.600,58.422,66.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.892 | Acc: 38.590,58.406,66.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.891 | Acc: 38.701,58.459,66.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.892 | Acc: 38.729,58.414,66.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.893 | Acc: 38.652,58.401,66.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.412 | Acc: 35.938,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.303 | Acc: 32.887,48.103,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.364 | Acc: 32.755,47.142,54.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.291 | Acc: 32.569,47.298,54.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 4.928 | Acc: 43.750,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.859 | Acc: 38.951,58.296,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.836 | Acc: 39.425,58.746,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.818 | Acc: 39.229,58.901,67.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.818 | Acc: 39.140,58.652,67.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.795 | Acc: 39.310,59.135,67.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.811 | Acc: 39.179,59.033,67.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.830 | Acc: 39.240,58.843,67.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.840 | Acc: 39.325,58.802,67.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.844 | Acc: 39.196,58.835,67.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.852 | Acc: 39.257,58.804,67.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.862 | Acc: 39.147,58.845,67.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.853 | Acc: 39.137,58.850,67.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.859 | Acc: 38.922,58.761,67.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.850 | Acc: 38.990,58.927,67.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.849 | Acc: 38.969,58.882,67.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.864 | Acc: 38.841,58.767,66.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.871 | Acc: 38.833,58.674,66.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.875 | Acc: 38.801,58.607,66.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.885 | Acc: 38.714,58.506,66.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.770 | Acc: 28.906,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.681 | Acc: 28.683,46.354,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.767 | Acc: 28.697,44.169,52.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.771 | Acc: 28.471,44.326,52.357,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.648 | Acc: 35.156,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.795 | Acc: 39.955,59.673,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.769 | Acc: 39.463,59.718,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.756 | Acc: 39.152,59.900,68.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.771 | Acc: 38.918,59.848,68.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.784 | Acc: 39.163,59.313,68.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.773 | Acc: 39.431,59.356,68.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.772 | Acc: 39.461,59.419,68.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.794 | Acc: 39.354,59.307,67.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.805 | Acc: 39.244,59.202,67.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.821 | Acc: 39.210,59.014,67.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.841 | Acc: 38.935,58.834,67.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.851 | Acc: 38.784,58.801,67.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.849 | Acc: 38.802,58.830,67.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.849 | Acc: 38.832,58.880,67.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.848 | Acc: 38.868,58.897,67.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.854 | Acc: 38.829,58.844,67.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.854 | Acc: 38.868,58.795,67.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.859 | Acc: 38.870,58.758,67.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.868 | Acc: 38.862,58.686,66.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.472 | Acc: 32.812,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.490 | Acc: 30.692,46.280,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.496 | Acc: 30.011,45.789,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.456 | Acc: 29.918,46.004,53.573,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 4.877 | Acc: 36.719,60.938,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.738 | Acc: 41.555,60.789,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.717 | Acc: 41.235,60.804,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.778 | Acc: 40.510,59.721,68.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.782 | Acc: 40.230,59.375,68.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.759 | Acc: 40.354,59.483,68.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.750 | Acc: 40.231,59.646,68.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.773 | Acc: 39.971,59.336,68.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.783 | Acc: 39.873,59.064,68.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.795 | Acc: 39.839,58.835,67.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.811 | Acc: 39.661,58.625,67.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.835 | Acc: 39.501,58.491,67.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.842 | Acc: 39.448,58.542,67.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.836 | Acc: 39.371,58.582,67.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.835 | Acc: 39.452,58.591,67.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.845 | Acc: 39.340,58.430,67.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.846 | Acc: 39.376,58.440,67.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.842 | Acc: 39.326,58.484,67.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.845 | Acc: 39.324,58.509,67.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.845 | Acc: 39.302,58.532,67.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.274 | Acc: 28.906,44.531,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.622 | Acc: 29.427,45.164,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.644 | Acc: 28.659,45.560,53.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.614 | Acc: 28.778,45.505,53.496,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 3.773 | Acc: 48.438,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.903 | Acc: 37.909,57.961,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.812 | Acc: 39.082,58.765,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.788 | Acc: 39.191,59.247,68.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.778 | Acc: 38.802,59.240,68.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.782 | Acc: 38.660,59.089,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.799 | Acc: 38.869,58.994,68.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.799 | Acc: 38.924,59.087,68.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.775 | Acc: 39.325,59.283,68.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.778 | Acc: 39.192,59.258,68.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.786 | Acc: 39.164,59.286,68.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.799 | Acc: 39.031,59.117,67.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.799 | Acc: 39.050,59.142,67.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.807 | Acc: 38.976,59.103,67.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.815 | Acc: 38.907,59.025,67.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.815 | Acc: 38.964,59.025,67.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.821 | Acc: 39.033,59.083,67.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.827 | Acc: 39.076,59.041,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.824 | Acc: 39.058,59.033,67.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.836 | Acc: 39.024,58.858,67.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.144 | Acc: 25.781,46.094,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.013 | Acc: 24.368,46.875,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.115 | Acc: 23.933,46.037,53.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.171 | Acc: 24.206,45.210,52.741,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 5.091 | Acc: 35.938,57.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.702 | Acc: 39.323,59.933,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 39.272,60.480,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.723 | Acc: 39.139,60.015,68.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.721 | Acc: 39.419,60.224,68.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.748 | Acc: 39.442,60.056,68.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.774 | Acc: 39.185,59.737,68.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.766 | Acc: 39.268,59.929,68.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.773 | Acc: 39.208,59.880,68.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.776 | Acc: 39.201,59.794,68.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.788 | Acc: 39.152,59.768,68.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.792 | Acc: 39.154,59.668,67.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.789 | Acc: 39.173,59.680,67.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.791 | Acc: 39.230,59.662,67.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.799 | Acc: 39.252,59.508,67.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.793 | Acc: 39.306,59.520,67.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.788 | Acc: 39.279,59.519,67.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.791 | Acc: 39.326,59.496,67.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.799 | Acc: 39.255,59.431,67.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.802 | Acc: 39.319,59.432,67.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.676 | Acc: 31.250,46.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.279 | Acc: 31.548,48.475,57.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.349 | Acc: 31.021,47.790,56.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.320 | Acc: 31.032,47.951,56.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 3.879 | Acc: 47.656,72.656,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.650 | Acc: 40.327,59.487,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 39.748,59.794,69.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 39.895,60.156,69.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.677 | Acc: 40.095,59.954,69.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.683 | Acc: 39.937,60.025,68.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.712 | Acc: 39.631,59.801,68.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.728 | Acc: 39.545,59.635,68.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.730 | Acc: 39.548,59.618,68.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.740 | Acc: 39.460,59.574,68.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.738 | Acc: 39.478,59.628,68.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.733 | Acc: 39.561,59.700,68.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.737 | Acc: 39.802,59.751,68.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.747 | Acc: 39.772,59.677,68.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.756 | Acc: 39.774,59.500,68.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.762 | Acc: 39.828,59.461,68.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.775 | Acc: 39.703,59.338,68.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.768 | Acc: 39.725,59.439,68.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.778 | Acc: 39.664,59.336,67.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.790 | Acc: 39.612,59.209,67.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.623 | Acc: 23.438,39.062,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.690 | Acc: 23.884,41.146,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.673 | Acc: 23.590,39.748,49.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.639 | Acc: 23.630,39.895,49.372,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 5.065 | Acc: 40.625,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.634 | Acc: 40.774,60.863,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.705 | Acc: 40.130,60.042,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.687 | Acc: 40.113,60.259,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.675 | Acc: 40.152,60.388,69.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.681 | Acc: 39.968,60.342,69.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.693 | Acc: 39.960,60.266,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.711 | Acc: 39.772,59.951,68.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.720 | Acc: 39.616,59.836,68.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.744 | Acc: 39.520,59.677,68.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.761 | Acc: 39.401,59.554,68.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.775 | Acc: 39.345,59.470,68.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.788 | Acc: 39.244,59.223,67.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.789 | Acc: 39.152,59.165,67.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.780 | Acc: 39.174,59.297,68.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.780 | Acc: 39.197,59.310,67.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.773 | Acc: 39.369,59.438,68.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.778 | Acc: 39.388,59.423,68.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.781 | Acc: 39.350,59.405,68.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.789 | Acc: 39.222,59.369,67.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.887 | Acc: 16.406,39.844,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.541 | Acc: 17.225,35.603,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.729 | Acc: 16.845,34.870,45.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.750 | Acc: 16.496,34.900,46.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.590 | Acc: 43.750,63.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.716 | Acc: 39.769,59.524,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.783 | Acc: 39.024,58.880,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.763 | Acc: 39.165,58.965,68.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.748 | Acc: 39.198,59.144,68.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.760 | Acc: 39.124,59.158,68.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.741 | Acc: 39.353,59.427,68.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.756 | Acc: 39.223,59.231,68.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.753 | Acc: 39.184,59.331,68.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.749 | Acc: 39.209,59.496,68.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.749 | Acc: 39.366,59.433,68.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.750 | Acc: 39.444,59.379,68.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.760 | Acc: 39.374,59.275,68.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.760 | Acc: 39.416,59.393,68.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.762 | Acc: 39.349,59.322,68.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.763 | Acc: 39.332,59.276,67.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.777 | Acc: 39.252,59.163,67.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.771 | Acc: 39.227,59.256,67.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.770 | Acc: 39.268,59.265,67.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.775 | Acc: 39.286,59.246,67.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.798 | Acc: 33.594,41.406,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.763 | Acc: 28.199,45.164,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.862 | Acc: 27.344,44.226,55.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.866 | Acc: 27.318,43.852,55.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.515 | Acc: 41.406,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.687 | Acc: 39.435,59.301,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 39.482,60.099,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 39.524,60.438,69.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.646 | Acc: 39.477,60.706,69.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.674 | Acc: 39.434,60.512,69.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.693 | Acc: 39.431,60.305,68.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.697 | Acc: 39.439,60.339,68.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.709 | Acc: 39.514,60.219,68.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.707 | Acc: 39.542,60.178,68.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.716 | Acc: 39.478,59.950,68.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.724 | Acc: 39.469,59.895,68.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.722 | Acc: 39.581,59.845,68.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.738 | Acc: 39.452,59.824,68.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.747 | Acc: 39.379,59.739,68.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.758 | Acc: 39.234,59.603,68.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.766 | Acc: 39.140,59.538,68.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.767 | Acc: 39.271,59.554,68.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.770 | Acc: 39.361,59.470,68.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.766 | Acc: 39.397,59.549,68.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.953 | Acc: 22.656,39.062,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.550 | Acc: 24.554,40.774,50.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.428 | Acc: 24.790,41.044,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.438 | Acc: 24.270,40.996,50.256,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 4.286 | Acc: 37.500,53.125,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 39.955,61.012,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.665 | Acc: 39.501,60.918,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 39.485,60.605,69.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.685 | Acc: 39.882,60.590,69.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.702 | Acc: 39.929,60.110,69.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.696 | Acc: 39.966,60.298,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.716 | Acc: 39.844,60.212,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.734 | Acc: 39.756,59.928,68.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.727 | Acc: 39.852,60.035,68.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.728 | Acc: 39.817,60.001,68.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.725 | Acc: 39.907,60.001,68.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.727 | Acc: 39.957,60.010,68.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.731 | Acc: 39.829,59.938,68.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.734 | Acc: 39.852,59.848,68.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.743 | Acc: 39.766,59.827,68.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.743 | Acc: 39.827,59.740,68.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.745 | Acc: 39.761,59.680,68.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.748 | Acc: 39.779,59.604,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.760 | Acc: 39.680,59.525,68.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.123 | Acc: 32.812,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.453 | Acc: 33.631,44.866,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.502 | Acc: 32.832,44.055,53.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.499 | Acc: 32.761,44.390,53.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 5.461 | Acc: 37.500,55.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.660 | Acc: 39.025,59.970,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 39.386,60.499,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 39.741,60.720,69.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.612 | Acc: 39.892,60.851,70.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.613 | Acc: 39.983,61.123,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.605 | Acc: 39.966,61.176,69.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.623 | Acc: 40.038,60.760,69.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.641 | Acc: 39.776,60.666,69.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.649 | Acc: 39.753,60.540,69.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.659 | Acc: 39.634,60.459,69.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.670 | Acc: 39.515,60.322,69.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.680 | Acc: 39.588,60.237,69.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.691 | Acc: 39.574,60.183,68.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.708 | Acc: 39.446,59.989,68.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.718 | Acc: 39.509,59.907,68.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.720 | Acc: 39.588,59.886,68.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.724 | Acc: 39.610,59.870,68.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.730 | Acc: 39.571,59.827,68.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.735 | Acc: 39.514,59.810,68.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.882 | Acc: 28.906,45.312,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.042 | Acc: 26.674,45.982,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.066 | Acc: 26.505,45.503,54.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.065 | Acc: 25.717,45.108,53.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.909 | Acc: 35.156,56.250,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 40.960,61.198,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 39.996,61.109,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 39.831,60.656,69.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.634 | Acc: 40.008,60.735,69.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.631 | Acc: 39.542,60.775,69.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.624 | Acc: 39.824,60.770,69.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.648 | Acc: 39.894,60.533,69.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.661 | Acc: 39.732,60.438,69.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.680 | Acc: 39.645,60.290,69.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.681 | Acc: 39.770,60.222,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.678 | Acc: 39.830,60.262,69.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.692 | Acc: 39.766,60.163,68.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.699 | Acc: 39.757,60.054,68.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.697 | Acc: 39.877,60.165,68.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.704 | Acc: 39.818,60.097,68.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.714 | Acc: 39.744,60.013,68.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.718 | Acc: 39.686,60.021,68.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.721 | Acc: 39.630,59.938,68.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.719 | Acc: 39.751,59.912,68.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.010 | Acc: 23.438,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.126 | Acc: 23.735,45.796,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.181 | Acc: 23.876,44.303,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.187 | Acc: 23.566,44.173,54.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.676 | Acc: 35.938,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 39.918,61.235,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.595 | Acc: 39.596,61.890,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.671 | Acc: 39.357,60.925,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.689 | Acc: 39.390,60.571,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.699 | Acc: 39.047,60.458,68.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.694 | Acc: 39.288,60.492,69.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.681 | Acc: 39.323,60.710,69.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.665 | Acc: 39.412,60.836,69.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.662 | Acc: 39.537,60.722,69.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.663 | Acc: 39.611,60.658,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.661 | Acc: 39.794,60.672,69.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.649 | Acc: 39.892,60.694,69.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.663 | Acc: 39.850,60.596,69.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.674 | Acc: 39.894,60.476,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.677 | Acc: 39.815,60.501,68.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.675 | Acc: 39.875,60.577,68.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.686 | Acc: 39.912,60.514,68.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.690 | Acc: 39.837,60.349,68.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.695 | Acc: 39.815,60.331,68.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.790 | Acc: 28.906,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.344 | Acc: 33.073,48.177,53.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.400 | Acc: 33.041,47.256,52.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.361 | Acc: 33.543,47.541,52.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 5.120 | Acc: 34.375,53.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 39.583,59.970,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.639 | Acc: 39.101,59.680,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 39.626,59.862,69.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.624 | Acc: 39.902,59.934,69.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.619 | Acc: 40.215,60.272,69.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.641 | Acc: 40.257,60.195,69.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.643 | Acc: 40.060,60.228,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.654 | Acc: 39.839,60.147,69.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.660 | Acc: 39.844,60.087,69.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.661 | Acc: 39.902,60.133,69.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.681 | Acc: 39.787,59.842,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.687 | Acc: 39.708,59.877,68.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.692 | Acc: 39.760,59.902,68.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.689 | Acc: 39.824,60.003,68.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.696 | Acc: 39.872,59.936,68.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.704 | Acc: 39.858,59.862,68.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.705 | Acc: 39.967,59.829,68.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.707 | Acc: 40.036,59.894,68.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.700 | Acc: 40.036,59.927,68.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.948 | Acc: 29.688,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.797 | Acc: 33.445,53.720,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.867 | Acc: 33.994,52.534,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.826 | Acc: 33.799,52.497,58.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.926 | Acc: 33.594,57.031,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 40.104,60.900,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 40.415,61.376,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.597 | Acc: 39.908,61.040,69.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.595 | Acc: 39.873,61.159,69.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.597 | Acc: 40.053,61.108,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.614 | Acc: 40.257,61.125,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.631 | Acc: 40.032,61.015,69.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.646 | Acc: 40.125,60.889,69.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.650 | Acc: 40.254,60.851,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.662 | Acc: 40.201,60.782,68.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.668 | Acc: 40.134,60.725,68.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.669 | Acc: 40.113,60.649,68.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.675 | Acc: 40.098,60.590,68.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.673 | Acc: 39.999,60.590,68.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.664 | Acc: 40.018,60.652,68.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.660 | Acc: 40.046,60.684,69.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.661 | Acc: 40.025,60.665,69.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.673 | Acc: 39.937,60.600,68.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.683 | Acc: 39.930,60.527,68.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.469 | Acc: 22.656,49.219,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.229 | Acc: 25.446,45.982,52.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.344 | Acc: 24.943,45.732,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.336 | Acc: 25.218,45.889,52.075,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.734 | Acc: 39.844,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.555 | Acc: 40.885,61.719,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.512 | Acc: 40.968,62.367,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.514 | Acc: 41.086,62.423,71.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.530 | Acc: 40.953,62.153,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.520 | Acc: 40.857,62.183,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.545 | Acc: 40.677,61.635,70.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.570 | Acc: 40.520,61.397,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.603 | Acc: 40.111,61.141,70.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.596 | Acc: 40.180,61.162,70.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.613 | Acc: 40.089,60.965,69.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.631 | Acc: 39.964,60.863,69.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.634 | Acc: 39.947,60.798,69.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.637 | Acc: 39.937,60.719,69.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.639 | Acc: 39.913,60.710,69.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.636 | Acc: 39.924,60.743,69.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.649 | Acc: 39.897,60.614,69.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.657 | Acc: 39.851,60.603,69.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.658 | Acc: 39.870,60.604,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.668 | Acc: 39.844,60.519,69.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.422 | Acc: 28.906,44.531,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.902 | Acc: 28.013,43.936,53.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.932 | Acc: 27.439,43.636,53.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.934 | Acc: 27.677,43.929,53.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.677 | Acc: 35.938,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 40.923,60.268,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 40.911,60.556,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 40.971,60.976,70.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.590 | Acc: 40.635,61.130,70.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.592 | Acc: 40.416,61.231,70.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.597 | Acc: 40.528,61.318,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.615 | Acc: 40.503,61.076,69.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.625 | Acc: 40.387,60.933,69.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.628 | Acc: 40.383,60.851,69.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.624 | Acc: 40.473,60.871,69.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.619 | Acc: 40.505,60.959,69.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.626 | Acc: 40.414,60.889,69.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.636 | Acc: 40.296,60.797,69.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.641 | Acc: 40.286,60.737,69.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.654 | Acc: 40.186,60.665,69.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.656 | Acc: 40.197,60.631,69.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.657 | Acc: 40.148,60.564,69.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.662 | Acc: 40.188,60.461,69.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.669 | Acc: 40.149,60.392,69.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.325 | Acc: 24.219,43.750,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.121 | Acc: 26.265,43.676,51.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.131 | Acc: 26.601,43.445,51.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.100 | Acc: 26.575,43.750,51.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.710 | Acc: 37.500,57.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.442 | Acc: 40.662,62.760,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.505 | Acc: 40.930,62.100,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 41.022,62.039,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.516 | Acc: 40.461,61.728,70.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.532 | Acc: 40.408,61.703,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.553 | Acc: 40.257,61.583,70.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.560 | Acc: 40.359,61.553,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.573 | Acc: 40.431,61.403,70.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.600 | Acc: 40.401,61.218,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.600 | Acc: 40.403,61.175,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.607 | Acc: 40.416,61.143,69.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.612 | Acc: 40.440,61.113,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.614 | Acc: 40.403,61.108,69.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.628 | Acc: 40.416,61.001,69.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.632 | Acc: 40.386,60.888,69.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.633 | Acc: 40.338,60.886,69.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.632 | Acc: 40.300,60.811,69.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.638 | Acc: 40.248,60.741,69.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.645 | Acc: 40.182,60.671,69.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.602 | Acc: 24.219,44.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.514 | Acc: 25.818,43.601,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.573 | Acc: 25.495,43.197,49.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.639 | Acc: 25.231,42.725,49.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 5.262 | Acc: 35.156,57.031,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.604 | Acc: 40.402,60.938,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.499 | Acc: 41.330,62.519,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.500 | Acc: 41.099,62.423,70.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.493 | Acc: 41.233,62.008,70.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.512 | Acc: 41.012,61.935,70.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.495 | Acc: 40.967,61.945,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.543 | Acc: 40.658,61.597,69.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.558 | Acc: 40.664,61.520,69.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.563 | Acc: 40.543,61.529,69.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.570 | Acc: 40.454,61.454,69.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.573 | Acc: 40.438,61.330,69.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.565 | Acc: 40.596,61.427,70.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.572 | Acc: 40.619,61.312,69.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.584 | Acc: 40.450,61.074,69.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.597 | Acc: 40.391,60.914,69.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.603 | Acc: 40.296,60.867,69.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.611 | Acc: 40.213,60.692,69.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.620 | Acc: 40.153,60.624,69.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.623 | Acc: 40.112,60.589,69.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.500 | Acc: 27.344,50.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.760 | Acc: 26.525,45.387,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.743 | Acc: 26.905,45.312,53.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.744 | Acc: 27.177,45.146,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 3.508 | Acc: 49.219,73.438,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.470 | Acc: 39.621,61.607,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.504 | Acc: 40.358,61.966,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 40.407,61.194,71.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.521 | Acc: 40.693,61.545,71.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.508 | Acc: 40.911,61.819,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.516 | Acc: 40.935,61.648,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.528 | Acc: 41.107,61.691,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.522 | Acc: 41.193,61.811,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.538 | Acc: 40.793,61.684,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.554 | Acc: 40.749,61.618,70.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.553 | Acc: 40.742,61.680,70.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.563 | Acc: 40.631,61.524,70.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.575 | Acc: 40.556,61.327,70.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.584 | Acc: 40.517,61.335,69.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.596 | Acc: 40.498,61.220,69.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.597 | Acc: 40.530,61.191,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.603 | Acc: 40.504,61.162,69.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.614 | Acc: 40.435,61.050,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.625 | Acc: 40.393,60.940,69.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.208 | Acc: 27.344,47.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.167 | Acc: 25.893,43.601,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.191 | Acc: 25.953,42.778,52.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.123 | Acc: 26.178,43.507,52.766,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.533 | Acc: 43.750,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 40.290,60.379,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.552 | Acc: 40.415,61.280,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.519 | Acc: 40.638,61.501,71.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.508 | Acc: 40.856,61.526,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.527 | Acc: 40.927,61.456,70.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.525 | Acc: 40.741,61.544,70.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.550 | Acc: 40.403,61.309,70.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.564 | Acc: 40.247,61.146,70.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.570 | Acc: 40.362,61.283,70.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.576 | Acc: 40.473,61.280,69.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.580 | Acc: 40.402,61.157,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.586 | Acc: 40.346,61.129,70.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.593 | Acc: 40.374,61.039,69.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.598 | Acc: 40.355,61.018,69.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.607 | Acc: 40.342,60.891,69.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.605 | Acc: 40.428,60.930,69.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.611 | Acc: 40.320,60.814,69.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.614 | Acc: 40.324,60.751,69.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.616 | Acc: 40.213,60.769,69.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.561 | Acc: 18.750,43.750,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.052 | Acc: 21.949,45.126,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.189 | Acc: 21.246,44.341,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.215 | Acc: 21.286,44.070,54.585,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.122 | Acc: 45.312,64.844,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.457 | Acc: 41.146,61.682,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.474 | Acc: 40.644,61.966,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 40.484,61.501,70.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.526 | Acc: 40.471,61.564,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.515 | Acc: 40.981,61.734,71.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.527 | Acc: 40.987,61.512,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.547 | Acc: 40.730,61.492,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.565 | Acc: 40.567,61.292,70.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.570 | Acc: 40.625,61.287,70.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.588 | Acc: 40.427,61.093,69.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.592 | Acc: 40.374,61.079,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.593 | Acc: 40.346,61.074,69.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.604 | Acc: 40.308,61.066,69.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.612 | Acc: 40.305,60.949,69.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.612 | Acc: 40.311,60.958,69.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.615 | Acc: 40.345,60.852,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.617 | Acc: 40.311,60.876,69.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.616 | Acc: 40.361,60.864,69.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.616 | Acc: 40.354,60.903,69.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.289 | Acc: 25.000,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.481 | Acc: 22.210,44.159,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.496 | Acc: 21.837,43.483,52.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.530 | Acc: 21.286,43.327,52.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.599 | Acc: 41.406,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 41.109,60.379,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 41.101,60.709,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 40.740,60.566,70.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.570 | Acc: 40.287,60.909,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.548 | Acc: 40.455,61.324,70.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.545 | Acc: 40.786,61.460,70.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.567 | Acc: 40.547,61.348,70.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.562 | Acc: 40.707,61.335,70.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.556 | Acc: 40.716,61.391,70.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.558 | Acc: 40.660,61.392,70.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.560 | Acc: 40.731,61.326,70.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.563 | Acc: 40.914,61.294,70.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.561 | Acc: 40.933,61.318,70.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.568 | Acc: 40.834,61.293,70.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.572 | Acc: 40.838,61.244,69.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.578 | Acc: 40.825,61.120,69.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.582 | Acc: 40.845,61.137,69.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.586 | Acc: 40.807,61.104,69.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.599 | Acc: 40.740,60.952,69.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.963 | Acc: 26.562,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.614 | Acc: 28.646,47.247,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.609 | Acc: 28.925,46.951,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.622 | Acc: 28.932,47.041,55.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.206 | Acc: 46.875,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.344 | Acc: 42.634,62.574,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.410 | Acc: 42.035,62.519,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.427 | Acc: 41.714,62.628,71.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.430 | Acc: 41.686,62.471,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.452 | Acc: 41.530,62.144,71.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.457 | Acc: 41.451,61.958,70.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.478 | Acc: 41.290,61.813,70.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.494 | Acc: 41.227,61.753,70.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.514 | Acc: 41.169,61.585,70.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.526 | Acc: 41.111,61.524,70.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.543 | Acc: 40.968,61.418,70.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.553 | Acc: 40.891,61.391,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.558 | Acc: 40.847,61.291,70.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 40.808,61.165,69.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.572 | Acc: 40.804,61.104,69.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.580 | Acc: 40.659,61.011,69.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.576 | Acc: 40.666,61.029,69.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.584 | Acc: 40.673,60.948,69.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.587 | Acc: 40.709,61.001,69.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.965 | Acc: 29.688,53.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.662 | Acc: 29.427,47.768,53.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.581 | Acc: 30.030,47.961,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.592 | Acc: 29.790,47.618,54.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 5.021 | Acc: 35.938,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.439 | Acc: 40.588,61.942,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.499 | Acc: 40.663,62.100,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.514 | Acc: 40.305,61.911,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.533 | Acc: 40.037,61.574,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.520 | Acc: 40.153,61.827,71.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.509 | Acc: 40.586,61.719,71.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.521 | Acc: 40.409,61.575,70.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.528 | Acc: 40.402,61.491,70.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.533 | Acc: 40.198,61.430,70.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.540 | Acc: 40.225,61.318,70.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.544 | Acc: 40.243,61.238,70.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.555 | Acc: 40.239,61.135,70.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.558 | Acc: 40.263,61.159,70.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.559 | Acc: 40.286,61.177,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.562 | Acc: 40.225,61.202,70.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.569 | Acc: 40.211,61.205,70.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.576 | Acc: 40.160,61.146,70.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.577 | Acc: 40.140,61.119,70.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.577 | Acc: 40.162,61.118,69.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.159 | Acc: 23.438,39.844,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.403 | Acc: 27.865,41.592,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.346 | Acc: 27.401,41.235,48.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.365 | Acc: 27.177,40.920,48.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.392 | Acc: 35.156,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.419 | Acc: 41.220,63.207,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.479 | Acc: 40.758,62.081,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.461 | Acc: 40.689,62.385,71.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.489 | Acc: 40.654,62.066,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.458 | Acc: 41.027,62.330,71.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.477 | Acc: 41.135,61.964,71.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.488 | Acc: 41.074,61.863,70.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.498 | Acc: 40.965,61.826,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.500 | Acc: 40.953,61.758,70.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.502 | Acc: 40.917,61.777,70.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.511 | Acc: 40.961,61.673,70.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.527 | Acc: 40.985,61.476,70.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.539 | Acc: 40.996,61.336,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.546 | Acc: 40.906,61.371,70.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.561 | Acc: 40.869,61.241,70.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.566 | Acc: 40.876,61.247,69.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.566 | Acc: 40.886,61.320,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.566 | Acc: 40.783,61.318,69.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.562 | Acc: 40.844,61.419,69.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.114 | Acc: 25.781,51.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.089 | Acc: 26.339,47.582,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.188 | Acc: 26.124,46.322,53.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.177 | Acc: 25.576,46.286,53.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.531 | Acc: 42.969,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.405 | Acc: 40.365,63.467,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.416 | Acc: 40.415,63.148,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.421 | Acc: 40.766,62.871,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.476 | Acc: 40.172,62.375,71.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.471 | Acc: 40.664,62.237,71.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.460 | Acc: 40.619,62.280,71.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.483 | Acc: 40.619,62.151,71.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.501 | Acc: 40.499,62.029,71.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.512 | Acc: 40.603,61.948,70.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.515 | Acc: 40.718,61.855,70.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.529 | Acc: 40.685,61.687,70.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.525 | Acc: 40.845,61.790,70.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.529 | Acc: 40.826,61.728,70.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.534 | Acc: 40.850,61.616,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.548 | Acc: 40.630,61.493,70.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.549 | Acc: 40.635,61.522,70.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.558 | Acc: 40.556,61.531,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.560 | Acc: 40.569,61.489,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.561 | Acc: 40.604,61.497,70.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.103 | Acc: 32.031,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.465 | Acc: 27.232,47.693,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.452 | Acc: 28.277,47.351,57.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.455 | Acc: 27.638,47.349,57.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.767 | Acc: 34.375,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 40.104,60.156,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.444 | Acc: 40.911,61.490,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 40.638,61.373,71.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.495 | Acc: 40.287,61.593,71.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.502 | Acc: 40.424,61.703,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.492 | Acc: 40.593,61.751,71.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.511 | Acc: 40.520,61.575,71.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.513 | Acc: 40.649,61.578,71.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.515 | Acc: 40.655,61.658,70.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.513 | Acc: 40.738,61.688,70.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.529 | Acc: 40.561,61.556,70.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.537 | Acc: 40.495,61.495,70.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.545 | Acc: 40.484,61.395,70.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.533 | Acc: 40.619,61.480,70.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.537 | Acc: 40.646,61.524,70.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.540 | Acc: 40.735,61.478,70.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.541 | Acc: 40.733,61.393,70.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.539 | Acc: 40.751,61.483,70.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.544 | Acc: 40.693,61.397,70.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.967 | Acc: 26.562,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.186 | Acc: 25.967,43.266,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.164 | Acc: 25.495,43.026,52.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.115 | Acc: 26.025,43.110,52.613,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 4.822 | Acc: 36.719,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.387 | Acc: 42.894,63.356,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.385 | Acc: 42.454,63.110,72.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.409 | Acc: 41.842,63.025,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.440 | Acc: 41.657,62.568,71.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.458 | Acc: 41.561,62.399,71.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.465 | Acc: 41.432,62.313,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.481 | Acc: 41.401,62.256,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.488 | Acc: 41.319,62.083,71.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.500 | Acc: 41.342,62.060,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.498 | Acc: 41.348,62.014,71.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.504 | Acc: 41.251,62.044,71.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.517 | Acc: 41.131,61.907,70.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.525 | Acc: 41.026,61.877,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.530 | Acc: 40.922,61.747,70.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.540 | Acc: 40.869,61.688,70.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.549 | Acc: 40.820,61.561,70.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.556 | Acc: 40.831,61.460,70.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.554 | Acc: 40.776,61.487,70.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.550 | Acc: 40.861,61.518,70.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.548 | Acc: 30.469,52.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.491 | Acc: 30.432,48.028,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.502 | Acc: 30.412,47.313,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.475 | Acc: 30.418,47.093,55.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 4.504 | Acc: 37.500,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.345 | Acc: 40.774,63.467,73.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 41.082,63.014,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.428 | Acc: 40.433,62.257,71.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.430 | Acc: 40.220,62.133,71.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.458 | Acc: 40.308,62.106,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.455 | Acc: 40.522,62.177,71.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.470 | Acc: 40.486,61.968,71.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.474 | Acc: 40.528,62.049,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.468 | Acc: 40.767,62.245,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.479 | Acc: 40.711,62.119,71.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.491 | Acc: 40.717,61.963,71.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.506 | Acc: 40.709,61.865,70.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.527 | Acc: 40.541,61.671,70.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.528 | Acc: 40.517,61.680,70.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.532 | Acc: 40.526,61.693,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.543 | Acc: 40.477,61.536,70.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.555 | Acc: 40.439,61.430,70.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.555 | Acc: 40.506,61.505,70.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.554 | Acc: 40.600,61.538,70.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.374 | Acc: 14.844,39.062,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.497 | Acc: 19.308,40.997,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.602 | Acc: 19.569,40.587,50.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.657 | Acc: 19.390,40.113,49.859,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.796 | Acc: 42.188,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.432 | Acc: 41.406,62.909,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.398 | Acc: 41.978,63.319,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.401 | Acc: 41.739,63.012,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.407 | Acc: 41.753,62.953,72.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.418 | Acc: 41.615,62.709,71.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.460 | Acc: 41.277,62.442,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.474 | Acc: 41.185,62.223,71.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.486 | Acc: 41.091,62.112,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.492 | Acc: 41.160,62.112,71.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.505 | Acc: 41.053,61.983,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.510 | Acc: 40.957,61.938,71.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.513 | Acc: 40.965,61.865,70.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.520 | Acc: 40.885,61.853,70.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.523 | Acc: 40.861,61.852,70.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.517 | Acc: 40.965,61.908,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.511 | Acc: 40.983,61.918,70.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.511 | Acc: 41.063,61.911,70.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.509 | Acc: 41.155,61.968,70.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.522 | Acc: 41.074,61.827,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.753 | Acc: 29.688,48.438,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.710 | Acc: 27.195,46.987,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.718 | Acc: 27.058,46.608,55.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.688 | Acc: 27.485,47.157,55.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 4.820 | Acc: 36.719,56.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 41.109,62.240,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.415 | Acc: 41.273,62.309,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.421 | Acc: 41.586,62.410,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.426 | Acc: 41.242,62.394,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.423 | Acc: 41.453,62.631,71.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.453 | Acc: 40.999,62.313,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.470 | Acc: 40.946,62.251,71.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.480 | Acc: 40.965,62.029,71.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.480 | Acc: 41.013,62.034,71.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.484 | Acc: 40.990,61.948,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.482 | Acc: 41.056,61.945,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.488 | Acc: 41.063,61.861,70.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.487 | Acc: 41.011,61.889,70.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.495 | Acc: 40.939,61.808,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.496 | Acc: 40.898,61.781,70.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.500 | Acc: 40.810,61.682,70.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.508 | Acc: 40.845,61.641,70.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.508 | Acc: 40.878,61.667,70.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.510 | Acc: 40.937,61.674,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.701 | Acc: 30.469,44.531,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.799 | Acc: 30.506,44.568,51.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.807 | Acc: 29.878,43.636,52.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.743 | Acc: 29.956,43.993,52.664,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.346 | Acc: 40.625,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.444 | Acc: 41.257,62.016,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.460 | Acc: 41.330,61.300,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.467 | Acc: 40.996,61.642,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.452 | Acc: 41.406,62.066,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.468 | Acc: 40.958,61.982,71.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.462 | Acc: 41.019,62.080,70.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.469 | Acc: 40.880,62.162,71.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.471 | Acc: 40.970,62.136,70.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.474 | Acc: 41.052,62.090,70.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.478 | Acc: 41.072,62.072,70.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.484 | Acc: 40.986,61.970,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.492 | Acc: 41.011,61.988,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.491 | Acc: 41.020,61.976,70.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.496 | Acc: 40.948,61.866,70.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.495 | Acc: 40.975,61.828,70.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.502 | Acc: 40.978,61.809,70.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.507 | Acc: 40.957,61.808,70.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.507 | Acc: 41.006,61.892,70.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.508 | Acc: 40.988,61.840,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.197 | Acc: 25.781,42.188,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.188 | Acc: 25.967,45.164,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.140 | Acc: 26.143,45.236,54.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.084 | Acc: 26.409,45.671,54.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 3.815 | Acc: 46.875,70.312,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.480 | Acc: 41.369,61.496,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.472 | Acc: 41.254,61.452,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.440 | Acc: 41.509,62.193,72.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.423 | Acc: 41.657,62.432,72.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.440 | Acc: 41.375,62.160,72.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.436 | Acc: 41.316,62.435,71.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.453 | Acc: 41.157,62.350,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.447 | Acc: 41.207,62.369,71.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.438 | Acc: 41.272,62.487,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.456 | Acc: 41.216,62.317,71.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.465 | Acc: 41.134,62.302,71.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.475 | Acc: 41.033,62.241,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.481 | Acc: 41.092,62.180,71.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.484 | Acc: 41.039,62.141,71.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.494 | Acc: 40.965,62.061,70.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.494 | Acc: 40.990,62.055,70.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.501 | Acc: 40.827,62.010,70.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.507 | Acc: 40.768,61.959,70.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.514 | Acc: 40.674,61.914,70.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.688 | Acc: 28.125,47.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.733 | Acc: 28.013,47.284,54.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.680 | Acc: 27.553,48.075,54.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.655 | Acc: 27.613,48.156,54.572,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 4.569 | Acc: 37.500,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 41.183,64.249,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 41.197,63.396,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 41.355,63.845,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.364 | Acc: 41.281,63.850,72.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.370 | Acc: 41.383,63.575,72.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.381 | Acc: 41.342,63.507,72.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.403 | Acc: 41.367,63.126,72.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.416 | Acc: 41.387,63.014,72.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.420 | Acc: 41.445,62.867,72.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.431 | Acc: 41.305,62.694,71.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.433 | Acc: 41.283,62.673,71.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.436 | Acc: 41.192,62.649,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.447 | Acc: 41.248,62.518,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.462 | Acc: 41.248,62.330,71.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.472 | Acc: 41.173,62.196,71.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.468 | Acc: 41.265,62.220,71.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.476 | Acc: 41.205,62.182,71.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.482 | Acc: 41.134,62.110,71.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.493 | Acc: 41.090,62.037,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.196 | Acc: 30.469,44.531,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.261 | Acc: 25.112,43.527,53.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.301 | Acc: 25.781,44.093,53.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.309 | Acc: 25.640,43.955,53.330,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.326 | Acc: 50.000,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.324 | Acc: 43.452,63.058,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 41.330,62.100,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.440 | Acc: 41.073,62.001,71.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.463 | Acc: 41.030,62.056,71.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.485 | Acc: 40.919,62.098,71.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.463 | Acc: 41.077,62.384,71.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.447 | Acc: 41.268,62.666,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.456 | Acc: 41.115,62.539,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.479 | Acc: 40.919,62.289,71.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.472 | Acc: 41.006,62.329,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.471 | Acc: 41.003,62.387,71.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.475 | Acc: 41.001,62.260,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.471 | Acc: 41.083,62.258,71.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.469 | Acc: 41.175,62.322,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.467 | Acc: 41.217,62.318,71.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.464 | Acc: 41.309,62.398,71.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.462 | Acc: 41.395,62.379,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.470 | Acc: 41.374,62.286,70.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.485 | Acc: 41.259,62.184,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.385 | Acc: 23.438,42.969,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.562 | Acc: 23.735,40.476,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.646 | Acc: 23.304,40.263,51.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.585 | Acc: 23.630,40.791,51.780,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.240 | Acc: 39.844,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.386 | Acc: 40.365,63.653,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 41.044,63.967,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.353 | Acc: 40.996,62.987,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.380 | Acc: 41.165,62.828,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.397 | Acc: 41.275,62.871,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.417 | Acc: 41.368,62.565,72.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.436 | Acc: 41.279,62.389,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.447 | Acc: 41.333,62.214,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.459 | Acc: 41.475,62.198,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.451 | Acc: 41.507,62.290,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.455 | Acc: 41.548,62.242,71.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.459 | Acc: 41.442,62.211,71.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.466 | Acc: 41.316,62.168,71.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.470 | Acc: 41.353,62.150,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.469 | Acc: 41.430,62.157,71.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.475 | Acc: 41.418,62.098,71.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.478 | Acc: 41.381,62.003,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.475 | Acc: 41.331,62.082,71.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.481 | Acc: 41.242,62.045,71.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.230 | Acc: 26.562,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.191 | Acc: 24.702,42.969,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.182 | Acc: 24.790,43.236,52.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.139 | Acc: 24.718,43.251,52.638,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.637 | Acc: 47.656,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.454 | Acc: 41.183,62.202,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 41.444,62.862,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.364 | Acc: 42.098,63.640,72.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.386 | Acc: 41.917,63.465,72.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.371 | Acc: 41.994,63.405,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.375 | Acc: 41.949,63.178,72.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.400 | Acc: 41.916,62.982,71.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.423 | Acc: 41.620,62.665,71.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.429 | Acc: 41.454,62.768,71.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 41.321,62.663,71.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.446 | Acc: 41.392,62.705,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.453 | Acc: 41.312,62.584,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.457 | Acc: 41.322,62.449,71.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.452 | Acc: 41.445,62.486,71.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.459 | Acc: 41.422,62.435,70.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.459 | Acc: 41.426,62.408,70.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.467 | Acc: 41.305,62.360,70.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.472 | Acc: 41.318,62.297,70.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.481 | Acc: 41.337,62.203,70.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.338 | Acc: 24.219,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.245 | Acc: 27.530,44.717,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.310 | Acc: 27.306,43.750,52.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.343 | Acc: 26.614,43.545,51.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 3.991 | Acc: 47.656,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.395 | Acc: 40.030,62.500,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 40.777,63.053,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.434 | Acc: 40.612,62.641,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.418 | Acc: 40.567,62.596,72.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.394 | Acc: 40.579,62.871,72.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.408 | Acc: 40.761,62.765,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.422 | Acc: 40.869,62.705,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.425 | Acc: 40.926,62.767,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.432 | Acc: 40.862,62.673,71.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.445 | Acc: 40.738,62.574,71.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.444 | Acc: 40.947,62.638,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.442 | Acc: 41.105,62.691,71.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.438 | Acc: 41.077,62.778,71.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.444 | Acc: 41.087,62.700,71.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.442 | Acc: 41.071,62.676,71.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.449 | Acc: 41.048,62.573,71.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.451 | Acc: 41.024,62.530,71.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.456 | Acc: 41.043,62.452,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.470 | Acc: 40.990,62.338,71.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.304 | Acc: 27.344,42.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.339 | Acc: 26.079,43.750,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.452 | Acc: 25.877,43.521,52.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.460 | Acc: 25.961,43.174,52.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.702 | Acc: 39.844,57.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 40.253,62.388,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 40.568,62.481,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.370 | Acc: 41.329,62.987,72.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.372 | Acc: 41.474,63.108,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.358 | Acc: 41.344,63.274,72.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.373 | Acc: 41.225,63.133,72.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.388 | Acc: 41.428,62.960,72.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.402 | Acc: 41.251,62.966,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.410 | Acc: 41.216,62.755,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.409 | Acc: 41.216,62.795,71.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.420 | Acc: 41.229,62.553,71.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.424 | Acc: 41.166,62.536,71.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.420 | Acc: 41.287,62.596,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.436 | Acc: 41.131,62.536,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.442 | Acc: 41.139,62.391,71.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.447 | Acc: 41.187,62.347,71.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.459 | Acc: 41.184,62.282,71.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.465 | Acc: 41.134,62.240,71.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.478 | Acc: 41.025,62.112,70.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.461 | Acc: 22.656,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.594 | Acc: 21.317,40.141,49.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.651 | Acc: 21.208,39.501,49.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.714 | Acc: 21.235,39.460,49.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.243 | Acc: 42.969,59.375,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.423 | Acc: 41.220,62.202,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.385 | Acc: 41.959,62.405,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.388 | Acc: 42.200,62.449,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.372 | Acc: 42.255,62.654,72.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.372 | Acc: 42.311,62.577,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.373 | Acc: 42.259,62.668,72.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.391 | Acc: 41.971,62.677,72.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.402 | Acc: 41.804,62.762,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.396 | Acc: 41.795,62.927,72.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.403 | Acc: 41.725,62.869,72.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.412 | Acc: 41.763,62.762,72.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.409 | Acc: 41.701,62.759,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.416 | Acc: 41.649,62.686,71.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.421 | Acc: 41.609,62.683,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.428 | Acc: 41.554,62.653,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.433 | Acc: 41.428,62.627,71.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.442 | Acc: 41.319,62.587,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.441 | Acc: 41.369,62.584,71.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.452 | Acc: 41.279,62.463,71.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.482 | Acc: 27.344,45.312,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.424 | Acc: 27.530,49.740,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.532 | Acc: 26.220,48.780,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.483 | Acc: 25.999,48.886,57.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 3.840 | Acc: 42.969,65.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.310 | Acc: 43.192,63.356,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.331 | Acc: 42.302,63.110,72.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.368 | Acc: 41.714,62.679,72.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.374 | Acc: 41.966,62.780,72.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.387 | Acc: 41.708,62.778,72.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.382 | Acc: 41.690,62.778,72.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.382 | Acc: 41.661,62.749,72.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.389 | Acc: 41.683,62.762,72.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.411 | Acc: 41.411,62.509,71.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.406 | Acc: 41.418,62.519,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.418 | Acc: 41.463,62.376,71.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.427 | Acc: 41.504,62.315,71.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.436 | Acc: 41.448,62.287,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.438 | Acc: 41.309,62.219,71.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.440 | Acc: 41.235,62.196,71.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.440 | Acc: 41.258,62.249,71.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.448 | Acc: 41.237,62.227,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.449 | Acc: 41.192,62.349,71.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.451 | Acc: 41.109,62.361,71.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.296 | Acc: 28.906,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.512 | Acc: 29.911,48.326,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.425 | Acc: 30.678,47.847,55.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.409 | Acc: 31.084,48.220,55.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 3.955 | Acc: 48.438,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.312 | Acc: 43.601,64.844,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.363 | Acc: 42.340,64.177,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 42.072,64.075,72.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.375 | Acc: 41.541,63.667,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.372 | Acc: 41.545,63.629,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.394 | Acc: 41.290,63.397,72.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.388 | Acc: 41.489,63.475,72.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.394 | Acc: 41.610,63.310,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.403 | Acc: 41.484,63.165,71.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.407 | Acc: 41.480,63.192,71.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.411 | Acc: 41.502,63.207,71.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.409 | Acc: 41.491,63.178,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.407 | Acc: 41.571,63.260,71.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.414 | Acc: 41.454,63.128,71.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.413 | Acc: 41.471,63.105,71.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.420 | Acc: 41.414,63.023,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.430 | Acc: 41.386,62.883,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.437 | Acc: 41.326,62.794,71.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.442 | Acc: 41.291,62.728,71.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.454 | Acc: 26.562,48.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.697 | Acc: 28.497,47.954,54.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.690 | Acc: 27.553,46.341,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.702 | Acc: 27.357,46.516,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.265 | Acc: 44.531,67.969,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.478 | Acc: 42.374,62.574,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.390 | Acc: 42.550,63.014,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.367 | Acc: 42.469,63.281,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.334 | Acc: 42.776,63.677,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.369 | Acc: 42.188,63.111,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.376 | Acc: 42.155,63.113,72.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.367 | Acc: 42.215,63.109,72.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.360 | Acc: 42.149,63.087,72.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.347 | Acc: 42.062,63.225,72.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.360 | Acc: 41.947,63.141,72.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.367 | Acc: 41.852,63.126,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.378 | Acc: 41.789,63.035,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.387 | Acc: 41.795,62.937,71.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.392 | Acc: 41.829,62.884,71.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.400 | Acc: 41.713,62.791,71.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.413 | Acc: 41.599,62.629,71.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.416 | Acc: 41.502,62.578,71.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.425 | Acc: 41.430,62.439,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.434 | Acc: 41.425,62.391,71.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.397 | Acc: 36.719,50.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.331 | Acc: 31.138,48.475,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.422 | Acc: 31.117,47.161,55.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.426 | Acc: 30.840,46.862,55.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.150 | Acc: 48.438,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.417 | Acc: 42.113,63.095,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.372 | Acc: 41.845,63.205,72.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.304 | Acc: 42.085,63.947,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.341 | Acc: 41.734,63.889,72.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 41.460,63.382,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.360 | Acc: 41.613,63.701,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.376 | Acc: 41.390,63.475,72.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.378 | Acc: 41.358,63.466,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.378 | Acc: 41.372,63.506,72.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.395 | Acc: 41.286,63.285,72.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.415 | Acc: 41.240,63.094,71.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.417 | Acc: 41.387,62.967,72.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.424 | Acc: 41.263,62.829,71.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.431 | Acc: 41.334,62.781,71.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.434 | Acc: 41.269,62.760,71.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.437 | Acc: 41.241,62.675,71.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.439 | Acc: 41.230,62.681,71.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.441 | Acc: 41.266,62.680,71.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.432 | Acc: 41.396,62.789,71.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.553 | Acc: 32.812,51.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.531 | Acc: 28.497,48.996,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.589 | Acc: 28.296,48.228,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.544 | Acc: 28.227,48.284,56.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.100 | Acc: 43.750,67.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.234 | Acc: 42.671,64.211,73.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.305 | Acc: 41.883,63.720,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.319 | Acc: 42.047,63.499,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.326 | Acc: 41.966,63.677,72.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.322 | Acc: 41.979,63.846,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.310 | Acc: 42.110,63.875,73.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.324 | Acc: 42.265,63.863,72.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.339 | Acc: 42.066,63.577,72.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.349 | Acc: 41.808,63.389,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.363 | Acc: 41.803,63.114,72.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.377 | Acc: 41.576,62.924,72.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.386 | Acc: 41.510,62.921,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.386 | Acc: 41.571,62.919,71.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.392 | Acc: 41.523,62.886,71.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.400 | Acc: 41.557,62.739,71.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.409 | Acc: 41.543,62.624,71.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.412 | Acc: 41.571,62.596,71.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.415 | Acc: 41.549,62.545,71.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.418 | Acc: 41.546,62.514,71.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.876 | Acc: 30.469,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.440 | Acc: 31.362,49.926,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.404 | Acc: 31.364,48.857,54.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.433 | Acc: 30.943,48.553,55.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.004 | Acc: 44.531,61.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.348 | Acc: 41.109,62.574,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.340 | Acc: 41.006,63.567,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.338 | Acc: 41.611,63.371,72.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.367 | Acc: 41.628,63.079,72.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 41.824,63.165,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.385 | Acc: 41.742,63.094,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.368 | Acc: 41.816,63.276,72.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.383 | Acc: 41.746,63.174,72.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.382 | Acc: 41.682,63.143,72.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.386 | Acc: 41.655,63.067,72.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.399 | Acc: 41.572,62.935,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.392 | Acc: 41.688,63.032,71.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.403 | Acc: 41.580,62.997,71.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.410 | Acc: 41.529,62.917,71.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.421 | Acc: 41.489,62.817,71.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.420 | Acc: 41.414,62.790,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.416 | Acc: 41.445,62.841,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.423 | Acc: 41.443,62.766,71.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.421 | Acc: 41.492,62.859,71.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.019 | Acc: 29.688,47.656,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.036 | Acc: 27.716,46.317,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.039 | Acc: 27.420,46.037,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.989 | Acc: 27.497,46.055,52.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 4.789 | Acc: 40.625,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.320 | Acc: 41.034,64.025,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.336 | Acc: 41.635,63.815,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.318 | Acc: 41.995,63.742,72.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.360 | Acc: 41.937,63.445,72.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.358 | Acc: 41.994,63.235,72.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.356 | Acc: 42.026,63.268,72.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.352 | Acc: 42.215,63.331,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.348 | Acc: 42.255,63.480,72.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.360 | Acc: 42.153,63.355,72.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 42.195,63.180,72.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.381 | Acc: 41.997,63.066,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.388 | Acc: 41.999,63.093,72.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.392 | Acc: 41.876,63.087,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.390 | Acc: 41.857,63.134,72.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.397 | Acc: 41.725,63.050,72.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.405 | Acc: 41.633,63.006,72.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.408 | Acc: 41.631,62.981,71.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.414 | Acc: 41.577,62.922,71.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.414 | Acc: 41.607,62.906,71.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.347 | Acc: 31.250,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.074 | Acc: 33.854,50.112,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.171 | Acc: 33.727,49.428,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.171 | Acc: 33.171,49.308,55.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 3.616 | Acc: 46.094,67.188,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.318 | Acc: 41.295,63.467,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.291 | Acc: 41.654,63.891,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.300 | Acc: 41.778,63.525,73.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.312 | Acc: 42.188,63.879,73.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.340 | Acc: 42.010,63.560,73.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.349 | Acc: 41.916,63.443,72.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.364 | Acc: 41.927,63.281,72.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.365 | Acc: 41.858,63.306,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.366 | Acc: 41.790,63.208,72.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.365 | Acc: 41.981,63.367,72.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.376 | Acc: 41.894,63.147,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.391 | Acc: 41.679,63.061,72.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.395 | Acc: 41.709,62.961,72.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.400 | Acc: 41.709,62.975,72.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.406 | Acc: 41.762,62.933,71.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.406 | Acc: 41.747,62.972,71.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.408 | Acc: 41.722,62.928,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.410 | Acc: 41.666,62.866,71.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.417 | Acc: 41.642,62.822,71.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.613 | Acc: 31.250,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.227 | Acc: 29.204,43.973,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.218 | Acc: 28.563,43.102,52.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.154 | Acc: 28.522,43.481,52.702,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.545 | Acc: 35.156,57.812,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.410 | Acc: 41.146,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.386 | Acc: 41.178,62.538,71.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 41.842,63.153,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.341 | Acc: 41.850,63.407,71.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.349 | Acc: 41.522,63.459,72.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.377 | Acc: 41.348,63.165,71.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.397 | Acc: 41.223,63.004,71.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.400 | Acc: 41.168,63.068,71.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.389 | Acc: 41.354,63.165,71.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.373 | Acc: 41.441,63.382,71.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.378 | Acc: 41.420,63.317,71.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.374 | Acc: 41.578,63.411,71.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.375 | Acc: 41.637,63.377,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.374 | Acc: 41.670,63.390,71.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.387 | Acc: 41.606,63.198,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.386 | Acc: 41.667,63.206,71.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.393 | Acc: 41.656,63.119,71.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.399 | Acc: 41.614,63.106,71.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.402 | Acc: 41.554,63.045,71.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.822 | Acc: 31.250,43.750,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.642 | Acc: 29.799,46.280,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.631 | Acc: 29.402,45.922,54.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.572 | Acc: 29.483,46.568,54.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.058 | Acc: 49.219,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.454 | Acc: 41.257,62.909,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.388 | Acc: 41.120,62.710,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.382 | Acc: 41.073,62.410,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.365 | Acc: 41.194,62.809,72.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.348 | Acc: 41.391,62.833,72.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.336 | Acc: 41.626,63.004,72.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.344 | Acc: 41.705,62.977,72.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.375 | Acc: 41.290,62.820,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.372 | Acc: 41.294,62.949,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.377 | Acc: 41.313,62.935,72.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.382 | Acc: 41.265,62.956,72.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.383 | Acc: 41.328,62.925,72.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.382 | Acc: 41.460,62.943,72.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.385 | Acc: 41.498,62.895,72.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.382 | Acc: 41.520,62.967,72.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.381 | Acc: 41.574,62.960,72.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.385 | Acc: 41.606,62.951,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.390 | Acc: 41.625,62.918,72.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.397 | Acc: 41.570,62.877,72.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.699 | Acc: 28.906,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.663 | Acc: 33.891,53.943,61.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.720 | Acc: 34.223,52.553,60.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.720 | Acc: 34.388,52.574,59.964,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 3.966 | Acc: 41.406,64.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.209 | Acc: 42.411,64.918,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 41.006,63.148,73.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.335 | Acc: 41.381,63.256,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.330 | Acc: 41.377,63.378,73.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.318 | Acc: 41.553,63.475,73.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.353 | Acc: 41.393,63.359,73.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.365 | Acc: 41.379,63.098,72.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.385 | Acc: 41.285,62.883,72.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.383 | Acc: 41.229,62.988,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.387 | Acc: 41.301,62.865,72.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.391 | Acc: 41.293,62.928,72.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.393 | Acc: 41.299,62.931,72.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.388 | Acc: 41.406,63.048,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.387 | Acc: 41.462,63.050,72.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.386 | Acc: 41.559,63.066,72.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.392 | Acc: 41.530,62.972,71.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.395 | Acc: 41.512,62.979,72.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.397 | Acc: 41.512,62.989,72.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.399 | Acc: 41.542,62.937,71.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.080 | Acc: 32.031,42.188,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.885 | Acc: 31.362,43.862,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.893 | Acc: 31.364,42.969,50.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.875 | Acc: 31.199,43.507,50.602,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 4.832 | Acc: 35.156,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.241 | Acc: 43.155,64.472,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.227 | Acc: 42.931,64.748,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.233 | Acc: 42.841,64.613,74.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.241 | Acc: 42.728,64.660,73.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.274 | Acc: 42.319,64.287,73.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.310 | Acc: 42.142,63.733,72.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.308 | Acc: 41.899,63.808,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.322 | Acc: 41.862,63.878,72.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.335 | Acc: 41.747,63.756,72.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.345 | Acc: 41.616,63.775,72.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.354 | Acc: 41.608,63.698,72.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.364 | Acc: 41.588,63.492,72.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 41.756,63.485,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.374 | Acc: 41.556,63.345,72.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.378 | Acc: 41.583,63.346,72.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.377 | Acc: 41.652,63.379,72.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.377 | Acc: 41.704,63.382,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.380 | Acc: 41.653,63.320,71.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.381 | Acc: 41.716,63.289,71.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.966 | Acc: 34.375,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.415 | Acc: 29.613,49.107,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.380 | Acc: 29.097,48.647,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.385 | Acc: 29.265,48.617,56.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.645 | Acc: 39.844,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.315 | Acc: 41.220,63.504,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.316 | Acc: 41.082,63.415,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.305 | Acc: 41.329,63.550,72.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.316 | Acc: 41.821,63.600,72.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.321 | Acc: 41.948,63.506,72.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.326 | Acc: 41.916,63.481,72.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.326 | Acc: 41.877,63.686,72.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.331 | Acc: 41.697,63.694,72.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.331 | Acc: 41.717,63.484,72.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.325 | Acc: 41.729,63.503,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.323 | Acc: 41.827,63.493,72.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.344 | Acc: 41.572,63.288,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.351 | Acc: 41.649,63.290,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.352 | Acc: 41.604,63.278,72.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.351 | Acc: 41.689,63.219,72.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.354 | Acc: 41.693,63.194,72.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.357 | Acc: 41.661,63.270,71.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.366 | Acc: 41.553,63.193,71.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.369 | Acc: 41.576,63.152,71.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.696 | Acc: 33.594,46.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.379 | Acc: 29.390,48.624,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.446 | Acc: 28.354,48.133,57.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.431 | Acc: 28.663,48.335,57.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 3.803 | Acc: 43.750,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.313 | Acc: 40.513,63.430,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.242 | Acc: 41.845,64.139,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 42.162,64.331,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.257 | Acc: 42.004,63.966,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.277 | Acc: 41.832,63.908,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.287 | Acc: 41.716,63.901,72.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.290 | Acc: 41.794,63.935,73.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.299 | Acc: 41.712,63.980,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.312 | Acc: 41.721,63.864,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.309 | Acc: 41.818,63.911,72.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.319 | Acc: 41.763,63.801,72.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.333 | Acc: 41.685,63.732,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.340 | Acc: 41.721,63.718,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.347 | Acc: 41.643,63.590,72.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.350 | Acc: 41.629,63.567,72.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.359 | Acc: 41.659,63.452,72.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.365 | Acc: 41.635,63.373,72.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.367 | Acc: 41.644,63.322,72.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.375 | Acc: 41.628,63.250,71.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.087 | Acc: 31.250,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.582 | Acc: 30.506,47.879,54.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.531 | Acc: 30.488,47.771,55.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.518 | Acc: 30.789,48.117,55.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.051 | Acc: 50.000,62.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.307 | Acc: 42.299,63.616,73.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.258 | Acc: 42.378,64.520,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.260 | Acc: 42.111,64.434,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.267 | Acc: 41.898,64.487,73.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.278 | Acc: 42.033,64.186,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.271 | Acc: 42.136,64.166,73.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.283 | Acc: 42.066,63.963,73.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.301 | Acc: 42.027,63.961,72.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.308 | Acc: 41.998,63.933,72.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.300 | Acc: 42.009,63.942,72.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.311 | Acc: 42.014,63.907,72.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.317 | Acc: 41.954,63.897,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.331 | Acc: 41.897,63.724,72.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.344 | Acc: 41.832,63.559,72.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.356 | Acc: 41.749,63.489,72.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.362 | Acc: 41.618,63.454,72.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.365 | Acc: 41.645,63.423,72.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.370 | Acc: 41.592,63.348,72.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.370 | Acc: 41.636,63.312,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.009 | Acc: 29.688,44.531,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.810 | Acc: 28.237,46.689,54.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.848 | Acc: 27.992,45.846,54.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.775 | Acc: 27.882,45.697,54.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.615 | Acc: 39.062,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.191 | Acc: 42.001,65.290,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.203 | Acc: 41.597,65.263,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.262 | Acc: 41.406,64.677,73.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.243 | Acc: 41.802,64.728,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.267 | Acc: 41.615,64.519,73.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.297 | Acc: 41.652,64.230,73.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.307 | Acc: 41.733,64.057,73.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.335 | Acc: 41.668,63.684,72.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.337 | Acc: 41.972,63.609,72.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.351 | Acc: 41.845,63.511,72.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.357 | Acc: 41.753,63.476,72.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.362 | Acc: 41.727,63.537,72.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.363 | Acc: 41.724,63.557,72.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.370 | Acc: 41.707,63.523,72.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.374 | Acc: 41.671,63.424,72.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.366 | Acc: 41.737,63.534,72.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.367 | Acc: 41.722,63.531,72.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.370 | Acc: 41.737,63.461,72.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.376 | Acc: 41.652,63.382,71.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.191 | Acc: 29.688,50.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.949 | Acc: 29.315,46.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.919 | Acc: 29.440,45.846,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.957 | Acc: 29.355,45.658,50.986,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.232 | Acc: 41.406,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.252 | Acc: 43.266,63.802,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.240 | Acc: 42.969,64.558,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.271 | Acc: 42.149,64.293,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.323 | Acc: 41.628,63.715,73.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.304 | Acc: 41.839,63.730,73.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.315 | Acc: 41.813,63.791,73.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.318 | Acc: 41.822,63.797,73.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.310 | Acc: 42.027,63.907,73.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.313 | Acc: 42.041,63.825,73.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.310 | Acc: 41.947,63.849,73.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.314 | Acc: 41.887,63.794,73.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.331 | Acc: 41.860,63.596,73.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.334 | Acc: 41.963,63.596,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.342 | Acc: 41.871,63.540,72.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.343 | Acc: 41.951,63.523,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.346 | Acc: 41.947,63.515,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.356 | Acc: 41.823,63.412,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.365 | Acc: 41.789,63.309,72.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.369 | Acc: 41.786,63.261,72.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.238 | Acc: 28.906,53.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.419 | Acc: 29.911,48.810,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.457 | Acc: 30.088,48.476,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.423 | Acc: 29.905,48.924,57.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 4.341 | Acc: 39.844,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.325 | Acc: 42.150,64.881,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.281 | Acc: 42.854,64.825,73.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.242 | Acc: 43.763,64.664,73.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.228 | Acc: 43.191,64.853,73.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 42.915,64.604,73.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.269 | Acc: 42.491,64.527,73.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.267 | Acc: 42.620,64.461,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.263 | Acc: 42.697,64.572,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.270 | Acc: 42.693,64.498,73.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.279 | Acc: 42.565,64.428,73.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.287 | Acc: 42.456,64.420,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.299 | Acc: 42.340,64.374,72.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.310 | Acc: 42.164,64.212,72.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.316 | Acc: 42.204,64.151,72.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.318 | Acc: 42.200,64.073,72.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.319 | Acc: 42.190,64.007,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.321 | Acc: 42.204,63.927,72.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.331 | Acc: 42.099,63.855,72.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.333 | Acc: 42.069,63.800,72.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.584 | Acc: 32.031,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.156 | Acc: 33.594,50.670,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.044 | Acc: 34.413,50.800,58.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.027 | Acc: 34.580,50.128,57.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 3.732 | Acc: 45.312,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.169 | Acc: 42.708,65.104,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.286 | Acc: 41.673,63.834,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 41.803,63.845,73.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.332 | Acc: 41.493,63.677,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.347 | Acc: 41.538,63.683,72.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.345 | Acc: 41.116,63.630,72.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.326 | Acc: 41.356,63.769,72.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.325 | Acc: 41.309,63.786,72.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.326 | Acc: 41.333,63.881,72.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.334 | Acc: 41.313,63.744,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.340 | Acc: 41.328,63.631,72.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.346 | Acc: 41.267,63.635,72.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.353 | Acc: 41.248,63.581,72.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.353 | Acc: 41.437,63.604,72.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.357 | Acc: 41.520,63.569,72.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.359 | Acc: 41.586,63.593,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.361 | Acc: 41.706,63.600,72.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.364 | Acc: 41.765,63.534,72.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.369 | Acc: 41.769,63.474,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.856 | Acc: 18.750,44.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.381 | Acc: 19.271,44.196,53.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.340 | Acc: 19.131,44.722,53.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.358 | Acc: 18.981,44.518,52.984,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.743 | Acc: 56.250,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.133 | Acc: 44.345,65.848,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.225 | Acc: 43.559,65.053,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.238 | Acc: 43.148,64.357,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.254 | Acc: 43.326,64.082,73.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 43.185,64.117,73.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.269 | Acc: 42.807,63.882,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.276 | Acc: 42.708,63.918,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.291 | Acc: 42.639,63.757,73.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.293 | Acc: 42.667,63.825,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.290 | Acc: 42.724,63.942,73.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.296 | Acc: 42.537,63.854,73.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.303 | Acc: 42.424,63.842,73.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.313 | Acc: 42.397,63.808,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.327 | Acc: 42.221,63.698,72.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.333 | Acc: 42.195,63.689,72.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.334 | Acc: 42.258,63.705,72.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.333 | Acc: 42.199,63.701,72.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.334 | Acc: 42.120,63.695,72.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.342 | Acc: 42.099,63.646,72.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.447 | Acc: 26.562,50.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.672 | Acc: 26.935,50.000,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.717 | Acc: 27.191,49.829,55.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.715 | Acc: 27.267,49.577,55.546,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 4.098 | Acc: 45.312,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.144 | Acc: 42.150,66.034,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 41.616,64.444,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 41.778,64.370,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.272 | Acc: 41.667,64.506,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.265 | Acc: 41.917,64.442,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 41.884,64.676,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.272 | Acc: 41.744,64.550,73.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.280 | Acc: 41.751,64.397,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.286 | Acc: 41.756,64.270,73.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.294 | Acc: 41.849,64.039,73.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.301 | Acc: 41.891,63.910,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.300 | Acc: 42.003,63.878,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.315 | Acc: 41.876,63.763,72.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.325 | Acc: 41.946,63.654,72.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.327 | Acc: 41.915,63.652,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.324 | Acc: 41.956,63.671,72.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.327 | Acc: 41.940,63.623,72.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.330 | Acc: 41.956,63.573,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.339 | Acc: 41.911,63.488,72.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.684 | Acc: 23.438,43.750,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.042 | Acc: 22.545,39.658,50.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.013 | Acc: 22.104,39.729,50.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.985 | Acc: 22.003,39.536,50.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.853 | Acc: 42.188,57.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.268 | Acc: 41.629,63.876,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.265 | Acc: 42.397,64.444,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.248 | Acc: 42.418,64.716,74.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.251 | Acc: 42.149,64.738,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.251 | Acc: 42.172,64.643,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.239 | Acc: 42.575,64.947,74.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.255 | Acc: 42.404,64.833,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.258 | Acc: 42.382,64.853,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.272 | Acc: 42.287,64.645,73.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.282 | Acc: 42.242,64.494,73.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.282 | Acc: 42.159,64.427,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.285 | Acc: 42.188,64.345,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.293 | Acc: 42.122,64.296,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.298 | Acc: 42.079,64.176,73.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.307 | Acc: 42.091,64.018,73.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.314 | Acc: 42.110,63.972,72.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.317 | Acc: 42.066,63.891,72.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.323 | Acc: 41.986,63.853,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.325 | Acc: 41.954,63.800,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.644 | Acc: 26.562,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.754 | Acc: 27.753,47.805,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.852 | Acc: 27.382,46.627,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.845 | Acc: 27.497,46.158,55.072,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 4.643 | Acc: 39.844,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.275 | Acc: 41.034,63.393,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.252 | Acc: 41.387,64.291,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.247 | Acc: 41.547,64.127,73.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.250 | Acc: 41.773,64.304,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.273 | Acc: 41.700,64.086,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.285 | Acc: 41.568,64.056,73.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.262 | Acc: 41.977,64.617,73.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.282 | Acc: 41.833,64.368,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.303 | Acc: 41.799,64.140,72.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.312 | Acc: 41.760,64.074,72.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.314 | Acc: 41.876,64.070,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.337 | Acc: 41.717,63.920,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.338 | Acc: 41.765,63.838,72.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.340 | Acc: 41.751,63.826,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.333 | Acc: 41.889,63.863,72.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.334 | Acc: 41.905,63.822,72.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.342 | Acc: 41.832,63.618,72.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.339 | Acc: 41.880,63.649,72.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.339 | Acc: 41.859,63.667,72.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.542 | Acc: 32.031,50.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.604 | Acc: 29.129,50.558,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.604 | Acc: 29.078,48.742,54.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.529 | Acc: 29.009,49.001,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 3.606 | Acc: 50.000,68.750,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.127 | Acc: 42.001,65.179,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.157 | Acc: 42.588,65.396,74.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.203 | Acc: 42.892,64.985,74.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.223 | Acc: 42.795,65.027,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.238 | Acc: 42.559,64.442,73.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.250 | Acc: 42.472,64.495,73.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.266 | Acc: 42.492,64.328,73.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.272 | Acc: 42.517,64.388,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.283 | Acc: 42.524,64.157,73.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.282 | Acc: 42.506,64.051,73.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.283 | Acc: 42.407,64.048,72.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.297 | Acc: 42.226,63.991,72.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.305 | Acc: 42.158,63.958,72.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.304 | Acc: 42.185,63.979,72.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.310 | Acc: 42.120,63.928,72.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.313 | Acc: 42.119,63.839,72.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.325 | Acc: 42.061,63.723,72.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.327 | Acc: 42.023,63.731,72.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.333 | Acc: 41.952,63.687,72.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.298 | Acc: 28.125,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.670 | Acc: 29.129,48.140,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.719 | Acc: 29.325,46.837,53.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.713 | Acc: 28.957,46.798,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 4.332 | Acc: 39.062,65.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 42.597,64.025,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.253 | Acc: 42.283,63.967,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.279 | Acc: 42.175,63.768,73.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.305 | Acc: 41.782,63.783,73.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.309 | Acc: 41.468,63.923,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.285 | Acc: 41.832,64.114,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.281 | Acc: 41.728,64.151,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.293 | Acc: 41.727,64.058,73.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.294 | Acc: 41.773,63.963,72.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.304 | Acc: 41.768,63.802,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.304 | Acc: 41.792,63.762,72.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.300 | Acc: 42.009,63.751,72.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.302 | Acc: 41.897,63.814,72.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.317 | Acc: 41.884,63.654,72.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.322 | Acc: 41.835,63.650,72.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.324 | Acc: 41.871,63.612,72.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.323 | Acc: 41.935,63.616,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.322 | Acc: 41.993,63.619,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.322 | Acc: 41.997,63.613,72.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.816 | Acc: 29.688,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.733 | Acc: 27.009,47.024,54.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.657 | Acc: 27.477,46.742,54.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.626 | Acc: 27.664,46.888,55.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.562 | Acc: 40.625,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 43.304,64.100,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.250 | Acc: 42.378,64.520,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.248 | Acc: 42.111,64.511,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.230 | Acc: 42.284,64.796,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.221 | Acc: 42.342,64.998,74.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.214 | Acc: 42.446,64.766,74.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.219 | Acc: 42.564,64.633,74.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.222 | Acc: 42.682,64.650,73.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.247 | Acc: 42.455,64.498,73.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.268 | Acc: 42.409,64.265,73.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.275 | Acc: 42.453,64.176,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.286 | Acc: 42.314,64.079,73.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.289 | Acc: 42.331,64.215,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.294 | Acc: 42.224,64.185,72.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.299 | Acc: 42.154,64.094,72.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.309 | Acc: 42.078,64.002,72.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.305 | Acc: 42.160,63.985,72.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.303 | Acc: 42.194,63.989,72.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.311 | Acc: 42.142,63.958,72.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.648 | Acc: 35.156,55.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.945 | Acc: 35.640,52.083,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.005 | Acc: 35.442,50.896,56.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.984 | Acc: 34.887,50.807,56.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.283 | Acc: 39.062,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.119 | Acc: 42.485,64.844,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.191 | Acc: 42.340,64.367,74.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 41.983,64.229,73.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.258 | Acc: 42.159,64.024,73.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.241 | Acc: 42.466,64.016,73.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 42.510,63.946,73.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.247 | Acc: 42.553,64.090,73.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.245 | Acc: 42.479,64.169,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.235 | Acc: 42.580,64.179,73.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.238 | Acc: 42.623,64.191,73.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.254 | Acc: 42.552,64.009,73.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.265 | Acc: 42.382,63.946,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.269 | Acc: 42.409,64.045,73.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.272 | Acc: 42.390,64.057,73.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.281 | Acc: 42.361,63.987,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.293 | Acc: 42.309,63.958,73.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.297 | Acc: 42.231,63.907,72.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.301 | Acc: 42.250,63.870,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.305 | Acc: 42.161,63.825,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.112 | Acc: 21.875,39.062,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.437 | Acc: 22.768,40.885,49.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.474 | Acc: 22.504,40.511,50.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.448 | Acc: 21.926,40.369,50.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.261 | Acc: 35.156,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.266 | Acc: 41.369,64.137,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 42.530,64.787,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.212 | Acc: 42.085,64.805,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.210 | Acc: 42.294,64.805,73.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.215 | Acc: 42.342,64.743,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.230 | Acc: 42.052,64.560,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.248 | Acc: 41.977,64.428,73.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.246 | Acc: 41.998,64.587,73.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.258 | Acc: 42.101,64.391,73.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.269 | Acc: 42.114,64.311,72.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.291 | Acc: 41.972,64.108,72.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.309 | Acc: 41.850,63.936,72.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.317 | Acc: 41.876,63.799,72.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.315 | Acc: 41.960,63.771,72.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.317 | Acc: 41.912,63.787,72.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.319 | Acc: 41.956,63.758,72.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.324 | Acc: 41.952,63.689,72.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.334 | Acc: 41.869,63.567,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.333 | Acc: 41.909,63.521,72.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.446 | Acc: 24.219,46.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.925 | Acc: 24.182,42.671,52.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.106 | Acc: 23.971,41.978,51.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.108 | Acc: 24.052,41.842,51.409,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 4.678 | Acc: 40.625,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.199 | Acc: 42.299,64.509,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.217 | Acc: 42.550,64.482,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.210 | Acc: 42.316,64.498,73.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 42.236,64.574,73.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.250 | Acc: 42.226,64.480,73.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.262 | Acc: 42.020,64.443,73.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.265 | Acc: 42.071,64.445,73.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.255 | Acc: 42.144,64.567,73.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.274 | Acc: 42.153,64.498,72.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.270 | Acc: 42.160,64.498,73.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.269 | Acc: 42.315,64.519,72.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.275 | Acc: 42.249,64.481,72.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.287 | Acc: 42.128,64.344,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.293 | Acc: 42.179,64.279,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.308 | Acc: 42.063,64.200,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.308 | Acc: 42.107,64.143,72.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.316 | Acc: 42.055,63.966,72.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.319 | Acc: 42.038,63.963,72.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.321 | Acc: 42.075,63.933,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.574 | Acc: 33.594,45.312,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.947 | Acc: 31.176,43.899,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.920 | Acc: 30.507,44.150,51.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.875 | Acc: 30.610,44.685,51.639,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 4.098 | Acc: 47.656,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.210 | Acc: 43.378,64.509,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.201 | Acc: 42.454,64.901,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.185 | Acc: 42.943,64.997,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.188 | Acc: 42.776,64.796,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.204 | Acc: 42.853,64.813,74.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.231 | Acc: 42.536,64.405,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.231 | Acc: 42.387,64.323,73.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.244 | Acc: 42.386,64.194,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.250 | Acc: 42.425,64.162,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.257 | Acc: 42.405,64.199,73.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 42.336,64.126,73.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.281 | Acc: 42.337,64.011,72.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.290 | Acc: 42.271,64.015,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.295 | Acc: 42.263,63.949,72.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.294 | Acc: 42.250,63.953,72.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.299 | Acc: 42.214,63.875,72.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.312 | Acc: 42.073,63.723,72.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.311 | Acc: 42.034,63.708,72.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.320 | Acc: 42.021,63.618,72.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.486 | Acc: 27.344,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.580 | Acc: 28.162,48.624,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.681 | Acc: 27.363,47.370,56.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.712 | Acc: 27.344,46.427,55.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 3.918 | Acc: 48.438,64.062,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.135 | Acc: 43.229,64.583,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.209 | Acc: 42.340,64.653,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.189 | Acc: 42.546,65.113,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.185 | Acc: 42.650,65.191,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.190 | Acc: 42.659,64.867,74.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.192 | Acc: 42.762,64.650,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.203 | Acc: 42.747,64.423,73.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.218 | Acc: 42.673,64.402,73.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.249 | Acc: 42.438,64.127,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.259 | Acc: 42.440,64.070,73.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.270 | Acc: 42.255,64.070,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.271 | Acc: 42.200,64.121,73.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.269 | Acc: 42.226,64.128,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.269 | Acc: 42.226,64.157,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.269 | Acc: 42.338,64.229,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.266 | Acc: 42.307,64.277,73.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.276 | Acc: 42.178,64.218,73.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.282 | Acc: 42.157,64.171,73.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.286 | Acc: 42.114,64.136,72.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.180 | Acc: 24.219,41.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.922 | Acc: 27.493,46.057,54.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.973 | Acc: 27.058,44.989,53.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.934 | Acc: 27.177,45.236,53.535,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 4.648 | Acc: 39.062,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.207 | Acc: 42.225,65.365,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.229 | Acc: 42.816,64.520,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.206 | Acc: 42.623,64.754,74.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.202 | Acc: 42.573,64.603,74.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.230 | Acc: 42.180,64.449,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.232 | Acc: 42.168,64.366,73.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.234 | Acc: 42.298,64.400,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.234 | Acc: 42.265,64.281,73.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.242 | Acc: 42.166,64.179,73.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.259 | Acc: 41.985,63.977,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.278 | Acc: 41.905,63.797,73.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.275 | Acc: 41.857,63.946,73.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.278 | Acc: 41.870,63.994,73.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.289 | Acc: 41.876,63.932,73.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.294 | Acc: 41.850,63.974,73.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.295 | Acc: 41.944,63.982,73.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.294 | Acc: 41.885,64.017,73.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.296 | Acc: 41.876,64.000,72.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.297 | Acc: 41.915,63.925,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.541 | Acc: 30.469,47.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.141 | Acc: 31.287,50.781,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.173 | Acc: 31.326,50.819,58.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.201 | Acc: 31.391,50.448,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 4.824 | Acc: 33.594,59.375,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.073 | Acc: 43.490,66.332,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.170 | Acc: 42.302,65.549,74.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 42.008,65.548,74.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.207 | Acc: 42.014,65.230,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.218 | Acc: 42.288,65.153,74.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.220 | Acc: 42.020,65.031,74.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.207 | Acc: 42.304,64.988,73.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.214 | Acc: 42.469,65.130,73.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.232 | Acc: 42.308,64.917,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.234 | Acc: 42.312,64.910,73.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.245 | Acc: 42.279,64.837,73.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.252 | Acc: 42.320,64.685,73.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.261 | Acc: 42.289,64.541,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.268 | Acc: 42.260,64.471,73.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.275 | Acc: 42.237,64.517,73.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 42.156,64.430,73.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 42.133,64.392,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.286 | Acc: 42.073,64.320,72.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.291 | Acc: 42.095,64.229,72.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.422 | Acc: 32.031,56.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.931 | Acc: 30.841,52.716,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.986 | Acc: 30.316,52.630,59.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.935 | Acc: 30.494,52.920,59.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 3.533 | Acc: 50.000,67.969,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.101 | Acc: 44.196,65.774,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.115 | Acc: 44.055,65.454,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.154 | Acc: 43.801,65.241,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.163 | Acc: 43.567,64.969,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.181 | Acc: 43.417,65.145,73.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.190 | Acc: 43.414,64.844,73.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.212 | Acc: 43.102,64.594,73.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.234 | Acc: 42.867,64.426,73.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.240 | Acc: 42.705,64.365,73.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.252 | Acc: 42.631,64.245,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.268 | Acc: 42.442,64.176,73.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.272 | Acc: 42.376,64.121,73.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.281 | Acc: 42.325,64.051,73.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.275 | Acc: 42.374,64.140,73.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.277 | Acc: 42.359,64.148,73.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.282 | Acc: 42.409,64.055,73.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.278 | Acc: 42.476,64.079,72.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.276 | Acc: 42.495,64.127,72.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.286 | Acc: 42.395,64.019,72.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.531 | Acc: 32.812,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.737 | Acc: 27.753,41.034,51.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.836 | Acc: 26.810,40.606,50.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.794 | Acc: 26.767,40.740,51.281,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.181 | Acc: 46.094,66.406,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.141 | Acc: 43.341,64.397,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.114 | Acc: 43.464,65.015,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.160 | Acc: 42.892,64.652,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.211 | Acc: 42.342,64.352,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.239 | Acc: 42.195,64.264,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.252 | Acc: 42.220,64.088,73.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.264 | Acc: 42.182,64.035,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.256 | Acc: 42.396,64.198,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.257 | Acc: 42.425,64.209,73.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.262 | Acc: 42.417,64.230,73.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.265 | Acc: 42.410,64.260,73.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.259 | Acc: 42.388,64.309,72.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.257 | Acc: 42.454,64.284,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.262 | Acc: 42.399,64.240,72.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.264 | Acc: 42.390,64.153,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.271 | Acc: 42.421,64.094,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.281 | Acc: 42.389,64.046,72.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.287 | Acc: 42.294,63.959,72.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.290 | Acc: 42.325,63.927,72.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.786 | Acc: 38.281,54.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.252 | Acc: 30.729,49.442,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.284 | Acc: 31.002,49.219,57.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.223 | Acc: 31.109,49.872,57.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 3.611 | Acc: 47.656,73.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.214 | Acc: 41.332,65.439,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.146 | Acc: 42.188,65.339,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.135 | Acc: 42.533,65.126,74.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.180 | Acc: 42.477,64.612,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.198 | Acc: 42.172,64.542,74.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.207 | Acc: 42.388,64.560,73.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.232 | Acc: 42.188,64.301,73.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.236 | Acc: 42.202,64.261,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.239 | Acc: 42.213,64.196,73.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.234 | Acc: 42.195,64.366,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.237 | Acc: 42.159,64.427,73.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.243 | Acc: 42.087,64.312,73.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.238 | Acc: 42.170,64.338,73.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.262 | Acc: 41.896,64.096,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.273 | Acc: 41.827,64.135,73.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.281 | Acc: 41.815,64.048,73.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 41.837,64.021,72.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 41.798,63.985,72.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.297 | Acc: 41.800,63.939,72.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.970 | Acc: 31.250,49.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.087 | Acc: 31.064,48.661,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.169 | Acc: 30.755,48.628,58.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.141 | Acc: 31.263,48.809,57.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 4.448 | Acc: 38.281,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.220 | Acc: 41.890,65.179,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.195 | Acc: 42.873,65.206,74.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.186 | Acc: 43.443,65.087,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.196 | Acc: 43.239,64.660,74.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.200 | Acc: 42.783,64.527,74.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.202 | Acc: 42.659,64.579,74.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.212 | Acc: 42.564,64.262,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.220 | Acc: 42.741,64.189,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.235 | Acc: 42.455,64.179,73.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.242 | Acc: 42.487,64.218,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.250 | Acc: 42.446,64.137,73.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.256 | Acc: 42.424,64.092,73.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.263 | Acc: 42.307,64.045,73.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.265 | Acc: 42.332,64.024,73.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.270 | Acc: 42.369,63.979,73.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.274 | Acc: 42.414,63.989,73.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.282 | Acc: 42.336,63.911,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 42.332,63.920,73.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.291 | Acc: 42.317,63.882,72.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.271 | Acc: 28.125,46.875,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.673 | Acc: 25.000,42.076,50.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.635 | Acc: 25.324,42.359,50.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.573 | Acc: 25.730,42.700,49.974,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.347 | Acc: 35.938,61.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.136 | Acc: 43.192,65.030,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.155 | Acc: 42.188,64.520,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.180 | Acc: 42.162,64.395,74.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.213 | Acc: 42.149,64.140,74.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.224 | Acc: 42.296,63.962,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.246 | Acc: 42.097,63.927,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.263 | Acc: 42.110,63.802,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.270 | Acc: 42.207,63.650,73.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.259 | Acc: 42.451,63.760,73.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.257 | Acc: 42.471,63.779,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.259 | Acc: 42.428,63.829,73.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.259 | Acc: 42.434,63.881,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 42.478,63.907,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.266 | Acc: 42.365,63.885,73.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.267 | Acc: 42.385,63.904,73.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.269 | Acc: 42.312,63.887,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.277 | Acc: 42.256,63.849,73.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.280 | Acc: 42.294,63.837,73.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.280 | Acc: 42.270,63.859,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.077 | Acc: 19.531,41.406,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.172 | Acc: 19.494,40.588,50.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.161 | Acc: 19.455,40.873,50.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.158 | Acc: 19.045,40.779,50.499,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.862 | Acc: 37.500,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.169 | Acc: 44.122,65.774,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.203 | Acc: 43.388,64.729,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.160 | Acc: 43.366,64.869,74.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.145 | Acc: 43.258,65.123,74.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.133 | Acc: 43.510,65.316,74.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.171 | Acc: 43.304,65.121,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.187 | Acc: 43.141,64.888,73.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.200 | Acc: 42.954,64.883,73.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.211 | Acc: 42.891,64.913,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.224 | Acc: 42.872,64.762,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.235 | Acc: 42.887,64.692,73.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.242 | Acc: 42.917,64.607,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.236 | Acc: 42.834,64.670,73.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.245 | Acc: 42.755,64.521,73.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.252 | Acc: 42.662,64.514,73.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.260 | Acc: 42.621,64.403,73.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.264 | Acc: 42.490,64.315,73.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.261 | Acc: 42.573,64.288,73.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.273 | Acc: 42.432,64.220,73.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.826 | Acc: 32.031,53.125,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.480 | Acc: 29.315,48.958,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.415 | Acc: 29.954,48.971,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.418 | Acc: 30.046,48.899,57.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 4.272 | Acc: 39.062,64.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.187 | Acc: 42.336,64.769,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.149 | Acc: 43.293,64.501,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.148 | Acc: 42.828,64.997,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.173 | Acc: 42.496,64.815,74.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.197 | Acc: 42.288,64.782,74.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.196 | Acc: 42.420,64.753,74.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.207 | Acc: 42.348,64.650,74.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.210 | Acc: 42.289,64.567,74.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.198 | Acc: 42.218,64.667,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.203 | Acc: 42.145,64.626,74.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.205 | Acc: 42.110,64.550,74.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.207 | Acc: 42.288,64.529,73.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.219 | Acc: 42.128,64.503,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.231 | Acc: 41.968,64.290,73.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.238 | Acc: 42.045,64.327,73.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.249 | Acc: 42.024,64.167,73.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.253 | Acc: 42.130,64.152,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.257 | Acc: 42.151,64.065,73.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.264 | Acc: 42.116,63.970,73.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.991 | Acc: 31.250,47.656,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.127 | Acc: 28.906,46.243,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.245 | Acc: 27.687,45.732,53.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.267 | Acc: 27.075,45.748,52.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 4.302 | Acc: 41.406,61.719,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.092 | Acc: 42.299,65.625,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.073 | Acc: 43.064,65.758,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.121 | Acc: 42.828,65.638,74.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.122 | Acc: 43.065,65.760,74.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.135 | Acc: 42.976,65.455,74.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.158 | Acc: 42.775,65.167,74.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.164 | Acc: 42.614,65.016,74.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.171 | Acc: 42.629,64.810,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.194 | Acc: 42.533,64.447,74.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.199 | Acc: 42.452,64.486,73.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.206 | Acc: 42.364,64.441,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.214 | Acc: 42.252,64.332,73.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.221 | Acc: 42.409,64.320,73.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.230 | Acc: 42.315,64.243,73.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.245 | Acc: 42.190,64.130,73.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.253 | Acc: 42.168,64.121,73.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.257 | Acc: 42.181,64.113,73.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.261 | Acc: 42.155,64.080,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.261 | Acc: 42.237,64.126,73.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.790 | Acc: 24.219,47.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.104 | Acc: 24.442,46.205,56.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.225 | Acc: 23.723,46.037,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.156 | Acc: 23.770,46.337,56.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.134 | Acc: 40.625,65.625,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.032 | Acc: 43.601,66.332,76.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.137 | Acc: 42.854,65.492,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.134 | Acc: 43.366,65.779,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.143 | Acc: 43.268,65.721,74.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.151 | Acc: 43.270,65.873,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.163 | Acc: 43.401,65.683,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.178 | Acc: 43.019,65.381,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.181 | Acc: 43.027,65.227,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.195 | Acc: 42.951,65.003,73.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.196 | Acc: 43.155,64.988,73.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.210 | Acc: 43.043,64.858,73.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.209 | Acc: 42.920,64.935,73.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.219 | Acc: 42.810,64.969,73.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.233 | Acc: 42.655,64.760,73.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.245 | Acc: 42.598,64.595,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.243 | Acc: 42.550,64.532,73.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.248 | Acc: 42.481,64.484,73.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.251 | Acc: 42.534,64.459,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.255 | Acc: 42.559,64.389,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.342 | Acc: 35.938,53.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.265 | Acc: 31.771,49.926,57.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.307 | Acc: 31.536,49.581,56.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.280 | Acc: 31.365,49.949,56.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 3.948 | Acc: 48.438,68.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.255 | Acc: 43.341,65.141,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.217 | Acc: 42.511,64.615,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.186 | Acc: 42.994,65.036,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.172 | Acc: 42.882,65.268,74.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.170 | Acc: 43.031,65.455,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.185 | Acc: 42.853,65.205,74.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.200 | Acc: 42.736,64.999,74.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.197 | Acc: 42.721,65.009,74.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.204 | Acc: 42.744,64.943,74.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.208 | Acc: 42.778,64.956,73.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.220 | Acc: 42.686,64.812,73.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.223 | Acc: 42.564,64.763,73.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.235 | Acc: 42.451,64.592,73.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.248 | Acc: 42.324,64.485,73.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.249 | Acc: 42.403,64.501,73.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.262 | Acc: 42.358,64.342,73.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.257 | Acc: 42.437,64.308,73.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.263 | Acc: 42.428,64.272,73.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.269 | Acc: 42.438,64.196,73.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.179 | Acc: 27.344,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.561 | Acc: 28.981,48.810,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.586 | Acc: 28.563,48.266,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.600 | Acc: 28.842,47.989,56.916,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.008 | Acc: 45.312,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.013 | Acc: 43.155,67.039,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.080 | Acc: 43.369,66.673,76.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.149 | Acc: 42.610,65.830,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.167 | Acc: 42.371,65.326,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.176 | Acc: 42.420,65.153,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.200 | Acc: 42.568,64.850,74.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.225 | Acc: 42.304,64.788,74.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.215 | Acc: 42.450,64.819,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.236 | Acc: 42.265,64.568,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.246 | Acc: 42.145,64.509,73.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.249 | Acc: 42.251,64.490,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.265 | Acc: 42.152,64.328,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.274 | Acc: 42.119,64.236,73.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.273 | Acc: 42.023,64.171,73.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.273 | Acc: 42.071,64.184,73.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.272 | Acc: 42.078,64.179,73.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.270 | Acc: 42.149,64.177,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.270 | Acc: 42.242,64.127,73.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.268 | Acc: 42.284,64.120,73.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.310 | Acc: 29.688,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.709 | Acc: 28.497,46.503,56.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.785 | Acc: 28.220,46.094,56.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.806 | Acc: 28.112,45.876,56.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.522 | Acc: 51.562,72.656,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.086 | Acc: 42.262,65.774,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.110 | Acc: 42.092,65.644,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.136 | Acc: 41.829,65.638,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.146 | Acc: 42.149,65.432,74.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.152 | Acc: 42.404,65.316,74.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.171 | Acc: 42.297,65.083,74.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.175 | Acc: 42.348,65.076,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.187 | Acc: 42.275,64.984,74.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.194 | Acc: 42.270,64.904,74.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.203 | Acc: 42.304,64.719,74.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.206 | Acc: 42.414,64.628,73.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.208 | Acc: 42.424,64.682,73.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.218 | Acc: 42.253,64.547,73.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.225 | Acc: 42.257,64.446,73.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.230 | Acc: 42.258,64.447,73.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.237 | Acc: 42.195,64.396,73.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.245 | Acc: 42.110,64.278,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.254 | Acc: 42.021,64.173,73.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.251 | Acc: 42.105,64.181,73.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.323 | Acc: 32.812,53.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.454 | Acc: 29.055,49.851,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.466 | Acc: 28.030,49.143,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.462 | Acc: 27.971,48.963,58.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.607 | Acc: 49.219,73.438,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.232 | Acc: 42.225,64.211,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.141 | Acc: 42.454,65.263,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.116 | Acc: 43.033,65.382,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.154 | Acc: 42.872,64.969,74.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.182 | Acc: 42.891,64.898,74.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.185 | Acc: 42.891,64.618,74.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.191 | Acc: 42.725,64.495,74.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.203 | Acc: 42.634,64.223,73.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.207 | Acc: 42.675,64.296,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.214 | Acc: 42.739,64.237,73.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.215 | Acc: 42.792,64.215,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.232 | Acc: 42.570,64.082,73.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.246 | Acc: 42.556,63.958,73.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.248 | Acc: 42.510,63.915,73.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.250 | Acc: 42.460,63.902,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.259 | Acc: 42.287,63.814,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.260 | Acc: 42.300,63.849,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.267 | Acc: 42.244,63.881,73.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.271 | Acc: 42.169,63.894,73.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.114 | Acc: 28.125,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.849 | Acc: 26.451,48.103,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.813 | Acc: 25.857,47.885,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.789 | Acc: 25.922,48.143,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 4.057 | Acc: 46.875,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.151 | Acc: 42.894,64.583,75.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.122 | Acc: 43.274,64.977,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.144 | Acc: 42.725,65.074,74.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.161 | Acc: 42.834,65.210,74.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.157 | Acc: 42.613,65.200,74.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.177 | Acc: 42.775,64.844,74.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.203 | Acc: 42.714,64.600,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.217 | Acc: 42.615,64.344,73.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.218 | Acc: 42.662,64.425,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.219 | Acc: 42.658,64.475,73.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.223 | Acc: 42.675,64.458,73.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.220 | Acc: 42.632,64.503,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.218 | Acc: 42.580,64.514,73.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.226 | Acc: 42.546,64.385,73.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.229 | Acc: 42.476,64.415,73.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.235 | Acc: 42.448,64.335,73.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.240 | Acc: 42.430,64.278,73.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.243 | Acc: 42.410,64.283,73.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.252 | Acc: 42.298,64.270,73.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.981 | Acc: 29.688,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.839 | Acc: 30.134,47.507,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.899 | Acc: 30.088,47.085,54.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.888 | Acc: 30.161,47.093,53.804,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 4.423 | Acc: 40.625,65.625,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.212 | Acc: 42.857,65.737,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.207 | Acc: 42.645,65.320,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.211 | Acc: 42.277,65.215,74.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.197 | Acc: 42.438,65.201,74.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.176 | Acc: 42.830,65.192,74.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.167 | Acc: 42.794,65.218,74.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.180 | Acc: 42.553,64.982,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.186 | Acc: 42.508,64.786,74.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.189 | Acc: 42.632,64.727,73.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.192 | Acc: 42.541,64.681,73.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.204 | Acc: 42.340,64.621,73.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.215 | Acc: 42.285,64.604,73.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.243 | Acc: 42.065,64.323,73.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.249 | Acc: 42.062,64.338,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.247 | Acc: 42.172,64.387,73.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.263 | Acc: 42.119,64.233,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.270 | Acc: 42.087,64.108,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.268 | Acc: 42.153,64.123,73.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.273 | Acc: 42.194,64.126,73.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.800 | Acc: 27.344,46.094,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.550 | Acc: 28.832,49.702,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.663 | Acc: 28.849,48.952,55.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.703 | Acc: 28.356,48.860,55.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.036 | Acc: 41.406,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.153 | Acc: 42.076,64.732,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.192 | Acc: 41.825,64.215,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.195 | Acc: 41.983,64.383,74.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.162 | Acc: 42.486,64.516,74.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.153 | Acc: 42.814,65.114,74.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.172 | Acc: 42.601,64.966,74.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.190 | Acc: 42.492,64.905,74.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.216 | Acc: 42.542,64.732,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.222 | Acc: 42.490,64.706,73.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.217 | Acc: 42.712,64.754,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.225 | Acc: 42.704,64.649,73.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.227 | Acc: 42.645,64.588,73.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.239 | Acc: 42.559,64.431,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.236 | Acc: 42.616,64.488,73.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.240 | Acc: 42.530,64.384,73.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.247 | Acc: 42.477,64.291,73.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.250 | Acc: 42.495,64.218,73.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.249 | Acc: 42.471,64.205,73.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.242 | Acc: 42.491,64.229,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.988 | Acc: 35.156,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.566 | Acc: 32.552,47.433,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.498 | Acc: 32.622,47.732,54.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.464 | Acc: 32.492,47.413,54.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.572 | Acc: 50.000,71.875,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.092 | Acc: 43.713,65.179,75.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.147 | Acc: 43.121,64.158,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.137 | Acc: 43.443,64.690,74.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.138 | Acc: 42.901,65.085,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.132 | Acc: 43.077,65.176,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.136 | Acc: 42.917,65.031,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.143 | Acc: 42.814,64.999,74.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.157 | Acc: 42.978,64.907,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.147 | Acc: 43.137,64.965,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.143 | Acc: 43.155,65.069,74.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.157 | Acc: 43.015,65.045,74.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.155 | Acc: 42.978,65.087,74.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.160 | Acc: 43.091,65.110,74.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.183 | Acc: 42.846,64.905,74.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.194 | Acc: 42.831,64.727,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.204 | Acc: 42.803,64.596,73.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.214 | Acc: 42.721,64.560,73.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.224 | Acc: 42.644,64.489,73.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.233 | Acc: 42.565,64.325,73.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.222 | Acc: 29.688,50.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.573 | Acc: 30.357,48.065,55.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.516 | Acc: 30.564,47.732,55.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.472 | Acc: 31.019,47.976,55.571,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.137 | Acc: 42.969,69.531,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.305 | Acc: 41.257,64.769,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.261 | Acc: 41.883,64.386,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.203 | Acc: 42.597,64.933,74.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.177 | Acc: 43.007,65.529,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.183 | Acc: 42.775,65.416,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.158 | Acc: 42.949,65.793,74.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.153 | Acc: 43.041,65.675,74.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.159 | Acc: 42.993,65.581,74.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.159 | Acc: 43.163,65.491,74.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.165 | Acc: 43.186,65.396,74.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.163 | Acc: 43.195,65.395,74.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.173 | Acc: 43.040,65.353,74.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.190 | Acc: 42.909,65.161,74.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.192 | Acc: 42.905,65.080,74.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.192 | Acc: 42.901,65.090,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.210 | Acc: 42.696,64.958,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.221 | Acc: 42.627,64.805,73.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.229 | Acc: 42.523,64.720,73.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.232 | Acc: 42.483,64.690,73.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.193 | Acc: 33.594,50.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.250 | Acc: 31.771,50.186,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.232 | Acc: 31.421,50.553,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.214 | Acc: 31.737,50.909,58.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 4.230 | Acc: 43.750,61.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.023 | Acc: 43.824,66.592,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.059 | Acc: 43.693,65.949,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.076 | Acc: 43.673,65.881,75.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.078 | Acc: 43.432,65.808,75.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.107 | Acc: 42.961,65.602,75.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.157 | Acc: 42.491,65.057,74.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.174 | Acc: 42.404,64.966,74.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.182 | Acc: 42.343,64.819,74.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.179 | Acc: 42.511,64.874,74.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.192 | Acc: 42.436,64.688,74.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.201 | Acc: 42.407,64.557,74.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.203 | Acc: 42.353,64.513,74.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.204 | Acc: 42.340,64.491,74.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.212 | Acc: 42.418,64.341,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.226 | Acc: 42.356,64.268,73.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.232 | Acc: 42.365,64.247,73.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.235 | Acc: 42.371,64.310,73.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.239 | Acc: 42.380,64.322,73.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.247 | Acc: 42.370,64.284,73.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.960 | Acc: 25.781,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.149 | Acc: 26.711,44.754,53.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.141 | Acc: 27.325,44.588,53.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.128 | Acc: 27.113,44.416,53.445,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.280 | Acc: 39.844,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.067 | Acc: 43.080,67.113,76.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.092 | Acc: 42.569,65.816,75.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.143 | Acc: 42.418,65.740,75.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.170 | Acc: 42.178,65.500,74.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.156 | Acc: 42.350,65.749,74.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.147 | Acc: 42.659,65.677,74.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.165 | Acc: 42.448,65.287,74.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.166 | Acc: 42.712,65.280,74.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.163 | Acc: 42.878,65.331,74.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.167 | Acc: 42.887,65.197,74.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.164 | Acc: 42.993,65.176,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.179 | Acc: 42.940,65.103,74.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.198 | Acc: 42.780,64.826,74.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.210 | Acc: 42.663,64.669,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.213 | Acc: 42.678,64.688,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.214 | Acc: 42.643,64.651,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.222 | Acc: 42.611,64.612,73.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.225 | Acc: 42.635,64.530,73.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.232 | Acc: 42.591,64.425,73.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.793 | Acc: 27.344,50.781,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.659 | Acc: 29.278,47.991,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.773 | Acc: 28.182,47.809,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.785 | Acc: 27.997,47.464,56.519,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.049 | Acc: 39.062,67.969,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.097 | Acc: 42.671,65.923,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.072 | Acc: 42.873,66.349,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.100 | Acc: 42.713,66.265,74.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.120 | Acc: 42.699,65.982,74.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.159 | Acc: 42.744,65.501,74.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.158 | Acc: 42.594,65.748,74.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.167 | Acc: 42.537,65.836,74.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.166 | Acc: 42.561,65.853,74.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.183 | Acc: 42.386,65.586,74.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.180 | Acc: 42.576,65.512,73.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.189 | Acc: 42.495,65.356,73.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.197 | Acc: 42.479,65.168,73.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.201 | Acc: 42.415,65.116,73.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.204 | Acc: 42.485,65.033,73.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.209 | Acc: 42.528,65.036,73.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.217 | Acc: 42.543,64.902,73.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.222 | Acc: 42.531,64.867,73.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.233 | Acc: 42.523,64.710,73.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.235 | Acc: 42.514,64.688,73.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.965 | Acc: 25.000,45.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.389 | Acc: 20.275,42.597,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.417 | Acc: 19.284,42.873,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.332 | Acc: 19.378,43.033,52.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.452 | Acc: 39.844,59.375,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.063 | Acc: 44.196,66.257,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.923 | Acc: 44.836,67.778,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.846 | Acc: 45.210,68.635,77.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.801 | Acc: 45.467,68.875,78.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.768 | Acc: 45.815,69.369,78.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.732 | Acc: 45.784,69.867,79.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.709 | Acc: 45.977,70.085,79.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.686 | Acc: 46.205,70.380,79.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.675 | Acc: 46.210,70.554,79.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.661 | Acc: 46.276,70.666,80.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.651 | Acc: 46.207,70.694,80.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.640 | Acc: 46.272,70.747,80.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.629 | Acc: 46.351,70.995,80.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.618 | Acc: 46.483,71.094,80.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.609 | Acc: 46.553,71.159,80.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.601 | Acc: 46.576,71.203,80.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.594 | Acc: 46.538,71.224,81.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.586 | Acc: 46.514,71.323,81.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.577 | Acc: 46.514,71.426,81.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 46.094,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.447 | Acc: 43.601,62.984,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.447 | Acc: 43.274,62.691,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.418 | Acc: 43.737,63.115,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.537 | Acc: 42.969,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.440 | Acc: 46.057,71.763,84.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.397 | Acc: 47.104,73.190,83.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.392 | Acc: 47.605,73.284,83.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.392 | Acc: 47.714,73.553,83.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.386 | Acc: 47.942,73.422,83.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.393 | Acc: 47.908,73.179,83.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.394 | Acc: 47.939,73.305,83.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.397 | Acc: 47.792,73.311,83.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.400 | Acc: 47.699,73.230,83.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.394 | Acc: 47.551,73.220,83.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.396 | Acc: 47.472,73.176,83.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.388 | Acc: 47.608,73.266,83.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.392 | Acc: 47.581,73.315,83.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.396 | Acc: 47.512,73.271,83.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.394 | Acc: 47.469,73.305,83.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.395 | Acc: 47.464,73.306,83.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.395 | Acc: 47.468,73.277,83.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.391 | Acc: 47.459,73.349,83.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.386 | Acc: 47.482,73.425,83.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.509 | Acc: 46.094,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.426 | Acc: 44.085,64.025,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.433 | Acc: 43.293,63.681,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.399 | Acc: 43.366,63.755,70.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.159 | Acc: 46.875,71.875,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.311 | Acc: 47.173,74.330,84.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.315 | Acc: 47.752,74.295,85.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.332 | Acc: 47.861,74.103,84.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.333 | Acc: 47.454,73.978,84.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.322 | Acc: 47.571,74.056,85.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.327 | Acc: 47.727,73.909,85.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.327 | Acc: 47.573,74.086,85.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.319 | Acc: 47.613,74.151,85.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.324 | Acc: 47.812,74.171,84.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.318 | Acc: 47.975,74.215,85.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.314 | Acc: 47.907,74.268,85.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.310 | Acc: 47.757,74.267,85.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.308 | Acc: 47.767,74.225,85.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.306 | Acc: 47.792,74.274,85.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.301 | Acc: 47.833,74.328,85.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.302 | Acc: 47.814,74.297,85.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.304 | Acc: 47.762,74.221,85.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.300 | Acc: 47.777,74.264,85.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.308 | Acc: 47.746,74.225,84.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 48.438,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.401 | Acc: 43.787,63.839,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.406 | Acc: 43.407,63.777,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.374 | Acc: 43.494,63.832,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.213 | Acc: 47.656,74.219,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.184 | Acc: 47.768,75.930,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.189 | Acc: 48.514,75.762,85.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.188 | Acc: 48.502,75.999,86.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.210 | Acc: 48.553,75.588,86.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.226 | Acc: 48.352,75.333,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.230 | Acc: 48.405,75.174,86.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.232 | Acc: 48.620,75.000,86.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.233 | Acc: 48.525,75.034,85.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.236 | Acc: 48.502,74.987,85.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.234 | Acc: 48.414,75.047,85.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.237 | Acc: 48.441,75.018,85.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.252 | Acc: 48.275,74.867,85.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.251 | Acc: 48.399,74.895,85.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.252 | Acc: 48.435,74.833,85.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.249 | Acc: 48.417,74.901,85.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.257 | Acc: 48.335,74.861,85.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.263 | Acc: 48.284,74.810,85.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.263 | Acc: 48.303,74.786,85.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.262 | Acc: 48.327,74.764,85.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 48.438,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.465 | Acc: 43.638,63.579,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.436 | Acc: 43.331,63.891,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.405 | Acc: 43.404,64.011,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 2.946 | Acc: 50.000,76.562,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.226 | Acc: 48.214,74.888,86.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.254 | Acc: 47.847,74.505,86.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.222 | Acc: 48.143,74.513,86.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.236 | Acc: 47.946,74.402,86.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.231 | Acc: 48.144,74.613,86.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.238 | Acc: 47.992,74.567,86.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.228 | Acc: 48.227,74.773,86.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.226 | Acc: 48.277,74.733,86.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.228 | Acc: 48.084,74.711,86.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.223 | Acc: 48.076,74.736,86.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.233 | Acc: 47.974,74.604,86.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.229 | Acc: 48.172,74.763,86.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.234 | Acc: 48.066,74.755,86.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.229 | Acc: 48.132,74.828,86.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.233 | Acc: 48.199,74.818,86.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.232 | Acc: 48.197,74.786,86.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.238 | Acc: 48.167,74.748,86.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.233 | Acc: 48.234,74.777,86.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.237 | Acc: 48.198,74.727,86.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.421 | Acc: 43.750,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.451 | Acc: 43.304,63.876,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.444 | Acc: 43.350,63.853,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.415 | Acc: 43.494,64.050,70.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.532 | Acc: 42.969,71.094,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.249 | Acc: 49.628,75.112,85.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.230 | Acc: 49.085,74.962,86.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.204 | Acc: 49.308,75.128,86.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.203 | Acc: 48.978,75.164,86.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.215 | Acc: 49.010,74.954,86.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.209 | Acc: 48.806,74.987,86.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.198 | Acc: 49.025,75.155,86.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.203 | Acc: 48.797,75.019,86.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.198 | Acc: 48.804,75.073,86.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.200 | Acc: 48.710,75.066,86.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.193 | Acc: 48.742,75.152,86.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.203 | Acc: 48.707,75.110,86.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.196 | Acc: 48.788,75.216,86.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.194 | Acc: 48.841,75.217,86.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.195 | Acc: 48.718,75.174,86.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.196 | Acc: 48.683,75.158,86.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.201 | Acc: 48.609,75.080,86.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.201 | Acc: 48.537,75.097,86.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.207 | Acc: 48.433,74.984,86.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.361 | Acc: 46.094,62.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.399 | Acc: 44.308,64.100,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.404 | Acc: 43.921,64.215,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.382 | Acc: 43.584,64.229,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 2.670 | Acc: 53.125,78.906,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.122 | Acc: 48.698,76.079,88.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.096 | Acc: 49.181,76.181,87.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.100 | Acc: 49.052,76.473,87.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.132 | Acc: 48.601,76.022,87.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.135 | Acc: 48.700,75.944,87.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.135 | Acc: 49.077,75.743,87.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.148 | Acc: 48.831,75.715,87.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.157 | Acc: 48.578,75.500,87.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.157 | Acc: 48.476,75.509,87.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.157 | Acc: 48.515,75.552,87.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.171 | Acc: 48.512,75.421,87.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.179 | Acc: 48.509,75.370,87.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.178 | Acc: 48.497,75.350,86.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.177 | Acc: 48.515,75.400,86.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.175 | Acc: 48.544,75.428,86.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.181 | Acc: 48.403,75.428,86.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.190 | Acc: 48.261,75.289,86.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.186 | Acc: 48.269,75.333,86.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.185 | Acc: 48.288,75.318,86.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.348 | Acc: 46.875,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.456 | Acc: 43.638,63.616,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.467 | Acc: 43.331,63.605,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.437 | Acc: 43.391,63.678,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.456 | Acc: 52.344,70.312,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.167 | Acc: 48.512,75.223,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.148 | Acc: 48.914,75.781,87.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.124 | Acc: 48.604,76.165,87.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.126 | Acc: 48.592,75.945,87.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.099 | Acc: 48.832,76.392,87.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.102 | Acc: 48.948,76.537,87.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.097 | Acc: 48.903,76.601,87.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.102 | Acc: 48.996,76.490,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.109 | Acc: 49.063,76.304,87.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.122 | Acc: 48.958,76.139,87.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.131 | Acc: 48.770,76.011,87.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.133 | Acc: 48.856,75.943,87.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.135 | Acc: 48.800,75.898,87.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.138 | Acc: 48.749,75.795,87.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.130 | Acc: 48.739,75.908,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.131 | Acc: 48.715,75.825,87.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.139 | Acc: 48.566,75.793,87.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.144 | Acc: 48.511,75.727,87.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.152 | Acc: 48.429,75.627,87.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.308 | Acc: 47.656,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.456 | Acc: 44.382,63.207,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.431 | Acc: 43.807,63.548,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.400 | Acc: 43.673,63.742,70.479,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 2.945 | Acc: 43.750,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.151 | Acc: 48.512,75.484,86.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.167 | Acc: 48.095,75.819,86.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.152 | Acc: 48.386,75.640,86.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.133 | Acc: 48.476,75.627,87.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.146 | Acc: 48.461,75.696,87.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.159 | Acc: 48.360,75.426,87.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.154 | Acc: 48.631,75.482,87.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.150 | Acc: 48.389,75.636,87.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.150 | Acc: 48.511,75.647,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.134 | Acc: 48.647,75.781,87.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.141 | Acc: 48.575,75.686,87.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.143 | Acc: 48.583,75.674,87.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.139 | Acc: 48.542,75.757,87.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.143 | Acc: 48.376,75.676,87.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.150 | Acc: 48.352,75.613,87.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.149 | Acc: 48.438,75.672,87.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.148 | Acc: 48.392,75.683,87.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.145 | Acc: 48.433,75.749,87.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.143 | Acc: 48.415,75.767,87.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.380 | Acc: 42.969,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.456 | Acc: 44.457,64.025,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.465 | Acc: 43.788,64.062,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.444 | Acc: 43.865,64.114,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 3.160 | Acc: 49.219,78.125,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.061 | Acc: 48.363,75.298,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.058 | Acc: 48.552,75.877,88.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 49.052,75.986,88.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.090 | Acc: 48.891,75.907,88.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.102 | Acc: 48.739,75.665,88.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.099 | Acc: 48.851,75.910,88.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.102 | Acc: 48.770,75.981,88.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.114 | Acc: 48.486,75.786,88.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.114 | Acc: 48.614,75.816,88.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.113 | Acc: 48.710,75.836,88.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.124 | Acc: 48.529,75.718,88.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.130 | Acc: 48.457,75.584,88.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.129 | Acc: 48.506,75.545,88.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.128 | Acc: 48.524,75.509,88.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.126 | Acc: 48.632,75.628,87.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.123 | Acc: 48.691,75.635,87.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.124 | Acc: 48.667,75.669,87.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.124 | Acc: 48.585,75.695,87.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.121 | Acc: 48.677,75.767,87.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 43.750,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.494 | Acc: 43.936,64.025,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 43.083,63.796,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.487 | Acc: 43.097,64.229,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 3.100 | Acc: 47.656,75.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.171 | Acc: 48.140,74.665,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.144 | Acc: 48.742,75.171,87.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.129 | Acc: 48.514,75.307,87.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.109 | Acc: 48.833,75.598,88.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.104 | Acc: 48.948,75.657,88.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.116 | Acc: 48.715,75.768,88.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.119 | Acc: 48.665,75.909,88.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.126 | Acc: 48.564,75.801,88.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 48.748,75.833,87.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.111 | Acc: 48.884,75.906,88.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.110 | Acc: 48.890,75.923,88.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.103 | Acc: 48.940,76.005,88.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.106 | Acc: 48.776,75.976,88.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.113 | Acc: 48.724,75.879,88.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.114 | Acc: 48.731,75.893,88.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.110 | Acc: 48.812,75.891,88.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.105 | Acc: 48.944,75.942,88.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.110 | Acc: 48.901,75.918,88.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.110 | Acc: 48.958,75.923,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.310 | Acc: 46.094,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 43.638,63.728,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.465 | Acc: 43.255,64.062,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.439 | Acc: 43.648,64.075,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.119 | Acc: 48.438,73.438,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.125 | Acc: 47.284,76.153,88.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.117 | Acc: 47.904,75.896,88.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.128 | Acc: 48.233,75.499,88.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.127 | Acc: 48.003,75.656,88.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.116 | Acc: 48.298,75.913,88.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.101 | Acc: 48.502,76.059,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.109 | Acc: 48.249,75.792,88.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.103 | Acc: 48.535,75.927,88.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.099 | Acc: 48.541,75.971,88.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.102 | Acc: 48.438,75.851,88.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.095 | Acc: 48.491,75.831,88.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.101 | Acc: 48.519,75.772,88.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.093 | Acc: 48.671,75.928,88.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.093 | Acc: 48.663,75.926,88.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.094 | Acc: 48.591,75.971,88.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.093 | Acc: 48.557,76.083,88.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.098 | Acc: 48.598,76.022,88.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.101 | Acc: 48.643,76.015,88.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.103 | Acc: 48.591,75.990,88.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.361 | Acc: 43.750,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.499 | Acc: 43.118,63.839,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.507 | Acc: 43.121,63.815,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.484 | Acc: 43.289,63.742,70.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 2.904 | Acc: 50.781,79.688,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.997 | Acc: 49.888,77.418,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.045 | Acc: 49.505,77.039,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.051 | Acc: 49.577,76.883,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 49.585,76.736,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.044 | Acc: 49.667,76.640,88.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.049 | Acc: 49.613,76.537,88.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.057 | Acc: 49.451,76.540,88.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.056 | Acc: 49.437,76.626,88.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.049 | Acc: 49.495,76.679,88.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.055 | Acc: 49.304,76.660,88.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.058 | Acc: 49.304,76.651,88.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.062 | Acc: 49.209,76.621,88.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.065 | Acc: 49.213,76.548,88.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.066 | Acc: 49.138,76.515,88.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.068 | Acc: 49.045,76.438,88.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.075 | Acc: 48.990,76.346,88.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.075 | Acc: 48.969,76.299,88.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.079 | Acc: 48.877,76.244,88.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.080 | Acc: 48.852,76.275,88.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 44.531,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.443 | Acc: 44.866,64.062,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.438 | Acc: 44.531,64.120,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.413 | Acc: 44.378,64.062,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.989 | Acc: 45.312,81.250,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.039 | Acc: 49.144,76.451,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.044 | Acc: 48.438,76.639,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.022 | Acc: 48.873,76.985,89.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.040 | Acc: 48.872,76.688,89.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.026 | Acc: 48.971,76.709,89.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.026 | Acc: 48.993,76.601,89.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.035 | Acc: 48.980,76.635,89.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.040 | Acc: 49.107,76.470,89.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.051 | Acc: 49.094,76.338,89.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.054 | Acc: 48.927,76.287,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.057 | Acc: 48.826,76.230,88.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.054 | Acc: 48.804,76.313,88.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.058 | Acc: 48.821,76.239,88.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.058 | Acc: 48.899,76.212,88.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.062 | Acc: 48.848,76.116,88.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.054 | Acc: 48.944,76.154,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.058 | Acc: 48.887,76.084,88.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.058 | Acc: 48.905,76.095,88.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.063 | Acc: 48.901,76.025,88.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.374 | Acc: 48.438,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.474 | Acc: 44.754,63.951,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.489 | Acc: 44.207,64.234,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.461 | Acc: 44.070,64.421,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.112 | Acc: 50.781,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.078 | Acc: 48.586,76.079,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.084 | Acc: 49.352,76.220,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.068 | Acc: 49.116,76.089,89.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.035 | Acc: 49.711,76.601,89.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.030 | Acc: 49.667,76.508,89.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.018 | Acc: 49.626,76.666,89.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.010 | Acc: 49.712,76.740,89.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.015 | Acc: 49.680,76.727,89.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.019 | Acc: 49.676,76.683,89.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.032 | Acc: 49.479,76.566,89.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.029 | Acc: 49.441,76.750,89.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.030 | Acc: 49.426,76.747,89.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.039 | Acc: 49.368,76.628,89.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.044 | Acc: 49.333,76.526,88.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.045 | Acc: 49.208,76.508,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.049 | Acc: 49.243,76.468,88.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.051 | Acc: 49.152,76.418,88.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.051 | Acc: 49.106,76.422,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.057 | Acc: 49.003,76.337,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.397 | Acc: 45.312,60.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 45.238,64.211,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.455 | Acc: 44.531,64.329,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.439 | Acc: 44.352,64.191,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 2.955 | Acc: 53.125,75.000,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 48.810,77.269,89.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.014 | Acc: 49.695,76.925,89.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.003 | Acc: 49.705,76.934,88.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.025 | Acc: 49.016,76.794,88.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.009 | Acc: 49.312,77.011,89.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.000 | Acc: 49.587,77.092,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.006 | Acc: 49.479,76.961,89.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.007 | Acc: 49.529,76.878,89.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.009 | Acc: 49.547,76.739,89.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.020 | Acc: 49.452,76.629,89.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.027 | Acc: 49.275,76.545,89.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.020 | Acc: 49.310,76.524,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.023 | Acc: 49.261,76.494,89.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.026 | Acc: 49.316,76.490,89.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.031 | Acc: 49.234,76.485,89.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.034 | Acc: 49.197,76.443,89.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.033 | Acc: 49.260,76.425,89.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.040 | Acc: 49.156,76.426,88.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.042 | Acc: 49.067,76.423,89.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 46.875,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.476 | Acc: 43.973,64.137,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.513 | Acc: 43.407,64.215,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.486 | Acc: 43.494,64.050,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 3.072 | Acc: 39.844,75.000,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.972 | Acc: 50.223,76.451,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.946 | Acc: 50.019,76.886,89.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.954 | Acc: 50.179,76.806,89.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.962 | Acc: 49.952,76.688,89.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.957 | Acc: 49.961,77.058,89.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.972 | Acc: 49.606,76.705,89.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.984 | Acc: 49.590,76.679,89.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.990 | Acc: 49.612,76.689,89.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.007 | Acc: 49.378,76.437,89.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.003 | Acc: 49.584,76.465,89.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 49.466,76.428,89.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.018 | Acc: 49.404,76.326,89.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.020 | Acc: 49.279,76.299,89.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.023 | Acc: 49.235,76.368,88.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.028 | Acc: 49.154,76.350,88.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.031 | Acc: 49.155,76.317,88.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.031 | Acc: 49.123,76.340,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.032 | Acc: 49.059,76.318,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.038 | Acc: 48.985,76.290,88.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.344 | Acc: 48.438,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 43.899,64.546,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.453 | Acc: 44.322,64.729,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.435 | Acc: 44.224,64.524,70.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 3.227 | Acc: 53.125,74.219,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 49.554,76.860,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.960 | Acc: 50.343,77.210,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.975 | Acc: 49.680,77.164,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.976 | Acc: 49.807,77.122,89.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.998 | Acc: 49.582,77.081,89.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.006 | Acc: 49.425,77.002,89.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.000 | Acc: 49.479,77.150,89.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.009 | Acc: 49.267,76.990,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.008 | Acc: 49.158,76.981,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.008 | Acc: 49.164,76.959,89.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 49.123,76.895,89.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.010 | Acc: 49.118,76.887,89.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.012 | Acc: 49.108,76.793,89.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.002 | Acc: 49.219,76.913,89.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.006 | Acc: 49.169,76.874,89.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.007 | Acc: 49.153,76.862,89.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.014 | Acc: 49.106,76.776,89.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.014 | Acc: 49.093,76.770,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.011 | Acc: 49.102,76.770,89.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.387 | Acc: 48.438,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.510 | Acc: 43.713,63.728,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 44.188,63.891,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.495 | Acc: 43.993,63.832,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.925 | Acc: 46.875,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.920 | Acc: 49.219,78.013,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.935 | Acc: 49.314,78.239,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.955 | Acc: 49.475,77.497,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.970 | Acc: 49.084,77.170,89.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.002 | Acc: 48.778,76.841,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.009 | Acc: 48.780,76.724,89.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.005 | Acc: 48.814,76.729,89.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.011 | Acc: 48.763,76.514,89.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.006 | Acc: 48.882,76.403,89.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.994 | Acc: 48.993,76.671,89.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.998 | Acc: 48.932,76.697,89.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.993 | Acc: 48.992,76.822,89.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.998 | Acc: 49.012,76.763,89.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.996 | Acc: 49.060,76.799,89.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.998 | Acc: 49.081,76.775,89.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.000 | Acc: 49.070,76.750,89.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.001 | Acc: 49.120,76.743,89.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.003 | Acc: 49.119,76.643,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.001 | Acc: 49.112,76.645,89.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.350 | Acc: 41.406,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.468 | Acc: 44.085,64.546,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.482 | Acc: 43.998,64.425,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.457 | Acc: 44.173,64.255,69.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 3.032 | Acc: 50.781,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.000 | Acc: 48.400,77.827,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.021 | Acc: 48.171,77.096,89.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.020 | Acc: 48.348,76.857,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.008 | Acc: 48.669,76.987,89.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.009 | Acc: 48.786,76.841,89.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.003 | Acc: 48.967,76.834,89.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.995 | Acc: 49.141,76.690,89.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.993 | Acc: 49.136,76.732,89.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.991 | Acc: 49.098,76.796,89.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.986 | Acc: 49.234,76.842,89.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.985 | Acc: 49.074,76.888,89.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.988 | Acc: 48.985,76.874,89.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.988 | Acc: 49.105,76.922,89.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.988 | Acc: 49.158,76.857,89.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.988 | Acc: 49.066,76.861,89.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.989 | Acc: 49.002,76.857,89.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.988 | Acc: 49.061,76.904,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.988 | Acc: 49.102,76.902,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.989 | Acc: 49.112,76.897,89.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.521 | Acc: 48.438,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 42.969,64.100,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.592 | Acc: 43.083,64.062,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 43.058,63.832,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.110 | Acc: 55.469,71.875,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.929 | Acc: 51.004,77.493,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.931 | Acc: 50.819,77.515,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.934 | Acc: 50.205,77.677,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.940 | Acc: 49.923,77.488,90.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.947 | Acc: 50.062,77.251,90.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.945 | Acc: 49.923,77.266,90.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.947 | Acc: 49.801,77.161,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.954 | Acc: 49.583,77.057,90.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.960 | Acc: 49.542,76.973,89.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.970 | Acc: 49.448,76.827,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.973 | Acc: 49.261,76.838,89.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.982 | Acc: 49.154,76.796,89.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.985 | Acc: 49.054,76.805,89.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.981 | Acc: 49.066,76.885,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.981 | Acc: 49.193,76.864,89.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.980 | Acc: 49.287,76.886,89.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.978 | Acc: 49.359,76.876,89.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.979 | Acc: 49.362,76.898,89.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.981 | Acc: 49.358,76.852,89.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.365 | Acc: 48.438,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.495 | Acc: 45.796,64.211,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 45.122,64.234,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.470 | Acc: 44.851,64.395,69.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.885 | Acc: 47.656,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.988 | Acc: 48.065,77.939,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.966 | Acc: 49.104,77.782,90.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.982 | Acc: 48.783,77.459,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.967 | Acc: 49.064,77.488,90.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.977 | Acc: 48.963,77.437,90.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.971 | Acc: 48.980,77.608,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.975 | Acc: 49.119,77.466,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.964 | Acc: 49.083,77.441,90.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.965 | Acc: 49.063,77.374,90.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.965 | Acc: 49.184,77.336,90.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.964 | Acc: 49.183,77.178,90.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.970 | Acc: 49.190,77.162,89.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.967 | Acc: 49.279,77.173,89.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.974 | Acc: 49.230,77.069,89.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.979 | Acc: 49.131,77.037,89.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.977 | Acc: 49.119,77.044,89.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.977 | Acc: 49.159,77.089,89.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.984 | Acc: 49.095,77.021,89.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.978 | Acc: 49.161,77.030,89.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 46.094,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.504 | Acc: 44.048,64.137,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.484 | Acc: 43.731,64.482,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.467 | Acc: 43.622,64.485,69.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.857 | Acc: 49.219,76.562,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.017 | Acc: 48.400,76.042,89.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.940 | Acc: 49.543,76.467,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.972 | Acc: 49.219,76.447,90.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.968 | Acc: 49.199,76.813,90.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.960 | Acc: 49.373,76.949,90.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.962 | Acc: 49.193,76.911,90.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.958 | Acc: 49.379,76.989,90.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.961 | Acc: 49.194,76.960,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.962 | Acc: 49.301,76.886,90.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.958 | Acc: 49.421,77.002,90.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.964 | Acc: 49.293,76.958,90.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.970 | Acc: 49.209,76.900,90.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.980 | Acc: 49.060,76.802,90.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.977 | Acc: 49.135,76.788,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.976 | Acc: 49.177,76.755,89.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.977 | Acc: 49.177,76.733,89.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.974 | Acc: 49.221,76.753,89.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.972 | Acc: 49.230,76.844,89.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.976 | Acc: 49.143,76.864,89.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.343 | Acc: 45.312,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 44.196,64.397,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.495 | Acc: 43.693,64.444,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.482 | Acc: 43.737,64.255,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.724 | Acc: 49.219,80.469,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.983 | Acc: 47.731,77.269,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.937 | Acc: 48.495,77.420,90.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.948 | Acc: 48.899,77.408,90.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.918 | Acc: 49.624,77.913,90.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.921 | Acc: 49.652,77.630,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.938 | Acc: 49.322,77.402,90.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.938 | Acc: 49.601,77.344,90.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.935 | Acc: 49.719,77.368,90.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.947 | Acc: 49.422,77.210,90.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.941 | Acc: 49.534,77.336,90.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.944 | Acc: 49.502,77.291,90.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.947 | Acc: 49.468,77.169,90.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.949 | Acc: 49.362,77.179,90.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.953 | Acc: 49.422,77.208,90.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.960 | Acc: 49.367,77.139,90.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.963 | Acc: 49.314,77.125,90.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.961 | Acc: 49.308,77.154,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.963 | Acc: 49.288,77.125,90.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.967 | Acc: 49.293,77.081,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.440 | Acc: 46.094,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.547 | Acc: 44.196,64.100,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 44.074,64.158,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.556 | Acc: 43.904,64.011,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 2.895 | Acc: 49.219,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.857 | Acc: 51.339,78.125,90.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.934 | Acc: 49.695,76.639,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.917 | Acc: 50.077,77.126,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 49.489,77.064,90.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.922 | Acc: 49.528,77.522,90.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.914 | Acc: 49.793,77.602,90.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.924 | Acc: 49.717,77.449,90.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.919 | Acc: 49.786,77.460,90.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.912 | Acc: 49.944,77.529,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.915 | Acc: 49.833,77.569,90.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.926 | Acc: 49.629,77.460,90.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.929 | Acc: 49.553,77.535,90.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.936 | Acc: 49.530,77.487,90.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.941 | Acc: 49.472,77.430,90.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.945 | Acc: 49.471,77.380,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.948 | Acc: 49.392,77.334,90.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.951 | Acc: 49.345,77.291,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.954 | Acc: 49.288,77.255,90.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.957 | Acc: 49.239,77.227,90.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.572 | Acc: 46.875,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 43.862,64.062,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 43.559,63.796,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 43.699,63.806,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 2.551 | Acc: 48.438,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.978 | Acc: 47.024,77.641,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.956 | Acc: 47.752,77.268,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.963 | Acc: 48.796,77.267,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.950 | Acc: 48.939,77.334,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.941 | Acc: 48.809,77.437,90.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.938 | Acc: 48.889,77.492,90.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.940 | Acc: 48.814,77.427,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.932 | Acc: 48.874,77.494,90.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.939 | Acc: 48.666,77.486,90.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.948 | Acc: 48.655,77.324,90.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.954 | Acc: 48.614,77.368,90.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.953 | Acc: 48.726,77.389,90.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.951 | Acc: 48.869,77.389,90.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.949 | Acc: 48.955,77.372,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.953 | Acc: 48.931,77.253,90.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.953 | Acc: 48.915,77.224,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.954 | Acc: 48.923,77.254,90.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.952 | Acc: 48.944,77.329,90.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.955 | Acc: 48.981,77.311,90.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.494 | Acc: 42.188,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.560 | Acc: 43.155,64.211,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 43.026,63.948,69.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.526 | Acc: 43.263,64.242,69.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.849 | Acc: 46.094,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.974 | Acc: 48.698,77.493,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.925 | Acc: 49.581,77.439,90.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 50.064,77.382,90.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 49.537,77.199,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.936 | Acc: 49.590,77.483,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.917 | Acc: 49.864,77.537,90.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.923 | Acc: 49.817,77.399,90.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.912 | Acc: 50.010,77.528,90.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.916 | Acc: 49.927,77.568,90.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.924 | Acc: 49.751,77.456,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.934 | Acc: 49.671,77.312,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.934 | Acc: 49.653,77.253,90.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.941 | Acc: 49.548,77.218,90.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.939 | Acc: 49.569,77.174,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.937 | Acc: 49.577,77.240,90.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.945 | Acc: 49.550,77.227,90.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.944 | Acc: 49.581,77.225,90.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.943 | Acc: 49.576,77.274,90.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.944 | Acc: 49.561,77.190,90.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.431 | Acc: 46.094,64.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.532 | Acc: 44.457,64.993,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.528 | Acc: 44.112,64.882,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.526 | Acc: 43.814,64.741,69.813,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 2.916 | Acc: 53.125,79.688,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.926 | Acc: 48.735,78.571,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.900 | Acc: 49.123,78.392,90.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.886 | Acc: 49.168,78.317,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.911 | Acc: 48.978,77.961,90.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.909 | Acc: 48.716,77.939,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.912 | Acc: 48.818,77.809,90.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.907 | Acc: 48.947,77.926,90.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.909 | Acc: 49.015,77.844,90.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.914 | Acc: 49.089,77.741,90.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.908 | Acc: 49.219,77.764,90.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.914 | Acc: 49.194,77.605,90.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.921 | Acc: 49.206,77.490,90.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.921 | Acc: 49.270,77.496,90.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.922 | Acc: 49.322,77.527,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.921 | Acc: 49.421,77.494,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.925 | Acc: 49.331,77.475,90.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.931 | Acc: 49.260,77.357,90.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.934 | Acc: 49.253,77.368,90.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.938 | Acc: 49.241,77.305,90.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.246 | Acc: 49.219,62.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.585 | Acc: 42.857,64.137,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.556 | Acc: 43.369,64.120,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.553 | Acc: 43.161,64.037,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 3.061 | Acc: 49.219,73.438,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.893 | Acc: 50.781,76.860,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.914 | Acc: 50.324,77.191,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.932 | Acc: 49.872,77.062,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.948 | Acc: 49.576,76.977,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.939 | Acc: 49.520,77.042,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.919 | Acc: 49.768,77.357,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.921 | Acc: 49.662,77.316,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.928 | Acc: 49.481,77.339,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.915 | Acc: 49.694,77.378,90.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.917 | Acc: 49.580,77.402,90.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.924 | Acc: 49.410,77.436,90.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.918 | Acc: 49.416,77.574,90.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.919 | Acc: 49.392,77.526,90.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 49.330,77.494,90.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.922 | Acc: 49.304,77.468,90.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.923 | Acc: 49.326,77.531,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.925 | Acc: 49.287,77.532,90.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.926 | Acc: 49.333,77.493,90.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.928 | Acc: 49.305,77.413,90.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.376 | Acc: 46.094,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.483 | Acc: 44.680,64.211,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 44.436,64.748,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.472 | Acc: 44.275,64.600,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.957 | Acc: 49.219,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 51.786,78.981,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.824 | Acc: 50.343,78.754,91.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.819 | Acc: 50.435,78.970,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 50.376,78.906,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.817 | Acc: 50.472,78.937,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.842 | Acc: 50.103,78.512,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.861 | Acc: 49.994,78.269,91.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.873 | Acc: 49.913,78.222,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.877 | Acc: 49.853,78.280,90.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.871 | Acc: 50.012,78.199,90.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.872 | Acc: 50.085,78.107,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.877 | Acc: 49.974,78.031,90.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.883 | Acc: 49.901,77.945,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.894 | Acc: 49.769,77.853,90.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.900 | Acc: 49.730,77.759,90.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.897 | Acc: 49.759,77.823,90.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.899 | Acc: 49.750,77.797,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.902 | Acc: 49.686,77.764,90.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 49.584,77.692,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.349 | Acc: 44.531,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.537 | Acc: 44.457,63.616,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.538 | Acc: 44.417,63.796,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.512 | Acc: 44.454,64.062,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.832 | Acc: 50.000,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 49.405,77.158,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.928 | Acc: 49.123,77.401,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.910 | Acc: 49.513,77.344,90.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.918 | Acc: 49.547,77.315,90.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.906 | Acc: 49.420,77.568,90.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.897 | Acc: 49.341,77.738,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.901 | Acc: 49.385,77.665,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.900 | Acc: 49.403,77.615,91.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.893 | Acc: 49.590,77.620,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.902 | Acc: 49.471,77.523,91.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.907 | Acc: 49.548,77.453,91.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.906 | Acc: 49.608,77.486,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.907 | Acc: 49.563,77.520,91.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.899 | Acc: 49.636,77.638,90.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.905 | Acc: 49.499,77.629,90.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.911 | Acc: 49.443,77.582,90.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.911 | Acc: 49.519,77.635,90.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.914 | Acc: 49.459,77.636,90.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.911 | Acc: 49.487,77.647,90.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.532 | Acc: 47.656,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.526 | Acc: 44.420,63.765,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 43.902,64.234,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.534 | Acc: 43.852,64.178,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.642 | Acc: 50.781,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.890 | Acc: 48.251,77.865,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.855 | Acc: 49.752,78.239,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.870 | Acc: 49.834,78.407,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.879 | Acc: 49.441,78.299,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.883 | Acc: 49.312,78.148,91.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.881 | Acc: 49.471,78.112,91.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.890 | Acc: 49.446,77.986,91.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.894 | Acc: 49.461,77.853,91.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.896 | Acc: 49.331,77.849,91.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.890 | Acc: 49.405,77.993,91.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 49.342,77.998,91.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 49.319,77.937,91.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.897 | Acc: 49.276,77.954,91.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 49.386,77.967,91.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.892 | Acc: 49.416,77.943,91.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.890 | Acc: 49.486,77.899,90.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.891 | Acc: 49.585,77.823,90.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 49.563,77.751,90.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.903 | Acc: 49.475,77.682,90.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.253 | Acc: 48.438,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 43.490,63.504,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 43.712,63.700,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.561 | Acc: 43.827,63.742,69.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 2.700 | Acc: 53.125,82.031,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 50.074,77.307,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.824 | Acc: 50.000,78.049,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.796 | Acc: 50.179,78.189,91.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.837 | Acc: 49.961,77.961,91.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.848 | Acc: 49.752,78.148,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.859 | Acc: 49.890,77.886,91.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.867 | Acc: 49.823,77.787,91.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.886 | Acc: 49.447,77.659,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.889 | Acc: 49.607,77.577,91.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.894 | Acc: 49.565,77.620,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.892 | Acc: 49.664,77.726,91.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.899 | Acc: 49.523,77.674,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.898 | Acc: 49.485,77.661,91.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.902 | Acc: 49.455,77.644,91.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.900 | Acc: 49.468,77.699,91.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.901 | Acc: 49.389,77.697,91.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.893 | Acc: 49.455,77.758,91.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.900 | Acc: 49.422,77.590,91.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.899 | Acc: 49.436,77.567,90.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.523 | Acc: 43.750,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 44.085,64.323,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 43.293,63.758,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 43.212,63.601,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.825 | Acc: 51.562,77.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 49.107,78.125,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 49.295,77.820,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.882 | Acc: 49.667,77.946,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.869 | Acc: 49.508,77.951,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 49.636,77.669,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.869 | Acc: 49.593,77.893,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.877 | Acc: 49.740,77.743,91.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.883 | Acc: 49.685,77.688,91.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 49.676,77.650,91.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.877 | Acc: 49.860,77.826,91.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 49.632,77.704,91.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.892 | Acc: 49.585,77.739,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.889 | Acc: 49.596,77.808,91.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.892 | Acc: 49.530,77.833,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.893 | Acc: 49.535,77.759,91.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.899 | Acc: 49.496,77.697,91.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.901 | Acc: 49.546,77.674,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.901 | Acc: 49.535,77.716,91.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.902 | Acc: 49.498,77.676,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 48.438,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 43.787,63.170,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 44.055,63.453,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 43.904,63.614,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.616 | Acc: 53.906,82.031,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.844 | Acc: 49.963,78.311,90.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.833 | Acc: 50.495,78.144,91.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.812 | Acc: 50.820,78.535,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.797 | Acc: 51.177,78.395,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.795 | Acc: 50.866,78.659,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.811 | Acc: 50.704,78.635,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.816 | Acc: 50.410,78.596,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.841 | Acc: 50.116,78.334,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.849 | Acc: 49.940,78.293,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.866 | Acc: 49.782,78.141,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.868 | Acc: 49.830,78.111,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.868 | Acc: 49.780,78.099,91.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 49.776,77.963,91.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.884 | Acc: 49.714,77.958,91.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.882 | Acc: 49.704,77.946,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.880 | Acc: 49.779,77.916,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.880 | Acc: 49.769,77.933,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.888 | Acc: 49.716,77.874,91.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.887 | Acc: 49.746,77.873,91.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.469 | Acc: 48.438,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 43.750,63.839,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 44.074,63.967,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 43.724,63.947,68.942,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 3.113 | Acc: 44.531,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.896 | Acc: 48.996,77.567,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.905 | Acc: 48.838,76.982,91.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.886 | Acc: 49.308,77.433,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.883 | Acc: 49.479,77.575,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.872 | Acc: 49.474,77.885,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.880 | Acc: 49.374,77.957,91.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.880 | Acc: 49.429,77.981,91.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 49.529,77.926,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.875 | Acc: 49.685,77.983,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.874 | Acc: 49.740,77.966,91.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.876 | Acc: 49.756,77.931,91.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.879 | Acc: 49.754,77.901,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.877 | Acc: 49.752,77.993,91.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.874 | Acc: 49.830,77.986,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.868 | Acc: 49.883,78.021,91.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.871 | Acc: 49.847,77.986,91.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.878 | Acc: 49.753,77.926,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.879 | Acc: 49.812,77.826,91.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.883 | Acc: 49.723,77.795,91.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.521 | Acc: 43.750,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.660 | Acc: 42.894,63.095,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 43.102,63.110,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 43.276,63.192,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.868 | Acc: 46.094,79.688,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.848 | Acc: 49.144,78.385,91.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.841 | Acc: 49.562,77.534,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.840 | Acc: 49.347,78.023,91.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.851 | Acc: 49.711,78.077,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.856 | Acc: 49.606,78.349,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.863 | Acc: 49.496,78.267,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.856 | Acc: 49.734,78.363,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.845 | Acc: 50.010,78.567,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.837 | Acc: 50.173,78.583,91.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.847 | Acc: 50.000,78.444,91.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.846 | Acc: 50.032,78.450,91.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 49.922,78.439,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.853 | Acc: 49.916,78.275,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.860 | Acc: 49.930,78.250,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.862 | Acc: 49.842,78.289,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.865 | Acc: 49.759,78.171,91.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.871 | Acc: 49.737,78.118,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.873 | Acc: 49.719,78.045,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.877 | Acc: 49.682,77.969,91.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.644 | Acc: 50.000,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 44.680,62.872,68.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.675 | Acc: 43.521,62.862,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 43.455,63.281,68.545,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 2.833 | Acc: 46.094,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.902 | Acc: 48.996,76.637,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 49.848,77.534,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.837 | Acc: 50.064,77.728,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.847 | Acc: 49.778,77.826,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.835 | Acc: 49.814,78.117,91.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.853 | Acc: 49.574,78.022,91.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.859 | Acc: 49.573,77.975,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 49.612,77.989,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.853 | Acc: 49.767,78.121,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.853 | Acc: 49.736,78.160,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.856 | Acc: 49.650,78.079,91.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.857 | Acc: 49.647,78.086,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.867 | Acc: 49.512,77.990,91.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.868 | Acc: 49.589,77.925,91.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 49.483,77.852,91.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.870 | Acc: 49.472,77.894,91.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.868 | Acc: 49.574,77.955,91.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.870 | Acc: 49.574,77.961,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.866 | Acc: 49.658,78.035,91.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 45.312,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.683 | Acc: 42.820,64.211,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.698 | Acc: 42.873,63.681,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 42.713,63.576,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 3.163 | Acc: 46.094,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.761 | Acc: 49.628,78.869,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.835 | Acc: 49.257,78.030,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.798 | Acc: 50.141,78.945,91.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.786 | Acc: 50.077,78.906,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.815 | Acc: 49.799,78.581,91.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.812 | Acc: 49.716,78.596,91.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.825 | Acc: 49.701,78.424,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.826 | Acc: 49.612,78.494,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.831 | Acc: 49.689,78.371,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.829 | Acc: 49.728,78.385,91.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.833 | Acc: 49.689,78.355,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.837 | Acc: 49.669,78.388,91.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.845 | Acc: 49.596,78.257,91.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.850 | Acc: 49.566,78.128,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.854 | Acc: 49.585,78.112,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.856 | Acc: 49.615,78.086,91.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.679,78.049,91.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.857 | Acc: 49.647,78.060,91.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.862 | Acc: 49.615,78.000,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.453 | Acc: 44.531,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.615 | Acc: 44.903,63.951,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.625 | Acc: 44.531,63.605,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 44.506,63.704,68.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 3.181 | Acc: 42.969,67.969,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.878 | Acc: 49.628,78.237,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.838 | Acc: 49.600,78.220,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.845 | Acc: 49.795,78.227,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.842 | Acc: 49.643,78.463,91.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.842 | Acc: 49.791,78.411,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.821 | Acc: 50.149,78.784,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 50.122,78.729,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.832 | Acc: 49.922,78.484,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.834 | Acc: 49.940,78.496,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.836 | Acc: 49.961,78.428,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.841 | Acc: 49.855,78.493,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.838 | Acc: 49.935,78.404,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.837 | Acc: 49.988,78.364,91.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 49.850,78.295,91.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.850 | Acc: 49.839,78.231,91.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.859 | Acc: 49.749,78.152,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.860 | Acc: 49.780,78.077,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.856 | Acc: 49.887,78.103,91.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 49.850,78.121,91.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.283 | Acc: 45.312,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.773 | Acc: 42.671,62.872,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.750 | Acc: 42.740,62.976,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.733 | Acc: 42.392,62.846,68.609,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 2.950 | Acc: 50.781,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 48.735,77.827,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.859 | Acc: 49.428,77.763,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 49.347,78.087,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.841 | Acc: 49.277,78.183,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.857 | Acc: 49.343,77.939,91.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.871 | Acc: 48.993,77.647,91.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.871 | Acc: 49.230,77.787,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.857 | Acc: 49.486,77.916,91.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.860 | Acc: 49.396,77.996,91.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.851 | Acc: 49.518,78.094,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.846 | Acc: 49.664,78.143,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.849 | Acc: 49.699,78.187,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.849 | Acc: 49.647,78.155,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 49.716,78.100,91.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.848 | Acc: 49.753,78.094,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.851 | Acc: 49.679,78.086,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.854 | Acc: 49.739,77.992,91.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.854 | Acc: 49.781,78.002,91.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.856 | Acc: 49.707,78.006,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.290 | Acc: 47.656,64.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 43.899,64.100,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.641 | Acc: 43.617,64.367,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 43.827,63.934,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 3.113 | Acc: 52.344,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.813 | Acc: 49.702,79.167,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.812 | Acc: 49.371,79.135,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.823 | Acc: 49.667,78.804,92.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.802 | Acc: 49.682,79.109,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.816 | Acc: 49.706,78.659,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.811 | Acc: 49.742,78.667,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.806 | Acc: 49.917,78.496,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.812 | Acc: 50.039,78.387,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.813 | Acc: 49.953,78.224,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.817 | Acc: 49.903,78.249,91.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.825 | Acc: 49.802,78.196,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.831 | Acc: 49.686,78.122,91.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.838 | Acc: 49.530,78.059,91.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.841 | Acc: 49.550,78.058,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.840 | Acc: 49.580,78.120,91.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 49.559,78.074,91.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.846 | Acc: 49.631,78.068,91.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.852 | Acc: 49.539,78.002,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.855 | Acc: 49.559,77.951,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.496 | Acc: 42.969,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 43.862,63.318,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 43.312,63.491,68.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 43.481,63.678,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.351 | Acc: 56.250,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.769 | Acc: 50.818,79.427,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.770 | Acc: 50.343,79.268,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.778 | Acc: 50.371,79.239,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 50.415,78.848,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.803 | Acc: 50.232,78.636,92.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.818 | Acc: 49.968,78.487,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.821 | Acc: 50.022,78.280,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.831 | Acc: 50.107,78.149,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.833 | Acc: 50.030,78.138,92.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.842 | Acc: 49.949,78.098,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.840 | Acc: 49.894,78.217,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.840 | Acc: 49.818,78.209,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.842 | Acc: 49.823,78.197,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 49.705,78.200,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.849 | Acc: 49.689,78.154,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.856 | Acc: 49.557,78.110,91.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 49.604,78.116,91.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.853 | Acc: 49.634,78.119,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.853 | Acc: 49.625,78.131,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.317 | Acc: 46.094,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 42.932,63.951,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.646 | Acc: 43.369,63.910,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 43.212,63.640,68.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.484 | Acc: 56.250,85.156,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 51.004,79.092,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.766 | Acc: 50.915,79.402,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.792 | Acc: 50.666,79.111,91.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.802 | Acc: 50.222,78.974,91.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.818 | Acc: 49.729,78.512,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 49.774,78.422,91.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.822 | Acc: 49.712,78.485,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.822 | Acc: 49.806,78.499,91.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.819 | Acc: 49.909,78.552,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 49.957,78.537,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 50.049,78.496,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.829 | Acc: 49.844,78.329,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 49.770,78.317,91.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.835 | Acc: 49.780,78.245,91.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.836 | Acc: 49.795,78.182,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.839 | Acc: 49.757,78.123,91.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.840 | Acc: 49.716,78.146,91.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.842 | Acc: 49.701,78.170,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 49.701,78.137,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.413 | Acc: 46.875,61.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.551 | Acc: 44.903,63.914,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.579 | Acc: 45.046,63.796,69.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 44.506,63.678,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.496 | Acc: 53.906,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.780 | Acc: 50.037,79.241,92.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.788 | Acc: 49.409,79.249,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 50.077,79.201,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.787 | Acc: 49.711,79.051,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.795 | Acc: 50.124,78.984,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.801 | Acc: 50.252,78.706,92.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.804 | Acc: 50.089,78.701,92.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.814 | Acc: 50.049,78.557,91.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.824 | Acc: 49.953,78.466,91.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.822 | Acc: 50.035,78.498,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.828 | Acc: 49.929,78.298,91.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 49.925,78.449,91.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.820 | Acc: 50.027,78.454,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.829 | Acc: 49.811,78.409,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 49.862,78.431,91.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.834 | Acc: 49.735,78.390,91.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 49.757,78.370,91.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.836 | Acc: 49.764,78.348,91.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.839 | Acc: 49.727,78.330,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.527 | Acc: 42.188,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.745 | Acc: 43.118,62.500,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.738 | Acc: 43.178,62.976,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.698 | Acc: 43.122,63.230,68.443,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 2.899 | Acc: 50.000,76.562,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.864 | Acc: 50.223,78.683,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.839 | Acc: 50.095,78.506,92.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.824 | Acc: 49.846,78.714,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.808 | Acc: 50.154,78.839,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.796 | Acc: 50.487,79.216,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.806 | Acc: 50.329,79.074,91.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 50.327,78.845,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.807 | Acc: 50.398,78.833,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 50.276,78.738,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.814 | Acc: 50.241,78.696,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.822 | Acc: 50.283,78.577,91.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 50.195,78.501,91.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.827 | Acc: 50.129,78.418,91.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.827 | Acc: 50.133,78.439,91.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.832 | Acc: 50.122,78.309,91.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 50.075,78.256,91.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.843 | Acc: 50.018,78.251,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.842 | Acc: 50.002,78.214,91.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.843 | Acc: 50.049,78.217,91.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.615 | Acc: 46.094,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 44.010,63.430,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.711 | Acc: 43.693,63.434,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.683 | Acc: 43.635,63.653,68.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.668 | Acc: 52.344,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.791 | Acc: 50.298,79.055,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.805 | Acc: 50.381,78.849,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 49.962,78.266,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 50.019,78.453,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.786 | Acc: 50.093,78.659,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 50.213,78.596,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.814 | Acc: 49.884,78.469,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.810 | Acc: 50.029,78.460,92.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.813 | Acc: 49.905,78.470,92.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.813 | Acc: 49.922,78.448,92.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.807 | Acc: 49.905,78.475,92.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.814 | Acc: 49.877,78.378,92.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.824 | Acc: 49.823,78.358,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 49.778,78.392,91.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.823 | Acc: 49.798,78.449,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.824 | Acc: 49.791,78.478,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.828 | Acc: 49.764,78.455,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 49.719,78.504,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.829 | Acc: 49.733,78.465,91.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.574 | Acc: 42.969,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.671 | Acc: 44.494,63.356,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.668 | Acc: 44.284,63.834,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.648 | Acc: 43.750,63.819,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.563 | Acc: 46.875,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.797 | Acc: 49.070,78.348,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.824 | Acc: 49.390,78.335,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.810 | Acc: 49.667,78.599,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.829 | Acc: 49.566,78.154,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.812 | Acc: 50.000,78.349,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.807 | Acc: 49.942,78.667,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.824 | Acc: 49.906,78.380,92.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.832 | Acc: 49.835,78.295,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 49.763,78.388,92.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.823 | Acc: 49.802,78.409,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 49.802,78.517,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.814 | Acc: 49.968,78.498,92.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 49.994,78.571,92.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 50.070,78.639,92.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.813 | Acc: 50.143,78.577,92.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.127,78.556,92.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.817 | Acc: 50.078,78.531,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.822 | Acc: 49.946,78.491,91.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.818 | Acc: 50.000,78.474,91.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.339 | Acc: 43.750,60.938,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.695 | Acc: 43.787,63.430,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.679 | Acc: 43.540,63.777,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 43.353,63.858,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.948 | Acc: 43.750,74.219,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.723 | Acc: 50.298,78.646,93.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.763 | Acc: 49.981,78.830,92.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.763 | Acc: 50.218,78.855,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.768 | Acc: 50.473,79.022,92.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.456,78.860,92.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.770 | Acc: 50.323,78.906,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.778 | Acc: 50.271,78.912,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.780 | Acc: 50.189,78.887,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.797 | Acc: 50.039,78.600,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.798 | Acc: 49.977,78.700,92.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.799 | Acc: 50.021,78.669,92.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.812 | Acc: 49.922,78.559,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 49.985,78.550,92.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.810 | Acc: 50.000,78.553,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.810 | Acc: 50.026,78.564,91.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 49.890,78.446,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.821 | Acc: 49.940,78.418,91.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.821 | Acc: 49.942,78.409,91.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.826 | Acc: 49.895,78.375,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.548 | Acc: 47.656,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.696 | Acc: 43.192,63.207,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.738 | Acc: 43.216,63.357,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.717 | Acc: 43.174,63.128,67.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.694 | Acc: 50.781,85.156,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.794 | Acc: 49.144,80.246,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.778 | Acc: 49.752,79.325,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.743 | Acc: 50.628,79.867,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.738 | Acc: 50.723,79.716,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.750 | Acc: 50.441,79.363,92.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.765 | Acc: 50.271,79.255,92.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 50.233,78.879,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.774 | Acc: 50.228,78.994,92.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 50.000,78.928,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 49.852,78.895,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 49.880,78.828,92.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.788 | Acc: 49.848,78.848,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 49.847,78.837,92.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.797 | Acc: 49.817,78.645,91.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.804 | Acc: 49.785,78.520,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.803 | Acc: 49.754,78.558,91.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 49.720,78.388,91.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 49.853,78.389,91.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 49.811,78.330,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.609 | Acc: 43.750,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.768 | Acc: 43.266,63.467,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.743 | Acc: 43.331,63.453,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.718 | Acc: 43.135,63.371,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 2.773 | Acc: 50.781,79.688,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.744 | Acc: 51.265,78.125,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 50.495,78.468,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.782 | Acc: 50.192,78.932,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 50.347,78.684,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.788 | Acc: 50.162,78.643,92.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.792 | Acc: 50.065,78.680,91.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.795 | Acc: 50.211,78.646,91.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.810 | Acc: 50.102,78.503,91.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 50.151,78.656,91.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 50.062,78.525,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.818 | Acc: 50.021,78.415,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.817 | Acc: 50.136,78.478,91.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.814 | Acc: 50.189,78.463,91.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.819 | Acc: 50.061,78.409,91.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.825 | Acc: 49.899,78.444,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 49.876,78.454,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.829 | Acc: 49.851,78.423,91.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.826 | Acc: 49.849,78.467,91.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.822 | Acc: 49.904,78.494,91.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.726 | Acc: 46.875,59.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.660 | Acc: 44.531,63.616,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.679 | Acc: 43.941,63.681,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 43.712,63.858,68.673,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.520 | Acc: 47.656,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.810 | Acc: 48.363,78.720,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 49.790,79.554,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.761 | Acc: 50.333,79.265,92.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.767 | Acc: 50.231,79.167,92.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.240,79.162,92.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.785 | Acc: 49.813,78.822,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 50.050,78.807,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.794 | Acc: 49.825,78.702,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 49.922,78.768,92.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 49.911,78.809,92.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.792 | Acc: 49.848,78.783,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.795 | Acc: 49.825,78.851,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 49.835,78.888,92.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.798 | Acc: 49.805,78.884,92.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.800 | Acc: 49.834,78.867,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 49.832,78.867,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.806 | Acc: 49.959,78.794,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.810 | Acc: 49.887,78.707,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.813 | Acc: 49.916,78.660,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.481 | Acc: 44.531,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.663 | Acc: 44.345,63.318,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.672 | Acc: 44.131,63.929,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.658 | Acc: 43.955,63.870,67.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.657 | Acc: 43.750,81.250,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.651 | Acc: 52.679,79.539,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.680 | Acc: 51.734,79.249,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 51.153,78.714,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 51.148,78.926,92.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.746 | Acc: 51.013,78.744,92.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.777 | Acc: 50.536,78.571,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 50.288,78.546,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 50.073,78.436,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.806 | Acc: 49.918,78.410,92.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.815 | Acc: 49.743,78.382,92.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 49.731,78.390,92.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 49.799,78.410,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.811 | Acc: 49.838,78.421,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.812 | Acc: 49.847,78.381,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 49.888,78.429,92.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.816 | Acc: 49.854,78.419,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 49.805,78.476,92.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.812 | Acc: 49.801,78.497,92.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.814 | Acc: 49.883,78.390,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.720 | Acc: 40.625,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.813 | Acc: 43.155,63.504,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.815 | Acc: 43.102,62.767,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.755 | Acc: 43.161,62.974,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.795 | Acc: 53.906,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.775 | Acc: 49.926,81.064,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.457,80.774,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.797 | Acc: 50.064,79.867,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.809 | Acc: 49.769,79.543,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.813 | Acc: 49.598,79.285,92.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.812 | Acc: 49.638,79.242,92.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.810 | Acc: 49.562,79.167,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.809 | Acc: 49.738,79.013,92.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.810 | Acc: 49.754,78.880,92.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.818 | Acc: 49.712,78.794,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.813 | Acc: 49.809,78.800,91.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.809 | Acc: 49.883,78.790,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.809 | Acc: 49.883,78.810,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.804 | Acc: 50.000,78.840,91.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.811 | Acc: 49.956,78.691,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.812 | Acc: 49.927,78.651,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.809 | Acc: 49.943,78.695,91.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.814 | Acc: 49.911,78.623,91.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.816 | Acc: 49.834,78.593,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.378 | Acc: 48.438,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.845 | Acc: 43.118,63.393,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.827 | Acc: 42.950,63.167,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.813 | Acc: 42.725,62.782,67.649,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.816 | Acc: 48.438,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 49.293,79.055,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 49.181,78.468,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.799 | Acc: 49.513,78.151,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.803 | Acc: 49.672,78.202,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 49.613,78.133,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.793 | Acc: 49.626,78.370,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 49.701,78.197,92.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.805 | Acc: 49.694,78.174,92.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.790 | Acc: 49.909,78.393,92.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.794 | Acc: 49.845,78.319,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 49.873,78.422,92.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.796 | Acc: 49.877,78.426,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 49.829,78.397,92.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.793 | Acc: 49.933,78.442,92.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.795 | Acc: 49.907,78.333,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.796 | Acc: 49.869,78.400,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.800 | Acc: 49.892,78.421,92.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 49.883,78.428,92.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.804 | Acc: 49.809,78.400,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.518 | Acc: 42.969,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.699 | Acc: 42.485,63.132,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.716 | Acc: 42.854,63.529,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.686 | Acc: 43.366,63.448,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 3.110 | Acc: 42.969,72.656,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.822 | Acc: 49.926,77.976,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.780 | Acc: 49.943,78.906,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.786 | Acc: 49.629,78.599,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.758 | Acc: 50.029,79.147,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.738 | Acc: 50.464,79.394,92.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 50.252,79.119,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.764 | Acc: 50.227,78.945,92.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 50.121,78.809,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.780 | Acc: 49.905,78.772,91.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.786 | Acc: 49.813,78.591,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.790 | Acc: 50.011,78.602,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.796 | Acc: 50.097,78.533,91.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.796 | Acc: 50.078,78.562,91.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.799 | Acc: 50.117,78.492,91.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 50.122,78.455,91.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.803 | Acc: 50.068,78.410,91.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 50.016,78.430,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.805 | Acc: 50.035,78.413,91.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.805 | Acc: 50.014,78.461,91.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.506 | Acc: 42.188,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.714 | Acc: 43.899,63.393,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.712 | Acc: 43.331,63.929,68.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.670 | Acc: 43.584,64.011,68.878,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.696 | Acc: 47.656,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.733 | Acc: 51.228,78.757,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.779 | Acc: 49.771,78.201,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.800 | Acc: 49.565,78.074,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.812 | Acc: 49.479,78.048,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.806 | Acc: 49.536,78.241,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.803 | Acc: 49.613,78.377,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.803 | Acc: 49.479,78.513,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.801 | Acc: 49.583,78.460,92.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.805 | Acc: 49.538,78.462,92.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 49.487,78.506,92.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.793 | Acc: 49.689,78.680,92.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.803 | Acc: 49.556,78.589,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.804 | Acc: 49.587,78.628,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 49.747,78.600,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 49.714,78.556,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.802 | Acc: 49.720,78.551,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 49.746,78.485,92.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.808 | Acc: 49.781,78.458,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.811 | Acc: 49.811,78.396,92.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.761 | Acc: 44.531,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.764 | Acc: 43.415,63.765,67.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.775 | Acc: 42.873,63.186,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.777 | Acc: 42.918,62.948,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.605 | Acc: 49.219,87.500,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.823 | Acc: 49.330,77.939,92.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.743 | Acc: 51.124,78.659,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.747 | Acc: 50.628,78.829,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.771 | Acc: 50.521,78.839,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.778 | Acc: 50.108,78.968,92.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.784 | Acc: 50.181,78.803,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.797 | Acc: 49.950,78.662,92.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.792 | Acc: 49.961,78.630,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 50.000,78.621,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.788 | Acc: 50.047,78.595,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.792 | Acc: 50.060,78.592,92.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.790 | Acc: 50.084,78.634,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 50.048,78.682,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.789 | Acc: 50.028,78.675,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.788 | Acc: 50.088,78.743,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.789 | Acc: 50.083,78.743,92.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.797 | Acc: 50.000,78.650,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 50.117,78.673,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.796 | Acc: 50.068,78.652,92.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.573 | Acc: 43.750,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 44.643,63.876,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 44.684,63.815,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.675 | Acc: 44.352,63.665,68.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.747 | Acc: 55.469,78.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.716 | Acc: 51.228,80.097,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.772 | Acc: 50.572,79.402,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.755 | Acc: 50.640,79.444,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.781 | Acc: 50.338,79.176,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.778 | Acc: 50.487,79.076,92.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.789 | Acc: 50.458,78.990,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 50.288,79.000,92.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.779 | Acc: 50.238,79.076,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 50.211,78.949,92.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.775 | Acc: 50.466,79.062,92.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 50.403,79.058,92.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.782 | Acc: 50.408,79.010,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.780 | Acc: 50.296,78.930,92.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.782 | Acc: 50.297,78.873,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.790 | Acc: 50.117,78.774,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.792 | Acc: 50.151,78.729,92.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.795 | Acc: 50.021,78.684,92.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.795 | Acc: 50.078,78.642,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.800 | Acc: 49.959,78.605,92.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.620 | Acc: 42.969,64.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.747 | Acc: 43.750,63.095,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.718 | Acc: 44.245,63.167,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.685 | Acc: 43.929,63.256,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.463 | Acc: 55.469,83.594,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.789 | Acc: 51.004,80.208,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.791 | Acc: 50.076,79.992,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.772 | Acc: 50.333,79.739,92.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.777 | Acc: 50.502,79.543,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.178,79.486,92.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.762 | Acc: 50.097,79.410,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 50.166,79.582,92.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.756 | Acc: 50.238,79.576,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.762 | Acc: 50.104,79.407,92.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 50.167,79.415,92.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.768 | Acc: 50.156,79.249,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.771 | Acc: 50.029,79.221,92.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.777 | Acc: 49.961,79.089,92.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.777 | Acc: 49.964,79.029,92.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.774 | Acc: 50.075,79.039,92.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.777 | Acc: 50.095,78.977,92.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.779 | Acc: 50.037,78.954,92.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.788 | Acc: 50.011,78.889,92.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.789 | Acc: 50.006,78.837,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.544 | Acc: 46.094,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.806 | Acc: 42.671,62.686,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.781 | Acc: 42.950,63.681,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.762 | Acc: 43.135,63.717,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 3.284 | Acc: 43.750,78.906,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 51.079,79.688,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.696 | Acc: 51.715,79.726,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.746 | Acc: 51.165,79.239,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.753 | Acc: 50.781,79.090,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.763 | Acc: 50.627,79.100,92.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 50.374,79.074,92.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 50.377,79.122,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.775 | Acc: 50.306,79.057,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 50.324,79.057,92.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.780 | Acc: 50.257,78.984,92.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.777 | Acc: 50.304,78.980,92.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.770 | Acc: 50.499,79.020,92.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.770 | Acc: 50.404,78.969,92.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.773 | Acc: 50.392,78.934,92.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.773 | Acc: 50.350,78.852,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.776 | Acc: 50.377,78.848,92.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.780 | Acc: 50.252,78.780,92.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.785 | Acc: 50.193,78.705,92.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 50.152,78.672,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.647 | Acc: 44.531,64.062,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.824 | Acc: 42.336,62.909,67.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.814 | Acc: 42.454,63.243,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.806 | Acc: 42.636,62.910,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 3.332 | Acc: 42.188,70.312,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 50.521,78.795,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 50.972,79.459,92.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 49.923,79.034,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 49.894,78.954,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.766 | Acc: 50.402,78.798,92.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.761 | Acc: 50.239,78.977,92.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 50.238,78.973,92.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.758 | Acc: 50.277,78.819,92.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.767 | Acc: 50.224,78.630,92.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.769 | Acc: 50.222,78.681,92.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.776 | Acc: 50.081,78.708,92.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.771 | Acc: 50.130,78.812,92.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.775 | Acc: 50.147,78.798,92.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.776 | Acc: 50.092,78.767,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.768 | Acc: 50.182,78.795,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.770 | Acc: 50.144,78.797,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.771 | Acc: 50.142,78.808,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 50.154,78.783,92.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.775 | Acc: 50.209,78.734,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.702 | Acc: 42.969,63.281,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.852 | Acc: 42.188,62.760,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.816 | Acc: 42.626,63.014,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.813 | Acc: 42.649,62.820,68.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 2.702 | Acc: 49.219,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.691 | Acc: 51.711,79.576,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 50.991,79.535,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 50.628,79.175,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.727 | Acc: 50.733,79.321,92.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.723 | Acc: 50.820,79.278,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.731 | Acc: 50.620,79.248,92.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.738 | Acc: 50.609,79.372,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.745 | Acc: 50.471,79.251,92.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.748 | Acc: 50.445,79.247,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 50.299,78.976,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.765 | Acc: 50.336,78.998,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.770 | Acc: 50.269,78.884,92.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.766 | Acc: 50.314,78.882,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.766 | Acc: 50.450,78.834,92.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.767 | Acc: 50.485,78.802,92.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.778 | Acc: 50.341,78.673,92.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.780 | Acc: 50.300,78.682,92.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.782 | Acc: 50.242,78.657,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.783 | Acc: 50.185,78.638,92.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.615 | Acc: 40.625,63.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.851 | Acc: 43.006,61.905,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.844 | Acc: 43.159,62.329,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.834 | Acc: 42.700,62.385,67.175,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.585 | Acc: 47.656,80.469,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.754 | Acc: 50.670,79.278,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 51.162,79.611,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 50.935,79.431,92.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.740 | Acc: 50.559,79.282,92.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.731 | Acc: 50.348,79.440,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.732 | Acc: 50.465,79.378,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.725 | Acc: 50.676,79.399,92.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.739 | Acc: 50.427,79.324,92.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.752 | Acc: 50.289,79.221,92.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.755 | Acc: 50.113,79.233,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.758 | Acc: 50.198,79.108,92.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.762 | Acc: 50.230,79.078,92.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.769 | Acc: 50.219,79.017,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.768 | Acc: 50.247,78.979,92.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.774 | Acc: 50.125,78.935,92.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.772 | Acc: 50.075,79.016,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.770 | Acc: 50.025,79.039,92.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 50.017,78.988,92.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 49.988,78.949,92.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.421 | Acc: 45.312,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.759 | Acc: 43.824,63.467,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 43.750,63.262,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.738 | Acc: 43.481,63.307,67.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 2.595 | Acc: 50.781,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.726 | Acc: 50.298,80.246,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.746 | Acc: 49.657,79.688,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.726 | Acc: 49.910,79.419,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.749 | Acc: 49.749,79.273,93.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 49.838,79.223,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.744 | Acc: 49.774,79.384,93.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.743 | Acc: 49.884,79.228,93.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.754 | Acc: 49.772,79.149,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.758 | Acc: 49.793,79.092,92.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 49.856,79.038,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.764 | Acc: 49.749,79.051,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.768 | Acc: 49.718,79.052,92.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.763 | Acc: 49.865,79.089,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.769 | Acc: 49.811,79.056,92.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.770 | Acc: 49.702,79.031,92.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.773 | Acc: 49.671,78.928,92.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.776 | Acc: 49.686,78.876,92.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.779 | Acc: 49.697,78.848,92.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.784 | Acc: 49.664,78.761,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.678 | Acc: 46.875,60.938,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.991 | Acc: 41.778,61.533,67.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.989 | Acc: 41.349,61.490,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.974 | Acc: 41.329,61.706,66.726,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.943 | Acc: 46.875,73.438,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 50.744,80.432,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.702 | Acc: 50.857,79.649,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 50.077,79.162,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.735 | Acc: 49.932,78.983,93.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 49.745,78.937,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.744 | Acc: 49.858,79.048,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.749 | Acc: 49.668,79.045,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.750 | Acc: 49.879,78.940,92.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.740 | Acc: 50.013,79.088,92.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.744 | Acc: 49.794,79.042,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.748 | Acc: 49.830,79.044,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.752 | Acc: 49.935,78.981,92.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.757 | Acc: 49.799,78.945,92.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 49.892,78.973,92.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.760 | Acc: 49.891,78.943,92.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.763 | Acc: 49.837,78.974,92.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.770 | Acc: 49.759,78.849,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.767 | Acc: 49.831,78.902,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 49.916,78.935,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.808 | Acc: 42.969,59.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.891 | Acc: 41.406,62.240,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.912 | Acc: 41.044,61.966,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.894 | Acc: 41.368,62.039,66.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.762 | Acc: 46.875,82.031,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.718 | Acc: 49.665,80.022,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.733 | Acc: 50.152,80.221,92.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.738 | Acc: 50.013,79.777,92.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.745 | Acc: 50.376,79.842,92.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.753 | Acc: 50.039,79.680,92.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.767 | Acc: 50.019,79.545,92.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 50.299,79.499,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.762 | Acc: 50.330,79.280,92.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.764 | Acc: 50.173,79.299,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.772 | Acc: 50.249,79.206,92.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 50.290,79.094,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.781 | Acc: 50.301,79.065,92.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.777 | Acc: 50.401,79.059,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.778 | Acc: 50.303,79.045,92.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.779 | Acc: 50.348,79.039,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.778 | Acc: 50.431,78.974,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.781 | Acc: 50.339,78.849,92.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.778 | Acc: 50.431,78.867,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.783 | Acc: 50.388,78.814,92.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.549 | Acc: 43.750,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.783 | Acc: 44.048,62.723,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.791 | Acc: 43.807,62.252,67.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.768 | Acc: 43.763,62.577,67.687,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.669 | Acc: 50.000,83.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.760 | Acc: 49.479,79.874,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.708 | Acc: 50.915,79.935,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.724 | Acc: 51.025,79.419,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.738 | Acc: 50.694,79.157,92.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.737 | Acc: 50.828,79.038,92.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.750 | Acc: 50.471,79.010,92.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.740 | Acc: 50.621,79.006,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.741 | Acc: 50.611,78.979,92.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.735 | Acc: 50.535,79.066,92.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.743 | Acc: 50.400,79.027,92.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.755 | Acc: 50.269,78.920,92.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.759 | Acc: 50.340,78.939,92.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.761 | Acc: 50.323,78.921,92.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.762 | Acc: 50.348,78.917,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.763 | Acc: 50.280,78.873,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.765 | Acc: 50.270,78.843,92.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.765 | Acc: 50.252,78.865,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.767 | Acc: 50.242,78.843,92.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.767 | Acc: 50.211,78.791,92.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.509 | Acc: 47.656,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.782 | Acc: 43.787,62.798,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.811 | Acc: 43.255,62.919,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.773 | Acc: 43.199,62.884,67.162,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.887 | Acc: 49.219,74.219,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.709 | Acc: 50.632,78.348,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.739 | Acc: 50.000,78.430,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.744 | Acc: 50.090,78.727,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.735 | Acc: 50.434,78.916,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.736 | Acc: 50.333,78.837,93.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.729 | Acc: 50.220,78.932,93.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.729 | Acc: 50.255,78.879,93.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.737 | Acc: 50.184,78.756,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.737 | Acc: 50.086,78.785,93.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.739 | Acc: 50.202,78.875,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.749 | Acc: 50.092,78.832,92.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.744 | Acc: 50.201,78.900,92.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.742 | Acc: 50.263,79.038,92.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.746 | Acc: 50.225,79.040,92.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.757 | Acc: 49.979,78.896,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.759 | Acc: 50.022,78.872,92.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.763 | Acc: 49.906,78.854,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.764 | Acc: 49.922,78.776,92.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.768 | Acc: 49.953,78.732,92.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.517 | Acc: 42.969,61.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.853 | Acc: 42.783,62.872,67.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.866 | Acc: 42.511,62.805,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.869 | Acc: 42.354,62.513,66.829,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.839 | Acc: 47.656,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.658 | Acc: 50.595,80.729,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.651 | Acc: 51.543,81.098,93.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.677 | Acc: 51.255,80.418,92.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.706 | Acc: 50.704,79.861,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.715 | Acc: 50.657,79.834,92.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.727 | Acc: 50.368,79.778,92.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.724 | Acc: 50.537,79.643,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.727 | Acc: 50.558,79.508,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.735 | Acc: 50.328,79.467,92.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.730 | Acc: 50.315,79.501,92.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.732 | Acc: 50.350,79.518,92.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.734 | Acc: 50.350,79.422,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.740 | Acc: 50.284,79.328,92.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.743 | Acc: 50.206,79.265,92.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.745 | Acc: 50.182,79.215,92.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 50.080,79.116,92.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.755 | Acc: 50.092,79.131,92.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.753 | Acc: 50.117,79.090,92.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.755 | Acc: 50.057,79.091,92.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.763 | Acc: 49.219,61.719,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.731 | Acc: 43.638,63.021,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.756 | Acc: 43.388,63.072,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.728 | Acc: 43.571,63.397,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.797 | Acc: 45.312,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.763 | Acc: 49.330,78.646,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.734 | Acc: 49.714,79.021,92.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.764 | Acc: 49.155,78.932,92.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.759 | Acc: 49.306,79.003,92.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.752 | Acc: 49.582,78.999,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 49.406,79.152,92.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.769 | Acc: 49.424,79.028,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.770 | Acc: 49.413,78.979,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.770 | Acc: 49.426,79.044,92.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.763 | Acc: 49.627,79.213,92.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.765 | Acc: 49.562,79.189,92.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.770 | Acc: 49.592,79.130,92.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.775 | Acc: 49.647,79.029,92.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.776 | Acc: 49.664,79.026,92.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.771 | Acc: 49.803,79.020,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.773 | Acc: 49.871,78.960,92.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.772 | Acc: 49.897,78.925,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.772 | Acc: 49.885,78.895,92.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.769 | Acc: 50.006,78.972,92.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.844 | Acc: 42.188,58.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.987 | Acc: 42.039,62.314,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.982 | Acc: 41.482,62.100,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.962 | Acc: 41.650,62.231,66.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 3.088 | Acc: 46.094,75.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.758 | Acc: 50.930,79.799,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.095,79.535,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 50.282,79.752,92.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.721 | Acc: 50.405,79.784,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.744 | Acc: 50.333,79.711,92.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.732 | Acc: 50.671,79.733,93.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.734 | Acc: 50.615,79.621,93.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.750 | Acc: 50.320,79.290,92.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.744 | Acc: 50.371,79.364,92.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.745 | Acc: 50.346,79.334,92.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.748 | Acc: 50.159,79.288,92.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.750 | Acc: 50.191,79.331,92.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.747 | Acc: 50.287,79.265,92.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.752 | Acc: 50.206,79.245,92.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.755 | Acc: 50.241,79.249,92.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.759 | Acc: 50.114,79.215,92.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.759 | Acc: 50.151,79.211,92.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.759 | Acc: 50.260,79.149,92.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.764 | Acc: 50.224,79.101,92.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.612 | Acc: 44.531,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.882 | Acc: 42.671,62.835,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.872 | Acc: 43.083,63.072,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.863 | Acc: 42.943,63.025,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.943 | Acc: 45.312,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 49.144,79.315,92.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.719 | Acc: 50.229,80.316,93.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.723 | Acc: 50.256,79.918,93.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.742 | Acc: 50.135,79.649,92.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.736 | Acc: 50.170,79.517,92.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.747 | Acc: 49.929,79.533,92.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.751 | Acc: 49.983,79.560,92.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.739 | Acc: 50.184,79.624,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.745 | Acc: 50.229,79.580,92.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.744 | Acc: 50.249,79.458,92.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.748 | Acc: 50.209,79.415,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.754 | Acc: 50.243,79.344,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.763 | Acc: 50.207,79.239,92.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.759 | Acc: 50.311,79.248,92.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.760 | Acc: 50.213,79.189,92.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.758 | Acc: 50.214,79.169,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.762 | Acc: 50.247,79.099,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.763 | Acc: 50.296,79.123,92.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.761 | Acc: 50.314,79.097,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.605 | Acc: 46.875,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.748 | Acc: 44.792,63.281,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.786 | Acc: 44.474,63.262,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.762 | Acc: 44.339,63.371,67.354,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 2.934 | Acc: 42.969,79.688,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.705 | Acc: 50.149,79.650,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 50.781,79.707,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 50.653,79.470,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.719 | Acc: 50.463,79.427,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.715 | Acc: 50.758,79.440,92.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.729 | Acc: 50.717,79.223,92.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.721 | Acc: 50.709,79.172,92.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.721 | Acc: 50.602,79.256,92.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.726 | Acc: 50.518,79.277,92.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.732 | Acc: 50.276,79.217,92.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.743 | Acc: 50.124,79.111,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.741 | Acc: 50.259,79.204,92.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.746 | Acc: 50.233,79.146,92.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.747 | Acc: 50.209,79.115,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.748 | Acc: 50.200,79.166,92.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.753 | Acc: 50.148,79.081,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.753 | Acc: 50.039,79.126,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.759 | Acc: 50.032,79.045,92.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.757 | Acc: 50.018,79.056,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.611 | Acc: 43.750,62.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.838 | Acc: 42.560,62.165,68.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.865 | Acc: 42.607,62.691,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.860 | Acc: 42.879,62.705,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.869 | Acc: 50.781,78.125,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.742 | Acc: 51.042,78.423,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.776 | Acc: 50.324,78.354,92.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 50.154,78.714,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 50.135,78.771,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 50.248,78.759,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.758 | Acc: 50.697,78.997,92.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.755 | Acc: 50.720,79.089,92.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.756 | Acc: 50.587,79.037,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.754 | Acc: 50.470,79.182,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 50.385,79.159,92.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.758 | Acc: 50.410,79.235,92.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.763 | Acc: 50.282,79.266,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.766 | Acc: 50.207,79.188,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.762 | Acc: 50.161,79.259,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.769 | Acc: 50.104,79.166,92.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.775 | Acc: 50.066,79.021,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.776 | Acc: 50.041,79.005,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.774 | Acc: 50.043,78.988,92.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 50.072,78.925,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 44.531,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.813 | Acc: 43.006,62.388,68.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.799 | Acc: 42.740,63.319,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.804 | Acc: 42.777,63.243,67.610,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.293 | Acc: 55.469,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.661 | Acc: 52.679,79.688,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.677 | Acc: 51.486,79.402,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.665 | Acc: 51.294,80.020,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.669 | Acc: 51.196,80.237,93.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.666 | Acc: 51.145,80.337,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.661 | Acc: 51.027,80.507,93.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.662 | Acc: 50.698,80.541,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.657 | Acc: 50.689,80.532,93.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.651 | Acc: 50.833,80.637,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.641 | Acc: 50.937,80.745,93.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.633 | Acc: 51.018,80.847,93.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.638 | Acc: 50.872,80.761,93.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.636 | Acc: 50.865,80.771,93.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.632 | Acc: 50.962,80.841,93.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.627 | Acc: 51.002,80.845,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.628 | Acc: 51.044,80.795,94.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.624 | Acc: 51.022,80.822,94.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.625 | Acc: 50.961,80.815,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.622 | Acc: 51.009,80.832,94.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.309 | Acc: 44.531,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.563 | Acc: 46.019,64.472,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 45.694,64.710,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.544 | Acc: 45.351,64.716,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.342 | Acc: 53.125,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.557 | Acc: 51.488,81.436,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.561 | Acc: 51.677,81.345,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.535 | Acc: 51.844,82.185,94.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.620,82.051,94.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.532 | Acc: 51.988,82.209,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.542 | Acc: 51.931,82.147,94.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.551 | Acc: 51.734,82.048,94.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.551 | Acc: 51.781,81.944,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.558 | Acc: 51.774,81.837,94.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.564 | Acc: 51.656,81.837,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.563 | Acc: 51.608,81.756,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.559 | Acc: 51.734,81.785,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.559 | Acc: 51.610,81.798,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.555 | Acc: 51.601,81.820,94.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.561 | Acc: 51.508,81.704,94.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.564 | Acc: 51.509,81.610,94.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.571 | Acc: 51.466,81.509,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.574 | Acc: 51.396,81.527,94.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.575 | Acc: 51.345,81.488,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.335 | Acc: 42.969,62.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.548 | Acc: 45.796,64.472,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.560 | Acc: 45.503,64.768,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 45.236,64.626,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.519 | Acc: 50.000,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.566 | Acc: 50.930,81.622,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.562 | Acc: 51.753,81.822,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.576 | Acc: 51.114,81.865,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.564 | Acc: 51.514,82.051,95.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.571 | Acc: 51.098,82.016,95.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.568 | Acc: 51.220,82.076,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.572 | Acc: 51.103,81.948,95.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.565 | Acc: 51.237,81.939,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.567 | Acc: 51.252,81.867,95.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.563 | Acc: 51.267,81.810,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.565 | Acc: 51.092,81.862,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.563 | Acc: 51.306,81.808,95.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.565 | Acc: 51.200,81.816,95.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.565 | Acc: 51.262,81.759,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.568 | Acc: 51.220,81.696,95.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.565 | Acc: 51.300,81.729,95.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.567 | Acc: 51.235,81.635,95.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.566 | Acc: 51.147,81.672,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.565 | Acc: 51.210,81.720,95.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.377 | Acc: 44.531,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.543 | Acc: 46.019,64.993,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.548 | Acc: 45.732,65.244,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.537 | Acc: 45.428,65.010,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.763 | Acc: 49.219,85.156,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.646 | Acc: 48.289,80.432,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.576 | Acc: 50.095,81.231,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.561 | Acc: 50.307,81.340,95.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.555 | Acc: 50.646,81.327,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.568 | Acc: 50.503,81.412,95.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.566 | Acc: 50.465,81.366,95.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.570 | Acc: 50.654,81.444,95.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.559 | Acc: 50.796,81.638,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.562 | Acc: 50.695,81.647,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.558 | Acc: 50.906,81.740,95.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.560 | Acc: 50.926,81.773,95.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.558 | Acc: 50.985,81.723,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.559 | Acc: 50.997,81.663,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.559 | Acc: 51.087,81.731,95.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.559 | Acc: 51.171,81.767,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.559 | Acc: 51.205,81.783,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.562 | Acc: 51.210,81.759,95.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.564 | Acc: 51.190,81.774,95.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.567 | Acc: 51.154,81.715,95.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 43.750,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 45.052,64.249,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.548 | Acc: 45.217,64.463,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 45.210,64.511,69.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.504 | Acc: 53.906,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.517 | Acc: 51.116,81.696,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.517 | Acc: 51.905,81.822,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.524 | Acc: 51.332,82.057,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 51.080,81.877,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.549 | Acc: 50.975,81.799,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.549 | Acc: 51.001,81.909,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.545 | Acc: 51.075,81.932,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.537 | Acc: 51.281,82.060,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 51.364,82.053,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.537 | Acc: 51.341,82.156,95.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.546 | Acc: 51.234,82.077,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.551 | Acc: 51.148,81.999,95.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.552 | Acc: 51.245,82.019,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.557 | Acc: 51.182,81.951,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.558 | Acc: 51.202,81.907,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.557 | Acc: 51.283,81.778,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.557 | Acc: 51.251,81.768,95.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.557 | Acc: 51.275,81.761,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.555 | Acc: 51.339,81.720,95.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.293 | Acc: 45.312,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 45.573,64.137,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.544 | Acc: 45.484,64.672,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.531 | Acc: 45.287,64.754,69.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.415 | Acc: 50.781,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.521 | Acc: 52.158,81.585,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.535 | Acc: 51.639,81.879,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 51.511,81.852,95.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.536 | Acc: 51.890,82.118,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 51.841,82.116,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.525 | Acc: 52.014,82.193,95.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.522 | Acc: 52.022,82.114,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.526 | Acc: 52.043,82.089,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.526 | Acc: 51.929,82.135,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.533 | Acc: 51.815,82.074,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.540 | Acc: 51.842,81.989,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.542 | Acc: 51.857,81.976,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.548 | Acc: 51.730,81.944,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.550 | Acc: 51.682,81.901,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.549 | Acc: 51.656,81.904,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.552 | Acc: 51.562,81.824,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.549 | Acc: 51.620,81.857,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.550 | Acc: 51.653,81.756,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.547 | Acc: 51.698,81.785,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.358 | Acc: 43.750,60.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.557 | Acc: 45.685,64.100,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.554 | Acc: 45.503,64.520,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.535 | Acc: 45.312,64.639,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.350 | Acc: 57.812,84.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.541 | Acc: 51.674,81.920,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.550 | Acc: 50.991,81.669,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 51.434,81.890,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.528 | Acc: 51.649,81.983,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.523 | Acc: 51.702,82.217,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.659,82.309,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.536 | Acc: 51.535,82.059,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.544 | Acc: 51.398,82.017,95.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.548 | Acc: 51.256,81.941,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.544 | Acc: 51.341,81.930,95.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.545 | Acc: 51.304,81.893,95.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.552 | Acc: 51.190,81.827,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.549 | Acc: 51.305,81.837,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.552 | Acc: 51.354,81.764,95.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.554 | Acc: 51.420,81.743,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.552 | Acc: 51.312,81.688,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.551 | Acc: 51.386,81.711,95.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.549 | Acc: 51.396,81.739,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.549 | Acc: 51.382,81.720,95.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.382 | Acc: 46.094,59.375,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.569 | Acc: 45.685,64.621,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.522,64.787,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.547 | Acc: 45.248,64.728,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.680 | Acc: 47.656,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.574 | Acc: 50.781,82.850,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.526 | Acc: 51.315,83.060,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.553 | Acc: 51.614,82.608,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.552 | Acc: 51.678,82.494,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.547 | Acc: 51.516,82.457,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 51.724,82.438,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.532 | Acc: 51.840,82.325,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.534 | Acc: 51.834,82.322,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.530 | Acc: 51.765,82.307,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.534 | Acc: 51.632,82.327,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 51.626,82.342,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.533 | Acc: 51.553,82.268,95.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.538 | Acc: 51.458,82.247,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 51.465,82.098,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.542 | Acc: 51.526,82.096,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.541 | Acc: 51.575,82.092,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.539 | Acc: 51.624,82.091,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.538 | Acc: 51.636,82.025,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.541 | Acc: 51.616,81.970,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.412 | Acc: 44.531,59.375,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.550 | Acc: 46.280,64.807,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.558 | Acc: 45.865,65.168,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.546 | Acc: 45.569,65.087,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.752 | Acc: 48.438,85.938,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.558 | Acc: 50.744,82.924,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.517 | Acc: 51.181,83.327,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 51.729,82.877,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 51.225,82.726,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.529 | Acc: 51.114,82.619,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.529 | Acc: 51.285,82.464,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.542 | Acc: 50.992,82.375,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.542 | Acc: 51.058,82.342,95.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.541 | Acc: 51.213,82.359,95.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.538 | Acc: 51.294,82.249,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.539 | Acc: 51.326,82.247,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 51.310,82.261,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.534 | Acc: 51.383,82.262,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.533 | Acc: 51.485,82.187,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.531 | Acc: 51.534,82.179,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.530 | Acc: 51.502,82.182,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 51.579,82.231,95.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.529 | Acc: 51.521,82.209,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.532 | Acc: 51.474,82.165,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.381 | Acc: 50.000,63.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.588 | Acc: 45.647,64.658,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 45.465,64.882,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 45.146,64.664,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.862 | Acc: 49.219,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.551 | Acc: 52.493,82.068,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.542 | Acc: 52.153,82.527,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 52.088,82.211,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.519 | Acc: 52.546,82.494,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 52.452,82.287,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.526 | Acc: 52.105,82.167,95.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.523 | Acc: 52.033,82.186,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.526 | Acc: 51.723,82.187,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.520 | Acc: 51.834,82.126,95.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.803,82.074,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.516 | Acc: 51.849,81.982,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.515 | Acc: 51.848,82.086,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.519 | Acc: 51.790,82.013,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 51.854,82.051,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 51.768,82.034,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 51.728,81.941,95.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 51.764,81.919,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.525 | Acc: 51.814,81.871,95.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.530 | Acc: 51.708,81.814,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.379 | Acc: 47.656,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.538 | Acc: 45.759,64.174,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.553 | Acc: 45.579,64.729,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.537 | Acc: 45.492,64.728,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.374 | Acc: 56.250,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.500 | Acc: 51.860,83.482,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.511 | Acc: 51.886,82.946,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 51.627,82.595,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.519 | Acc: 51.254,82.571,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 51.601,82.472,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 51.265,82.186,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.545 | Acc: 51.285,82.020,95.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.549 | Acc: 51.281,81.852,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.547 | Acc: 51.295,81.850,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.544 | Acc: 51.388,82.004,95.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.542 | Acc: 51.464,82.091,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.536 | Acc: 51.562,82.077,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.535 | Acc: 51.506,82.097,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.530 | Acc: 51.679,82.201,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 51.723,82.182,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.528 | Acc: 51.723,82.119,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.530 | Acc: 51.707,82.100,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 51.751,82.053,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.536 | Acc: 51.663,82.019,95.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.405 | Acc: 45.312,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 45.461,64.695,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.655,65.053,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 45.402,64.882,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.956 | Acc: 42.969,76.562,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.581 | Acc: 50.632,81.362,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.582 | Acc: 50.457,81.326,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.549 | Acc: 50.922,81.826,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.532 | Acc: 51.524,81.925,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 51.416,81.861,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.541 | Acc: 51.472,81.637,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.549 | Acc: 51.285,81.605,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.555 | Acc: 51.223,81.624,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.549 | Acc: 51.291,81.647,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.549 | Acc: 51.399,81.507,95.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.544 | Acc: 51.467,81.642,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.547 | Acc: 51.391,81.564,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.543 | Acc: 51.488,81.675,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.541 | Acc: 51.504,81.764,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.538 | Acc: 51.521,81.811,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.538 | Acc: 51.531,81.871,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 51.595,81.928,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.535 | Acc: 51.517,81.925,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.537 | Acc: 51.487,81.884,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.498 | Acc: 42.969,58.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.565 | Acc: 45.536,64.286,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.576 | Acc: 45.198,64.444,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 45.159,64.549,69.557,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.314 | Acc: 47.656,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 51.376,81.845,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.560 | Acc: 51.296,82.241,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 51.550,82.287,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.528 | Acc: 52.035,82.128,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 52.019,82.109,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.521 | Acc: 51.763,82.012,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.529 | Acc: 51.574,81.948,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 51.431,81.764,95.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.539 | Acc: 51.407,81.815,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.536 | Acc: 51.512,81.829,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.533 | Acc: 51.591,81.893,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 51.725,81.859,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.528 | Acc: 51.745,81.962,95.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.532 | Acc: 51.671,81.878,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.531 | Acc: 51.599,81.925,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.532 | Acc: 51.638,81.924,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.532 | Acc: 51.636,81.919,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.534 | Acc: 51.534,81.906,95.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.534 | Acc: 51.554,81.900,95.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 44.531,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 45.685,64.435,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.585 | Acc: 45.598,64.672,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.563 | Acc: 45.377,64.549,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.670 | Acc: 55.469,82.031,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.525 | Acc: 51.414,82.589,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.520 | Acc: 50.553,82.470,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.549 | Acc: 50.205,81.980,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.554 | Acc: 50.637,81.771,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 51.191,81.815,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.528 | Acc: 51.485,81.831,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.538 | Acc: 51.396,81.932,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.540 | Acc: 51.393,81.934,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 51.437,82.113,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.527 | Acc: 51.407,82.086,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 51.474,82.113,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.530 | Acc: 51.426,82.022,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.532 | Acc: 51.425,81.965,95.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 51.376,81.990,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.528 | Acc: 51.350,81.938,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.529 | Acc: 51.348,81.990,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.533 | Acc: 51.288,81.940,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.528 | Acc: 51.316,82.016,95.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.528 | Acc: 51.347,82.009,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.334 | Acc: 45.312,60.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.566 | Acc: 46.019,64.062,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 45.541,64.882,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.551 | Acc: 45.364,64.818,69.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.662 | Acc: 53.906,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 50.260,81.696,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.543 | Acc: 50.800,81.879,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.534 | Acc: 50.884,81.775,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.537 | Acc: 50.974,81.790,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.537 | Acc: 50.959,81.877,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.324,81.857,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 51.407,82.081,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 51.359,82.196,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.528 | Acc: 51.256,82.161,95.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.531 | Acc: 51.213,82.105,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.537 | Acc: 51.032,82.049,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.536 | Acc: 51.148,82.005,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.543 | Acc: 51.146,81.882,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 51.187,81.848,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.539 | Acc: 51.280,81.891,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.537 | Acc: 51.317,81.902,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 51.441,81.946,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.531 | Acc: 51.524,81.949,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.531 | Acc: 51.499,81.968,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.392 | Acc: 43.750,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 45.536,64.211,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.578 | Acc: 45.503,64.691,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.562 | Acc: 45.261,64.498,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.724 | Acc: 44.531,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 51.935,83.482,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.486 | Acc: 52.096,83.194,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.496 | Acc: 51.985,83.081,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.533 | Acc: 51.167,82.398,95.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.523 | Acc: 51.199,82.696,95.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 51.285,82.599,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 51.252,82.480,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.523 | Acc: 51.024,82.376,95.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 51.127,82.333,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.531 | Acc: 51.158,82.257,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.522 | Acc: 51.372,82.318,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.524 | Acc: 51.397,82.278,95.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.519 | Acc: 51.577,82.325,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 51.632,82.345,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.518 | Acc: 51.630,82.366,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.523 | Acc: 51.572,82.333,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 51.634,82.352,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.523 | Acc: 51.562,82.278,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.526 | Acc: 51.583,82.193,95.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.404 | Acc: 45.312,58.594,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.571 | Acc: 45.685,64.397,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.568 | Acc: 45.579,64.901,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 45.441,64.908,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.612 | Acc: 56.250,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 52.307,81.436,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.505 | Acc: 52.401,81.784,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.528 | Acc: 51.703,81.647,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.560 | Acc: 50.897,81.346,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.561 | Acc: 50.920,81.258,95.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.548 | Acc: 51.040,81.444,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.530 | Acc: 51.225,81.771,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 51.334,81.764,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.532 | Acc: 51.234,81.742,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.536 | Acc: 51.201,81.654,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.536 | Acc: 51.170,81.664,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.535 | Acc: 51.219,81.684,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.533 | Acc: 51.302,81.726,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 51.504,81.853,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.521 | Acc: 51.495,81.917,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.517 | Acc: 51.597,81.907,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 51.556,81.960,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.552,81.964,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 51.604,81.980,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.435 | Acc: 43.750,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 45.610,64.546,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 45.408,64.996,69.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 45.377,65.061,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.636 | Acc: 60.156,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.552 | Acc: 52.381,82.403,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.523 | Acc: 52.229,81.860,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 51.883,82.082,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.522 | Acc: 51.842,81.838,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.516 | Acc: 51.748,81.962,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.524 | Acc: 51.537,82.012,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.524 | Acc: 51.596,81.954,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 51.524,82.022,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.519 | Acc: 51.550,82.066,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 51.570,82.062,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.519 | Acc: 51.598,82.102,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.523 | Acc: 51.553,82.051,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.527 | Acc: 51.586,81.995,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.526 | Acc: 51.521,82.053,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 51.659,82.052,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 51.706,82.077,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.521 | Acc: 51.739,82.093,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.695,82.088,95.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.780,82.062,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.428 | Acc: 43.750,61.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.576 | Acc: 45.871,64.137,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 45.732,64.558,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 45.697,64.664,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.543 | Acc: 41.406,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.498 | Acc: 51.004,82.552,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 51.486,82.450,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 52.293,82.364,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.482 | Acc: 52.344,82.340,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 52.058,82.542,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 51.853,82.412,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 51.934,82.303,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.497 | Acc: 52.048,82.220,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 51.839,82.113,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 51.811,82.175,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.508 | Acc: 51.785,82.173,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 51.728,82.171,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.511 | Acc: 51.688,82.181,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 51.804,82.137,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.516 | Acc: 51.734,82.143,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.518 | Acc: 51.701,82.085,95.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.519 | Acc: 51.698,82.100,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 51.690,82.122,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.655,82.148,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.420 | Acc: 45.312,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.590 | Acc: 45.796,64.360,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 45.770,64.615,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 45.466,64.626,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.412 | Acc: 50.000,83.594,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.431 | Acc: 52.753,82.961,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 52.134,82.298,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 51.998,82.608,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 52.035,82.436,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 51.887,82.372,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 51.634,82.380,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 51.535,82.558,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.500 | Acc: 51.456,82.410,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.503 | Acc: 51.480,82.372,95.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.511 | Acc: 51.419,82.222,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.507 | Acc: 51.506,82.349,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 51.446,82.242,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.513 | Acc: 51.293,82.190,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.518 | Acc: 51.212,82.117,95.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.514 | Acc: 51.251,82.192,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.513 | Acc: 51.280,82.216,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.517 | Acc: 51.327,82.166,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 51.281,82.161,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.523 | Acc: 51.318,82.146,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.426 | Acc: 44.531,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.583 | Acc: 45.871,64.546,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 45.522,64.691,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 45.364,64.869,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.641 | Acc: 51.562,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.488 | Acc: 53.274,81.362,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.519 | Acc: 51.734,81.250,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 51.831,81.775,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.509 | Acc: 51.736,82.012,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.518 | Acc: 51.539,82.047,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.522 | Acc: 51.562,81.973,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.515 | Acc: 51.729,81.970,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.514 | Acc: 51.635,82.046,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 51.584,82.092,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.520 | Acc: 51.493,82.035,95.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.520 | Acc: 51.517,82.081,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.521 | Acc: 51.533,82.012,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.524 | Acc: 51.655,81.983,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 51.674,82.056,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 51.697,82.143,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.518 | Acc: 51.665,82.206,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.521 | Acc: 51.650,82.095,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.660,82.126,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.520 | Acc: 51.513,82.083,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 46.875,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 45.722,64.583,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 45.484,64.882,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.312,64.703,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.532 | Acc: 44.531,75.781,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 52.641,82.738,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 51.505,82.812,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.520 | Acc: 51.089,82.544,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.516 | Acc: 51.138,82.475,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.517 | Acc: 50.998,82.426,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.529 | Acc: 50.839,82.135,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.531 | Acc: 50.715,82.153,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.525 | Acc: 50.888,82.264,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 51.053,82.247,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 51.108,82.354,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.523 | Acc: 51.202,82.282,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 51.365,82.265,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.368,82.289,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.512 | Acc: 51.499,82.334,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 51.461,82.260,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 51.475,82.260,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.518 | Acc: 51.473,82.325,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 51.437,82.291,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 51.439,82.341,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.370 | Acc: 44.531,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 45.536,64.062,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 45.274,64.558,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.567 | Acc: 45.248,64.626,69.454,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 3.077 | Acc: 44.531,78.906,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.542 | Acc: 52.455,82.217,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.531 | Acc: 52.687,81.688,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 52.203,82.185,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.529 | Acc: 51.543,82.301,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 51.501,82.132,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.530 | Acc: 51.479,82.231,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.523 | Acc: 51.590,82.347,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.524 | Acc: 51.499,82.327,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.522 | Acc: 51.645,82.277,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.511 | Acc: 51.885,82.331,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 51.874,82.342,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 52.003,82.245,95.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.517 | Acc: 51.916,82.118,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.515 | Acc: 51.902,82.151,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.519 | Acc: 51.814,82.109,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.516 | Acc: 51.811,82.131,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 51.766,82.105,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.517 | Acc: 51.714,82.105,95.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.515 | Acc: 51.733,82.107,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.426 | Acc: 45.312,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.594 | Acc: 45.759,64.397,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 45.732,64.768,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 45.569,64.844,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.329 | Acc: 52.344,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 52.083,82.440,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.494 | Acc: 51.905,82.908,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.474 | Acc: 52.011,82.979,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.486 | Acc: 51.823,82.957,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 51.416,82.874,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.508 | Acc: 51.246,82.599,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 51.225,82.535,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 51.354,82.458,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 51.468,82.523,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 51.442,82.575,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.508 | Acc: 51.372,82.434,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.506 | Acc: 51.462,82.362,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.515 | Acc: 51.386,82.271,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.516 | Acc: 51.360,82.245,95.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 51.373,82.223,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.512 | Acc: 51.502,82.331,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.512 | Acc: 51.562,82.286,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.512 | Acc: 51.550,82.282,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.511 | Acc: 51.548,82.333,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.462 | Acc: 45.312,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 45.164,63.988,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.611 | Acc: 45.236,64.634,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 45.210,64.754,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 2.402 | Acc: 50.000,87.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.448 | Acc: 52.455,83.891,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 51.829,82.851,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.496 | Acc: 51.985,82.672,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.458 | Acc: 52.344,83.083,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.458 | Acc: 52.274,83.207,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 52.370,83.264,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 51.939,83.040,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 51.931,82.929,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 51.752,82.718,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.493 | Acc: 51.710,82.719,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.502 | Acc: 51.570,82.569,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 51.776,82.634,95.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.497 | Acc: 51.820,82.648,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 51.804,82.562,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 51.765,82.592,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.506 | Acc: 51.733,82.562,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 51.668,82.533,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 51.562,82.505,95.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.513 | Acc: 51.558,82.484,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 43.750,60.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.589 | Acc: 45.982,64.435,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 45.865,64.863,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 45.594,64.895,69.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.107 | Acc: 57.812,91.406,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 50.967,81.957,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.532 | Acc: 51.200,81.059,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 51.127,81.596,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.572,81.867,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 51.679,82.024,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.507 | Acc: 51.666,82.012,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 51.673,82.148,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.512 | Acc: 51.446,82.075,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.517 | Acc: 51.416,82.070,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.523 | Acc: 51.329,82.132,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.522 | Acc: 51.506,82.137,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 51.546,82.164,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.518 | Acc: 51.574,82.163,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 51.632,82.109,95.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.520 | Acc: 51.638,82.034,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.521 | Acc: 51.601,81.953,95.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 51.604,81.903,95.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.524 | Acc: 51.649,81.919,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.521 | Acc: 51.692,81.992,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.445 | Acc: 46.094,60.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 45.945,64.397,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 45.598,65.091,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 45.517,64.985,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.744 | Acc: 41.406,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 51.190,82.626,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 51.982,82.679,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.516 | Acc: 51.550,82.326,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.528 | Acc: 51.167,82.330,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.522 | Acc: 51.307,82.356,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.526 | Acc: 51.265,82.457,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.530 | Acc: 51.069,82.463,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 50.951,82.541,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.518 | Acc: 51.222,82.528,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 51.271,82.568,95.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.512 | Acc: 51.350,82.625,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.510 | Acc: 51.462,82.647,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.505 | Acc: 51.482,82.714,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.505 | Acc: 51.554,82.718,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 51.607,82.693,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.500 | Acc: 51.701,82.666,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.504 | Acc: 51.666,82.602,95.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.506 | Acc: 51.643,82.609,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.506 | Acc: 51.606,82.532,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.513 | Acc: 45.312,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 45.424,63.728,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 45.274,64.367,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 45.159,64.460,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.314 | Acc: 57.812,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.499 | Acc: 53.646,82.664,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.522 | Acc: 51.810,82.393,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.529 | Acc: 51.473,82.159,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.523 | Acc: 51.813,82.186,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 51.818,82.441,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 51.543,82.361,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.514 | Acc: 51.740,82.281,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.509 | Acc: 51.834,82.483,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.516 | Acc: 51.739,82.523,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.520 | Acc: 51.745,82.552,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.518 | Acc: 51.739,82.530,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.516 | Acc: 51.760,82.599,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.516 | Acc: 51.718,82.537,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 51.752,82.509,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 51.765,82.504,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.506 | Acc: 51.752,82.542,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.504 | Acc: 51.760,82.618,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 51.673,82.607,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.507 | Acc: 51.651,82.577,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.465 | Acc: 44.531,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 45.201,64.211,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 45.332,64.672,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 45.056,64.664,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.624 | Acc: 52.344,83.594,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 51.562,81.920,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.530 | Acc: 51.315,82.031,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 52.088,82.313,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.508 | Acc: 51.881,82.012,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 51.663,82.263,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.504 | Acc: 51.459,82.309,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.497 | Acc: 51.690,82.425,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 51.601,82.381,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 51.489,82.251,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.510 | Acc: 51.399,82.198,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 51.403,82.105,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 51.517,82.184,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.503 | Acc: 51.676,82.214,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.702,82.354,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.498 | Acc: 51.643,82.356,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 51.691,82.408,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 51.675,82.297,95.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.502 | Acc: 51.638,82.267,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.508 | Acc: 51.601,82.160,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.456 | Acc: 46.875,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.605 | Acc: 45.685,64.100,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 45.694,64.558,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 45.389,64.754,68.968,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.496 | Acc: 46.094,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.484 | Acc: 52.493,82.403,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.484 | Acc: 52.229,82.317,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.532 | Acc: 51.294,81.878,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.542 | Acc: 51.061,81.559,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.522 | Acc: 51.323,81.931,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.519 | Acc: 51.679,82.173,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.522 | Acc: 51.607,82.098,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.521 | Acc: 51.655,82.080,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.512 | Acc: 51.761,82.221,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 51.718,82.202,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.515 | Acc: 51.637,82.123,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 51.741,82.129,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 51.814,82.211,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.503 | Acc: 51.849,82.273,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.502 | Acc: 51.827,82.239,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.502 | Acc: 51.881,82.318,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 51.906,82.350,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 51.816,82.336,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.503 | Acc: 51.804,82.329,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 46.875,62.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 45.387,64.472,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 45.293,64.787,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.587 | Acc: 44.941,64.728,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.193 | Acc: 56.250,90.625,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.394 | Acc: 53.460,83.445,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.457 | Acc: 52.896,82.698,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 52.254,82.748,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.479 | Acc: 52.276,82.697,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.073,82.588,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 51.956,82.793,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 51.856,82.696,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.481 | Acc: 51.975,82.740,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.477 | Acc: 51.981,82.812,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 52.052,82.824,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.486 | Acc: 51.888,82.742,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.486 | Acc: 51.854,82.680,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.486 | Acc: 51.817,82.660,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 51.777,82.637,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 51.768,82.646,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 51.801,82.645,96.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 51.808,82.583,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 51.796,82.633,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.490 | Acc: 51.819,82.581,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 47.656,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.629 | Acc: 46.280,64.174,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 45.846,64.501,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.603 | Acc: 45.556,64.472,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.414 | Acc: 53.906,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.553 | Acc: 51.190,82.626,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 52.039,83.327,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 52.395,83.043,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.228,82.948,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 52.104,83.137,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.040,82.942,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.011,83.073,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.082,83.075,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.033,82.989,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 52.122,82.949,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 52.015,82.894,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.497 | Acc: 51.883,82.858,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 51.829,82.708,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.500 | Acc: 51.824,82.679,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 51.703,82.613,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 51.820,82.679,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.500 | Acc: 51.750,82.599,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.501 | Acc: 51.669,82.613,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 51.708,82.595,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.422 | Acc: 47.656,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.590 | Acc: 46.577,64.174,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.586 | Acc: 46.056,64.901,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.566 | Acc: 45.748,64.767,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.380 | Acc: 55.469,85.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.536 | Acc: 50.372,81.622,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 51.181,81.974,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.503 | Acc: 51.434,81.878,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 51.350,81.829,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 51.214,81.730,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 51.330,81.831,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.512 | Acc: 51.080,81.826,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 51.102,81.745,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 51.165,81.854,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.508 | Acc: 51.333,81.954,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 51.386,81.900,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 51.280,81.866,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.507 | Acc: 51.341,81.918,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.506 | Acc: 51.368,81.953,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.509 | Acc: 51.357,82.016,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.513 | Acc: 51.351,82.014,96.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.511 | Acc: 51.368,82.084,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.507 | Acc: 51.409,82.085,96.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.505 | Acc: 51.478,82.169,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.341 | Acc: 46.094,62.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 45.647,64.658,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 45.427,64.977,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 45.325,64.831,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.334 | Acc: 56.250,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 50.632,82.738,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.463 | Acc: 52.001,83.308,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 52.024,82.928,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.493 | Acc: 51.640,82.812,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 51.408,82.627,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 51.879,82.658,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 51.817,82.596,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 51.926,82.570,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 51.778,82.666,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 51.749,82.665,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.500 | Acc: 51.683,82.600,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 51.540,82.641,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.497 | Acc: 51.557,82.630,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.599,82.629,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.499 | Acc: 51.555,82.602,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 51.504,82.552,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 51.592,82.565,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 51.545,82.527,95.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 51.552,82.527,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.441 | Acc: 46.875,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.612 | Acc: 45.424,64.286,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 45.408,64.615,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 45.210,64.652,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.327 | Acc: 55.469,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.417 | Acc: 52.418,82.812,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.434 | Acc: 52.115,82.927,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.465 | Acc: 52.024,82.941,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.471 | Acc: 52.267,82.986,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 52.205,82.905,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.228,83.071,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.028,82.868,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 51.985,82.779,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 51.804,82.718,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.493 | Acc: 51.667,82.579,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 51.693,82.607,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.490 | Acc: 51.802,82.592,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.490 | Acc: 51.832,82.558,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 51.743,82.498,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 51.755,82.480,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 51.779,82.506,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.493 | Acc: 51.776,82.407,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 51.710,82.321,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 51.671,82.327,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.474 | Acc: 45.312,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.618 | Acc: 46.094,64.695,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.622 | Acc: 45.941,64.729,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 45.658,64.588,68.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.326 | Acc: 53.125,85.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.500 | Acc: 52.083,81.771,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 51.772,82.889,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 51.575,82.953,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.465 | Acc: 51.842,82.909,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.468 | Acc: 51.841,82.905,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.472 | Acc: 51.827,82.703,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.471 | Acc: 52.000,82.702,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.471 | Acc: 52.033,82.662,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 51.843,82.575,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.490 | Acc: 51.745,82.618,96.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 51.821,82.657,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.493 | Acc: 51.734,82.634,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 51.769,82.627,96.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 51.818,82.518,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.497 | Acc: 51.726,82.436,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 51.604,82.408,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 51.634,82.327,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.499 | Acc: 51.656,82.358,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 51.780,82.374,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.531 | Acc: 45.312,59.375,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 45.982,64.583,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 45.846,64.748,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 45.543,64.767,68.981,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.682 | Acc: 46.094,80.469,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.552 | Acc: 51.042,81.622,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.514 | Acc: 51.467,82.565,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 51.127,82.736,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 51.640,82.841,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.497 | Acc: 51.439,82.495,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.512 | Acc: 51.304,82.328,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 51.568,82.419,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.508 | Acc: 51.592,82.342,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.506 | Acc: 51.714,82.364,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 51.811,82.595,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.497 | Acc: 51.838,82.600,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.502 | Acc: 51.666,82.469,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 51.766,82.597,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 51.796,82.534,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.501 | Acc: 51.866,82.472,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 51.911,82.518,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 51.897,82.535,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 51.915,82.512,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.498 | Acc: 51.870,82.482,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 46.094,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 46.205,64.397,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.614 | Acc: 45.960,64.577,69.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 45.620,64.511,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.550 | Acc: 52.344,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.440 | Acc: 51.935,83.594,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.451 | Acc: 52.020,83.327,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 51.524,83.120,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.479 | Acc: 51.408,82.948,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 51.369,82.805,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.478 | Acc: 51.614,82.858,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 51.612,82.757,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.475 | Acc: 52.014,82.701,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.475 | Acc: 51.899,82.748,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.473 | Acc: 51.920,82.820,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 51.792,82.827,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.475 | Acc: 51.666,82.796,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.479 | Acc: 51.670,82.705,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.483 | Acc: 51.615,82.668,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 51.550,82.641,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 51.577,82.701,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 51.533,82.696,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.488 | Acc: 51.506,82.678,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 51.507,82.651,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.482 | Acc: 46.094,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.627 | Acc: 45.796,64.286,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.627 | Acc: 45.598,64.539,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 45.415,64.549,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.260 | Acc: 53.125,89.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.437 | Acc: 52.455,82.961,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.455 | Acc: 52.896,82.946,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 52.075,82.531,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.482 | Acc: 51.939,82.841,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.483 | Acc: 51.725,82.836,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 52.034,82.948,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.475 | Acc: 52.017,82.829,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 51.970,82.779,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.479 | Acc: 51.778,82.804,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.480 | Acc: 51.699,82.774,96.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 51.693,82.749,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.473 | Acc: 51.880,82.738,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 51.844,82.747,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 51.785,82.790,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 51.744,82.828,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.479 | Acc: 51.706,82.757,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 51.773,82.801,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.475 | Acc: 51.807,82.862,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.473 | Acc: 51.864,82.866,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.443 | Acc: 44.531,59.375,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.590 | Acc: 46.354,64.509,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 46.075,64.806,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.572 | Acc: 45.812,64.831,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.449 | Acc: 49.219,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.452 | Acc: 52.679,82.775,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.465 | Acc: 51.810,82.870,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.501 | Acc: 51.883,82.185,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 52.045,82.407,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.494 | Acc: 52.019,82.325,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 52.098,82.354,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 52.045,82.120,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.507 | Acc: 51.975,82.157,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 51.951,82.269,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.512 | Acc: 51.547,82.167,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.512 | Acc: 51.566,82.123,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 51.731,82.261,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.502 | Acc: 51.784,82.283,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.501 | Acc: 51.729,82.259,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 51.871,82.371,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 51.825,82.404,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.487 | Acc: 51.954,82.457,96.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.002,82.518,96.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.486 | Acc: 51.987,82.513,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 44.531,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 45.945,64.286,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 45.675,64.634,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.601 | Acc: 45.466,64.652,69.121,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.502 | Acc: 44.531,81.250,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.529 | Acc: 51.488,81.659,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.508 | Acc: 51.944,81.822,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.508 | Acc: 51.767,82.031,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 51.987,82.407,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 52.019,82.650,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.814,82.651,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.484 | Acc: 51.823,82.646,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 51.752,82.546,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.489 | Acc: 51.718,82.597,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 51.636,82.610,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.484 | Acc: 51.644,82.752,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 51.657,82.728,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 51.598,82.651,96.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 51.582,82.679,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.496 | Acc: 51.565,82.691,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.494 | Acc: 51.650,82.691,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.488 | Acc: 51.764,82.741,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.486 | Acc: 51.837,82.817,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.481 | Acc: 51.934,82.817,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.499 | Acc: 45.312,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 46.205,64.769,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 45.884,64.977,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 45.620,64.908,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.375 | Acc: 54.688,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.476 | Acc: 51.339,83.036,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 51.791,83.117,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 51.678,82.966,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 51.408,82.571,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.495 | Acc: 51.338,82.580,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.480 | Acc: 51.440,82.890,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 51.518,82.763,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 51.674,82.856,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.490 | Acc: 51.459,82.821,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 51.664,83.061,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 51.806,82.972,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.825,82.981,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.919,83.022,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 52.016,83.054,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 52.061,83.098,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.468 | Acc: 52.108,83.073,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.468 | Acc: 52.131,83.026,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.471 | Acc: 52.023,82.964,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.471 | Acc: 51.948,82.993,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.483 | Acc: 47.656,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.592 | Acc: 46.503,64.546,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 46.037,64.806,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 45.799,64.780,69.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.418 | Acc: 57.812,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 52.418,82.552,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.490 | Acc: 51.505,82.107,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 51.601,82.044,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 51.900,82.195,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.484 | Acc: 51.887,82.256,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.485 | Acc: 51.743,82.238,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.487 | Acc: 51.729,82.314,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 51.553,82.308,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 51.679,82.307,96.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 51.539,82.323,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 51.707,82.378,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.491 | Acc: 51.731,82.346,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.488 | Acc: 51.769,82.358,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 51.757,82.462,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 51.757,82.509,96.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 51.674,82.440,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 51.640,82.439,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.497 | Acc: 51.608,82.518,96.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 51.653,82.579,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.492 | Acc: 49.219,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 46.466,64.583,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 45.960,64.920,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 45.671,65.061,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.149 | Acc: 50.781,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.480 | Acc: 51.190,82.701,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.465 | Acc: 51.391,83.155,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.459 | Acc: 51.294,83.056,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 51.640,82.880,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.466 | Acc: 51.717,82.929,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.466 | Acc: 51.756,82.858,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.467 | Acc: 51.806,82.718,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 51.771,82.633,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.464 | Acc: 51.796,82.705,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.466 | Acc: 51.811,82.770,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 51.732,82.763,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 51.592,82.686,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.670,82.636,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 51.771,82.612,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 51.788,82.649,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 51.808,82.666,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.473 | Acc: 51.842,82.599,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 51.842,82.657,96.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.472 | Acc: 51.872,82.698,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 47.656,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 46.019,64.323,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 45.579,64.596,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.588 | Acc: 45.466,64.652,69.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.383 | Acc: 56.250,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 51.488,82.552,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.498 | Acc: 51.143,82.355,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 52.267,82.633,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.474 | Acc: 51.929,82.841,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.470 | Acc: 51.756,82.936,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.472 | Acc: 51.653,82.942,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 51.751,82.696,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.475 | Acc: 51.800,82.614,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.476 | Acc: 51.787,82.562,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.479 | Acc: 51.726,82.564,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.476 | Acc: 51.697,82.618,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.483 | Acc: 51.669,82.566,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 51.739,82.609,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 51.779,82.621,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 51.832,82.628,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 51.855,82.559,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 51.815,82.650,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.489 | Acc: 51.736,82.633,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 51.735,82.669,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.468 | Acc: 46.094,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.596 | Acc: 46.131,64.435,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 45.903,64.863,69.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.574 | Acc: 45.620,64.831,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.445 | Acc: 53.125,85.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.398 | Acc: 53.385,83.966,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.430 | Acc: 52.611,83.765,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.485,83.069,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.452 | Acc: 52.517,83.266,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.459 | Acc: 52.413,83.176,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.008,82.948,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 51.906,82.879,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.140,82.827,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.474 | Acc: 52.119,82.847,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.475 | Acc: 52.111,82.824,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.476 | Acc: 51.965,82.763,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.473 | Acc: 51.994,82.744,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.479 | Acc: 51.898,82.672,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.478 | Acc: 51.927,82.640,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 51.957,82.709,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 51.818,82.713,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 51.858,82.675,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 51.805,82.706,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.483 | Acc: 51.743,82.694,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.471 | Acc: 46.094,59.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 46.205,64.621,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.618 | Acc: 45.941,64.844,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.592 | Acc: 45.581,64.780,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.410 | Acc: 46.875,84.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.519 | Acc: 50.409,81.622,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.463 | Acc: 52.039,82.431,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 52.228,82.915,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.471 | Acc: 51.611,82.899,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 51.493,82.588,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 51.517,82.509,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 51.790,82.497,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 51.820,82.516,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 51.878,82.377,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 51.788,82.385,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.484 | Acc: 51.700,82.480,96.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 51.702,82.423,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 51.754,82.453,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 51.663,82.459,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.484 | Acc: 51.596,82.491,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 51.616,82.418,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 51.659,82.496,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.484 | Acc: 51.746,82.542,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 51.722,82.589,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.470 | Acc: 45.312,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.604 | Acc: 46.019,64.583,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 45.846,64.691,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 45.479,64.677,69.185,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.173 | Acc: 56.250,84.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.527 | Acc: 51.823,82.403,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.494 | Acc: 51.562,82.489,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.483 | Acc: 51.883,82.364,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.480 | Acc: 51.746,82.514,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 51.795,82.457,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.471 | Acc: 51.911,82.386,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.471 | Acc: 51.984,82.524,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.473 | Acc: 51.917,82.492,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 51.813,82.407,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 51.881,82.338,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 51.831,82.473,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.825,82.537,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 51.895,82.507,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 51.782,82.384,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.488 | Acc: 51.705,82.413,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.483 | Acc: 51.779,82.457,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.484 | Acc: 51.762,82.467,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.483 | Acc: 51.749,82.520,96.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.487 | Acc: 51.702,82.534,96.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.444 | Acc: 48.438,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 46.429,64.286,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 46.151,64.691,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 45.710,64.690,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 1.760 | Acc: 68.750,86.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.460 | Acc: 53.534,81.362,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 52.858,81.707,96.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.445 | Acc: 53.112,82.339,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 52.623,82.369,96.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.461 | Acc: 52.468,82.480,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 52.318,82.444,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.475 | Acc: 52.022,82.380,96.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 51.960,82.410,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 51.839,82.351,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.490 | Acc: 51.838,82.373,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 51.835,82.448,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 51.786,82.482,96.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.480 | Acc: 51.778,82.507,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 51.749,82.512,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 51.866,82.672,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 51.801,82.654,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.476 | Acc: 51.801,82.677,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 51.863,82.657,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 51.794,82.661,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.471 | Acc: 45.312,60.156,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 46.094,64.509,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 45.827,64.825,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.573 | Acc: 45.607,64.857,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.315 | Acc: 55.469,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.501 | Acc: 52.307,81.994,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 51.372,82.298,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.506 | Acc: 51.370,82.505,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.518 | Acc: 51.360,82.359,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 51.153,82.225,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.506 | Acc: 51.343,82.264,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.495 | Acc: 51.651,82.408,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.488 | Acc: 51.640,82.536,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 51.735,82.597,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.486 | Acc: 51.815,82.560,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.487 | Acc: 51.789,82.547,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 51.851,82.456,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 51.874,82.555,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.485 | Acc: 51.824,82.571,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.486 | Acc: 51.858,82.584,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.486 | Acc: 51.845,82.630,96.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 51.886,82.652,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.477 | Acc: 51.995,82.752,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.477 | Acc: 51.973,82.706,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 45.312,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.598 | Acc: 45.833,64.844,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 45.598,64.806,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.590 | Acc: 45.453,64.857,69.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.208 | Acc: 60.156,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.450 | Acc: 52.344,83.631,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.469 | Acc: 51.810,83.175,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 51.627,82.723,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.491 | Acc: 51.755,82.166,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.489 | Acc: 51.918,82.170,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.483 | Acc: 51.814,82.335,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 51.745,82.281,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 51.640,82.356,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 51.718,82.454,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 51.765,82.529,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 51.690,82.558,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 51.744,82.540,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.479 | Acc: 51.799,82.582,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.485 | Acc: 51.807,82.562,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 51.736,82.602,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.485 | Acc: 51.706,82.637,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 51.686,82.641,96.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 51.733,82.657,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.489 | Acc: 51.653,82.601,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.437 | Acc: 47.656,60.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 45.871,64.695,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 45.541,64.882,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 45.364,64.921,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.362 | Acc: 51.562,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 52.158,83.073,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.493 | Acc: 52.001,83.155,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 51.947,82.928,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.488 | Acc: 51.881,82.687,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.486 | Acc: 51.802,82.635,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 51.582,82.812,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 51.513,82.702,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 51.718,82.759,96.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.493 | Acc: 51.554,82.597,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.492 | Acc: 51.594,82.638,96.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 51.601,82.692,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.725,82.709,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.481 | Acc: 51.718,82.699,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.478 | Acc: 51.702,82.804,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 51.672,82.802,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.478 | Acc: 51.660,82.808,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 51.753,82.872,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.471 | Acc: 51.762,82.908,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.469 | Acc: 51.724,82.946,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.472 | Acc: 46.094,60.938,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.600 | Acc: 46.280,64.546,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 45.884,64.901,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.583 | Acc: 45.671,64.972,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.248 | Acc: 58.594,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 53.013,81.696,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 52.668,82.603,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.549,83.107,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.527,82.880,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.480 | Acc: 52.351,82.812,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 52.234,82.729,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 52.261,82.696,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 52.188,82.793,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.479 | Acc: 52.206,82.787,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 52.103,82.820,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 52.082,82.738,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.473 | Acc: 52.097,82.851,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.940,82.756,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 52.035,82.718,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.478 | Acc: 51.954,82.670,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.479 | Acc: 51.867,82.652,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 51.945,82.673,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 51.926,82.722,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.480 | Acc: 51.917,82.745,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.438 | Acc: 45.312,59.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 46.131,64.472,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 45.808,64.615,69.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.584 | Acc: 45.620,64.613,69.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.549 | Acc: 53.906,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 51.302,81.845,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 51.715,82.107,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.507 | Acc: 51.370,82.159,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.491 | Acc: 51.968,82.407,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.471 | Acc: 52.413,82.658,96.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 52.447,82.490,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.477 | Acc: 52.405,82.519,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 52.319,82.570,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 52.469,82.722,96.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 52.239,82.638,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.266,82.611,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.479 | Acc: 52.230,82.553,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 52.359,82.648,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.291,82.618,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.469 | Acc: 52.253,82.662,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.466 | Acc: 52.268,82.720,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.466 | Acc: 52.254,82.725,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.468 | Acc: 52.214,82.663,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.471 | Acc: 52.161,82.618,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.449 | Acc: 49.219,60.156,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.606 | Acc: 46.615,64.769,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 46.246,64.996,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.580 | Acc: 45.876,65.074,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.620 | Acc: 46.094,86.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 51.042,82.887,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 50.877,82.774,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.481 | Acc: 51.434,82.672,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.492 | Acc: 51.495,82.928,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.496 | Acc: 51.516,82.836,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 51.472,82.696,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 51.712,82.696,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 51.669,82.754,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 51.649,82.769,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 51.543,82.801,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 51.524,82.805,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.484 | Acc: 51.559,82.832,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.727,82.980,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 51.740,82.985,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 51.799,82.940,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.473 | Acc: 51.772,82.886,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 51.732,82.819,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.480 | Acc: 51.759,82.858,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.479 | Acc: 51.761,82.794,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.433 | Acc: 45.312,60.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 45.871,64.695,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.616 | Acc: 45.770,64.748,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.593 | Acc: 45.620,64.703,69.173,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.568 | Acc: 48.438,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.384 | Acc: 52.902,83.780,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 52.363,83.060,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.468 | Acc: 52.164,82.620,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.474 | Acc: 52.016,82.755,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 51.864,82.604,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.950,82.515,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 51.950,82.402,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.140,82.691,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.180,82.709,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 52.041,82.634,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 52.033,82.689,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 51.815,82.553,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 51.676,82.480,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.487 | Acc: 51.688,82.604,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.487 | Acc: 51.620,82.571,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.483 | Acc: 51.679,82.601,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 51.711,82.634,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.482 | Acc: 51.707,82.674,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.481 | Acc: 51.737,82.681,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.457 | Acc: 46.094,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 46.429,64.546,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 45.827,64.939,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 45.530,64.857,69.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.382 | Acc: 54.688,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.531 | Acc: 52.455,81.920,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 51.829,81.993,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 52.139,82.185,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.481 | Acc: 51.958,82.378,96.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 52.058,82.588,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 51.989,82.554,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 51.695,82.480,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 51.859,82.662,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 51.748,82.597,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 51.671,82.575,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.479 | Acc: 51.697,82.583,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.478 | Acc: 51.770,82.641,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.483 | Acc: 51.664,82.642,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 51.574,82.740,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.475 | Acc: 51.731,82.755,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 51.740,82.800,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 51.679,82.723,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.477 | Acc: 51.682,82.743,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.478 | Acc: 51.663,82.669,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 47.656,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 46.094,64.807,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 45.751,65.034,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 45.530,64.921,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.447 | Acc: 50.000,82.031,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.467 | Acc: 51.935,82.254,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.489 | Acc: 52.058,82.127,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 51.767,82.403,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.482 | Acc: 51.678,82.552,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 51.578,82.480,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.489 | Acc: 51.459,82.548,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 51.407,82.535,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.486 | Acc: 51.465,82.628,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 51.338,82.674,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.482 | Acc: 51.461,82.657,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.476 | Acc: 51.619,82.678,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.476 | Acc: 51.634,82.754,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 51.533,82.708,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.481 | Acc: 51.515,82.696,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 51.492,82.688,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.484 | Acc: 51.507,82.659,96.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.481 | Acc: 51.508,82.689,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 51.617,82.724,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 51.657,82.749,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.445 | Acc: 48.438,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 46.429,64.695,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.596 | Acc: 46.037,64.920,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 45.620,64.844,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.530 | Acc: 50.000,83.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.460 | Acc: 52.232,83.371,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 52.344,83.289,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 51.947,83.158,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 52.160,83.468,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 51.957,83.222,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 52.460,83.245,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.471 | Acc: 52.338,83.156,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 52.232,82.953,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.124,82.882,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 52.029,82.708,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 52.135,82.678,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.480 | Acc: 52.136,82.790,96.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 52.059,82.777,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 52.152,82.815,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.479 | Acc: 52.063,82.797,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 52.061,82.815,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.475 | Acc: 52.188,82.829,96.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.476 | Acc: 52.108,82.802,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 52.077,82.788,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.451 | Acc: 46.094,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 46.429,64.658,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.594 | Acc: 45.922,64.901,69.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.575 | Acc: 45.684,64.882,69.378,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.405 | Acc: 51.562,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.442 | Acc: 51.451,83.854,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.482 | Acc: 51.353,83.041,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 51.857,82.710,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.483 | Acc: 51.649,82.851,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 51.841,82.952,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.491 | Acc: 51.640,82.819,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 51.718,82.885,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 51.781,82.876,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 51.908,82.989,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 52.060,83.015,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.486 | Acc: 51.867,82.919,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 51.942,82.949,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.476 | Acc: 51.904,82.980,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 51.868,83.010,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 51.905,83.028,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 51.859,83.010,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.470 | Acc: 51.936,83.055,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 51.811,83.044,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.472 | Acc: 51.815,83.040,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.439 | Acc: 46.875,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.593 | Acc: 46.131,64.621,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 45.675,64.787,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 45.517,64.844,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.685 | Acc: 59.375,75.781,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 52.344,83.482,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.432 | Acc: 52.344,83.270,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.434 | Acc: 52.293,83.222,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.462 | Acc: 52.132,82.841,96.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.027,82.766,96.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 52.073,82.922,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 52.000,82.680,96.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.493 | Acc: 51.800,82.521,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 52.016,82.700,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 52.021,82.649,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.479 | Acc: 52.093,82.692,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.480 | Acc: 52.007,82.654,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.482 | Acc: 51.955,82.690,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 51.963,82.754,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 51.895,82.735,96.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.482 | Acc: 52.001,82.791,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.482 | Acc: 51.959,82.714,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.480 | Acc: 52.019,82.752,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.481 | Acc: 51.991,82.753,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.436 | Acc: 45.312,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 45.908,64.658,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.622 | Acc: 45.522,64.844,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.599 | Acc: 45.415,64.844,69.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.600 | Acc: 54.688,78.906,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.443 | Acc: 53.088,83.222,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.453 | Acc: 53.125,83.060,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.437 | Acc: 53.227,83.197,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.447 | Acc: 52.768,83.256,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.452 | Acc: 52.545,83.052,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 52.182,82.793,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 52.011,82.707,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 51.892,82.526,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.478 | Acc: 51.925,82.515,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.479 | Acc: 51.858,82.614,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.474 | Acc: 51.951,82.770,96.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.472 | Acc: 51.903,82.673,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.473 | Acc: 51.931,82.666,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 51.910,82.685,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 51.928,82.685,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 52.005,82.584,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 52.007,82.533,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.475 | Acc: 52.080,82.655,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.473 | Acc: 52.122,82.700,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 46.875,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 46.057,64.583,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 45.827,64.958,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 45.479,64.985,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.571 | Acc: 51.562,86.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.482 | Acc: 51.004,83.408,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 50.972,83.098,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.470 | Acc: 51.114,82.928,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.458 | Acc: 51.823,83.015,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.456 | Acc: 51.911,83.021,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.451 | Acc: 52.040,82.935,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.451 | Acc: 52.083,82.934,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.456 | Acc: 51.990,82.837,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.463 | Acc: 52.033,82.748,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.466 | Acc: 51.912,82.727,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.465 | Acc: 51.856,82.756,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 51.890,82.731,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 51.871,82.681,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 51.924,82.693,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.473 | Acc: 51.900,82.753,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.473 | Acc: 51.896,82.725,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 51.918,82.650,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 52.015,82.663,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.473 | Acc: 51.987,82.704,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.470 | Acc: 46.875,60.938,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.619 | Acc: 45.982,64.360,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 45.675,64.710,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.594 | Acc: 45.351,64.728,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.291 | Acc: 55.469,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.435 | Acc: 52.679,83.705,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.439 | Acc: 52.954,83.289,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 52.741,82.697,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.451 | Acc: 52.440,83.015,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.447 | Acc: 52.560,82.959,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.459 | Acc: 52.402,82.884,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.461 | Acc: 52.261,82.945,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.470 | Acc: 51.951,82.944,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.470 | Acc: 51.809,82.938,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 51.718,82.871,96.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 51.672,82.947,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.478 | Acc: 51.611,82.958,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.472 | Acc: 51.661,82.986,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.466 | Acc: 51.752,83.038,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.468 | Acc: 51.713,82.984,96.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.462 | Acc: 51.789,82.995,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.463 | Acc: 51.842,82.945,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 51.972,82.927,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.465 | Acc: 52.010,82.895,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.474 | Acc: 46.094,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 45.610,64.323,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.629 | Acc: 45.503,64.615,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 45.312,64.664,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.422 | Acc: 51.562,86.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.472 | Acc: 51.897,82.403,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.463 | Acc: 51.524,82.641,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 51.319,81.993,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.472 | Acc: 51.997,82.407,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 52.251,82.673,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.460 | Acc: 52.163,82.690,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.462 | Acc: 52.061,82.707,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 51.844,82.754,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.466 | Acc: 51.903,82.765,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.471 | Acc: 51.870,82.805,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 51.757,82.781,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 51.783,82.718,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 51.769,82.738,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.478 | Acc: 51.763,82.668,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.479 | Acc: 51.827,82.709,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.481 | Acc: 51.772,82.761,96.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 51.837,82.769,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 51.816,82.696,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.477 | Acc: 51.858,82.743,96.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.504 | Acc: 47.656,60.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.612 | Acc: 45.982,64.509,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.613 | Acc: 45.636,64.882,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.589 | Acc: 45.492,64.869,69.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.337 | Acc: 56.250,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.442 | Acc: 52.344,83.668,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.490 | Acc: 51.963,82.946,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 51.627,82.339,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 51.640,82.436,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.514 | Acc: 51.470,82.302,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.511 | Acc: 51.498,82.302,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.501 | Acc: 51.646,82.319,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 51.669,82.347,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 51.679,82.571,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 51.644,82.587,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.489 | Acc: 51.626,82.586,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 51.585,82.621,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.751,82.717,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 51.732,82.760,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 51.804,82.729,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 51.799,82.747,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 51.831,82.719,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 51.775,82.668,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.479 | Acc: 51.792,82.700,96.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.420 | Acc: 47.656,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.601 | Acc: 46.540,64.621,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 45.941,65.015,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.577 | Acc: 45.581,65.061,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.841 | Acc: 44.531,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.441 | Acc: 51.674,82.180,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.494 | Acc: 51.296,82.031,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.496 | Acc: 51.332,82.313,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.490 | Acc: 51.688,82.398,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 51.276,82.348,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 51.291,82.658,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 51.601,82.785,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 51.737,82.837,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.475 | Acc: 51.752,82.843,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 51.722,82.816,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.477 | Acc: 51.757,82.911,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 51.890,82.913,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.772,82.866,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.480 | Acc: 51.674,82.840,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.481 | Acc: 51.684,82.820,96.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.474 | Acc: 51.816,82.856,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 51.892,82.849,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.473 | Acc: 51.811,82.795,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.470 | Acc: 51.880,82.831,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 46.094,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.597 | Acc: 46.019,64.435,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.608 | Acc: 45.808,64.787,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 45.594,64.677,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.800 | Acc: 42.969,82.031,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 51.749,81.548,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.477 | Acc: 51.658,82.260,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 51.012,82.531,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 51.196,82.417,96.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.500 | Acc: 51.261,82.271,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 51.317,82.664,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.490 | Acc: 51.313,82.740,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.495 | Acc: 51.325,82.754,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.497 | Acc: 51.304,82.692,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.497 | Acc: 51.255,82.688,96.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.492 | Acc: 51.258,82.689,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 51.284,82.696,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 51.236,82.663,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.489 | Acc: 51.273,82.726,96.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.482 | Acc: 51.505,82.771,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 51.609,82.839,96.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.478 | Acc: 51.553,82.796,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.476 | Acc: 51.608,82.830,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.477 | Acc: 51.690,82.831,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.467 | Acc: 46.094,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.595 | Acc: 46.094,64.732,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 45.865,64.901,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.578 | Acc: 45.748,64.895,68.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.398 | Acc: 51.562,87.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.488 | Acc: 51.302,83.147,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.473 | Acc: 51.639,82.641,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 51.255,82.313,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.485 | Acc: 51.264,82.417,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 51.230,82.611,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.476 | Acc: 51.562,82.683,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 51.579,82.663,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 51.533,82.657,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.486 | Acc: 51.450,82.523,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.478 | Acc: 51.559,82.564,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 51.559,82.562,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.480 | Acc: 51.608,82.618,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 51.685,82.654,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 51.757,82.715,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.475 | Acc: 51.796,82.735,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.469 | Acc: 51.935,82.800,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 51.920,82.762,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 51.950,82.793,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.470 | Acc: 51.942,82.849,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.449 | Acc: 48.438,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.584 | Acc: 46.503,63.914,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.591 | Acc: 46.056,64.596,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.570 | Acc: 45.735,64.575,69.506,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.288 | Acc: 52.344,87.500,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.404 | Acc: 52.307,83.594,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.436 | Acc: 51.905,83.575,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.454 | Acc: 51.921,83.069,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.459 | Acc: 51.968,82.957,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 51.856,82.766,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 51.801,82.619,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.482 | Acc: 51.657,82.502,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 51.781,82.580,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 51.921,82.683,96.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.469 | Acc: 51.955,82.746,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.465 | Acc: 51.980,82.880,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 51.958,82.874,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.469 | Acc: 51.976,82.810,96.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.468 | Acc: 52.057,82.782,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.466 | Acc: 52.079,82.828,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.468 | Acc: 52.054,82.783,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.470 | Acc: 51.979,82.714,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 51.904,82.698,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 51.897,82.616,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.486 | Acc: 46.875,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 46.652,64.546,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.600 | Acc: 45.998,64.748,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.576 | Acc: 45.671,64.882,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.282 | Acc: 54.688,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.437 | Acc: 52.046,83.891,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.470 | Acc: 51.944,83.022,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 51.639,82.723,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 51.833,82.687,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 51.872,82.867,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.486 | Acc: 51.730,82.800,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.495 | Acc: 51.701,82.757,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 51.844,82.754,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 52.055,82.877,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 52.134,82.879,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 51.980,82.929,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.003,82.907,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 51.928,82.965,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 51.955,83.040,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 51.941,82.950,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.480 | Acc: 51.969,82.895,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 51.952,82.847,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 51.924,82.828,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.482 | Acc: 51.845,82.788,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.477 | Acc: 48.438,59.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 46.540,64.360,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.601 | Acc: 46.246,64.882,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.579 | Acc: 45.902,64.844,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.161 | Acc: 59.375,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 52.269,82.924,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 51.886,82.260,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.498 | Acc: 51.422,82.364,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.488 | Acc: 51.427,82.533,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 51.477,82.704,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 51.498,82.670,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.484 | Acc: 51.474,82.602,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 51.490,82.589,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 51.826,82.709,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.472 | Acc: 51.885,82.661,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 51.934,82.551,96.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 51.802,82.365,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 51.841,82.507,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.477 | Acc: 51.827,82.582,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.478 | Acc: 51.822,82.571,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 51.847,82.603,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.480 | Acc: 51.780,82.629,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 51.755,82.652,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.479 | Acc: 51.770,82.603,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.478 | Acc: 45.312,60.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.594 | Acc: 46.168,64.360,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 45.922,64.806,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.581 | Acc: 45.658,64.869,69.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.630 | Acc: 54.688,83.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 52.679,82.329,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.484 | Acc: 52.363,82.450,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 52.241,82.236,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.016,82.514,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.493 | Acc: 52.112,82.488,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 52.376,82.670,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 52.455,82.801,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.478 | Acc: 52.256,82.667,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.479 | Acc: 52.201,82.726,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 52.138,82.754,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.485 | Acc: 51.965,82.777,96.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.483 | Acc: 51.994,82.774,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.131,82.827,96.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 52.274,82.849,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.287,82.870,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.473 | Acc: 52.234,82.881,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 52.181,82.842,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.473 | Acc: 52.168,82.838,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.473 | Acc: 52.126,82.831,96.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.429 | Acc: 46.875,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.600 | Acc: 46.205,64.658,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.609 | Acc: 45.808,64.901,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 45.607,64.754,69.134,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.767 | Acc: 46.875,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.469 | Acc: 51.562,82.143,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.493 | Acc: 51.124,82.508,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.498 | Acc: 50.948,82.646,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.506 | Acc: 51.128,82.552,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.484 | Acc: 51.524,82.874,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 51.698,82.903,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.467 | Acc: 51.828,82.923,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.464 | Acc: 52.009,82.905,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.462 | Acc: 52.037,82.877,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.456 | Acc: 52.219,82.972,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.459 | Acc: 52.227,82.957,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.462 | Acc: 52.191,82.968,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.467 | Acc: 52.131,82.857,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.465 | Acc: 52.069,82.824,96.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.468 | Acc: 52.043,82.771,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.470 | Acc: 52.061,82.747,96.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 51.973,82.682,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.476 | Acc: 51.950,82.639,96.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 51.907,82.675,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.449 | Acc: 46.094,60.938,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.614 | Acc: 45.982,64.472,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 45.846,64.539,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.600 | Acc: 45.581,64.498,69.083,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.573 | Acc: 46.094,86.719,96.094,% | Adaptive Acc: 86.719% | clf_exit: 0.297 0.547 0.156
Batch: 20 | Loss: 2.414 | Acc: 53.423,84.003,96.466,% | Adaptive Acc: 88.430% | clf_exit: 0.346 0.466 0.188
Batch: 40 | Loss: 2.429 | Acc: 52.992,83.155,96.475,% | Adaptive Acc: 87.633% | clf_exit: 0.360 0.458 0.182
Batch: 60 | Loss: 2.442 | Acc: 53.023,82.812,96.478,% | Adaptive Acc: 87.731% | clf_exit: 0.358 0.459 0.183
Batch: 80 | Loss: 2.442 | Acc: 52.874,82.784,96.296,% | Adaptive Acc: 87.587% | clf_exit: 0.358 0.457 0.184
Batch: 100 | Loss: 2.446 | Acc: 52.576,82.828,96.310,% | Adaptive Acc: 87.492% | clf_exit: 0.356 0.459 0.185
Batch: 120 | Loss: 2.454 | Acc: 52.344,82.832,96.294,% | Adaptive Acc: 87.287% | clf_exit: 0.356 0.461 0.184
Batch: 140 | Loss: 2.450 | Acc: 52.455,82.796,96.282,% | Adaptive Acc: 87.467% | clf_exit: 0.355 0.460 0.185
Batch: 160 | Loss: 2.454 | Acc: 52.334,82.934,96.273,% | Adaptive Acc: 87.519% | clf_exit: 0.354 0.460 0.186
Batch: 180 | Loss: 2.457 | Acc: 52.301,82.925,96.301,% | Adaptive Acc: 87.535% | clf_exit: 0.355 0.459 0.186
Batch: 200 | Loss: 2.464 | Acc: 52.278,82.960,96.269,% | Adaptive Acc: 87.578% | clf_exit: 0.354 0.460 0.186
Batch: 220 | Loss: 2.460 | Acc: 52.326,82.996,96.288,% | Adaptive Acc: 87.610% | clf_exit: 0.354 0.460 0.186
Batch: 240 | Loss: 2.457 | Acc: 52.428,83.004,96.266,% | Adaptive Acc: 87.581% | clf_exit: 0.355 0.459 0.186
Batch: 260 | Loss: 2.453 | Acc: 52.628,83.004,96.285,% | Adaptive Acc: 87.599% | clf_exit: 0.355 0.460 0.185
Batch: 280 | Loss: 2.455 | Acc: 52.591,82.979,96.236,% | Adaptive Acc: 87.567% | clf_exit: 0.354 0.460 0.186
Batch: 300 | Loss: 2.461 | Acc: 52.476,82.862,96.208,% | Adaptive Acc: 87.549% | clf_exit: 0.354 0.460 0.186
Batch: 320 | Loss: 2.467 | Acc: 52.368,82.815,96.186,% | Adaptive Acc: 87.490% | clf_exit: 0.354 0.460 0.187
Batch: 340 | Loss: 2.467 | Acc: 52.282,82.815,96.217,% | Adaptive Acc: 87.456% | clf_exit: 0.354 0.459 0.186
Batch: 360 | Loss: 2.470 | Acc: 52.210,82.765,96.226,% | Adaptive Acc: 87.448% | clf_exit: 0.354 0.458 0.187
Batch: 380 | Loss: 2.469 | Acc: 52.188,82.808,96.198,% | Adaptive Acc: 87.408% | clf_exit: 0.355 0.459 0.187
Batch: 0 | Loss: 4.462 | Acc: 46.094,61.719,67.969,% | Adaptive Acc: 60.156% | clf_exit: 0.398 0.406 0.195
Batch: 20 | Loss: 4.607 | Acc: 45.759,64.621,70.089,% | Adaptive Acc: 62.872% | clf_exit: 0.404 0.381 0.214
Batch: 40 | Loss: 4.609 | Acc: 45.541,64.768,69.360,% | Adaptive Acc: 63.072% | clf_exit: 0.401 0.390 0.209
Batch: 60 | Loss: 4.587 | Acc: 45.428,64.780,69.224,% | Adaptive Acc: 63.320% | clf_exit: 0.402 0.385 0.212
model is save as models/resnet56_h12_cifar100_adaptive0_circles2_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 14.321 | Acc: 10.938,17.188,39.844,% | Adaptive Acc: 19.531% | clf_exit: 0.594 0.188 0.219
Batch: 20 | Loss: 15.443 | Acc: 10.565,12.835,35.417,% | Adaptive Acc: 18.936% | clf_exit: 0.593 0.122 0.285
Batch: 40 | Loss: 15.516 | Acc: 10.099,12.557,34.813,% | Adaptive Acc: 18.178% | clf_exit: 0.583 0.124 0.293
Batch: 60 | Loss: 15.554 | Acc: 10.003,12.449,34.477,% | Adaptive Acc: 18.289% | clf_exit: 0.583 0.124 0.293
Batch: 0 | Loss: 6.301 | Acc: 28.906,50.781,66.406,% | Adaptive Acc: 50.000% | clf_exit: 0.445 0.297 0.258
Batch: 20 | Loss: 6.825 | Acc: 25.856,51.637,65.625,% | Adaptive Acc: 48.065% | clf_exit: 0.453 0.260 0.287
Batch: 40 | Loss: 6.833 | Acc: 25.953,51.067,64.444,% | Adaptive Acc: 48.628% | clf_exit: 0.440 0.266 0.294
Batch: 60 | Loss: 6.838 | Acc: 25.602,50.845,64.344,% | Adaptive Acc: 48.642% | clf_exit: 0.436 0.264 0.299
Batch: 0 | Loss: 4.462 | Acc: 46.094,61.719,67.969,% | Adaptive Acc: 60.156% | clf_exit: 0.398 0.406 0.195
Batch: 20 | Loss: 4.607 | Acc: 45.759,64.621,70.089,% | Adaptive Acc: 62.872% | clf_exit: 0.404 0.381 0.214
Batch: 40 | Loss: 4.609 | Acc: 45.541,64.768,69.360,% | Adaptive Acc: 63.072% | clf_exit: 0.401 0.390 0.209
Batch: 60 | Loss: 4.587 | Acc: 45.428,64.780,69.224,% | Adaptive Acc: 63.320% | clf_exit: 0.402 0.385 0.212







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.034 |  Acc: 3.692,5.316,6.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 12.197 |  Acc: 5.470,6.950,9.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 11.705 |  Acc: 6.592,10.304,13.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 11.519 |  Acc: 6.450,10.640,15.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 11.007 |  Acc: 9.216,13.738,17.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 10.743 |  Acc: 10.410,14.550,19.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 10.418 |  Acc: 11.480,16.648,21.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 10.485 |  Acc: 10.470,16.830,22.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 9.869 |  Acc: 14.272,20.206,25.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 10.208 |  Acc: 13.010,17.710,22.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 9.406 |  Acc: 16.254,22.930,27.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 9.664 |  Acc: 15.150,21.210,26.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 8.972 |  Acc: 18.432,25.412,31.278,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 9.212 |  Acc: 16.070,22.860,31.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 8.604 |  Acc: 20.022,28.022,34.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 9.499 |  Acc: 14.880,19.410,29.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.266 |  Acc: 21.802,29.886,36.626,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 8.900 |  Acc: 17.170,25.730,33.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 7.995 |  Acc: 23.238,31.856,39.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 8.382 |  Acc: 20.190,28.170,38.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 7.762 |  Acc: 24.256,33.524,40.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 8.211 |  Acc: 21.030,29.460,38.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 7.509 |  Acc: 25.412,35.380,42.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 8.475 |  Acc: 19.320,27.600,37.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.337 |  Acc: 26.306,36.830,44.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 8.652 |  Acc: 16.900,30.600,40.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.155 |  Acc: 26.768,38.212,45.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 8.266 |  Acc: 21.010,32.440,41.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 6.986 |  Acc: 27.516,39.804,47.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 8.448 |  Acc: 18.940,29.880,39.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 6.849 |  Acc: 28.224,40.634,48.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 7.883 |  Acc: 23.060,33.610,41.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 6.715 |  Acc: 28.922,42.110,49.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 9.649 |  Acc: 14.110,26.130,36.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.601 |  Acc: 29.508,42.860,50.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 8.988 |  Acc: 16.370,30.560,40.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.508 |  Acc: 30.084,43.938,51.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 7.474 |  Acc: 27.060,35.790,44.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.374 |  Acc: 30.878,45.018,52.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.221 |  Acc: 26.560,38.570,46.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.274 |  Acc: 31.188,45.836,53.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.527 |  Acc: 24.060,38.300,45.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.188 |  Acc: 31.898,46.640,54.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 7.589 |  Acc: 23.550,38.030,47.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.115 |  Acc: 32.476,47.306,54.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.422 |  Acc: 23.970,39.360,46.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.036 |  Acc: 32.772,48.042,55.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 7.200 |  Acc: 26.240,41.300,48.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 5.948 |  Acc: 33.364,48.722,56.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 8.787 |  Acc: 18.880,34.080,42.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 5.897 |  Acc: 33.616,49.236,56.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 8.466 |  Acc: 17.400,36.450,45.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 5.811 |  Acc: 33.964,50.010,57.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 7.344 |  Acc: 23.550,39.270,47.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.767 |  Acc: 34.098,50.346,58.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 7.366 |  Acc: 25.600,38.340,46.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.695 |  Acc: 34.448,50.996,58.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.051 |  Acc: 25.630,41.740,49.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.643 |  Acc: 34.938,51.534,59.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.828 |  Acc: 26.820,34.320,42.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.612 |  Acc: 35.186,51.738,59.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 6.929 |  Acc: 29.180,42.420,50.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.546 |  Acc: 35.118,52.516,60.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 7.465 |  Acc: 25.500,38.910,48.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.495 |  Acc: 35.444,52.634,60.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 8.652 |  Acc: 19.670,33.450,45.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.468 |  Acc: 36.040,53.098,61.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.631 |  Acc: 23.390,39.380,47.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.437 |  Acc: 36.380,53.410,61.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 6.935 |  Acc: 28.290,40.960,50.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.398 |  Acc: 36.370,53.648,61.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 8.531 |  Acc: 18.950,35.360,47.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.348 |  Acc: 36.440,54.168,62.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 7.491 |  Acc: 23.830,40.060,48.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.314 |  Acc: 36.638,54.362,62.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 7.350 |  Acc: 24.500,40.010,48.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.282 |  Acc: 37.044,54.462,62.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 7.363 |  Acc: 26.390,39.670,48.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.250 |  Acc: 37.170,54.980,63.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 6.805 |  Acc: 25.940,45.540,54.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.225 |  Acc: 36.904,55.188,63.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 6.884 |  Acc: 29.560,43.480,52.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.186 |  Acc: 37.336,55.616,63.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 7.884 |  Acc: 22.080,37.100,48.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.171 |  Acc: 37.280,55.896,63.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 6.974 |  Acc: 26.930,43.860,51.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.142 |  Acc: 37.530,55.912,64.308,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 6.140 |  Acc: 31.620,48.530,55.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.112 |  Acc: 37.710,56.272,64.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 8.239 |  Acc: 19.020,38.450,48.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.095 |  Acc: 37.642,56.448,64.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.644 |  Acc: 22.880,37.680,48.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.072 |  Acc: 37.956,56.588,65.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 6.658 |  Acc: 28.980,44.460,53.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.053 |  Acc: 38.048,57.036,65.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.974 |  Acc: 25.690,44.060,52.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.026 |  Acc: 38.098,57.196,65.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.986 |  Acc: 27.630,43.940,52.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 4.991 |  Acc: 38.462,57.414,65.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 6.527 |  Acc: 27.750,46.330,55.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 4.984 |  Acc: 38.362,57.140,65.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 6.316 |  Acc: 32.080,45.730,54.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 4.954 |  Acc: 38.616,57.852,66.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 6.298 |  Acc: 30.070,48.070,56.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 4.941 |  Acc: 38.520,57.782,66.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 6.440 |  Acc: 29.530,46.930,54.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 4.913 |  Acc: 38.838,58.234,66.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 6.643 |  Acc: 29.020,45.540,51.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 4.895 |  Acc: 38.644,58.346,66.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.272 |  Acc: 32.540,47.340,55.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.889 |  Acc: 38.734,58.476,66.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 6.743 |  Acc: 28.610,44.450,52.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.870 |  Acc: 38.794,58.680,66.974,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 6.454 |  Acc: 29.960,46.050,53.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.848 |  Acc: 39.304,58.496,67.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.564 |  Acc: 28.860,45.660,53.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.836 |  Acc: 39.046,58.848,67.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 7.136 |  Acc: 24.370,45.540,53.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.804 |  Acc: 39.334,59.402,67.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 6.321 |  Acc: 30.810,47.990,57.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.788 |  Acc: 39.632,59.232,67.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 7.615 |  Acc: 23.790,40.290,49.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.792 |  Acc: 39.196,59.302,67.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 8.684 |  Acc: 16.700,34.670,46.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.779 |  Acc: 39.248,59.220,67.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 6.889 |  Acc: 27.080,43.600,55.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.768 |  Acc: 39.368,59.598,68.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 7.436 |  Acc: 24.160,40.620,50.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.760 |  Acc: 39.676,59.538,67.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 6.518 |  Acc: 32.860,44.450,53.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.735 |  Acc: 39.564,59.824,68.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 7.004 |  Acc: 26.020,45.440,54.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.724 |  Acc: 39.776,59.874,68.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 7.173 |  Acc: 23.710,44.140,55.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.698 |  Acc: 39.774,60.252,68.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 6.338 |  Acc: 33.730,47.640,53.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.701 |  Acc: 40.060,59.962,68.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 5.810 |  Acc: 33.890,52.610,59.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.688 |  Acc: 39.916,60.466,68.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 7.339 |  Acc: 25.430,45.970,52.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.673 |  Acc: 39.840,60.444,69.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 6.921 |  Acc: 27.680,44.370,53.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.666 |  Acc: 40.208,60.448,69.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 7.084 |  Acc: 26.460,44.080,51.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.651 |  Acc: 40.130,60.608,68.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 7.592 |  Acc: 25.330,42.790,49.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.627 |  Acc: 40.096,60.570,69.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.703 |  Acc: 27.250,45.710,54.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.630 |  Acc: 40.370,60.916,69.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 7.101 |  Acc: 26.150,43.590,52.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.614 |  Acc: 40.254,60.802,69.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 7.187 |  Acc: 21.310,44.280,54.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.622 |  Acc: 40.330,60.810,69.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 7.525 |  Acc: 21.310,43.570,52.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.599 |  Acc: 40.680,60.942,69.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.641 |  Acc: 28.870,46.980,55.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.592 |  Acc: 40.678,60.966,69.632,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.581 |  Acc: 29.780,47.410,54.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.579 |  Acc: 40.188,61.122,69.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 7.373 |  Acc: 27.470,41.190,48.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.567 |  Acc: 40.764,61.324,69.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 7.160 |  Acc: 26.000,46.600,53.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.560 |  Acc: 40.612,61.538,70.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.428 |  Acc: 27.740,47.620,57.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.550 |  Acc: 40.664,61.384,70.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 7.066 |  Acc: 26.020,43.280,53.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.546 |  Acc: 40.862,61.566,70.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 6.455 |  Acc: 30.310,47.390,56.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.555 |  Acc: 40.576,61.524,70.202,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 8.615 |  Acc: 19.850,40.460,49.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.528 |  Acc: 41.008,61.786,70.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 6.690 |  Acc: 27.330,47.460,55.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.514 |  Acc: 40.856,61.594,70.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.724 |  Acc: 30.060,44.070,53.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.515 |  Acc: 40.954,61.782,70.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 7.079 |  Acc: 26.490,45.900,54.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.518 |  Acc: 40.690,61.832,70.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 6.664 |  Acc: 27.580,48.420,54.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.501 |  Acc: 41.056,62.000,70.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 7.293 |  Acc: 25.650,44.160,53.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.490 |  Acc: 41.218,62.196,70.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 7.537 |  Acc: 23.980,41.220,51.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.482 |  Acc: 41.272,62.040,71.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 7.123 |  Acc: 24.840,43.760,53.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.488 |  Acc: 41.270,62.148,70.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 7.326 |  Acc: 26.510,43.690,52.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.474 |  Acc: 40.958,62.322,71.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 7.458 |  Acc: 25.890,43.380,52.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.485 |  Acc: 40.930,62.052,70.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 8.706 |  Acc: 20.980,39.500,49.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.457 |  Acc: 41.252,62.442,71.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 6.464 |  Acc: 26.040,48.890,57.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.452 |  Acc: 41.070,62.366,71.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 6.375 |  Acc: 31.070,48.540,55.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.453 |  Acc: 41.232,62.632,71.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.698 |  Acc: 27.690,46.640,54.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.436 |  Acc: 41.418,62.410,71.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.384 |  Acc: 30.790,47.180,55.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.430 |  Acc: 41.482,62.812,71.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.537 |  Acc: 28.130,48.200,56.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.418 |  Acc: 41.608,62.528,71.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 6.450 |  Acc: 30.870,48.550,55.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.427 |  Acc: 41.450,62.800,71.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 7.000 |  Acc: 27.450,46.080,52.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.418 |  Acc: 41.594,62.842,71.726,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.134 |  Acc: 33.300,49.540,55.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.417 |  Acc: 41.644,62.818,71.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 7.135 |  Acc: 28.440,43.350,52.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.408 |  Acc: 41.510,63.006,71.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.601 |  Acc: 29.440,46.330,55.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.397 |  Acc: 41.564,62.898,72.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 5.714 |  Acc: 34.370,52.900,60.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.403 |  Acc: 41.482,62.934,71.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 6.866 |  Acc: 31.000,43.450,50.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.388 |  Acc: 41.640,63.200,71.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.394 |  Acc: 29.280,48.610,56.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.374 |  Acc: 41.518,63.152,71.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 6.378 |  Acc: 28.750,48.660,57.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.377 |  Acc: 41.620,63.200,71.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 6.548 |  Acc: 30.680,47.890,55.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.371 |  Acc: 41.628,63.290,72.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 6.764 |  Acc: 28.000,46.080,54.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.376 |  Acc: 41.656,63.396,71.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 6.953 |  Acc: 29.230,45.620,51.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.374 |  Acc: 41.760,63.184,72.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.414 |  Acc: 29.780,49.070,57.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.336 |  Acc: 42.064,63.772,72.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.013 |  Acc: 34.550,50.400,57.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.368 |  Acc: 41.846,63.502,72.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 8.407 |  Acc: 18.850,44.610,52.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.343 |  Acc: 42.118,63.632,72.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.697 |  Acc: 27.540,49.840,55.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.340 |  Acc: 41.910,63.500,72.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 7.930 |  Acc: 22.070,39.730,50.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.327 |  Acc: 41.888,63.778,72.782,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.816 |  Acc: 27.700,46.270,55.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.343 |  Acc: 41.810,63.618,72.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.523 |  Acc: 28.950,49.120,55.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.334 |  Acc: 42.000,63.678,72.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 6.704 |  Acc: 28.890,47.120,53.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.326 |  Acc: 41.988,63.614,72.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 6.619 |  Acc: 27.330,46.990,55.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.312 |  Acc: 42.106,63.942,72.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 5.979 |  Acc: 35.190,51.340,57.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.306 |  Acc: 42.172,63.822,72.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 8.410 |  Acc: 22.040,40.640,50.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.334 |  Acc: 41.938,63.508,72.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 8.049 |  Acc: 24.010,41.970,51.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.328 |  Acc: 41.978,63.854,72.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.829 |  Acc: 30.550,45.210,52.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.322 |  Acc: 42.010,63.620,72.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 6.674 |  Acc: 27.500,46.670,56.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.296 |  Acc: 42.026,64.068,72.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 6.879 |  Acc: 27.540,45.300,53.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.295 |  Acc: 41.902,63.950,72.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.163 |  Acc: 31.600,50.520,58.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.293 |  Acc: 42.086,64.186,72.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 5.952 |  Acc: 30.460,52.850,59.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.297 |  Acc: 42.352,63.944,72.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 7.752 |  Acc: 26.850,40.950,51.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.293 |  Acc: 42.284,63.906,72.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.197 |  Acc: 31.430,50.180,57.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.300 |  Acc: 41.812,63.896,72.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 6.120 |  Acc: 31.460,49.290,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.298 |  Acc: 42.268,63.822,72.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 7.489 |  Acc: 25.800,43.260,50.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.281 |  Acc: 42.266,63.858,73.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 8.084 |  Acc: 19.180,41.200,50.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.276 |  Acc: 42.416,64.196,73.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 6.411 |  Acc: 30.090,48.820,57.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.265 |  Acc: 42.204,63.938,73.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 7.235 |  Acc: 27.330,45.700,53.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.262 |  Acc: 42.186,64.154,73.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 7.132 |  Acc: 23.980,46.730,56.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.259 |  Acc: 42.508,64.354,73.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 6.241 |  Acc: 31.530,50.600,57.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.268 |  Acc: 42.472,64.232,73.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.558 |  Acc: 29.210,48.200,57.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.266 |  Acc: 42.306,64.132,73.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 6.818 |  Acc: 27.550,45.950,56.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.253 |  Acc: 42.080,64.156,73.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 6.434 |  Acc: 28.160,49.520,58.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.273 |  Acc: 42.190,63.842,73.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 6.748 |  Acc: 26.020,48.420,57.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.254 |  Acc: 42.288,64.218,73.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 6.856 |  Acc: 30.160,47.030,53.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.278 |  Acc: 42.150,64.094,73.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 6.686 |  Acc: 28.200,49.050,55.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.252 |  Acc: 42.418,64.168,73.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.443 |  Acc: 32.520,47.740,55.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.232 |  Acc: 42.640,64.364,73.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 6.441 |  Acc: 30.910,48.230,56.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.234 |  Acc: 42.496,64.634,73.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 6.159 |  Acc: 31.830,51.230,59.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.254 |  Acc: 42.336,64.220,73.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 7.103 |  Acc: 27.060,44.490,53.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.238 |  Acc: 42.528,64.370,73.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 6.797 |  Acc: 27.980,47.510,56.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.236 |  Acc: 42.536,64.672,73.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 8.281 |  Acc: 19.450,43.360,52.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.574 |  Acc: 46.582,71.530,81.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.405 |  Acc: 43.870,63.640,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.384 |  Acc: 47.492,73.422,83.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.383 |  Acc: 43.630,64.160,70.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.309 |  Acc: 47.750,74.202,84.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.359 |  Acc: 43.640,64.390,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.265 |  Acc: 48.322,74.712,85.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.391 |  Acc: 43.520,64.360,70.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.240 |  Acc: 48.136,74.662,86.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.402 |  Acc: 43.590,64.640,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.207 |  Acc: 48.424,74.998,86.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.374 |  Acc: 43.560,64.740,70.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.186 |  Acc: 48.284,75.292,86.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.423 |  Acc: 43.520,64.130,70.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.155 |  Acc: 48.380,75.574,87.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.383 |  Acc: 43.930,64.320,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.146 |  Acc: 48.398,75.738,87.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.427 |  Acc: 43.890,64.750,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.121 |  Acc: 48.722,75.762,87.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.469 |  Acc: 43.300,64.490,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.110 |  Acc: 48.964,75.920,88.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.431 |  Acc: 43.820,64.560,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.099 |  Acc: 48.652,76.048,88.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.477 |  Acc: 43.360,64.180,70.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.079 |  Acc: 48.788,76.310,88.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.393 |  Acc: 44.290,64.560,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.066 |  Acc: 48.846,76.008,88.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.453 |  Acc: 43.940,64.690,70.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.057 |  Acc: 48.974,76.346,88.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.422 |  Acc: 44.330,64.660,70.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.040 |  Acc: 49.114,76.432,89.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.464 |  Acc: 43.610,64.360,70.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.037 |  Acc: 49.020,76.312,88.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.420 |  Acc: 44.190,64.840,70.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.014 |  Acc: 49.056,76.730,89.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.476 |  Acc: 43.840,64.290,69.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.003 |  Acc: 49.130,76.644,89.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.439 |  Acc: 44.150,64.650,70.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 2.995 |  Acc: 49.054,76.878,89.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.561 |  Acc: 43.080,64.370,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 2.985 |  Acc: 49.350,76.804,89.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.448 |  Acc: 44.830,64.650,70.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 2.979 |  Acc: 49.182,77.020,89.766,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.451 |  Acc: 43.770,64.720,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 2.978 |  Acc: 49.134,76.842,89.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.465 |  Acc: 43.790,64.760,70.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 2.969 |  Acc: 49.294,77.048,89.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.539 |  Acc: 44.000,64.340,69.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.957 |  Acc: 49.248,77.244,90.214,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.547 |  Acc: 43.510,63.980,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.953 |  Acc: 49.010,77.340,90.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.506 |  Acc: 43.390,64.880,69.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.947 |  Acc: 49.542,77.168,90.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.507 |  Acc: 43.830,64.990,70.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.939 |  Acc: 49.224,77.290,90.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.543 |  Acc: 43.060,64.440,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.929 |  Acc: 49.288,77.380,90.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.460 |  Acc: 44.210,64.990,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.909 |  Acc: 49.570,77.672,90.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.484 |  Acc: 44.620,64.500,69.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.916 |  Acc: 49.450,77.584,90.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.517 |  Acc: 43.880,64.740,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.901 |  Acc: 49.460,77.716,90.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.545 |  Acc: 43.660,64.430,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.898 |  Acc: 49.448,77.590,90.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.571 |  Acc: 43.180,63.940,69.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.903 |  Acc: 49.482,77.662,90.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.582 |  Acc: 43.930,64.080,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.888 |  Acc: 49.762,77.858,91.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.597 |  Acc: 43.620,64.300,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.880 |  Acc: 49.768,77.830,91.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.622 |  Acc: 43.120,63.650,69.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.878 |  Acc: 49.664,77.950,91.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.625 |  Acc: 43.450,63.720,68.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.866 |  Acc: 49.632,78.038,91.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.647 |  Acc: 42.860,64.010,69.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.863 |  Acc: 49.618,77.998,91.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.565 |  Acc: 44.470,64.330,69.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.860 |  Acc: 49.812,78.076,91.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.715 |  Acc: 42.400,63.260,68.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.854 |  Acc: 49.722,78.036,91.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.593 |  Acc: 43.910,64.520,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.854 |  Acc: 49.638,77.968,91.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.616 |  Acc: 43.560,64.080,69.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.852 |  Acc: 49.646,78.126,91.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.631 |  Acc: 43.100,64.000,68.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.848 |  Acc: 49.688,78.054,91.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.558 |  Acc: 44.420,64.120,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.841 |  Acc: 49.754,78.302,91.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.679 |  Acc: 42.910,63.630,68.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.844 |  Acc: 50.034,78.182,91.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.667 |  Acc: 43.630,64.150,68.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.829 |  Acc: 49.700,78.484,91.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.633 |  Acc: 43.660,64.350,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.818 |  Acc: 49.972,78.458,92.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.649 |  Acc: 43.300,64.230,68.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.826 |  Acc: 49.920,78.344,91.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.702 |  Acc: 43.350,63.410,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.819 |  Acc: 49.836,78.322,91.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.701 |  Acc: 43.080,63.760,68.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.824 |  Acc: 49.882,78.476,91.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.637 |  Acc: 43.620,64.240,68.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.818 |  Acc: 49.846,78.640,91.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.644 |  Acc: 44.080,64.160,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.814 |  Acc: 49.862,78.400,92.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.743 |  Acc: 43.300,63.350,68.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.818 |  Acc: 49.824,78.614,91.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.798 |  Acc: 42.870,63.050,67.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.806 |  Acc: 49.826,78.400,92.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.674 |  Acc: 43.420,63.790,68.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.806 |  Acc: 49.968,78.454,91.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.645 |  Acc: 43.730,64.420,69.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.810 |  Acc: 49.824,78.420,92.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.761 |  Acc: 42.920,63.550,67.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.797 |  Acc: 50.032,78.688,92.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.656 |  Acc: 44.110,64.080,68.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.799 |  Acc: 49.982,78.632,92.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.680 |  Acc: 43.760,63.540,68.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.790 |  Acc: 49.954,78.798,92.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.760 |  Acc: 42.960,64.010,68.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.787 |  Acc: 50.170,78.674,92.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.791 |  Acc: 42.640,63.290,67.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.779 |  Acc: 50.198,78.708,92.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.804 |  Acc: 42.390,63.390,68.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.787 |  Acc: 50.156,78.572,92.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.816 |  Acc: 42.680,62.960,67.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.777 |  Acc: 50.012,78.948,92.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.732 |  Acc: 43.520,63.490,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.782 |  Acc: 49.676,78.762,92.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.969 |  Acc: 41.140,62.100,67.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.770 |  Acc: 49.912,78.878,92.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.871 |  Acc: 41.390,62.440,66.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.785 |  Acc: 50.316,78.798,92.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.751 |  Acc: 43.610,63.090,68.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.769 |  Acc: 50.206,78.794,92.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.739 |  Acc: 43.340,63.260,67.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.767 |  Acc: 49.986,78.720,92.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.851 |  Acc: 42.170,62.970,67.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.760 |  Acc: 50.022,79.020,92.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.700 |  Acc: 43.780,63.730,68.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.772 |  Acc: 49.980,78.924,92.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.938 |  Acc: 41.620,62.670,67.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.765 |  Acc: 50.184,79.084,92.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.830 |  Acc: 42.940,63.390,68.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.763 |  Acc: 50.322,79.068,92.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.739 |  Acc: 44.150,63.560,67.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.759 |  Acc: 49.986,79.016,92.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.846 |  Acc: 42.750,63.210,67.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.779 |  Acc: 50.052,78.890,92.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.804 |  Acc: 42.740,63.340,67.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.624 |  Acc: 50.978,80.810,94.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.528 |  Acc: 45.390,65.120,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.575 |  Acc: 51.362,81.502,94.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.524 |  Acc: 45.190,65.030,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.563 |  Acc: 51.260,81.762,95.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.518 |  Acc: 45.330,65.360,69.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.566 |  Acc: 51.164,81.734,95.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.511 |  Acc: 45.310,65.020,70.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.556 |  Acc: 51.308,81.706,95.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.513 |  Acc: 45.330,65.230,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.548 |  Acc: 51.686,81.766,95.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.517 |  Acc: 45.280,65.120,69.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.548 |  Acc: 51.398,81.728,95.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.526 |  Acc: 45.280,65.150,69.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.542 |  Acc: 51.586,81.962,95.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.524 |  Acc: 45.530,65.400,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.535 |  Acc: 51.478,82.120,95.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.543 |  Acc: 45.120,64.990,69.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.530 |  Acc: 51.664,81.870,95.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.516 |  Acc: 45.460,65.120,70.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.537 |  Acc: 51.610,82.050,95.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.530 |  Acc: 45.310,65.260,69.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.539 |  Acc: 51.516,81.892,95.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.533 |  Acc: 45.250,64.970,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.535 |  Acc: 51.580,81.894,95.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.538 |  Acc: 45.380,65.000,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.529 |  Acc: 51.352,82.020,95.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.527 |  Acc: 45.470,65.220,69.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.532 |  Acc: 51.478,81.972,95.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.536 |  Acc: 45.310,64.960,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.527 |  Acc: 51.626,82.182,95.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.529 |  Acc: 45.440,65.370,69.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.521 |  Acc: 51.598,81.998,95.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.537 |  Acc: 45.460,65.380,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.520 |  Acc: 51.802,82.068,95.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.545 |  Acc: 45.690,65.020,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.521 |  Acc: 51.664,82.156,95.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.552 |  Acc: 45.470,65.040,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.523 |  Acc: 51.360,82.170,95.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.549 |  Acc: 45.370,65.210,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.522 |  Acc: 51.476,82.084,95.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.546 |  Acc: 45.410,65.230,69.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.515 |  Acc: 51.452,82.406,95.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.541 |  Acc: 45.250,65.020,69.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.516 |  Acc: 51.692,82.066,95.942,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.552 |  Acc: 45.540,65.210,69.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.509 |  Acc: 51.586,82.342,95.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.563 |  Acc: 45.220,65.060,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.513 |  Acc: 51.562,82.482,95.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.555 |  Acc: 45.700,65.220,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.523 |  Acc: 51.662,81.982,95.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.559 |  Acc: 45.620,65.340,69.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.508 |  Acc: 51.594,82.524,95.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.573 |  Acc: 45.280,64.920,69.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.506 |  Acc: 51.728,82.564,95.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.568 |  Acc: 45.090,65.020,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.508 |  Acc: 51.568,82.148,95.892,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.557 |  Acc: 45.450,65.170,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.502 |  Acc: 51.832,82.320,95.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.561 |  Acc: 45.010,65.080,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.494 |  Acc: 51.786,82.514,96.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.578 |  Acc: 45.520,64.970,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.500 |  Acc: 51.686,82.544,96.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.543 |  Acc: 45.700,65.200,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.504 |  Acc: 51.500,82.238,96.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.561 |  Acc: 45.340,65.170,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.498 |  Acc: 51.512,82.532,95.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.568 |  Acc: 45.170,65.060,69.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.498 |  Acc: 51.674,82.354,96.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.579 |  Acc: 45.670,65.040,69.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.500 |  Acc: 51.746,82.340,96.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.567 |  Acc: 45.620,65.120,69.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.499 |  Acc: 51.848,82.452,96.006,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.572 |  Acc: 45.520,64.950,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.490 |  Acc: 51.542,82.628,96.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.582 |  Acc: 45.410,64.930,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.474 |  Acc: 51.872,82.830,96.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.551 |  Acc: 45.710,65.140,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.486 |  Acc: 51.926,82.524,96.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.579 |  Acc: 45.550,65.070,69.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.484 |  Acc: 51.886,82.786,96.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.553 |  Acc: 45.540,65.290,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.472 |  Acc: 51.920,82.984,96.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.560 |  Acc: 45.630,65.180,69.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.487 |  Acc: 51.684,82.620,96.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.554 |  Acc: 45.630,65.460,69.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.474 |  Acc: 51.842,82.698,96.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.565 |  Acc: 45.370,65.080,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.485 |  Acc: 51.760,82.710,96.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.555 |  Acc: 45.570,65.240,69.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.483 |  Acc: 51.750,82.676,96.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.569 |  Acc: 45.640,65.240,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.487 |  Acc: 51.680,82.572,96.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.561 |  Acc: 45.480,65.100,69.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.485 |  Acc: 51.718,82.572,96.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.550 |  Acc: 45.660,65.140,69.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.475 |  Acc: 51.806,82.664,96.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.553 |  Acc: 45.560,65.220,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.478 |  Acc: 51.942,82.708,96.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.568 |  Acc: 45.380,65.170,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.484 |  Acc: 51.716,82.656,96.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.567 |  Acc: 45.340,65.360,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.470 |  Acc: 51.720,82.928,96.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.561 |  Acc: 45.680,65.240,69.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.482 |  Acc: 51.888,82.722,96.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.561 |  Acc: 45.490,65.030,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.470 |  Acc: 52.146,82.622,96.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.555 |  Acc: 45.860,65.370,69.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.478 |  Acc: 51.782,82.842,96.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.569 |  Acc: 45.590,65.120,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.483 |  Acc: 51.710,82.658,96.128,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.561 |  Acc: 45.570,65.190,69.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.478 |  Acc: 51.646,82.676,96.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.553 |  Acc: 45.530,65.300,69.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.474 |  Acc: 51.704,82.782,96.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.555 |  Acc: 45.480,65.190,69.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.476 |  Acc: 52.062,82.758,96.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.553 |  Acc: 45.580,65.210,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.475 |  Acc: 51.760,82.984,96.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.551 |  Acc: 45.540,65.220,69.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.478 |  Acc: 51.980,82.756,96.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.575 |  Acc: 45.410,65.160,69.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.477 |  Acc: 52.030,82.678,96.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.561 |  Acc: 45.580,65.380,69.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.474 |  Acc: 51.978,82.704,96.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.568 |  Acc: 45.460,65.180,69.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.468 |  Acc: 51.958,82.888,96.366,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.586 |  Acc: 45.460,64.960,69.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.478 |  Acc: 51.866,82.758,96.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.568 |  Acc: 45.500,65.240,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.479 |  Acc: 51.806,82.688,96.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.550 |  Acc: 45.450,65.380,69.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.470 |  Acc: 51.874,82.828,96.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.567 |  Acc: 45.640,65.050,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.475 |  Acc: 51.716,82.848,96.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.556 |  Acc: 45.720,65.220,69.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.471 |  Acc: 51.942,82.834,96.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.547 |  Acc: 45.630,64.960,69.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.475 |  Acc: 51.886,82.636,96.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.554 |  Acc: 45.590,65.240,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.480 |  Acc: 51.850,82.822,96.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.555 |  Acc: 45.790,65.180,69.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.476 |  Acc: 51.858,82.646,96.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.557 |  Acc: 45.620,65.210,69.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.472 |  Acc: 52.118,82.822,96.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.561 |  Acc: 45.600,65.060,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.477 |  Acc: 51.918,82.696,96.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.576 |  Acc: 45.550,65.010,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.469 |  Acc: 52.156,82.832,96.210,% | Adaptive Acc:87.414% | clf_exit: 0.354 0.459 0.187
Testing: Epoch=299 | Loss: 4.563 |  Acc: 45.510,65.210,69.370,% | Adaptive Acc:63.530% | clf_exit: 0.402 0.385 0.213

circles: 0
Testing: Epoch=299 | Loss: 15.564 |  Acc: 9.840,12.490,34.840,% | Adaptive Acc:18.250% | clf_exit: 0.581 0.124 0.295
circles: 1
Testing: Epoch=299 | Loss: 6.824 |  Acc: 25.430,51.360,64.520,% | Adaptive Acc:48.620% | clf_exit: 0.433 0.268 0.299
circles: 2
Testing: Epoch=299 | Loss: 4.563 |  Acc: 45.510,65.210,69.370,% | Adaptive Acc:63.530% | clf_exit: 0.402 0.385 0.213
