==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=32, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x32])
      (linear_bw): Linear(in_features=32, out_features=16, bias=True)
      (BN1d): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=32, out_features=100, bias=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=64, out_features=64, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x64])
      (linear_bw): Linear(in_features=64, out_features=64, bias=True)
      (BN1d): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (linear2): Linear(in_features=64, out_features=100, bias=True)
    )
    (2): ClassifierModule2(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=128, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=128, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 15.005 | Acc: 1.562,0.000,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 14.602 | Acc: 1.004,0.967,1.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 14.345 | Acc: 1.124,1.277,1.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 14.191 | Acc: 1.332,1.678,1.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 14.105 | Acc: 1.427,1.804,1.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 14.035 | Acc: 1.532,1.856,1.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.994 | Acc: 1.537,1.937,1.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.962 | Acc: 1.590,2.006,1.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.933 | Acc: 1.621,2.150,1.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.912 | Acc: 1.696,2.288,1.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.882 | Acc: 1.730,2.363,1.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.864 | Acc: 1.715,2.439,1.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.840 | Acc: 1.741,2.545,1.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.816 | Acc: 1.775,2.676,1.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.797 | Acc: 1.810,2.819,1.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.777 | Acc: 1.796,2.923,1.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.757 | Acc: 1.801,3.011,1.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.735 | Acc: 1.828,3.127,1.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 13.715 | Acc: 1.902,3.214,1.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 13.698 | Acc: 1.952,3.299,1.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 13.313 | Acc: 3.906,8.594,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.380 | Acc: 3.385,4.874,1.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.380 | Acc: 3.258,4.764,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.385 | Acc: 3.035,4.700,1.627,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 13.568 | Acc: 1.562,2.344,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 13.302 | Acc: 2.976,4.464,2.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 13.314 | Acc: 2.801,4.954,2.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 13.278 | Acc: 3.010,5.097,2.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 13.267 | Acc: 2.874,5.285,2.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 13.245 | Acc: 2.963,5.446,2.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 13.227 | Acc: 3.015,5.591,2.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 13.211 | Acc: 2.986,5.718,2.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 13.191 | Acc: 3.067,5.789,2.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 13.169 | Acc: 3.155,5.853,2.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 13.151 | Acc: 3.214,5.982,2.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 13.136 | Acc: 3.245,6.080,2.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 13.122 | Acc: 3.294,6.169,2.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 13.107 | Acc: 3.317,6.214,2.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 13.089 | Acc: 3.370,6.300,2.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 13.063 | Acc: 3.470,6.447,2.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 13.038 | Acc: 3.490,6.557,2.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 13.019 | Acc: 3.496,6.580,2.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.997 | Acc: 3.543,6.594,2.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.975 | Acc: 3.603,6.660,2.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.619 | Acc: 3.906,7.031,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.763 | Acc: 4.315,6.920,3.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.743 | Acc: 4.154,6.631,3.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.745 | Acc: 4.124,6.942,3.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 12.644 | Acc: 3.906,7.812,3.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.485 | Acc: 4.613,7.180,5.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.396 | Acc: 4.726,7.774,6.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.368 | Acc: 4.688,7.979,6.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 12.349 | Acc: 4.610,8.092,6.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 12.331 | Acc: 4.796,8.269,6.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 12.318 | Acc: 4.881,8.413,6.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 12.296 | Acc: 4.992,8.433,6.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 12.276 | Acc: 5.056,8.409,6.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 12.251 | Acc: 5.205,8.365,7.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 12.234 | Acc: 5.146,8.431,7.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 12.216 | Acc: 5.228,8.452,7.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 12.187 | Acc: 5.300,8.526,7.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 12.166 | Acc: 5.358,8.639,7.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 12.142 | Acc: 5.455,8.730,7.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 12.118 | Acc: 5.534,8.833,8.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 12.091 | Acc: 5.617,8.934,8.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 12.078 | Acc: 5.590,8.997,8.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 12.060 | Acc: 5.631,9.098,8.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 12.044 | Acc: 5.653,9.156,8.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.531 | Acc: 8.594,12.500,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.929 | Acc: 5.952,9.301,8.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.924 | Acc: 5.545,9.737,8.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.924 | Acc: 5.520,9.721,8.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 11.663 | Acc: 9.375,8.594,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.541 | Acc: 7.217,12.612,11.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.574 | Acc: 7.127,12.214,11.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.570 | Acc: 7.147,11.834,11.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 11.558 | Acc: 7.118,11.960,11.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 11.549 | Acc: 7.124,11.796,11.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 11.536 | Acc: 7.128,11.693,11.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 11.534 | Acc: 7.053,11.669,11.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 11.519 | Acc: 7.153,11.646,11.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 11.497 | Acc: 7.282,11.783,12.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 11.475 | Acc: 7.327,11.890,12.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 11.457 | Acc: 7.378,11.920,12.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 11.445 | Acc: 7.378,11.972,12.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 11.432 | Acc: 7.435,11.988,12.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 11.415 | Acc: 7.440,12.064,12.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 11.398 | Acc: 7.472,12.095,12.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 11.381 | Acc: 7.579,12.181,12.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 11.375 | Acc: 7.542,12.214,12.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 11.364 | Acc: 7.557,12.204,12.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 11.353 | Acc: 7.595,12.258,13.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 11.173 | Acc: 8.594,10.156,12.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 11.382 | Acc: 7.068,10.900,13.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 11.357 | Acc: 7.146,11.414,13.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 11.346 | Acc: 7.300,11.373,14.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 10.847 | Acc: 11.719,17.188,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.951 | Acc: 9.040,14.323,14.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.972 | Acc: 9.623,14.329,15.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.976 | Acc: 9.119,13.973,15.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.967 | Acc: 9.057,13.841,15.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.968 | Acc: 9.058,13.954,15.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.951 | Acc: 9.168,14.166,15.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.951 | Acc: 9.126,14.251,15.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.929 | Acc: 9.050,14.223,16.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.917 | Acc: 9.138,14.330,16.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.895 | Acc: 9.227,14.436,16.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.879 | Acc: 9.230,14.451,16.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.869 | Acc: 9.294,14.594,16.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.855 | Acc: 9.324,14.664,16.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.856 | Acc: 9.294,14.632,16.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.834 | Acc: 9.424,14.794,16.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.820 | Acc: 9.499,14.798,16.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.805 | Acc: 9.558,14.800,17.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.784 | Acc: 9.604,14.950,17.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.769 | Acc: 9.695,15.061,17.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 12.005 | Acc: 6.250,9.375,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 12.129 | Acc: 5.134,11.161,14.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 12.067 | Acc: 4.707,10.537,14.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 12.070 | Acc: 4.572,10.489,14.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 9.867 | Acc: 10.156,21.875,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.353 | Acc: 11.124,17.634,21.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.405 | Acc: 10.137,16.730,20.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.367 | Acc: 10.169,17.188,20.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 10.337 | Acc: 10.407,17.409,20.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 10.330 | Acc: 10.365,17.450,20.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 10.310 | Acc: 10.699,17.523,20.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 10.302 | Acc: 10.710,17.481,20.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 10.294 | Acc: 10.588,17.474,20.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 10.277 | Acc: 10.661,17.541,20.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 10.258 | Acc: 10.891,17.673,20.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 10.243 | Acc: 10.909,17.753,21.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 10.223 | Acc: 11.093,17.816,21.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 10.214 | Acc: 11.192,17.915,21.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 10.204 | Acc: 11.271,17.944,21.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 10.188 | Acc: 11.353,18.000,21.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 10.177 | Acc: 11.373,18.132,21.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 10.163 | Acc: 11.462,18.223,21.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 10.148 | Acc: 11.561,18.339,21.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 10.138 | Acc: 11.614,18.393,21.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.473 | Acc: 12.500,17.188,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.849 | Acc: 10.603,13.467,16.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.784 | Acc: 10.976,13.338,17.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.817 | Acc: 10.720,13.691,17.687,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 10.261 | Acc: 14.062,17.188,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.030 | Acc: 11.570,19.048,22.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.864 | Acc: 12.119,19.741,23.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.861 | Acc: 12.334,19.980,23.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.849 | Acc: 12.461,19.985,24.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.826 | Acc: 12.786,20.258,24.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.796 | Acc: 12.991,20.332,24.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.784 | Acc: 13.021,20.434,24.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.777 | Acc: 13.131,20.560,24.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.737 | Acc: 13.294,20.852,24.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.720 | Acc: 13.378,21.098,24.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.699 | Acc: 13.363,21.104,24.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.692 | Acc: 13.359,21.136,24.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.680 | Acc: 13.443,21.258,24.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.669 | Acc: 13.565,21.258,24.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.655 | Acc: 13.595,21.346,25.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.649 | Acc: 13.561,21.388,25.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.639 | Acc: 13.595,21.440,25.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.625 | Acc: 13.643,21.542,25.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.612 | Acc: 13.685,21.590,25.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.748 | Acc: 10.938,22.656,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.019 | Acc: 11.384,19.717,22.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.966 | Acc: 11.509,19.874,23.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.002 | Acc: 11.245,19.634,23.079,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 9.260 | Acc: 11.719,27.344,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.339 | Acc: 14.955,23.251,27.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.310 | Acc: 14.844,23.971,27.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.320 | Acc: 14.946,23.745,26.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 9.313 | Acc: 14.969,23.804,27.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 9.297 | Acc: 15.331,23.886,27.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 9.271 | Acc: 15.367,24.206,27.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 9.243 | Acc: 15.459,24.451,27.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 9.244 | Acc: 15.528,24.418,27.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 9.246 | Acc: 15.435,24.206,27.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 9.243 | Acc: 15.493,24.269,28.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 9.238 | Acc: 15.477,24.233,28.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 9.231 | Acc: 15.567,24.261,28.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 9.224 | Acc: 15.577,24.222,28.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 9.218 | Acc: 15.625,24.158,28.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 9.201 | Acc: 15.646,24.216,28.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 9.195 | Acc: 15.664,24.168,28.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 9.191 | Acc: 15.623,24.111,28.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 9.177 | Acc: 15.703,24.225,28.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 9.174 | Acc: 15.721,24.196,28.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.558 | Acc: 11.719,20.312,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.860 | Acc: 11.942,20.089,25.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.799 | Acc: 12.424,20.427,26.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.790 | Acc: 12.257,20.120,26.140,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 8.941 | Acc: 15.625,26.562,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.897 | Acc: 17.708,26.451,31.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.903 | Acc: 16.825,26.429,31.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.912 | Acc: 16.650,25.871,31.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.932 | Acc: 16.667,25.810,31.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.951 | Acc: 16.561,25.541,30.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.927 | Acc: 16.671,25.691,30.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.919 | Acc: 16.761,25.776,30.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.916 | Acc: 16.765,25.742,30.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.898 | Acc: 16.924,25.859,30.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.883 | Acc: 17.102,25.964,31.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.875 | Acc: 17.258,26.085,31.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.858 | Acc: 17.304,26.186,31.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.853 | Acc: 17.301,26.194,31.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.849 | Acc: 17.338,26.271,31.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.840 | Acc: 17.372,26.287,31.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.831 | Acc: 17.414,26.387,31.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.820 | Acc: 17.545,26.496,31.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.815 | Acc: 17.564,26.508,31.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.816 | Acc: 17.520,26.511,31.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.981 | Acc: 17.969,22.656,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.087 | Acc: 15.253,23.289,30.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.109 | Acc: 15.301,22.942,30.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.159 | Acc: 14.844,23.117,29.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 8.029 | Acc: 23.438,39.062,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.504 | Acc: 19.680,28.460,35.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.534 | Acc: 19.646,27.858,33.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.544 | Acc: 19.429,28.291,34.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.556 | Acc: 19.338,28.125,33.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.541 | Acc: 19.431,28.249,33.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.532 | Acc: 19.279,28.177,33.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.554 | Acc: 19.221,27.909,33.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.558 | Acc: 19.158,27.873,33.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.557 | Acc: 19.031,27.844,33.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.551 | Acc: 19.065,27.966,33.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.550 | Acc: 19.121,27.966,33.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.551 | Acc: 19.071,28.025,33.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.542 | Acc: 19.181,28.107,33.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.541 | Acc: 19.109,28.117,33.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.526 | Acc: 19.235,28.099,33.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.517 | Acc: 19.251,28.137,33.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.508 | Acc: 19.309,28.194,33.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.506 | Acc: 19.347,28.257,33.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.498 | Acc: 19.373,28.297,33.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.565 | Acc: 14.844,21.094,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.458 | Acc: 15.327,23.549,28.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.465 | Acc: 15.358,24.047,28.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.506 | Acc: 15.113,24.001,28.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 8.090 | Acc: 21.094,32.031,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.311 | Acc: 21.094,29.576,35.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.285 | Acc: 20.236,29.554,36.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.311 | Acc: 19.839,29.393,35.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 8.314 | Acc: 19.927,29.273,35.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.280 | Acc: 20.080,29.672,35.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.251 | Acc: 20.274,29.700,35.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.254 | Acc: 20.301,29.599,35.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.238 | Acc: 20.487,29.741,36.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.239 | Acc: 20.632,29.869,36.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.219 | Acc: 20.740,29.983,36.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.231 | Acc: 20.744,29.910,36.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.232 | Acc: 20.676,29.882,36.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.233 | Acc: 20.681,29.804,36.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 8.243 | Acc: 20.710,29.765,36.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 8.242 | Acc: 20.663,29.768,35.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 8.236 | Acc: 20.709,29.838,36.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 8.233 | Acc: 20.800,29.901,36.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 8.226 | Acc: 20.832,29.958,36.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 8.217 | Acc: 20.842,30.018,36.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.561 | Acc: 21.875,26.562,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.931 | Acc: 18.378,25.670,32.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.891 | Acc: 18.102,26.391,32.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.894 | Acc: 18.097,26.191,32.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 7.831 | Acc: 17.969,33.594,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.055 | Acc: 21.652,31.399,37.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.004 | Acc: 22.637,31.917,38.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.968 | Acc: 22.836,32.198,38.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.988 | Acc: 22.743,32.060,38.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 8.016 | Acc: 22.610,31.799,38.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 8.015 | Acc: 22.579,31.618,38.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 8.014 | Acc: 22.640,31.743,38.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 8.011 | Acc: 22.695,31.755,38.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 8.009 | Acc: 22.699,31.850,38.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 8.011 | Acc: 22.707,31.810,38.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 8.010 | Acc: 22.692,31.890,38.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 8.001 | Acc: 22.763,31.859,38.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 8.002 | Acc: 22.734,31.786,38.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.997 | Acc: 22.823,31.759,38.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.990 | Acc: 22.877,31.738,38.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.986 | Acc: 22.800,31.802,38.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.981 | Acc: 22.814,31.791,38.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.979 | Acc: 22.819,31.802,38.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.967 | Acc: 22.904,31.902,38.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 10.300 | Acc: 16.406,17.969,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 10.221 | Acc: 13.132,18.601,28.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 10.328 | Acc: 12.671,18.216,27.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 10.349 | Acc: 12.615,18.443,27.754,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 8.147 | Acc: 24.219,29.688,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.887 | Acc: 22.545,31.287,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.803 | Acc: 22.999,32.546,40.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.771 | Acc: 23.425,33.607,41.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.761 | Acc: 23.389,33.295,40.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.761 | Acc: 23.515,33.230,40.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.795 | Acc: 23.509,32.858,39.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.810 | Acc: 23.232,32.668,39.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.819 | Acc: 23.336,32.618,39.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.816 | Acc: 23.286,32.674,39.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.819 | Acc: 23.344,32.657,39.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.808 | Acc: 23.491,32.710,39.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.802 | Acc: 23.444,32.725,39.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.790 | Acc: 23.521,32.792,39.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.787 | Acc: 23.540,32.832,39.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.787 | Acc: 23.534,32.870,39.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.781 | Acc: 23.571,32.983,39.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.774 | Acc: 23.664,33.055,39.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.770 | Acc: 23.665,33.033,39.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.763 | Acc: 23.686,33.042,39.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.508 | Acc: 21.094,22.656,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.900 | Acc: 18.601,23.698,34.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.873 | Acc: 18.579,23.704,34.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.896 | Acc: 18.404,23.361,33.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 7.130 | Acc: 34.375,40.625,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.528 | Acc: 24.740,34.561,41.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.494 | Acc: 24.714,34.642,42.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.547 | Acc: 25.102,34.670,42.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.558 | Acc: 25.280,34.529,42.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.561 | Acc: 24.838,34.321,42.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.558 | Acc: 24.871,34.226,41.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.552 | Acc: 24.895,34.314,42.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.551 | Acc: 24.903,34.176,41.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.554 | Acc: 24.845,34.194,41.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.578 | Acc: 24.685,34.083,41.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.573 | Acc: 24.721,34.149,41.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.582 | Acc: 24.679,34.151,41.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.569 | Acc: 24.725,34.198,41.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.560 | Acc: 24.789,34.389,41.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.560 | Acc: 24.831,34.476,41.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.558 | Acc: 24.898,34.562,41.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.561 | Acc: 24.934,34.561,41.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.556 | Acc: 24.996,34.604,41.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.560 | Acc: 24.971,34.599,41.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 9.075 | Acc: 18.750,21.875,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.051 | Acc: 18.043,24.442,34.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.122 | Acc: 17.378,24.314,33.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.171 | Acc: 17.072,23.681,33.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 7.528 | Acc: 28.125,37.500,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.470 | Acc: 26.116,36.235,42.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.384 | Acc: 26.696,36.395,43.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.377 | Acc: 26.665,35.976,43.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.391 | Acc: 26.688,35.995,43.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.389 | Acc: 26.593,36.046,42.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.425 | Acc: 26.640,35.983,42.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.391 | Acc: 26.640,36.082,42.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.388 | Acc: 26.422,36.132,42.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.382 | Acc: 26.355,36.032,42.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.385 | Acc: 26.388,35.926,42.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.391 | Acc: 26.304,35.916,42.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.386 | Acc: 26.258,35.980,42.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.384 | Acc: 26.230,35.932,42.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.387 | Acc: 26.173,35.862,42.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.382 | Acc: 26.321,35.875,42.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.395 | Acc: 26.154,35.794,42.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.391 | Acc: 26.141,35.816,42.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.389 | Acc: 26.132,35.812,42.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.391 | Acc: 26.128,35.860,42.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.380 | Acc: 28.125,36.719,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.679 | Acc: 23.549,33.929,41.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.695 | Acc: 22.942,33.270,41.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.678 | Acc: 23.233,33.261,42.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 7.102 | Acc: 32.031,39.062,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.190 | Acc: 27.009,37.240,45.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.169 | Acc: 27.420,37.233,44.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.207 | Acc: 27.357,37.141,44.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.226 | Acc: 27.267,37.375,44.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.239 | Acc: 27.181,37.252,44.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.243 | Acc: 27.176,37.203,44.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.243 | Acc: 27.322,37.201,44.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.241 | Acc: 27.286,37.296,44.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.251 | Acc: 27.305,37.297,44.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.237 | Acc: 27.274,37.341,44.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.243 | Acc: 27.185,37.316,44.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.242 | Acc: 27.169,37.267,44.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.224 | Acc: 27.191,37.374,44.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.220 | Acc: 27.105,37.353,44.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.225 | Acc: 27.076,37.378,44.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.220 | Acc: 27.088,37.369,44.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.214 | Acc: 27.057,37.356,44.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.216 | Acc: 27.097,37.338,44.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.208 | Acc: 27.110,37.397,44.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.681 | Acc: 17.188,27.344,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 9.181 | Acc: 17.411,26.897,34.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.187 | Acc: 17.359,26.772,34.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.227 | Acc: 17.021,26.588,33.811,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 6.780 | Acc: 32.812,42.188,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.152 | Acc: 26.786,38.058,44.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.055 | Acc: 27.496,38.624,45.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.058 | Acc: 27.715,38.704,45.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 7.067 | Acc: 27.556,38.493,45.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 7.061 | Acc: 27.676,38.420,45.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 7.054 | Acc: 27.712,38.333,45.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 7.026 | Acc: 27.881,38.580,45.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 7.042 | Acc: 27.848,38.412,45.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 7.053 | Acc: 27.827,38.523,45.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 7.052 | Acc: 27.872,38.437,45.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 7.042 | Acc: 28.005,38.624,45.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 7.041 | Acc: 28.089,38.557,45.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 7.037 | Acc: 27.996,38.542,45.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 7.035 | Acc: 28.078,38.620,45.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 7.038 | Acc: 28.016,38.639,45.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 7.038 | Acc: 27.950,38.578,45.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 7.036 | Acc: 28.045,38.586,45.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 7.050 | Acc: 27.991,38.465,45.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 7.051 | Acc: 28.006,38.478,45.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.619 | Acc: 27.344,37.500,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.953 | Acc: 21.540,32.366,42.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.945 | Acc: 21.227,32.355,42.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.962 | Acc: 21.068,32.390,41.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 7.877 | Acc: 21.094,30.469,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.029 | Acc: 27.827,38.393,46.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.019 | Acc: 28.011,38.281,46.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.008 | Acc: 28.074,38.601,46.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.962 | Acc: 27.971,38.908,46.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.977 | Acc: 27.901,38.962,46.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.982 | Acc: 27.854,38.888,46.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.971 | Acc: 28.036,39.240,46.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.948 | Acc: 28.207,39.562,46.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.943 | Acc: 28.470,39.529,46.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.944 | Acc: 28.494,39.572,46.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.943 | Acc: 28.581,39.536,46.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.936 | Acc: 28.624,39.633,46.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.925 | Acc: 28.700,39.676,47.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.932 | Acc: 28.684,39.699,47.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.926 | Acc: 28.688,39.732,47.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.909 | Acc: 28.782,39.832,47.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.910 | Acc: 28.808,39.800,47.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.915 | Acc: 28.770,39.714,47.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.914 | Acc: 28.681,39.723,47.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.138 | Acc: 23.438,35.938,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.224 | Acc: 20.126,32.999,41.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.265 | Acc: 19.989,32.050,41.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.273 | Acc: 20.056,31.468,40.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 6.416 | Acc: 33.594,41.406,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.629 | Acc: 30.580,43.155,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.747 | Acc: 30.335,41.406,48.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.740 | Acc: 30.033,41.291,48.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.763 | Acc: 29.649,40.905,48.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.758 | Acc: 29.587,41.050,48.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.768 | Acc: 29.539,40.832,48.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.786 | Acc: 29.355,40.592,47.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.796 | Acc: 29.440,40.615,47.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.797 | Acc: 29.377,40.603,47.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.797 | Acc: 29.342,40.497,47.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.812 | Acc: 29.203,40.484,47.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.810 | Acc: 29.282,40.525,47.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.800 | Acc: 29.319,40.520,47.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.801 | Acc: 29.409,40.572,47.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.788 | Acc: 29.366,40.563,47.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.782 | Acc: 29.376,40.630,48.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.783 | Acc: 29.390,40.652,48.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.784 | Acc: 29.309,40.681,48.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.782 | Acc: 29.312,40.730,48.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.533 | Acc: 30.469,40.625,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.809 | Acc: 23.251,36.235,40.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.866 | Acc: 23.037,34.604,40.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.886 | Acc: 23.207,34.337,40.510,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 6.792 | Acc: 28.906,40.625,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.776 | Acc: 29.427,40.774,49.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.667 | Acc: 30.240,41.597,49.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.707 | Acc: 29.905,41.150,48.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.638 | Acc: 30.266,41.686,49.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.653 | Acc: 30.074,41.592,49.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.640 | Acc: 30.127,41.697,49.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.640 | Acc: 30.203,41.595,49.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.621 | Acc: 30.381,41.819,49.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.632 | Acc: 30.201,41.799,49.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.646 | Acc: 30.088,41.694,49.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.647 | Acc: 30.087,41.827,49.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.660 | Acc: 30.057,41.828,49.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.654 | Acc: 30.056,41.870,49.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.651 | Acc: 30.071,41.937,49.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.651 | Acc: 30.092,41.954,49.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.659 | Acc: 30.077,41.910,49.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.660 | Acc: 30.095,41.931,49.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.659 | Acc: 30.073,41.999,49.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.658 | Acc: 30.106,41.964,49.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.246 | Acc: 25.000,37.500,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.663 | Acc: 25.484,36.086,43.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.717 | Acc: 24.943,35.842,43.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.727 | Acc: 24.501,35.489,43.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 6.144 | Acc: 30.469,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.379 | Acc: 30.320,44.420,50.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.414 | Acc: 31.098,44.264,51.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.459 | Acc: 30.789,43.929,50.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.447 | Acc: 30.903,44.010,50.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.450 | Acc: 31.095,43.812,50.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.473 | Acc: 30.817,43.498,50.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.492 | Acc: 30.790,43.290,50.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.530 | Acc: 30.585,42.940,49.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.527 | Acc: 30.810,43.046,49.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.525 | Acc: 30.826,42.988,50.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.536 | Acc: 30.766,42.803,49.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.540 | Acc: 30.748,42.797,49.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.536 | Acc: 30.765,42.804,50.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.536 | Acc: 30.805,42.902,50.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.537 | Acc: 30.780,42.940,50.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.535 | Acc: 30.792,42.986,50.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.536 | Acc: 30.794,43.058,50.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.536 | Acc: 30.880,43.073,50.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.540 | Acc: 30.922,43.000,50.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.908 | Acc: 28.906,35.938,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.830 | Acc: 23.475,33.073,41.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.886 | Acc: 23.495,32.908,41.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.907 | Acc: 23.578,32.672,41.368,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 6.256 | Acc: 31.250,43.750,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.591 | Acc: 29.836,43.118,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.566 | Acc: 29.497,43.159,50.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.517 | Acc: 30.213,43.724,51.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.498 | Acc: 30.642,43.866,51.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.501 | Acc: 30.662,43.588,51.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.485 | Acc: 30.669,43.666,51.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.473 | Acc: 30.862,43.722,51.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.481 | Acc: 30.872,43.721,51.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.468 | Acc: 31.103,43.780,51.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.467 | Acc: 31.021,43.731,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.451 | Acc: 31.172,43.934,51.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.443 | Acc: 31.286,43.967,51.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.441 | Acc: 31.382,43.957,51.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.444 | Acc: 31.445,43.925,51.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.446 | Acc: 31.429,43.952,51.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.448 | Acc: 31.372,43.954,51.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.449 | Acc: 31.495,44.007,51.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.444 | Acc: 31.475,44.046,51.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.445 | Acc: 31.461,44.019,51.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.328 | Acc: 24.219,43.750,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.314 | Acc: 23.214,38.393,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.397 | Acc: 23.171,36.909,46.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.396 | Acc: 23.117,36.988,46.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 6.499 | Acc: 32.031,46.875,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.260 | Acc: 32.254,45.499,52.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.277 | Acc: 32.298,45.598,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.283 | Acc: 32.057,44.775,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.263 | Acc: 32.485,45.014,52.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.280 | Acc: 32.372,45.042,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.286 | Acc: 32.212,44.925,52.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.297 | Acc: 31.965,44.869,52.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.311 | Acc: 31.900,44.759,51.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.317 | Acc: 31.880,44.639,51.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.325 | Acc: 31.763,44.632,51.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.327 | Acc: 31.738,44.648,51.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.337 | Acc: 31.697,44.596,51.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.338 | Acc: 31.672,44.564,51.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.350 | Acc: 31.745,44.428,51.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.354 | Acc: 31.808,44.461,51.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.369 | Acc: 31.802,44.378,51.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.362 | Acc: 31.830,44.437,51.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.359 | Acc: 31.808,44.486,51.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.350 | Acc: 31.789,44.550,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.110 | Acc: 32.812,38.281,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.473 | Acc: 24.628,36.458,44.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.516 | Acc: 24.581,36.433,44.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.543 | Acc: 24.834,36.463,43.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 6.511 | Acc: 28.906,43.750,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.245 | Acc: 33.668,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.192 | Acc: 33.232,45.694,53.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.174 | Acc: 33.376,46.222,53.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.204 | Acc: 33.208,45.997,53.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.197 | Acc: 33.315,46.032,53.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.198 | Acc: 33.110,45.739,53.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.233 | Acc: 32.752,45.329,52.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.223 | Acc: 33.011,45.521,52.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.220 | Acc: 33.054,45.597,52.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.225 | Acc: 33.034,45.651,52.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.228 | Acc: 32.957,45.631,53.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.230 | Acc: 32.971,45.666,52.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.231 | Acc: 32.980,45.711,53.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.241 | Acc: 33.035,45.591,52.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.251 | Acc: 32.851,45.507,52.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.251 | Acc: 32.759,45.459,52.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.258 | Acc: 32.812,45.491,52.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.258 | Acc: 32.709,45.533,52.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.261 | Acc: 32.640,45.436,52.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.442 | Acc: 17.188,31.250,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.125 | Acc: 16.555,34.635,42.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.201 | Acc: 16.711,34.223,42.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.205 | Acc: 16.765,34.119,43.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 6.255 | Acc: 37.500,44.531,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.056 | Acc: 34.003,48.140,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.064 | Acc: 33.422,47.313,55.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.128 | Acc: 32.864,46.760,54.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.145 | Acc: 33.092,46.624,54.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.160 | Acc: 33.331,46.550,53.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.154 | Acc: 33.348,46.804,54.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.134 | Acc: 33.372,46.903,54.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.128 | Acc: 33.453,46.962,54.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.131 | Acc: 33.335,46.935,54.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.132 | Acc: 33.209,46.999,53.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.136 | Acc: 33.053,46.861,53.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.145 | Acc: 33.043,46.794,53.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.149 | Acc: 32.974,46.764,53.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.159 | Acc: 32.885,46.694,53.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.159 | Acc: 32.893,46.649,53.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.161 | Acc: 32.929,46.595,53.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.149 | Acc: 33.014,46.740,53.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.145 | Acc: 33.053,46.724,53.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.145 | Acc: 33.036,46.658,53.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.674 | Acc: 24.219,30.469,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.631 | Acc: 23.921,34.970,45.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.725 | Acc: 23.152,34.775,45.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.792 | Acc: 22.912,34.516,44.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 5.769 | Acc: 35.156,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.050 | Acc: 33.371,46.652,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.975 | Acc: 33.765,47.370,56.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.014 | Acc: 33.683,47.041,55.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 6.059 | Acc: 33.459,46.807,55.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 6.049 | Acc: 33.741,47.061,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 6.061 | Acc: 33.910,47.159,54.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 6.062 | Acc: 33.898,47.163,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 6.075 | Acc: 33.851,47.186,54.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.068 | Acc: 33.818,47.333,54.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.074 | Acc: 33.773,47.349,54.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.077 | Acc: 33.732,47.377,54.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.068 | Acc: 33.717,47.397,54.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.079 | Acc: 33.594,47.363,54.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.077 | Acc: 33.577,47.314,54.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.082 | Acc: 33.469,47.293,54.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.085 | Acc: 33.509,47.279,54.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.086 | Acc: 33.507,47.285,54.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.087 | Acc: 33.462,47.247,54.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.089 | Acc: 33.452,47.203,54.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.401 | Acc: 17.969,28.125,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.318 | Acc: 20.126,32.143,39.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.339 | Acc: 20.351,32.298,39.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.374 | Acc: 20.069,32.249,39.498,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 5.678 | Acc: 35.938,51.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.943 | Acc: 34.821,49.182,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.963 | Acc: 34.051,48.266,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.007 | Acc: 33.543,47.720,55.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.976 | Acc: 34.240,48.274,55.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.967 | Acc: 34.360,48.391,55.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.969 | Acc: 34.252,48.567,55.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.986 | Acc: 34.159,48.343,55.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.992 | Acc: 34.200,48.195,55.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 6.002 | Acc: 33.900,47.876,55.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 6.022 | Acc: 33.811,47.575,54.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 6.029 | Acc: 33.689,47.610,54.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 6.024 | Acc: 33.791,47.679,54.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 6.034 | Acc: 33.678,47.554,54.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 6.024 | Acc: 33.758,47.628,54.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 6.025 | Acc: 33.711,47.628,54.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 6.025 | Acc: 33.732,47.707,54.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 6.019 | Acc: 33.834,47.828,54.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 6.021 | Acc: 33.849,47.769,54.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 6.020 | Acc: 33.838,47.818,54.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.905 | Acc: 24.219,35.938,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.202 | Acc: 22.619,32.366,42.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.316 | Acc: 22.199,31.307,42.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.305 | Acc: 21.696,31.557,42.392,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 6.083 | Acc: 35.938,48.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.806 | Acc: 35.231,49.442,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.840 | Acc: 34.661,49.390,56.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.845 | Acc: 34.874,49.232,56.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.869 | Acc: 34.713,48.978,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.885 | Acc: 34.360,49.002,56.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.897 | Acc: 34.052,48.877,55.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.899 | Acc: 34.198,48.997,55.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.912 | Acc: 33.948,48.738,55.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.910 | Acc: 34.056,48.774,55.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.907 | Acc: 34.243,48.799,55.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.913 | Acc: 34.184,48.798,55.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.912 | Acc: 34.226,48.859,55.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.923 | Acc: 34.115,48.818,55.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.922 | Acc: 34.186,48.804,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.929 | Acc: 34.188,48.713,55.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.928 | Acc: 34.217,48.693,55.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.930 | Acc: 34.153,48.680,55.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.935 | Acc: 34.115,48.665,55.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.937 | Acc: 34.047,48.632,55.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.698 | Acc: 26.562,39.062,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.758 | Acc: 25.335,37.723,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.855 | Acc: 24.695,37.348,43.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.876 | Acc: 24.629,37.590,43.955,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 6.893 | Acc: 36.719,41.406,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.754 | Acc: 35.193,50.186,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.740 | Acc: 34.546,49.905,57.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.737 | Acc: 34.926,50.000,57.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.721 | Acc: 35.513,50.280,57.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.780 | Acc: 35.071,49.807,57.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.766 | Acc: 35.163,49.929,57.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.768 | Acc: 35.106,49.961,57.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.767 | Acc: 35.156,50.053,57.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.791 | Acc: 35.035,49.771,56.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.802 | Acc: 34.880,49.631,56.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.822 | Acc: 34.810,49.417,56.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.831 | Acc: 34.686,49.371,56.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.841 | Acc: 34.680,49.324,56.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.846 | Acc: 34.764,49.247,56.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.857 | Acc: 34.762,49.195,56.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.869 | Acc: 34.738,49.107,56.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.876 | Acc: 34.744,49.093,55.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.877 | Acc: 34.853,49.072,55.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.885 | Acc: 34.797,49.042,55.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.320 | Acc: 27.344,38.281,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.720 | Acc: 23.065,39.174,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.744 | Acc: 22.752,38.357,45.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.714 | Acc: 22.746,38.089,45.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 5.596 | Acc: 33.594,46.875,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.747 | Acc: 34.152,49.479,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.646 | Acc: 35.213,50.877,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.664 | Acc: 35.694,50.832,58.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.679 | Acc: 35.909,50.714,58.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.700 | Acc: 35.837,50.843,58.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.733 | Acc: 35.686,50.633,57.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.739 | Acc: 35.533,50.604,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.766 | Acc: 35.258,50.301,57.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.774 | Acc: 35.113,50.268,57.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.791 | Acc: 35.086,50.058,57.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.793 | Acc: 35.018,50.053,57.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.791 | Acc: 35.091,50.029,57.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.804 | Acc: 34.950,49.793,57.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.805 | Acc: 35.006,49.794,56.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.805 | Acc: 35.055,49.714,56.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.807 | Acc: 35.044,49.681,56.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.800 | Acc: 34.994,49.718,56.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.800 | Acc: 35.035,49.732,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.804 | Acc: 34.988,49.758,56.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.263 | Acc: 25.000,39.844,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.358 | Acc: 26.525,39.360,45.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.536 | Acc: 26.162,38.986,45.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.589 | Acc: 25.820,38.934,45.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 5.796 | Acc: 35.938,49.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.709 | Acc: 35.007,49.963,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.666 | Acc: 35.690,49.962,57.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.681 | Acc: 35.438,49.949,57.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.674 | Acc: 35.233,50.203,57.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.667 | Acc: 35.520,50.309,57.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.682 | Acc: 35.531,50.297,57.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.673 | Acc: 35.899,50.604,57.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.680 | Acc: 36.039,50.738,57.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.680 | Acc: 36.123,50.855,57.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.691 | Acc: 36.120,50.723,57.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.695 | Acc: 36.029,50.725,57.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.711 | Acc: 35.895,50.674,57.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.734 | Acc: 35.710,50.485,57.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.742 | Acc: 35.629,50.484,57.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.754 | Acc: 35.486,50.296,57.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.758 | Acc: 35.429,50.207,57.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.766 | Acc: 35.388,50.172,57.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.766 | Acc: 35.345,50.229,57.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.774 | Acc: 35.275,50.180,57.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.695 | Acc: 30.469,42.188,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.418 | Acc: 23.512,39.844,48.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.398 | Acc: 22.732,40.187,48.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.412 | Acc: 22.759,39.908,48.181,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 6.079 | Acc: 33.594,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.546 | Acc: 36.905,51.823,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.645 | Acc: 35.918,52.115,59.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.647 | Acc: 36.373,51.767,59.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.629 | Acc: 36.815,51.910,59.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.652 | Acc: 36.549,51.640,58.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.669 | Acc: 36.377,51.317,58.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.662 | Acc: 36.453,51.402,58.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.666 | Acc: 36.335,51.281,58.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.662 | Acc: 36.425,51.265,58.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.669 | Acc: 36.268,51.224,58.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.661 | Acc: 36.220,51.365,58.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.670 | Acc: 36.116,51.271,58.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.697 | Acc: 35.899,51.090,58.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.702 | Acc: 35.907,51.037,58.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.707 | Acc: 35.917,50.945,58.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.709 | Acc: 35.864,50.925,58.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.713 | Acc: 35.798,50.882,58.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.713 | Acc: 35.860,50.868,57.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.725 | Acc: 35.765,50.697,57.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.657 | Acc: 21.094,29.688,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.496 | Acc: 18.564,34.747,42.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.636 | Acc: 17.740,34.508,41.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.670 | Acc: 17.789,34.810,41.432,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 5.340 | Acc: 42.969,53.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.451 | Acc: 38.616,52.865,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.527 | Acc: 36.947,51.620,59.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.533 | Acc: 36.591,51.703,59.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.560 | Acc: 36.410,51.485,59.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.603 | Acc: 36.092,51.238,58.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.632 | Acc: 35.970,51.117,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.640 | Acc: 35.827,51.047,58.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.627 | Acc: 35.913,51.155,58.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.621 | Acc: 35.946,51.075,58.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.629 | Acc: 35.782,51.018,58.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.626 | Acc: 35.846,51.007,58.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.636 | Acc: 35.814,50.869,58.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.654 | Acc: 35.719,50.766,58.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.662 | Acc: 35.623,50.667,58.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.667 | Acc: 35.597,50.644,57.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.677 | Acc: 35.565,50.518,57.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.686 | Acc: 35.594,50.490,57.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.686 | Acc: 35.624,50.452,57.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.689 | Acc: 35.579,50.435,57.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.732 | Acc: 31.250,45.312,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.383 | Acc: 24.777,39.732,47.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.451 | Acc: 24.333,39.882,47.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.490 | Acc: 24.257,39.933,47.093,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 5.516 | Acc: 32.812,47.656,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.606 | Acc: 35.826,50.930,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.567 | Acc: 35.728,51.543,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.585 | Acc: 35.771,51.242,59.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.557 | Acc: 36.188,51.543,59.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.529 | Acc: 36.618,52.065,60.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.565 | Acc: 36.364,51.814,59.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.579 | Acc: 36.120,51.684,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.585 | Acc: 35.967,51.558,59.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.586 | Acc: 35.843,51.524,59.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.605 | Acc: 35.700,51.322,58.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.610 | Acc: 35.740,51.280,58.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.621 | Acc: 35.853,51.229,58.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.614 | Acc: 35.970,51.434,58.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.608 | Acc: 35.993,51.501,58.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.606 | Acc: 36.101,51.542,58.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.612 | Acc: 36.091,51.536,58.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.616 | Acc: 36.018,51.540,58.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.619 | Acc: 35.994,51.506,58.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.615 | Acc: 36.056,51.544,58.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.865 | Acc: 29.688,50.781,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.370 | Acc: 23.996,40.476,48.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.376 | Acc: 24.009,39.558,48.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.370 | Acc: 23.796,39.549,48.758,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 5.493 | Acc: 35.938,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.392 | Acc: 36.830,53.757,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.358 | Acc: 37.005,53.830,60.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.428 | Acc: 36.975,52.946,60.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.484 | Acc: 36.516,52.411,60.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.499 | Acc: 36.471,52.328,60.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.515 | Acc: 36.422,52.266,60.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.523 | Acc: 36.309,52.161,59.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.528 | Acc: 36.214,52.106,59.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.531 | Acc: 36.205,52.033,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.529 | Acc: 36.338,52.103,59.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.528 | Acc: 36.298,52.086,59.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.544 | Acc: 36.229,51.958,59.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.546 | Acc: 36.219,51.988,59.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.562 | Acc: 36.054,51.807,59.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.572 | Acc: 36.088,51.723,59.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.577 | Acc: 36.062,51.709,59.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.583 | Acc: 36.052,51.705,59.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.588 | Acc: 36.048,51.638,59.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.586 | Acc: 36.126,51.616,59.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.541 | Acc: 26.562,46.875,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.817 | Acc: 26.935,44.680,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.825 | Acc: 26.562,43.845,49.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.892 | Acc: 26.025,43.481,49.680,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 5.289 | Acc: 41.406,48.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.463 | Acc: 35.640,52.827,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.422 | Acc: 36.719,53.106,60.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.430 | Acc: 36.693,52.869,60.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.449 | Acc: 36.931,52.874,60.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.461 | Acc: 37.013,52.870,60.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.467 | Acc: 37.203,52.873,60.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.481 | Acc: 37.107,52.654,60.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.482 | Acc: 37.044,52.567,60.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.496 | Acc: 36.991,52.465,60.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.516 | Acc: 36.742,52.219,59.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.531 | Acc: 36.581,52.114,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.535 | Acc: 36.482,52.081,59.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.546 | Acc: 36.494,52.098,59.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.543 | Acc: 36.516,52.166,59.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.537 | Acc: 36.514,52.209,59.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.536 | Acc: 36.531,52.139,59.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.538 | Acc: 36.533,52.211,59.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.540 | Acc: 36.437,52.244,59.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.539 | Acc: 36.469,52.276,59.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.020 | Acc: 30.469,49.219,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.170 | Acc: 25.856,43.415,49.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.239 | Acc: 25.972,43.216,49.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.294 | Acc: 25.461,42.610,49.501,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 4.942 | Acc: 42.188,55.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.460 | Acc: 36.682,53.311,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.412 | Acc: 36.490,53.011,61.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.393 | Acc: 36.642,53.279,61.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.430 | Acc: 36.738,53.173,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.439 | Acc: 36.502,52.893,60.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.441 | Acc: 36.712,53.022,60.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.422 | Acc: 36.935,53.153,60.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.441 | Acc: 36.709,53.076,60.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.457 | Acc: 36.706,52.836,60.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.476 | Acc: 36.552,52.682,60.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.484 | Acc: 36.634,52.648,59.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.487 | Acc: 36.709,52.626,59.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.483 | Acc: 36.701,52.616,59.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.488 | Acc: 36.649,52.483,59.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.480 | Acc: 36.742,52.536,59.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.479 | Acc: 36.653,52.594,59.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.473 | Acc: 36.645,52.623,59.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.482 | Acc: 36.576,52.562,59.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.486 | Acc: 36.616,52.616,59.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.230 | Acc: 30.469,37.500,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.879 | Acc: 28.237,42.708,51.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.928 | Acc: 27.572,42.816,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.984 | Acc: 27.369,42.456,49.987,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 4.948 | Acc: 41.406,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.343 | Acc: 37.463,55.060,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.350 | Acc: 36.966,54.230,61.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.336 | Acc: 37.129,54.188,61.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.353 | Acc: 37.056,53.954,61.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.372 | Acc: 36.750,53.875,61.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.372 | Acc: 37.022,53.842,61.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.393 | Acc: 36.796,53.657,61.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.400 | Acc: 36.796,53.635,60.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.413 | Acc: 36.706,53.608,60.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.407 | Acc: 36.742,53.704,61.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.429 | Acc: 36.666,53.440,60.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.431 | Acc: 36.677,53.394,60.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.429 | Acc: 36.692,53.394,60.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.434 | Acc: 36.671,53.314,60.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.438 | Acc: 36.719,53.247,60.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.445 | Acc: 36.787,53.188,60.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.452 | Acc: 36.753,53.091,60.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.454 | Acc: 36.740,52.995,60.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.449 | Acc: 36.811,53.018,60.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.094 | Acc: 32.812,41.406,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.244 | Acc: 27.121,40.104,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.279 | Acc: 26.715,39.386,46.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.274 | Acc: 26.908,39.626,46.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 5.772 | Acc: 35.156,53.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.405 | Acc: 37.426,52.976,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.383 | Acc: 37.081,53.392,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.335 | Acc: 37.718,53.778,61.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.361 | Acc: 37.664,53.559,61.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.361 | Acc: 37.369,53.442,61.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.352 | Acc: 37.319,53.622,61.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.377 | Acc: 37.140,53.302,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.402 | Acc: 36.952,53.067,60.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.394 | Acc: 36.805,53.168,60.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.397 | Acc: 36.999,53.211,60.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.417 | Acc: 36.917,53.090,60.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.405 | Acc: 37.056,53.248,60.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.404 | Acc: 37.177,53.263,60.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.416 | Acc: 37.116,53.081,60.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.413 | Acc: 37.155,53.055,60.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.418 | Acc: 37.098,53.006,60.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.420 | Acc: 37.129,53.031,60.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.423 | Acc: 37.104,52.963,60.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.422 | Acc: 37.176,53.029,60.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.171 | Acc: 28.125,41.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.631 | Acc: 23.735,40.402,46.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.636 | Acc: 23.304,40.949,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.673 | Acc: 22.836,40.779,46.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 4.877 | Acc: 39.844,55.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.253 | Acc: 37.091,55.841,62.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.202 | Acc: 38.224,55.202,62.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.236 | Acc: 37.718,54.521,62.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.231 | Acc: 37.828,54.417,62.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.256 | Acc: 37.570,54.208,62.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.253 | Acc: 37.623,54.384,62.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.274 | Acc: 37.661,54.244,62.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.299 | Acc: 37.553,54.081,61.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.314 | Acc: 37.500,53.876,61.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.343 | Acc: 37.337,53.584,61.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.353 | Acc: 37.415,53.602,61.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.377 | Acc: 37.147,53.420,60.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.377 | Acc: 37.162,53.448,60.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.381 | Acc: 37.228,53.489,61.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.383 | Acc: 37.126,53.473,60.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.380 | Acc: 37.147,53.551,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.391 | Acc: 37.081,53.487,60.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.396 | Acc: 37.050,53.463,60.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.398 | Acc: 37.063,53.433,60.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.604 | Acc: 32.031,46.094,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.995 | Acc: 30.394,41.667,51.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.952 | Acc: 29.783,41.120,51.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.977 | Acc: 29.649,41.329,51.281,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 5.500 | Acc: 32.812,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.054 | Acc: 38.542,56.585,63.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.123 | Acc: 38.167,55.926,63.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.235 | Acc: 37.999,55.213,62.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.255 | Acc: 37.760,54.890,62.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.304 | Acc: 37.392,54.169,61.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.319 | Acc: 37.261,54.042,61.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.342 | Acc: 37.168,53.834,61.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.354 | Acc: 37.359,53.756,60.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.354 | Acc: 37.422,53.811,60.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.367 | Acc: 37.243,53.634,60.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.361 | Acc: 37.207,53.761,60.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.356 | Acc: 37.280,53.692,60.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.361 | Acc: 37.135,53.760,60.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.368 | Acc: 37.208,53.742,60.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.368 | Acc: 37.225,53.802,60.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.360 | Acc: 37.332,53.816,60.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.357 | Acc: 37.411,53.838,60.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.353 | Acc: 37.463,53.952,61.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.356 | Acc: 37.402,53.892,61.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.536 | Acc: 32.812,51.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.450 | Acc: 31.027,45.201,54.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.520 | Acc: 30.774,44.874,53.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.596 | Acc: 30.353,44.378,53.138,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 5.492 | Acc: 36.719,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.454 | Acc: 35.863,52.121,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.375 | Acc: 36.700,53.182,61.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.320 | Acc: 37.193,54.022,61.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.318 | Acc: 37.452,54.080,61.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.327 | Acc: 37.454,54.223,61.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.305 | Acc: 37.674,54.442,61.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.316 | Acc: 37.428,54.294,61.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.315 | Acc: 37.393,54.285,61.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.298 | Acc: 37.642,54.355,61.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.300 | Acc: 37.655,54.349,61.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.307 | Acc: 37.610,54.419,61.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.303 | Acc: 37.636,54.457,61.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.309 | Acc: 37.704,54.343,61.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.312 | Acc: 37.706,54.287,61.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.314 | Acc: 37.664,54.244,61.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.322 | Acc: 37.500,54.142,61.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.313 | Acc: 37.589,54.248,61.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.320 | Acc: 37.509,54.185,61.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.318 | Acc: 37.533,54.183,61.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.147 | Acc: 31.250,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.738 | Acc: 28.274,44.457,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.710 | Acc: 28.030,44.245,51.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.722 | Acc: 28.010,44.544,51.947,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 4.742 | Acc: 45.312,57.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.095 | Acc: 39.658,56.027,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.146 | Acc: 38.853,55.469,63.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.164 | Acc: 38.448,55.392,63.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.181 | Acc: 38.098,54.986,62.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.187 | Acc: 38.281,55.183,62.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.184 | Acc: 38.611,55.178,62.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.209 | Acc: 38.375,55.053,62.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.227 | Acc: 38.116,54.954,62.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.230 | Acc: 38.044,54.852,62.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.229 | Acc: 38.130,54.890,62.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.253 | Acc: 38.048,54.864,62.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.255 | Acc: 38.071,54.752,62.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.262 | Acc: 38.021,54.753,62.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.269 | Acc: 37.975,54.676,62.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.267 | Acc: 37.913,54.594,62.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.275 | Acc: 37.899,54.490,61.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.289 | Acc: 37.860,54.374,61.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.287 | Acc: 37.907,54.426,61.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.291 | Acc: 37.832,54.405,61.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.902 | Acc: 28.906,47.656,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.404 | Acc: 27.083,41.071,49.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.496 | Acc: 26.086,40.396,48.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.535 | Acc: 25.448,40.202,48.335,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 5.209 | Acc: 42.188,56.250,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.066 | Acc: 38.579,55.915,64.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.115 | Acc: 38.205,55.545,64.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.060 | Acc: 38.998,56.481,64.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.105 | Acc: 38.677,56.250,63.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.110 | Acc: 38.475,56.196,63.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.137 | Acc: 38.462,55.927,63.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.156 | Acc: 38.425,55.762,63.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.166 | Acc: 38.446,55.624,62.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.186 | Acc: 38.264,55.391,62.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.202 | Acc: 38.153,55.360,62.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.215 | Acc: 38.020,55.299,62.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.218 | Acc: 37.973,55.255,62.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.231 | Acc: 37.868,55.131,62.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.250 | Acc: 37.700,54.815,62.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.257 | Acc: 37.684,54.760,62.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.267 | Acc: 37.624,54.653,62.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.272 | Acc: 37.658,54.605,61.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.280 | Acc: 37.647,54.579,61.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.279 | Acc: 37.652,54.591,61.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.056 | Acc: 30.469,46.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.472 | Acc: 24.479,40.439,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.492 | Acc: 24.009,39.882,48.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.496 | Acc: 24.039,39.921,49.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 5.070 | Acc: 36.719,60.938,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.030 | Acc: 39.360,57.403,63.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.076 | Acc: 38.700,56.688,63.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.150 | Acc: 38.204,56.122,63.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.174 | Acc: 38.021,56.096,63.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.198 | Acc: 37.693,55.662,63.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.191 | Acc: 37.823,55.766,62.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.194 | Acc: 37.954,55.657,62.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.196 | Acc: 37.995,55.595,62.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.195 | Acc: 38.031,55.637,62.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.209 | Acc: 37.939,55.500,62.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.225 | Acc: 37.931,55.387,62.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.223 | Acc: 37.944,55.313,62.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.229 | Acc: 37.871,55.235,62.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.230 | Acc: 37.795,55.091,62.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.228 | Acc: 37.801,55.129,62.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.232 | Acc: 37.826,55.160,62.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.244 | Acc: 37.711,54.976,62.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.241 | Acc: 37.851,54.919,62.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.246 | Acc: 37.902,54.917,62.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.239 | Acc: 33.594,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.790 | Acc: 28.869,46.391,51.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.843 | Acc: 28.601,45.770,51.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.797 | Acc: 28.957,45.569,51.217,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 5.067 | Acc: 35.938,57.812,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.156 | Acc: 37.760,55.580,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.105 | Acc: 38.357,55.030,63.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.150 | Acc: 37.987,54.547,63.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.154 | Acc: 38.146,54.774,63.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.150 | Acc: 38.188,55.121,63.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.173 | Acc: 37.984,55.217,63.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.180 | Acc: 38.109,55.286,63.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.171 | Acc: 38.218,55.527,63.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.179 | Acc: 38.212,55.486,63.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.187 | Acc: 38.258,55.438,62.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.188 | Acc: 38.341,55.444,63.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.193 | Acc: 38.320,55.443,62.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.196 | Acc: 38.335,55.391,62.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.198 | Acc: 38.312,55.408,62.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.197 | Acc: 38.310,55.362,62.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.194 | Acc: 38.318,55.347,62.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.192 | Acc: 38.352,55.377,62.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.211 | Acc: 38.203,55.211,62.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.213 | Acc: 38.179,55.241,62.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.215 | Acc: 36.719,38.281,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.515 | Acc: 28.906,39.174,48.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.491 | Acc: 29.078,38.929,47.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.501 | Acc: 28.727,38.665,47.298,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 5.474 | Acc: 29.688,49.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.087 | Acc: 39.249,54.911,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.130 | Acc: 38.777,55.183,62.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.079 | Acc: 39.165,56.071,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.086 | Acc: 38.956,56.086,63.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.102 | Acc: 38.892,55.809,63.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.119 | Acc: 38.617,55.837,63.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.125 | Acc: 38.614,55.818,63.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.136 | Acc: 38.645,55.673,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.136 | Acc: 38.661,55.736,63.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.128 | Acc: 38.740,55.811,63.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.148 | Acc: 38.698,55.691,63.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.140 | Acc: 38.755,55.838,63.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.138 | Acc: 38.817,55.885,63.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.140 | Acc: 38.868,55.933,63.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.148 | Acc: 38.785,55.835,63.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.157 | Acc: 38.773,55.814,63.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.171 | Acc: 38.707,55.693,63.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.175 | Acc: 38.617,55.724,62.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.176 | Acc: 38.595,55.684,62.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.712 | Acc: 30.469,44.531,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.198 | Acc: 26.153,39.546,49.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.148 | Acc: 26.391,39.863,49.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.162 | Acc: 26.294,40.343,49.539,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 4.905 | Acc: 36.719,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.108 | Acc: 38.393,56.659,64.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.063 | Acc: 38.834,56.764,64.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.093 | Acc: 39.024,56.481,64.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.090 | Acc: 38.899,56.636,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.079 | Acc: 38.954,56.436,64.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.075 | Acc: 39.185,56.618,64.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.081 | Acc: 39.201,56.571,64.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.087 | Acc: 39.062,56.546,64.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.083 | Acc: 39.110,56.608,64.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.083 | Acc: 39.129,56.643,64.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.106 | Acc: 39.070,56.317,64.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.103 | Acc: 39.134,56.308,64.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.110 | Acc: 38.991,56.268,63.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.118 | Acc: 39.021,56.192,63.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.118 | Acc: 39.073,56.131,63.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.125 | Acc: 38.997,56.153,63.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.133 | Acc: 38.957,56.030,63.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.147 | Acc: 38.807,55.904,63.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.153 | Acc: 38.687,55.789,63.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.462 | Acc: 35.938,49.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.739 | Acc: 30.060,44.717,51.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.781 | Acc: 29.421,43.998,51.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.788 | Acc: 29.585,44.057,51.562,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 5.293 | Acc: 28.906,55.469,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.054 | Acc: 37.091,55.990,64.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.067 | Acc: 37.519,56.460,64.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.100 | Acc: 37.820,56.096,64.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.096 | Acc: 38.002,56.173,64.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.097 | Acc: 37.972,56.281,64.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.103 | Acc: 37.849,56.334,63.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.105 | Acc: 38.098,56.228,63.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.098 | Acc: 38.330,56.352,63.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.099 | Acc: 38.238,56.418,63.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.119 | Acc: 38.134,56.188,63.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.111 | Acc: 38.288,56.275,63.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.110 | Acc: 38.404,56.334,63.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.115 | Acc: 38.443,56.214,63.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.118 | Acc: 38.498,56.206,63.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.121 | Acc: 38.507,56.123,63.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.120 | Acc: 38.505,56.085,63.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.123 | Acc: 38.510,56.055,63.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.130 | Acc: 38.493,55.964,63.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.140 | Acc: 38.456,55.928,63.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.970 | Acc: 28.125,41.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.834 | Acc: 27.307,44.271,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.903 | Acc: 27.229,43.941,51.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.936 | Acc: 26.870,43.904,50.704,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 4.682 | Acc: 47.656,61.719,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.088 | Acc: 39.249,57.180,63.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.099 | Acc: 38.624,56.498,63.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.079 | Acc: 39.088,56.545,63.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.072 | Acc: 38.812,56.559,63.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.075 | Acc: 38.699,56.490,63.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.083 | Acc: 38.423,56.476,63.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.103 | Acc: 38.414,56.361,63.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.089 | Acc: 38.640,56.667,63.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.072 | Acc: 38.782,56.889,63.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.073 | Acc: 38.794,56.868,63.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.081 | Acc: 38.713,56.611,63.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.078 | Acc: 38.777,56.535,63.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.089 | Acc: 38.697,56.316,63.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.092 | Acc: 38.721,56.233,63.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.095 | Acc: 38.782,56.188,63.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.097 | Acc: 38.834,56.179,63.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.100 | Acc: 38.723,56.165,63.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.104 | Acc: 38.721,56.094,63.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.100 | Acc: 38.763,56.127,63.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.274 | Acc: 35.938,48.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.011 | Acc: 28.125,42.932,49.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.991 | Acc: 27.553,42.321,49.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.033 | Acc: 27.920,42.252,49.103,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 4.993 | Acc: 35.938,54.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.012 | Acc: 38.207,57.999,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.060 | Acc: 38.110,56.688,65.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.998 | Acc: 38.742,57.339,65.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.973 | Acc: 39.313,57.841,65.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.994 | Acc: 39.117,57.449,64.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.023 | Acc: 39.024,57.076,64.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.038 | Acc: 38.924,56.848,64.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.048 | Acc: 38.776,56.672,64.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.058 | Acc: 38.752,56.552,64.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.063 | Acc: 38.647,56.499,64.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.066 | Acc: 38.709,56.459,64.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.063 | Acc: 38.722,56.415,64.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.061 | Acc: 38.661,56.370,64.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.062 | Acc: 38.743,56.303,64.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.068 | Acc: 38.743,56.299,64.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.072 | Acc: 38.688,56.282,64.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.073 | Acc: 38.691,56.291,64.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.083 | Acc: 38.690,56.222,63.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.086 | Acc: 38.687,56.184,63.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.992 | Acc: 36.719,43.750,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.783 | Acc: 27.790,39.360,46.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.730 | Acc: 27.020,39.806,46.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.750 | Acc: 26.652,39.524,46.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 4.989 | Acc: 43.750,59.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.920 | Acc: 39.621,58.259,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.012 | Acc: 39.348,56.841,65.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.006 | Acc: 39.498,56.878,65.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.984 | Acc: 39.834,56.877,65.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.008 | Acc: 39.380,56.722,65.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.017 | Acc: 39.489,56.521,64.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.014 | Acc: 39.772,56.721,64.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.016 | Acc: 39.664,56.716,64.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.017 | Acc: 39.667,56.591,64.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.012 | Acc: 39.630,56.724,64.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.012 | Acc: 39.501,56.607,64.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.009 | Acc: 39.542,56.655,64.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.016 | Acc: 39.458,56.672,64.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.020 | Acc: 39.354,56.703,64.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.015 | Acc: 39.358,56.702,64.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.020 | Acc: 39.345,56.703,64.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.032 | Acc: 39.271,56.644,64.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.040 | Acc: 39.199,56.570,64.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.047 | Acc: 39.110,56.543,64.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.761 | Acc: 37.500,50.000,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.575 | Acc: 31.287,45.499,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.611 | Acc: 31.040,45.446,51.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.637 | Acc: 30.712,45.018,50.986,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 4.900 | Acc: 44.531,59.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.966 | Acc: 39.360,57.924,66.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.947 | Acc: 39.158,57.489,65.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.943 | Acc: 39.472,57.595,65.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.964 | Acc: 39.535,57.465,65.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.969 | Acc: 39.480,57.666,65.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.964 | Acc: 39.598,57.703,65.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.973 | Acc: 39.367,57.447,64.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.989 | Acc: 39.378,57.366,64.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.010 | Acc: 39.326,57.169,64.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.022 | Acc: 39.366,57.070,64.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.033 | Acc: 39.328,56.854,64.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.043 | Acc: 39.173,56.762,64.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.053 | Acc: 39.030,56.624,64.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.056 | Acc: 38.985,56.645,64.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.053 | Acc: 38.935,56.650,64.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.059 | Acc: 38.943,56.503,64.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.059 | Acc: 38.994,56.470,64.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.059 | Acc: 38.952,56.414,64.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.062 | Acc: 38.948,56.383,63.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.570 | Acc: 30.469,44.531,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.156 | Acc: 26.823,44.159,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.220 | Acc: 25.838,43.407,48.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.189 | Acc: 25.948,43.532,49.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 4.988 | Acc: 39.844,62.500,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.868 | Acc: 40.848,59.003,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.851 | Acc: 40.587,58.822,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.864 | Acc: 40.446,58.683,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.870 | Acc: 40.239,58.623,66.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.866 | Acc: 40.161,58.516,66.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.877 | Acc: 39.966,58.368,65.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.893 | Acc: 39.799,58.223,65.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.919 | Acc: 39.572,57.939,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.932 | Acc: 39.529,57.761,65.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.950 | Acc: 39.412,57.630,65.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.965 | Acc: 39.412,57.558,65.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.972 | Acc: 39.393,57.414,65.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.974 | Acc: 39.517,57.426,65.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.986 | Acc: 39.496,57.270,64.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.004 | Acc: 39.358,57.117,64.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.013 | Acc: 39.255,57.102,64.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.017 | Acc: 39.282,57.084,64.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.027 | Acc: 39.210,56.999,64.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.031 | Acc: 39.198,56.957,64.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.946 | Acc: 23.438,36.719,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.070 | Acc: 20.908,38.244,48.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.096 | Acc: 20.008,38.777,48.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.096 | Acc: 19.647,38.755,48.514,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 4.782 | Acc: 38.281,53.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.957 | Acc: 39.583,57.626,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.923 | Acc: 39.977,58.175,66.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.950 | Acc: 39.562,57.364,65.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.936 | Acc: 39.815,57.639,65.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.950 | Acc: 39.828,57.534,65.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.971 | Acc: 39.657,57.528,65.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.971 | Acc: 39.489,57.452,65.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.967 | Acc: 39.572,57.313,65.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.956 | Acc: 39.710,57.459,65.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.953 | Acc: 39.747,57.591,65.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.960 | Acc: 39.752,57.583,65.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.961 | Acc: 39.724,57.556,65.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.965 | Acc: 39.703,57.516,65.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.968 | Acc: 39.666,57.473,65.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.972 | Acc: 39.610,57.405,65.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.978 | Acc: 39.561,57.318,65.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.982 | Acc: 39.541,57.347,64.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.993 | Acc: 39.467,57.207,64.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.998 | Acc: 39.345,57.146,64.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.538 | Acc: 28.125,50.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.850 | Acc: 24.256,46.354,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.889 | Acc: 24.219,45.713,54.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.961 | Acc: 24.014,45.748,54.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 5.141 | Acc: 36.719,56.250,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.965 | Acc: 39.323,56.920,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.909 | Acc: 39.329,57.374,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.931 | Acc: 39.152,57.198,66.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.951 | Acc: 39.458,57.321,66.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.967 | Acc: 39.047,57.240,65.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.982 | Acc: 39.217,57.290,65.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.977 | Acc: 39.268,57.336,65.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.975 | Acc: 39.402,57.492,65.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.972 | Acc: 39.438,57.433,65.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.971 | Acc: 39.393,57.432,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.969 | Acc: 39.536,57.215,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.986 | Acc: 39.328,57.122,65.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.980 | Acc: 39.371,57.139,65.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.974 | Acc: 39.560,57.262,65.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.978 | Acc: 39.579,57.192,65.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.983 | Acc: 39.515,57.165,65.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.984 | Acc: 39.461,57.178,65.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.989 | Acc: 39.381,57.126,65.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.996 | Acc: 39.399,57.027,65.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.763 | Acc: 32.031,39.062,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.084 | Acc: 28.051,41.964,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.071 | Acc: 27.153,42.492,51.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.066 | Acc: 26.972,42.597,51.294,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 4.692 | Acc: 44.531,58.594,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.728 | Acc: 41.704,58.743,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.789 | Acc: 41.120,58.403,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.828 | Acc: 40.497,58.158,66.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.855 | Acc: 40.529,58.324,66.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.903 | Acc: 39.991,58.029,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.905 | Acc: 40.063,57.935,65.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.914 | Acc: 40.065,57.857,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.928 | Acc: 39.931,57.618,65.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.944 | Acc: 39.796,57.528,65.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.933 | Acc: 39.805,57.626,65.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.942 | Acc: 39.734,57.636,65.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.936 | Acc: 39.750,57.657,65.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.934 | Acc: 39.634,57.747,65.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.938 | Acc: 39.627,57.757,65.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.943 | Acc: 39.587,57.703,65.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.947 | Acc: 39.720,57.693,65.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.948 | Acc: 39.722,57.670,65.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.946 | Acc: 39.738,57.659,65.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.961 | Acc: 39.567,57.523,65.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.004 | Acc: 24.219,42.969,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.296 | Acc: 24.851,41.071,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.265 | Acc: 24.962,41.711,49.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.237 | Acc: 25.102,42.367,50.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 5.095 | Acc: 39.062,57.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.992 | Acc: 38.988,58.036,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.897 | Acc: 40.091,58.537,66.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.864 | Acc: 40.830,58.619,66.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.885 | Acc: 40.538,58.256,66.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.888 | Acc: 40.145,58.060,66.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.879 | Acc: 40.251,57.987,66.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.893 | Acc: 39.938,57.885,65.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.888 | Acc: 40.077,58.075,65.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.888 | Acc: 39.917,58.097,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.904 | Acc: 39.906,57.945,65.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.918 | Acc: 39.844,57.858,65.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.933 | Acc: 39.896,57.822,65.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.941 | Acc: 39.796,57.672,65.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.939 | Acc: 39.916,57.696,65.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.952 | Acc: 39.815,57.605,65.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.956 | Acc: 39.861,57.552,65.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.952 | Acc: 39.848,57.593,65.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.957 | Acc: 39.733,57.544,65.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.960 | Acc: 39.725,57.525,65.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.036 | Acc: 38.281,51.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.387 | Acc: 32.180,45.945,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.381 | Acc: 31.879,46.037,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.426 | Acc: 32.403,46.683,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 4.919 | Acc: 41.406,62.500,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.877 | Acc: 39.286,58.594,65.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.876 | Acc: 39.196,57.755,66.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.845 | Acc: 39.664,58.414,66.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.852 | Acc: 39.583,58.507,66.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.863 | Acc: 39.449,58.424,66.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.844 | Acc: 39.715,58.568,66.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.827 | Acc: 39.982,58.749,66.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.840 | Acc: 39.975,58.516,66.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.864 | Acc: 39.960,58.382,66.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.859 | Acc: 40.061,58.528,66.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.863 | Acc: 39.960,58.488,66.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.870 | Acc: 39.876,58.490,66.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.872 | Acc: 39.871,58.495,66.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.886 | Acc: 39.738,58.349,65.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.900 | Acc: 39.672,58.220,65.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.902 | Acc: 39.707,58.272,65.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.900 | Acc: 39.725,58.262,65.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.911 | Acc: 39.645,58.174,65.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.913 | Acc: 39.676,58.095,65.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.680 | Acc: 31.250,41.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.744 | Acc: 27.753,44.382,53.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.761 | Acc: 27.915,44.112,53.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.804 | Acc: 27.523,44.109,52.946,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 5.263 | Acc: 43.750,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.820 | Acc: 40.997,58.854,66.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.844 | Acc: 40.301,58.289,65.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.809 | Acc: 40.087,58.594,66.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.832 | Acc: 40.220,58.169,66.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.850 | Acc: 39.998,58.091,66.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.851 | Acc: 40.096,58.045,66.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.863 | Acc: 40.060,57.862,66.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.870 | Acc: 40.159,57.793,66.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.884 | Acc: 39.891,57.636,65.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.900 | Acc: 39.634,57.540,65.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.902 | Acc: 39.734,57.516,65.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.903 | Acc: 39.795,57.560,65.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.892 | Acc: 39.892,57.663,65.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.890 | Acc: 39.877,57.796,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.890 | Acc: 39.942,57.781,65.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.897 | Acc: 39.978,57.778,65.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.904 | Acc: 39.961,57.730,65.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.909 | Acc: 39.954,57.648,65.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.907 | Acc: 39.987,57.677,65.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.418 | Acc: 28.906,44.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.508 | Acc: 25.000,43.192,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.472 | Acc: 25.495,42.511,51.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.434 | Acc: 25.781,43.033,51.947,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 4.890 | Acc: 40.625,57.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.736 | Acc: 39.732,58.966,67.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.801 | Acc: 40.206,58.460,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.788 | Acc: 39.972,58.133,66.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.824 | Acc: 39.940,58.227,66.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.836 | Acc: 39.813,57.898,66.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.839 | Acc: 39.979,58.058,66.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.837 | Acc: 39.916,58.029,66.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.848 | Acc: 40.048,58.007,66.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.853 | Acc: 40.167,58.080,66.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.851 | Acc: 40.229,58.209,66.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.851 | Acc: 40.356,58.297,66.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.846 | Acc: 40.473,58.419,66.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.856 | Acc: 40.466,58.247,66.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.873 | Acc: 40.272,58.129,65.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.882 | Acc: 40.275,58.085,65.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.884 | Acc: 40.260,58.078,65.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.894 | Acc: 40.171,57.996,65.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.898 | Acc: 40.127,57.923,65.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.906 | Acc: 40.080,57.892,65.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.991 | Acc: 35.156,48.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.237 | Acc: 35.454,47.433,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.253 | Acc: 34.451,47.332,54.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.305 | Acc: 34.196,47.208,54.150,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 4.830 | Acc: 38.281,52.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.774 | Acc: 39.100,58.445,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.823 | Acc: 39.710,58.880,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.809 | Acc: 39.716,58.722,67.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.853 | Acc: 39.381,58.324,66.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.841 | Acc: 39.581,58.586,66.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.863 | Acc: 39.708,58.542,66.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.857 | Acc: 39.838,58.549,66.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.852 | Acc: 39.853,58.676,66.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.858 | Acc: 39.952,58.615,66.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.866 | Acc: 40.038,58.559,66.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.887 | Acc: 39.918,58.406,66.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.885 | Acc: 39.899,58.477,65.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.889 | Acc: 39.937,58.393,65.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.883 | Acc: 39.963,58.491,65.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.873 | Acc: 40.083,58.565,65.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.883 | Acc: 39.992,58.474,65.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.890 | Acc: 39.967,58.433,65.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.896 | Acc: 39.995,58.369,65.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.898 | Acc: 40.016,58.346,65.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.450 | Acc: 27.344,49.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.554 | Acc: 30.022,47.619,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.606 | Acc: 29.173,47.199,53.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.662 | Acc: 28.791,47.029,52.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 4.851 | Acc: 38.281,59.375,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.834 | Acc: 40.067,57.812,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.814 | Acc: 39.558,58.175,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.796 | Acc: 39.677,58.594,66.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.793 | Acc: 39.998,58.565,66.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.781 | Acc: 40.416,58.694,66.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.795 | Acc: 40.134,58.510,66.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.793 | Acc: 40.265,58.450,66.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.804 | Acc: 40.232,58.269,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.812 | Acc: 40.163,58.205,66.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.817 | Acc: 40.120,58.263,66.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.830 | Acc: 40.141,58.198,65.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.839 | Acc: 40.035,58.198,65.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.843 | Acc: 40.020,58.181,66.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.844 | Acc: 40.072,58.227,65.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.854 | Acc: 40.044,58.106,65.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.857 | Acc: 40.077,58.100,65.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.864 | Acc: 40.000,58.097,65.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.876 | Acc: 39.948,58.033,65.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.883 | Acc: 39.932,58.016,65.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.618 | Acc: 30.469,39.844,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.161 | Acc: 28.646,40.216,48.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.231 | Acc: 27.896,40.130,48.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.252 | Acc: 27.715,40.100,47.951,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 4.243 | Acc: 44.531,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.707 | Acc: 42.188,60.417,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.678 | Acc: 41.101,60.499,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.700 | Acc: 41.278,60.156,68.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.731 | Acc: 40.982,59.587,67.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.754 | Acc: 40.780,59.321,67.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.769 | Acc: 40.631,59.091,67.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.787 | Acc: 40.486,59.087,67.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.788 | Acc: 40.319,58.982,67.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.783 | Acc: 40.310,58.952,67.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.807 | Acc: 40.353,58.920,67.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.810 | Acc: 40.395,58.901,66.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.814 | Acc: 40.385,58.876,66.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.816 | Acc: 40.383,58.935,66.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.816 | Acc: 40.325,58.936,66.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.825 | Acc: 40.218,58.838,66.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.832 | Acc: 40.167,58.706,66.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.833 | Acc: 40.194,58.681,66.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.831 | Acc: 40.197,58.719,66.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.831 | Acc: 40.194,58.690,66.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.688 | Acc: 37.500,51.562,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.688 | Acc: 28.906,46.429,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.694 | Acc: 28.430,46.018,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.698 | Acc: 28.048,46.017,54.675,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 4.905 | Acc: 42.188,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.712 | Acc: 40.327,60.119,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.681 | Acc: 40.358,60.252,68.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.717 | Acc: 40.190,59.708,67.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.770 | Acc: 39.979,58.893,67.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.783 | Acc: 39.960,58.826,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.801 | Acc: 39.876,58.878,66.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.811 | Acc: 39.833,59.015,66.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.814 | Acc: 39.737,58.899,66.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.806 | Acc: 39.852,58.939,66.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.812 | Acc: 39.875,58.909,66.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.811 | Acc: 39.985,59.014,66.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.810 | Acc: 40.051,59.044,66.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.811 | Acc: 39.916,58.953,66.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.815 | Acc: 39.855,58.950,66.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.826 | Acc: 39.792,58.877,66.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.830 | Acc: 39.851,58.910,66.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.835 | Acc: 39.896,58.795,66.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.837 | Acc: 39.945,58.786,66.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.844 | Acc: 39.864,58.780,66.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.661 | Acc: 26.562,45.312,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.545 | Acc: 24.479,41.443,49.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.639 | Acc: 24.295,39.825,48.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.653 | Acc: 23.412,39.946,48.271,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 4.345 | Acc: 44.531,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.742 | Acc: 39.472,58.296,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.726 | Acc: 39.958,59.432,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.723 | Acc: 39.831,59.580,67.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.715 | Acc: 40.442,59.645,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.728 | Acc: 40.285,59.491,68.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.734 | Acc: 40.283,59.356,67.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.734 | Acc: 40.398,59.353,67.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.747 | Acc: 40.445,59.186,67.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.767 | Acc: 40.353,59.138,67.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.782 | Acc: 40.279,58.967,67.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.792 | Acc: 40.215,58.976,67.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.799 | Acc: 40.158,58.944,66.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.788 | Acc: 40.320,59.064,67.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.788 | Acc: 40.366,59.122,67.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.794 | Acc: 40.373,59.061,67.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.798 | Acc: 40.321,59.034,67.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.802 | Acc: 40.343,59.034,66.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.810 | Acc: 40.240,58.977,66.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.813 | Acc: 40.336,58.889,66.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.803 | Acc: 25.000,42.969,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.442 | Acc: 21.466,43.787,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.557 | Acc: 20.808,43.712,52.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.595 | Acc: 20.620,43.724,52.126,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 4.659 | Acc: 34.375,56.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.746 | Acc: 39.249,59.784,67.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.774 | Acc: 39.806,58.746,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.765 | Acc: 40.420,58.927,66.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.782 | Acc: 39.931,58.796,66.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.792 | Acc: 40.246,58.795,66.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.788 | Acc: 40.096,58.955,66.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.780 | Acc: 40.082,58.954,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.772 | Acc: 40.266,59.142,66.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.785 | Acc: 40.064,58.965,66.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.776 | Acc: 39.984,59.037,67.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.777 | Acc: 39.982,59.043,66.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.783 | Acc: 40.054,59.061,66.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.788 | Acc: 40.152,59.073,66.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.792 | Acc: 40.264,59.141,66.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.783 | Acc: 40.436,59.276,66.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.792 | Acc: 40.477,59.231,66.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.795 | Acc: 40.419,59.146,66.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.805 | Acc: 40.393,59.094,66.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.812 | Acc: 40.352,59.024,66.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.174 | Acc: 23.438,42.188,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.029 | Acc: 25.632,43.452,51.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.114 | Acc: 24.809,43.788,50.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.096 | Acc: 24.872,44.032,50.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 4.602 | Acc: 42.188,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.650 | Acc: 41.332,59.970,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.673 | Acc: 40.720,59.604,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.688 | Acc: 40.817,60.118,67.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.713 | Acc: 41.088,59.983,67.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.721 | Acc: 40.842,59.924,67.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.740 | Acc: 40.554,59.517,67.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.748 | Acc: 40.547,59.502,67.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.763 | Acc: 40.523,59.375,67.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.771 | Acc: 40.435,59.358,66.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.766 | Acc: 40.438,59.488,67.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.771 | Acc: 40.416,59.446,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.772 | Acc: 40.453,59.255,66.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.777 | Acc: 40.481,59.186,66.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.782 | Acc: 40.422,59.147,66.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.780 | Acc: 40.415,59.131,66.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.782 | Acc: 40.430,59.183,66.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.784 | Acc: 40.387,59.153,66.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.789 | Acc: 40.341,59.137,66.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.795 | Acc: 40.342,59.065,66.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.027 | Acc: 31.250,48.438,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.082 | Acc: 27.976,42.225,50.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.121 | Acc: 28.068,41.540,49.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.198 | Acc: 27.754,40.984,49.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 4.529 | Acc: 31.250,56.250,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.568 | Acc: 40.997,61.347,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 40.854,60.899,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.606 | Acc: 41.368,61.322,68.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.674 | Acc: 41.069,60.475,68.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.667 | Acc: 41.159,60.435,68.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.671 | Acc: 41.122,60.195,68.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.691 | Acc: 40.830,59.918,67.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.694 | Acc: 40.916,60.025,67.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.710 | Acc: 40.979,59.824,67.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.729 | Acc: 40.913,59.616,67.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.742 | Acc: 40.717,59.690,67.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.750 | Acc: 40.764,59.618,67.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.758 | Acc: 40.670,59.555,67.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.761 | Acc: 40.631,59.486,66.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.777 | Acc: 40.508,59.300,66.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.786 | Acc: 40.440,59.190,66.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.788 | Acc: 40.451,59.210,66.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.792 | Acc: 40.482,59.200,66.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.793 | Acc: 40.408,59.205,66.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.661 | Acc: 32.812,46.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.831 | Acc: 30.134,43.378,51.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.780 | Acc: 29.554,43.921,51.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.755 | Acc: 29.598,43.827,52.459,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 4.557 | Acc: 46.094,64.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.779 | Acc: 41.369,58.073,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 40.911,58.460,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.689 | Acc: 41.650,59.759,68.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.686 | Acc: 41.454,59.819,68.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.688 | Acc: 41.337,59.762,68.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.712 | Acc: 41.154,59.595,68.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.729 | Acc: 40.819,59.508,67.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.736 | Acc: 40.644,59.569,67.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.730 | Acc: 40.819,59.599,67.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.736 | Acc: 40.850,59.538,67.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.733 | Acc: 40.841,59.516,67.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.728 | Acc: 40.858,59.521,67.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.746 | Acc: 40.688,59.366,67.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.756 | Acc: 40.608,59.336,67.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.767 | Acc: 40.552,59.253,67.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.771 | Acc: 40.530,59.192,67.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.777 | Acc: 40.497,59.137,66.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.788 | Acc: 40.465,59.063,66.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.789 | Acc: 40.463,59.045,66.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.504 | Acc: 38.281,53.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.673 | Acc: 30.692,46.875,53.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.662 | Acc: 29.783,47.199,53.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.681 | Acc: 29.790,47.503,54.034,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 4.134 | Acc: 51.562,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 40.588,60.714,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.667 | Acc: 40.911,60.595,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.667 | Acc: 41.317,60.464,68.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.674 | Acc: 41.300,60.185,68.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.679 | Acc: 41.151,59.940,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.664 | Acc: 41.225,60.124,68.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.687 | Acc: 40.985,59.996,68.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.681 | Acc: 40.999,60.040,68.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.674 | Acc: 41.134,60.009,68.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.673 | Acc: 41.119,59.841,68.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.677 | Acc: 41.042,59.856,68.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.689 | Acc: 40.943,59.790,68.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.700 | Acc: 40.838,59.701,68.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.712 | Acc: 40.761,59.617,67.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.718 | Acc: 40.744,59.629,67.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.726 | Acc: 40.676,59.606,67.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.736 | Acc: 40.643,59.549,67.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.735 | Acc: 40.673,59.552,67.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.740 | Acc: 40.652,59.551,67.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.780 | Acc: 26.562,46.094,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.658 | Acc: 24.405,41.853,47.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.705 | Acc: 23.457,40.816,47.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.677 | Acc: 23.386,41.214,48.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 4.424 | Acc: 46.094,57.031,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.599 | Acc: 40.960,60.863,68.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 41.521,60.728,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 41.329,60.745,68.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.590 | Acc: 41.107,60.889,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.629 | Acc: 40.687,60.613,68.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.650 | Acc: 40.509,60.247,68.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.659 | Acc: 40.603,60.223,68.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.683 | Acc: 40.581,59.972,68.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.691 | Acc: 40.677,59.884,67.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.707 | Acc: 40.637,59.682,67.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.703 | Acc: 40.837,59.796,67.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.719 | Acc: 40.820,59.796,67.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.727 | Acc: 40.852,59.698,67.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.734 | Acc: 40.839,59.656,67.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.741 | Acc: 40.840,59.601,67.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.756 | Acc: 40.717,59.407,67.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.761 | Acc: 40.682,59.444,67.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.754 | Acc: 40.783,59.503,67.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.752 | Acc: 40.795,59.467,67.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.161 | Acc: 35.938,51.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.305 | Acc: 30.692,49.182,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.340 | Acc: 30.297,49.047,56.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.381 | Acc: 29.662,48.681,56.019,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 4.474 | Acc: 41.406,57.031,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.572 | Acc: 41.443,61.235,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 40.892,60.537,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 41.048,59.990,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.631 | Acc: 41.358,60.156,68.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.661 | Acc: 40.958,59.955,68.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.679 | Acc: 40.890,59.821,68.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.704 | Acc: 40.736,59.680,68.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.709 | Acc: 40.678,59.729,68.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.713 | Acc: 40.664,59.634,67.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.721 | Acc: 40.567,59.464,67.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.723 | Acc: 40.653,59.523,67.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.728 | Acc: 40.602,59.550,67.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.734 | Acc: 40.544,59.489,67.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.738 | Acc: 40.622,59.522,67.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.743 | Acc: 40.625,59.476,67.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.737 | Acc: 40.674,59.506,67.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.736 | Acc: 40.756,59.519,67.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.744 | Acc: 40.751,59.433,67.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.742 | Acc: 40.787,59.412,67.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.030 | Acc: 31.250,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.321 | Acc: 33.445,47.619,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.375 | Acc: 33.117,47.389,53.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.397 | Acc: 32.992,47.695,53.407,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 4.800 | Acc: 39.062,57.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.608 | Acc: 42.969,61.161,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.639 | Acc: 41.502,60.328,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 41.586,60.233,67.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.682 | Acc: 41.040,59.838,67.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.664 | Acc: 40.795,60.234,67.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.681 | Acc: 40.761,59.988,67.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.689 | Acc: 40.869,59.962,67.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.699 | Acc: 40.887,59.948,67.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.685 | Acc: 41.186,60.113,67.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.684 | Acc: 41.123,60.032,67.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.686 | Acc: 41.077,60.043,67.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.685 | Acc: 41.040,60.059,67.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.692 | Acc: 41.092,59.974,67.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.701 | Acc: 41.023,59.770,67.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.704 | Acc: 41.032,59.707,67.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.711 | Acc: 40.941,59.716,67.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.716 | Acc: 40.998,59.668,67.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.725 | Acc: 40.902,59.544,67.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.727 | Acc: 40.947,59.478,67.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.270 | Acc: 34.375,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.480 | Acc: 30.208,47.173,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.506 | Acc: 29.002,46.608,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.542 | Acc: 28.599,46.683,54.713,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 4.397 | Acc: 37.500,53.125,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.463 | Acc: 42.039,61.049,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.475 | Acc: 42.588,61.280,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.541 | Acc: 41.598,61.232,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.579 | Acc: 41.155,60.851,68.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.610 | Acc: 41.244,60.659,68.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.635 | Acc: 40.928,60.421,68.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.648 | Acc: 41.057,60.117,68.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.662 | Acc: 41.008,60.103,68.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.685 | Acc: 40.875,59.910,67.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.678 | Acc: 41.099,60.036,68.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.682 | Acc: 41.081,60.089,68.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.691 | Acc: 41.124,60.053,67.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.706 | Acc: 40.993,59.872,67.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.717 | Acc: 40.948,59.725,67.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.722 | Acc: 40.939,59.666,67.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.729 | Acc: 40.937,59.533,67.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.730 | Acc: 40.907,59.512,67.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.728 | Acc: 40.902,59.622,67.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.733 | Acc: 40.846,59.603,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.663 | Acc: 29.688,45.312,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.201 | Acc: 22.507,38.616,48.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.297 | Acc: 21.684,38.396,48.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.317 | Acc: 21.593,37.743,47.848,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 4.517 | Acc: 50.781,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.640 | Acc: 42.336,60.082,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.653 | Acc: 41.730,60.023,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 42.175,60.374,69.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.654 | Acc: 41.908,60.426,68.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.650 | Acc: 41.422,60.497,68.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.649 | Acc: 41.406,60.608,68.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.649 | Acc: 41.451,60.550,68.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.622 | Acc: 41.625,60.743,68.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.650 | Acc: 41.436,60.415,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.674 | Acc: 41.130,60.079,68.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.668 | Acc: 41.237,60.223,68.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.664 | Acc: 41.296,60.250,68.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.661 | Acc: 41.230,60.228,68.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.653 | Acc: 41.331,60.304,68.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.661 | Acc: 41.284,60.182,68.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.666 | Acc: 41.319,60.164,68.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.677 | Acc: 41.294,60.069,68.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.685 | Acc: 41.205,60.003,67.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.698 | Acc: 41.109,59.888,67.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.164 | Acc: 25.000,39.844,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.547 | Acc: 25.632,41.815,50.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.555 | Acc: 25.133,41.616,50.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.587 | Acc: 24.821,41.304,49.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 4.346 | Acc: 49.219,60.156,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.580 | Acc: 42.336,60.603,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 42.245,60.899,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.629 | Acc: 42.085,60.720,68.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.623 | Acc: 41.744,60.619,68.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.636 | Acc: 41.545,60.605,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.618 | Acc: 41.477,60.879,68.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.630 | Acc: 41.295,60.721,68.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.642 | Acc: 41.164,60.743,68.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.643 | Acc: 41.238,60.782,68.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.653 | Acc: 41.084,60.720,67.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.662 | Acc: 41.145,60.683,67.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.668 | Acc: 41.089,60.600,67.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.664 | Acc: 41.050,60.647,67.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.666 | Acc: 41.073,60.584,67.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.668 | Acc: 41.103,60.540,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.681 | Acc: 40.932,60.409,67.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.685 | Acc: 40.905,60.358,67.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.694 | Acc: 40.906,60.345,67.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.695 | Acc: 40.869,60.384,67.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.700 | Acc: 32.031,46.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.811 | Acc: 29.055,46.577,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.843 | Acc: 28.011,46.189,52.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.835 | Acc: 28.317,46.196,52.421,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 4.608 | Acc: 42.969,58.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.666 | Acc: 40.997,61.198,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.638 | Acc: 41.540,61.376,68.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.669 | Acc: 40.868,60.540,68.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.667 | Acc: 40.914,60.687,68.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.663 | Acc: 40.934,60.365,68.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.678 | Acc: 40.877,60.337,68.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.674 | Acc: 40.935,60.289,68.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.677 | Acc: 40.945,60.292,68.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.684 | Acc: 40.776,60.256,68.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.675 | Acc: 40.827,60.308,68.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.684 | Acc: 40.876,60.135,67.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.684 | Acc: 40.810,60.091,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.681 | Acc: 40.849,60.168,67.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.687 | Acc: 40.808,60.098,67.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.684 | Acc: 40.820,60.112,67.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.683 | Acc: 40.761,60.054,67.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.684 | Acc: 40.843,60.083,67.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.685 | Acc: 40.876,60.085,67.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.678 | Acc: 40.959,60.179,67.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.286 | Acc: 29.688,46.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.452 | Acc: 30.320,46.949,53.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.477 | Acc: 29.935,46.932,54.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.517 | Acc: 29.867,46.824,53.560,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 4.387 | Acc: 47.656,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.482 | Acc: 41.220,62.054,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.517 | Acc: 41.940,61.623,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.569 | Acc: 41.598,61.245,69.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.601 | Acc: 41.223,61.294,69.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.615 | Acc: 41.236,60.999,69.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.627 | Acc: 41.296,60.589,68.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.629 | Acc: 41.367,60.544,68.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.634 | Acc: 41.445,60.554,68.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.639 | Acc: 41.467,60.592,68.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.640 | Acc: 41.457,60.611,68.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.639 | Acc: 41.452,60.580,68.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.634 | Acc: 41.426,60.545,68.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.645 | Acc: 41.319,60.336,68.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.642 | Acc: 41.398,60.381,68.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.642 | Acc: 41.406,60.382,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.659 | Acc: 41.199,60.198,68.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.662 | Acc: 41.294,60.177,68.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.662 | Acc: 41.326,60.150,68.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.666 | Acc: 41.380,60.123,68.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.243 | Acc: 29.688,53.125,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.836 | Acc: 28.311,44.531,54.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.832 | Acc: 28.106,44.817,54.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.868 | Acc: 27.805,44.826,53.945,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 4.573 | Acc: 40.625,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 40.662,61.384,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.551 | Acc: 41.502,61.452,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.585 | Acc: 41.355,61.258,69.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.572 | Acc: 41.551,61.236,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.555 | Acc: 41.561,61.394,69.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.579 | Acc: 41.535,60.970,69.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.588 | Acc: 41.323,60.849,68.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.586 | Acc: 41.338,60.874,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.591 | Acc: 41.294,60.761,68.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.615 | Acc: 41.115,60.525,68.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.614 | Acc: 41.095,60.538,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.619 | Acc: 41.098,60.558,68.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.627 | Acc: 41.035,60.429,68.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.631 | Acc: 41.112,60.457,68.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.636 | Acc: 41.103,60.364,68.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.642 | Acc: 41.185,60.322,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.650 | Acc: 41.145,60.207,68.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.661 | Acc: 41.136,60.156,67.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.665 | Acc: 41.203,60.144,67.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.187 | Acc: 30.469,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.602 | Acc: 29.427,46.057,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.612 | Acc: 28.906,46.303,53.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.626 | Acc: 28.343,46.606,53.125,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 4.444 | Acc: 39.844,62.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 42.188,61.533,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.498 | Acc: 41.521,61.414,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.510 | Acc: 42.149,61.770,70.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.518 | Acc: 42.168,61.931,69.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.542 | Acc: 41.955,61.471,69.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.545 | Acc: 41.858,61.325,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.556 | Acc: 41.550,61.203,69.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.565 | Acc: 41.629,61.035,69.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.586 | Acc: 41.588,60.959,69.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.587 | Acc: 41.682,60.887,68.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.609 | Acc: 41.675,60.793,68.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.630 | Acc: 41.400,60.675,68.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.641 | Acc: 41.376,60.596,68.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.653 | Acc: 41.281,60.551,68.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.656 | Acc: 41.178,60.507,68.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.661 | Acc: 41.177,60.395,68.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.658 | Acc: 41.209,60.470,68.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.656 | Acc: 41.211,60.487,68.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.654 | Acc: 41.234,60.560,68.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.112 | Acc: 25.000,42.188,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.079 | Acc: 26.376,41.443,51.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.127 | Acc: 26.239,41.768,51.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.122 | Acc: 26.191,41.714,52.113,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 4.703 | Acc: 39.844,57.812,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 42.150,60.268,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.539 | Acc: 42.359,61.395,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.538 | Acc: 42.072,61.603,69.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.549 | Acc: 41.744,61.323,69.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.577 | Acc: 41.460,61.224,69.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.589 | Acc: 41.219,61.183,69.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.586 | Acc: 41.229,61.026,69.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.583 | Acc: 41.241,60.908,69.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.597 | Acc: 41.208,60.735,68.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.607 | Acc: 41.196,60.634,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.617 | Acc: 41.148,60.556,68.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.626 | Acc: 41.231,60.487,68.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.622 | Acc: 41.239,60.369,68.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.612 | Acc: 41.312,60.462,68.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.616 | Acc: 41.404,60.421,68.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.619 | Acc: 41.426,60.400,68.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.627 | Acc: 41.367,60.388,68.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.638 | Acc: 41.318,60.351,68.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.646 | Acc: 41.259,60.251,68.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.941 | Acc: 30.469,54.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.132 | Acc: 30.766,50.893,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.142 | Acc: 30.259,50.381,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.161 | Acc: 30.059,50.692,56.980,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 4.327 | Acc: 40.625,64.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.414 | Acc: 42.932,61.868,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 41.997,61.947,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 42.021,61.693,70.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.490 | Acc: 42.323,61.931,69.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.506 | Acc: 42.296,61.835,69.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.506 | Acc: 42.349,61.803,69.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.531 | Acc: 42.093,61.392,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.552 | Acc: 41.959,61.234,69.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.560 | Acc: 41.954,61.218,69.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.566 | Acc: 41.915,61.151,68.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.573 | Acc: 41.845,61.079,68.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.577 | Acc: 41.760,61.151,68.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.585 | Acc: 41.640,61.165,68.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.588 | Acc: 41.579,61.135,68.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.595 | Acc: 41.604,61.083,68.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.605 | Acc: 41.530,60.950,68.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.604 | Acc: 41.551,60.997,68.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.606 | Acc: 41.582,60.922,68.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.610 | Acc: 41.556,60.931,68.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.175 | Acc: 27.344,47.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.336 | Acc: 28.348,42.857,50.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.319 | Acc: 28.868,42.149,50.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.334 | Acc: 28.509,42.175,50.026,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 3.895 | Acc: 52.344,65.625,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.537 | Acc: 42.708,62.388,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.514 | Acc: 42.588,62.100,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.559 | Acc: 42.444,61.258,69.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.564 | Acc: 42.429,61.082,69.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.547 | Acc: 42.536,61.200,69.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.542 | Acc: 42.710,61.112,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.535 | Acc: 42.747,61.298,69.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.545 | Acc: 42.619,61.306,69.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.542 | Acc: 42.524,61.261,69.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.556 | Acc: 42.347,61.241,68.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.555 | Acc: 42.209,61.238,68.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.570 | Acc: 42.097,61.035,68.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.584 | Acc: 42.047,60.896,68.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.593 | Acc: 41.893,60.748,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.588 | Acc: 41.951,60.847,68.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.604 | Acc: 41.791,60.687,68.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.616 | Acc: 41.814,60.653,68.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.617 | Acc: 41.744,60.602,68.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.623 | Acc: 41.732,60.568,68.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.552 | Acc: 25.000,43.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.107 | Acc: 24.554,39.397,47.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.120 | Acc: 23.895,39.615,47.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.174 | Acc: 23.181,39.255,47.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 3.840 | Acc: 42.188,67.969,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.402 | Acc: 43.080,63.132,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.492 | Acc: 41.902,62.005,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.532 | Acc: 41.624,61.565,69.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.527 | Acc: 41.580,61.343,69.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.548 | Acc: 41.638,61.092,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.531 | Acc: 41.684,61.267,69.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.533 | Acc: 41.711,61.370,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.536 | Acc: 41.790,61.374,69.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.537 | Acc: 41.890,61.373,69.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.549 | Acc: 42.024,61.248,69.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.561 | Acc: 41.915,61.224,69.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.560 | Acc: 41.928,61.194,69.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.556 | Acc: 41.957,61.255,69.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.570 | Acc: 41.868,61.099,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.588 | Acc: 41.832,60.984,68.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.587 | Acc: 41.813,61.023,68.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.591 | Acc: 41.649,60.963,68.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.587 | Acc: 41.649,60.974,68.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.592 | Acc: 41.720,60.966,68.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.942 | Acc: 17.969,39.844,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.168 | Acc: 17.857,37.165,50.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.169 | Acc: 17.264,37.881,50.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.172 | Acc: 16.867,37.923,50.410,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 4.592 | Acc: 46.875,57.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.541 | Acc: 41.555,61.161,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 41.864,60.595,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.530 | Acc: 41.944,60.976,69.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.499 | Acc: 42.072,61.516,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.501 | Acc: 42.071,61.804,69.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.508 | Acc: 42.000,61.764,69.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.546 | Acc: 41.894,61.469,69.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.536 | Acc: 42.037,61.466,69.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.552 | Acc: 41.976,61.235,69.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.555 | Acc: 42.036,61.147,69.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.562 | Acc: 41.954,61.146,69.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.568 | Acc: 41.964,61.064,68.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.573 | Acc: 41.867,61.039,68.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.571 | Acc: 41.851,61.157,68.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.572 | Acc: 41.879,61.189,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.579 | Acc: 41.706,61.059,68.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.579 | Acc: 41.661,61.070,68.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.583 | Acc: 41.692,61.076,68.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.586 | Acc: 41.656,61.083,68.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.925 | Acc: 28.906,41.406,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.053 | Acc: 31.808,40.513,49.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.122 | Acc: 30.869,39.577,49.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.172 | Acc: 29.931,39.408,49.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 3.849 | Acc: 47.656,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.400 | Acc: 43.638,63.021,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.432 | Acc: 43.293,62.462,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.439 | Acc: 42.789,62.385,71.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.458 | Acc: 42.824,62.249,70.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.495 | Acc: 42.427,61.920,70.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.525 | Acc: 42.078,61.512,69.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.536 | Acc: 42.110,61.525,69.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.541 | Acc: 42.066,61.476,69.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.558 | Acc: 41.825,61.283,69.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.582 | Acc: 41.624,61.085,69.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.580 | Acc: 41.548,61.125,69.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.584 | Acc: 41.656,60.996,69.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.598 | Acc: 41.574,60.854,68.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.594 | Acc: 41.595,60.960,68.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.604 | Acc: 41.601,60.878,68.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.604 | Acc: 41.635,60.874,68.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.611 | Acc: 41.612,60.821,68.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.612 | Acc: 41.612,60.784,68.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.614 | Acc: 41.568,60.687,68.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.604 | Acc: 28.906,50.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.739 | Acc: 30.841,46.577,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.820 | Acc: 29.421,46.456,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.844 | Acc: 28.932,46.337,54.867,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 4.992 | Acc: 34.375,55.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.578 | Acc: 40.997,61.161,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.564 | Acc: 41.101,60.899,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.568 | Acc: 41.329,60.707,69.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.529 | Acc: 41.397,61.227,69.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.516 | Acc: 41.515,61.479,69.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.526 | Acc: 41.606,61.512,69.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.531 | Acc: 41.534,61.220,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.546 | Acc: 41.659,61.102,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.547 | Acc: 41.834,61.076,69.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.550 | Acc: 41.845,61.159,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.552 | Acc: 41.795,61.082,69.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.566 | Acc: 41.708,60.889,69.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.574 | Acc: 41.682,60.890,68.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.578 | Acc: 41.723,60.901,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.583 | Acc: 41.684,60.896,68.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.576 | Acc: 41.735,60.945,68.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.577 | Acc: 41.700,60.942,68.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.578 | Acc: 41.675,60.903,68.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.577 | Acc: 41.704,60.981,68.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.737 | Acc: 33.594,53.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.384 | Acc: 30.804,49.963,55.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.404 | Acc: 30.011,49.562,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.464 | Acc: 29.790,49.129,55.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 4.476 | Acc: 43.750,60.156,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.552 | Acc: 40.067,60.677,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.524 | Acc: 40.835,61.395,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.571 | Acc: 40.984,61.296,70.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.565 | Acc: 41.136,61.169,70.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.565 | Acc: 41.043,61.007,69.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.557 | Acc: 41.213,61.151,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.569 | Acc: 41.268,61.065,69.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.542 | Acc: 41.416,61.340,69.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.541 | Acc: 41.592,61.404,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.544 | Acc: 41.616,61.373,69.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.555 | Acc: 41.601,61.249,69.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.556 | Acc: 41.659,61.210,69.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.561 | Acc: 41.592,61.285,69.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.573 | Acc: 41.612,61.235,69.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.573 | Acc: 41.666,61.288,69.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.578 | Acc: 41.652,61.244,69.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.581 | Acc: 41.672,61.162,68.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.585 | Acc: 41.597,61.160,68.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.589 | Acc: 41.695,61.095,68.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.048 | Acc: 31.250,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.219 | Acc: 30.097,49.740,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.191 | Acc: 30.069,50.229,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.258 | Acc: 29.854,49.360,56.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 3.824 | Acc: 47.656,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.399 | Acc: 42.448,63.095,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.457 | Acc: 42.473,61.966,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.452 | Acc: 42.700,62.372,70.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.488 | Acc: 42.419,62.047,70.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.510 | Acc: 41.932,61.788,69.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.540 | Acc: 41.703,61.577,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.539 | Acc: 41.694,61.508,69.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.536 | Acc: 41.620,61.617,69.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.528 | Acc: 41.721,61.706,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.532 | Acc: 41.694,61.567,69.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.537 | Acc: 41.696,61.457,69.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.526 | Acc: 41.811,61.492,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.535 | Acc: 41.777,61.401,69.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.547 | Acc: 41.715,61.288,69.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.565 | Acc: 41.624,61.127,69.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.567 | Acc: 41.654,61.101,69.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.572 | Acc: 41.596,61.137,69.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.569 | Acc: 41.683,61.087,69.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.567 | Acc: 41.704,61.097,68.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.442 | Acc: 32.812,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.654 | Acc: 29.650,49.330,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.727 | Acc: 29.325,48.590,55.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.763 | Acc: 28.753,48.527,55.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 4.244 | Acc: 45.312,64.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.412 | Acc: 43.006,63.690,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.428 | Acc: 42.492,63.281,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.475 | Acc: 41.829,62.641,69.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.468 | Acc: 41.946,62.799,69.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.480 | Acc: 42.025,62.755,70.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.493 | Acc: 42.110,62.597,69.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.519 | Acc: 42.021,62.156,69.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.511 | Acc: 41.993,62.219,69.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.518 | Acc: 41.734,62.055,69.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.521 | Acc: 41.721,61.940,69.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.524 | Acc: 41.852,61.945,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.535 | Acc: 41.889,61.764,69.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.549 | Acc: 41.822,61.581,69.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.548 | Acc: 41.854,61.566,69.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.556 | Acc: 41.759,61.488,68.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.559 | Acc: 41.754,61.441,68.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.561 | Acc: 41.713,61.396,68.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.567 | Acc: 41.636,61.303,68.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.570 | Acc: 41.689,61.270,68.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.305 | Acc: 29.688,47.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.551 | Acc: 31.101,46.801,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.588 | Acc: 31.155,45.732,53.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.549 | Acc: 31.340,46.273,53.906,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 4.306 | Acc: 34.375,61.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 40.513,59.226,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.572 | Acc: 41.139,60.290,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.519 | Acc: 41.906,60.822,69.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.535 | Acc: 41.570,60.716,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.538 | Acc: 41.855,61.108,69.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.532 | Acc: 41.942,61.086,69.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.534 | Acc: 42.132,61.231,69.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.518 | Acc: 42.139,61.335,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.542 | Acc: 42.032,61.076,69.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.538 | Acc: 42.055,61.190,69.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.532 | Acc: 42.145,61.333,69.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.525 | Acc: 42.171,61.382,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.534 | Acc: 42.158,61.264,69.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.533 | Acc: 42.215,61.357,69.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.529 | Acc: 42.252,61.472,69.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.535 | Acc: 42.158,61.385,69.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.537 | Acc: 42.137,61.311,69.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.538 | Acc: 42.162,61.303,69.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.539 | Acc: 42.089,61.311,69.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.376 | Acc: 28.125,49.219,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.763 | Acc: 27.716,45.573,52.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.769 | Acc: 27.058,46.227,53.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.811 | Acc: 27.203,46.119,52.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 4.493 | Acc: 41.406,61.719,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.419 | Acc: 42.894,62.686,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.409 | Acc: 42.511,62.824,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.434 | Acc: 42.405,62.756,70.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.471 | Acc: 42.371,62.384,70.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.469 | Acc: 42.435,62.430,70.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.493 | Acc: 42.084,62.151,70.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.498 | Acc: 41.944,62.101,70.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.508 | Acc: 42.032,62.054,69.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.518 | Acc: 41.898,61.969,69.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.524 | Acc: 42.048,61.863,69.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.522 | Acc: 42.156,61.807,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.527 | Acc: 42.269,61.719,69.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.527 | Acc: 42.247,61.638,69.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.530 | Acc: 42.157,61.574,69.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.540 | Acc: 42.073,61.498,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.543 | Acc: 42.132,61.492,69.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.546 | Acc: 42.135,61.437,69.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.557 | Acc: 42.068,61.260,69.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.564 | Acc: 41.980,61.229,69.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.397 | Acc: 37.500,57.031,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.739 | Acc: 34.040,53.088,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.748 | Acc: 34.070,52.763,59.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.743 | Acc: 33.991,52.984,59.490,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 4.457 | Acc: 44.531,57.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.372 | Acc: 42.894,62.612,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.333 | Acc: 43.559,63.224,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.383 | Acc: 42.828,63.064,72.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.406 | Acc: 42.496,62.731,72.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.412 | Acc: 42.435,62.624,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.435 | Acc: 42.304,62.351,71.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.450 | Acc: 42.404,62.156,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.442 | Acc: 42.561,62.180,71.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.451 | Acc: 42.503,62.107,70.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.456 | Acc: 42.366,62.026,70.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.456 | Acc: 42.449,62.005,70.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.476 | Acc: 42.353,61.845,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.499 | Acc: 42.256,61.680,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.510 | Acc: 42.196,61.571,70.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.506 | Acc: 42.188,61.651,70.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.513 | Acc: 42.136,61.565,69.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.512 | Acc: 42.151,61.645,69.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.515 | Acc: 42.181,61.574,69.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.524 | Acc: 42.118,61.442,69.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.114 | Acc: 30.469,50.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.877 | Acc: 27.716,47.210,53.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.969 | Acc: 27.553,46.037,52.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.039 | Acc: 26.985,45.812,51.972,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 4.866 | Acc: 43.750,56.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.523 | Acc: 43.118,61.682,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.509 | Acc: 43.102,62.043,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.478 | Acc: 42.892,62.372,70.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.469 | Acc: 42.988,62.529,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.488 | Acc: 42.605,62.384,70.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.474 | Acc: 42.872,62.468,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.467 | Acc: 42.880,62.578,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.455 | Acc: 42.780,62.481,70.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.442 | Acc: 42.921,62.560,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.446 | Acc: 42.852,62.566,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.473 | Acc: 42.725,62.309,70.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.486 | Acc: 42.638,62.176,70.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.484 | Acc: 42.672,62.102,70.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.493 | Acc: 42.563,62.089,70.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.497 | Acc: 42.561,62.002,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.503 | Acc: 42.557,62.016,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.510 | Acc: 42.414,61.884,69.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.516 | Acc: 42.358,61.840,69.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.520 | Acc: 42.290,61.829,69.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.726 | Acc: 34.375,50.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.984 | Acc: 32.068,51.674,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.979 | Acc: 31.707,51.239,58.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.009 | Acc: 31.865,51.268,58.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 4.082 | Acc: 47.656,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.458 | Acc: 42.001,61.830,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.426 | Acc: 41.921,62.405,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 42.226,62.935,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.414 | Acc: 42.149,62.539,70.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.443 | Acc: 42.110,62.384,70.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.467 | Acc: 41.710,62.197,70.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.478 | Acc: 41.850,62.090,70.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.482 | Acc: 41.882,62.117,70.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.491 | Acc: 41.687,62.038,70.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.492 | Acc: 41.842,62.053,70.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.501 | Acc: 41.806,61.871,70.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.502 | Acc: 41.837,61.741,69.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.504 | Acc: 41.957,61.740,69.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.512 | Acc: 41.946,61.674,69.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.521 | Acc: 41.967,61.643,69.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.526 | Acc: 41.942,61.648,69.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.523 | Acc: 41.956,61.726,69.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.517 | Acc: 42.025,61.740,69.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.515 | Acc: 42.071,61.832,69.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.664 | Acc: 26.562,39.844,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.953 | Acc: 21.875,41.295,47.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.990 | Acc: 21.799,41.425,47.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.997 | Acc: 21.709,41.496,48.258,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 4.424 | Acc: 41.406,64.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.496 | Acc: 41.815,62.426,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.480 | Acc: 41.921,62.614,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.490 | Acc: 41.893,62.410,70.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.480 | Acc: 41.985,62.722,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.467 | Acc: 42.311,62.786,70.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.464 | Acc: 42.568,62.713,70.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.474 | Acc: 42.337,62.566,70.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.492 | Acc: 42.120,62.408,70.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.495 | Acc: 42.196,62.241,70.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.492 | Acc: 42.347,62.267,69.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.495 | Acc: 42.237,62.069,69.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.506 | Acc: 42.064,61.988,69.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.516 | Acc: 42.059,61.910,69.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.524 | Acc: 41.979,61.852,69.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.518 | Acc: 42.006,61.872,69.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.528 | Acc: 41.937,61.733,69.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.533 | Acc: 41.919,61.652,69.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.539 | Acc: 41.828,61.611,69.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.535 | Acc: 41.855,61.700,69.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.993 | Acc: 33.594,52.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.040 | Acc: 33.966,50.521,58.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.112 | Acc: 33.746,49.829,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.139 | Acc: 33.402,50.231,56.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 4.111 | Acc: 41.406,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.355 | Acc: 42.336,62.760,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.395 | Acc: 42.454,62.729,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.364 | Acc: 42.687,63.486,70.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.376 | Acc: 42.323,63.117,70.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.382 | Acc: 42.497,63.165,70.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.391 | Acc: 42.472,62.984,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.402 | Acc: 42.304,62.938,70.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.399 | Acc: 42.401,62.942,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.414 | Acc: 42.377,62.759,70.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.426 | Acc: 42.390,62.586,70.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.442 | Acc: 42.272,62.401,70.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.448 | Acc: 42.213,62.283,70.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.448 | Acc: 42.223,62.308,70.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.457 | Acc: 42.257,62.247,69.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.467 | Acc: 42.177,62.113,69.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.474 | Acc: 42.158,62.069,69.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.482 | Acc: 42.169,61.936,69.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.481 | Acc: 42.209,61.918,69.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.487 | Acc: 42.259,61.873,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.309 | Acc: 32.812,48.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.333 | Acc: 31.548,48.140,54.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.381 | Acc: 30.926,47.713,54.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.388 | Acc: 30.751,47.746,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 4.205 | Acc: 42.969,58.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.356 | Acc: 43.192,62.984,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.362 | Acc: 42.797,63.357,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.388 | Acc: 42.508,63.038,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.402 | Acc: 42.564,63.098,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.412 | Acc: 42.574,63.165,70.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.415 | Acc: 42.556,63.062,70.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.406 | Acc: 42.658,63.065,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.413 | Acc: 42.687,63.019,70.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.419 | Acc: 42.399,62.888,70.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.423 | Acc: 42.296,62.842,70.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.435 | Acc: 42.371,62.730,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.442 | Acc: 42.356,62.588,70.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.446 | Acc: 42.271,62.434,70.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.451 | Acc: 42.299,62.369,70.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.461 | Acc: 42.273,62.261,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.469 | Acc: 42.287,62.152,69.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.463 | Acc: 42.320,62.168,70.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.476 | Acc: 42.285,62.108,69.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.482 | Acc: 42.280,62.026,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.931 | Acc: 32.812,46.875,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.735 | Acc: 28.199,46.168,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.735 | Acc: 27.782,46.265,54.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.723 | Acc: 27.574,45.940,54.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 4.894 | Acc: 39.844,53.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.400 | Acc: 42.894,62.872,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 41.692,62.348,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.378 | Acc: 42.047,62.462,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.419 | Acc: 41.927,62.384,71.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.425 | Acc: 41.894,62.407,71.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.411 | Acc: 42.220,62.565,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.436 | Acc: 42.093,62.090,70.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.446 | Acc: 42.052,61.990,70.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.441 | Acc: 42.213,62.064,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.450 | Acc: 42.234,61.890,70.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.458 | Acc: 42.138,61.842,70.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.478 | Acc: 41.977,61.641,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.473 | Acc: 42.068,61.859,70.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.465 | Acc: 42.182,61.838,70.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.474 | Acc: 42.151,61.825,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.480 | Acc: 42.132,61.823,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.482 | Acc: 42.245,61.810,70.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.490 | Acc: 42.220,61.749,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.494 | Acc: 42.196,61.711,69.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.964 | Acc: 26.562,49.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.211 | Acc: 31.138,50.149,56.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.218 | Acc: 30.869,49.905,56.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.260 | Acc: 31.545,49.654,56.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 4.630 | Acc: 37.500,61.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.341 | Acc: 42.411,62.798,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.344 | Acc: 42.740,63.377,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.344 | Acc: 42.623,63.589,71.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.361 | Acc: 42.467,63.522,71.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.373 | Acc: 42.675,63.428,71.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.381 | Acc: 42.717,63.275,71.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.406 | Acc: 42.636,62.877,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.411 | Acc: 42.648,62.718,71.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.418 | Acc: 42.580,62.604,70.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.432 | Acc: 42.440,62.496,70.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.437 | Acc: 42.509,62.366,70.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.450 | Acc: 42.356,62.270,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.452 | Acc: 42.433,62.261,70.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.456 | Acc: 42.315,62.166,70.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.467 | Acc: 42.221,62.105,70.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.473 | Acc: 42.302,62.084,70.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.473 | Acc: 42.323,62.069,69.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.476 | Acc: 42.296,62.061,69.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.482 | Acc: 42.237,62.024,69.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.625 | Acc: 31.250,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.989 | Acc: 28.683,43.676,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.064 | Acc: 28.030,42.969,52.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.043 | Acc: 27.677,43.584,52.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 4.336 | Acc: 48.438,63.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.432 | Acc: 41.815,62.872,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.406 | Acc: 41.463,62.405,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.394 | Acc: 41.701,62.859,71.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.395 | Acc: 42.409,62.789,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.426 | Acc: 42.188,62.523,71.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.405 | Acc: 42.478,62.771,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.402 | Acc: 42.426,62.561,71.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.399 | Acc: 42.600,62.490,70.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.431 | Acc: 42.451,62.129,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.439 | Acc: 42.343,62.104,70.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.453 | Acc: 42.170,61.970,70.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.461 | Acc: 42.246,61.900,70.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.466 | Acc: 42.274,61.865,69.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.464 | Acc: 42.332,61.944,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.473 | Acc: 42.307,61.867,69.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.472 | Acc: 42.321,61.899,69.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.472 | Acc: 42.300,61.916,69.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.471 | Acc: 42.268,61.933,69.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.480 | Acc: 42.144,61.899,69.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.097 | Acc: 34.375,53.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.289 | Acc: 30.804,48.624,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.333 | Acc: 30.335,48.647,55.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.291 | Acc: 30.392,49.155,55.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 3.859 | Acc: 49.219,63.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.363 | Acc: 42.411,61.942,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.321 | Acc: 42.816,63.205,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.378 | Acc: 42.649,62.731,71.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.387 | Acc: 42.650,62.461,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.378 | Acc: 42.690,62.701,70.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.400 | Acc: 42.336,62.487,70.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.400 | Acc: 42.210,62.555,70.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.400 | Acc: 42.367,62.529,70.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.402 | Acc: 42.446,62.509,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.422 | Acc: 42.436,62.267,70.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.439 | Acc: 42.265,62.093,70.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.442 | Acc: 42.366,62.056,69.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.447 | Acc: 42.343,61.922,69.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.456 | Acc: 42.324,61.836,69.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.458 | Acc: 42.406,61.885,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.466 | Acc: 42.392,61.843,69.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.472 | Acc: 42.311,61.767,69.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.474 | Acc: 42.345,61.840,69.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.482 | Acc: 42.319,61.743,69.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.399 | Acc: 32.031,43.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.492 | Acc: 32.961,46.726,53.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.656 | Acc: 31.841,45.103,52.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.685 | Acc: 31.481,45.108,52.293,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 4.298 | Acc: 44.531,64.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.347 | Acc: 43.192,62.946,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.389 | Acc: 42.664,63.129,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.410 | Acc: 42.328,62.474,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.384 | Acc: 42.525,62.596,71.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.392 | Acc: 42.528,62.577,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.391 | Acc: 42.556,62.519,70.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.413 | Acc: 42.293,62.594,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.406 | Acc: 42.236,62.757,70.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.403 | Acc: 42.554,62.759,70.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.402 | Acc: 42.580,62.799,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.433 | Acc: 42.417,62.648,70.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.448 | Acc: 42.356,62.490,70.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.450 | Acc: 42.346,62.509,70.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.458 | Acc: 42.479,62.392,70.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.464 | Acc: 42.387,62.342,70.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.456 | Acc: 42.365,62.344,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.465 | Acc: 42.323,62.225,70.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.471 | Acc: 42.328,62.180,70.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.468 | Acc: 42.333,62.219,70.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.123 | Acc: 24.219,49.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.545 | Acc: 24.107,43.676,52.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.653 | Acc: 23.266,42.473,51.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.650 | Acc: 23.450,42.264,51.268,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 4.577 | Acc: 39.844,64.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.415 | Acc: 42.039,62.091,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.396 | Acc: 41.749,62.290,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.402 | Acc: 42.072,62.257,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.407 | Acc: 42.255,62.240,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.383 | Acc: 42.543,62.407,71.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.385 | Acc: 42.485,62.358,71.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.383 | Acc: 42.609,62.284,70.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.381 | Acc: 42.469,62.519,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.393 | Acc: 42.412,62.301,70.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.398 | Acc: 42.502,62.290,70.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.406 | Acc: 42.438,62.221,70.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.416 | Acc: 42.486,62.208,70.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.415 | Acc: 42.496,62.207,70.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.425 | Acc: 42.482,62.136,70.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 42.416,62.030,70.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.450 | Acc: 42.263,61.955,70.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.451 | Acc: 42.302,61.955,69.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.451 | Acc: 42.313,61.937,69.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.448 | Acc: 42.352,62.016,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.528 | Acc: 29.688,45.312,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.610 | Acc: 28.497,50.670,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.635 | Acc: 27.954,49.848,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.621 | Acc: 28.074,49.782,55.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 4.135 | Acc: 45.312,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.425 | Acc: 41.741,62.500,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.354 | Acc: 42.473,63.224,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.363 | Acc: 42.533,62.884,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.383 | Acc: 42.332,62.703,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.374 | Acc: 42.760,62.833,71.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.389 | Acc: 42.627,62.784,71.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.386 | Acc: 42.742,62.882,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.409 | Acc: 42.522,62.655,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.409 | Acc: 42.442,62.711,70.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.418 | Acc: 42.390,62.527,70.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.425 | Acc: 42.340,62.429,70.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.429 | Acc: 42.333,62.432,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.437 | Acc: 42.253,62.419,70.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.438 | Acc: 42.235,62.386,70.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.444 | Acc: 42.177,62.362,70.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.447 | Acc: 42.158,62.320,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.447 | Acc: 42.165,62.326,70.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.450 | Acc: 42.151,62.301,70.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.457 | Acc: 42.155,62.254,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.812 | Acc: 26.562,39.844,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.898 | Acc: 29.129,44.754,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.948 | Acc: 28.354,44.512,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.969 | Acc: 27.779,44.467,52.536,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 4.460 | Acc: 42.188,60.938,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.418 | Acc: 42.894,63.467,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.444 | Acc: 43.083,62.367,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.419 | Acc: 43.430,62.538,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.409 | Acc: 43.326,62.577,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.405 | Acc: 43.247,62.724,71.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.410 | Acc: 43.266,62.816,71.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.441 | Acc: 43.019,62.445,70.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.440 | Acc: 42.974,62.398,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.430 | Acc: 42.926,62.362,70.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.428 | Acc: 42.984,62.325,70.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.423 | Acc: 43.036,62.394,70.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.431 | Acc: 42.878,62.351,70.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.434 | Acc: 42.831,62.338,70.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.444 | Acc: 42.671,62.141,70.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.446 | Acc: 42.771,62.090,70.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.452 | Acc: 42.611,62.055,70.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.446 | Acc: 42.666,62.108,70.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.456 | Acc: 42.538,61.991,70.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.459 | Acc: 42.522,62.004,70.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.946 | Acc: 28.906,47.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.368 | Acc: 25.893,44.531,51.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.454 | Acc: 25.057,43.998,51.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.549 | Acc: 24.449,43.225,50.077,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 4.266 | Acc: 39.844,54.688,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.359 | Acc: 42.485,63.914,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.385 | Acc: 42.473,62.805,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.363 | Acc: 42.969,62.935,71.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.371 | Acc: 42.930,62.992,71.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.368 | Acc: 42.915,62.825,71.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.374 | Acc: 43.111,62.765,71.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.379 | Acc: 43.008,62.832,71.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.386 | Acc: 43.022,62.621,71.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.416 | Acc: 42.749,62.345,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.418 | Acc: 42.751,62.434,71.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.422 | Acc: 42.767,62.366,70.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.433 | Acc: 42.661,62.263,70.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.437 | Acc: 42.568,62.270,70.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.434 | Acc: 42.507,62.291,70.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.428 | Acc: 42.621,62.334,70.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.431 | Acc: 42.630,62.337,70.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.437 | Acc: 42.646,62.262,70.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.435 | Acc: 42.584,62.253,70.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.441 | Acc: 42.546,62.180,70.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.333 | Acc: 33.594,48.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.687 | Acc: 29.315,47.433,55.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.732 | Acc: 28.468,46.399,55.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.724 | Acc: 27.997,46.580,55.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 4.310 | Acc: 38.281,63.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.346 | Acc: 44.159,62.649,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.395 | Acc: 43.140,62.786,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.404 | Acc: 42.418,62.884,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.404 | Acc: 42.438,63.030,71.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.412 | Acc: 42.342,62.724,71.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.403 | Acc: 42.607,62.816,71.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.422 | Acc: 42.343,62.467,70.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.426 | Acc: 42.445,62.505,70.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.428 | Acc: 42.442,62.496,70.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.433 | Acc: 42.405,62.609,70.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.425 | Acc: 42.421,62.659,70.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.427 | Acc: 42.353,62.607,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.435 | Acc: 42.244,62.614,70.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.438 | Acc: 42.224,62.533,70.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.439 | Acc: 42.263,62.542,70.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.438 | Acc: 42.234,62.571,70.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.445 | Acc: 42.158,62.484,70.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.450 | Acc: 42.140,62.420,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.447 | Acc: 42.196,62.438,70.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.010 | Acc: 40.625,53.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.186 | Acc: 31.101,50.818,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.164 | Acc: 30.964,50.686,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.194 | Acc: 30.494,50.461,57.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 4.150 | Acc: 44.531,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.373 | Acc: 43.490,63.467,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.420 | Acc: 43.007,63.319,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.350 | Acc: 43.238,63.499,71.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.304 | Acc: 43.432,63.725,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.297 | Acc: 43.379,63.637,72.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.336 | Acc: 43.098,63.159,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.354 | Acc: 42.936,63.060,71.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.361 | Acc: 42.741,63.010,71.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.372 | Acc: 42.572,62.970,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.389 | Acc: 42.440,62.792,71.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.393 | Acc: 42.474,62.751,70.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.384 | Acc: 42.495,62.870,71.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.389 | Acc: 42.526,62.778,71.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.392 | Acc: 42.524,62.786,70.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.394 | Acc: 42.592,62.715,70.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.399 | Acc: 42.643,62.729,70.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.404 | Acc: 42.614,62.741,70.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.410 | Acc: 42.590,62.669,70.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.415 | Acc: 42.610,62.570,70.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.315 | Acc: 17.969,43.750,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.506 | Acc: 21.168,42.708,52.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.529 | Acc: 21.361,42.950,52.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.556 | Acc: 21.324,42.572,52.254,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 4.410 | Acc: 38.281,58.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.298 | Acc: 43.080,62.798,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.288 | Acc: 43.255,63.853,72.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.293 | Acc: 43.122,63.909,72.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.315 | Acc: 42.766,63.821,71.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.358 | Acc: 42.621,63.397,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.380 | Acc: 42.478,63.042,71.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.370 | Acc: 42.570,63.054,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.375 | Acc: 42.445,63.073,71.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.387 | Acc: 42.421,62.988,70.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.394 | Acc: 42.452,62.959,70.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.384 | Acc: 42.605,63.147,70.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.386 | Acc: 42.739,63.165,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.394 | Acc: 42.678,62.970,70.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.402 | Acc: 42.607,62.953,70.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.411 | Acc: 42.592,62.804,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.412 | Acc: 42.706,62.792,70.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.415 | Acc: 42.703,62.814,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.411 | Acc: 42.774,62.848,70.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.416 | Acc: 42.745,62.808,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.827 | Acc: 28.125,39.062,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.961 | Acc: 28.832,43.787,53.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.022 | Acc: 27.630,43.921,52.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.048 | Acc: 27.190,44.301,52.485,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 4.670 | Acc: 45.312,61.719,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 41.815,63.988,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.345 | Acc: 41.997,63.319,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.360 | Acc: 41.675,62.948,71.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.392 | Acc: 41.454,62.558,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.393 | Acc: 41.816,62.454,71.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.376 | Acc: 41.903,62.649,71.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.377 | Acc: 41.910,62.755,71.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.392 | Acc: 41.794,62.466,71.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.402 | Acc: 41.605,62.401,71.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.406 | Acc: 41.686,62.391,70.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.413 | Acc: 41.724,62.348,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.412 | Acc: 41.708,62.396,70.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.410 | Acc: 41.879,62.419,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.416 | Acc: 41.896,62.372,70.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.421 | Acc: 41.902,62.355,70.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.422 | Acc: 41.998,62.359,70.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.430 | Acc: 42.027,62.298,70.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.431 | Acc: 42.118,62.292,70.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.438 | Acc: 42.079,62.184,70.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.926 | Acc: 22.656,46.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.097 | Acc: 19.048,41.481,52.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.147 | Acc: 18.502,41.292,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.141 | Acc: 18.033,41.240,53.394,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 4.208 | Acc: 36.719,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.359 | Acc: 43.080,62.537,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.353 | Acc: 42.969,62.995,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.340 | Acc: 43.071,63.140,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.330 | Acc: 43.287,63.272,71.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.361 | Acc: 42.760,62.972,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.362 | Acc: 42.936,63.159,71.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.363 | Acc: 42.814,62.993,71.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.348 | Acc: 43.119,63.155,71.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.348 | Acc: 43.198,63.160,71.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.354 | Acc: 43.105,63.114,71.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.361 | Acc: 43.018,63.165,71.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.367 | Acc: 42.978,63.106,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.367 | Acc: 43.011,63.003,71.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.370 | Acc: 43.013,62.970,71.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.377 | Acc: 42.964,62.978,70.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.386 | Acc: 42.913,62.977,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.390 | Acc: 42.980,62.885,70.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.395 | Acc: 42.982,62.842,70.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.403 | Acc: 42.899,62.752,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.781 | Acc: 28.906,46.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.743 | Acc: 27.121,49.293,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.832 | Acc: 26.334,48.438,54.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.886 | Acc: 26.012,48.309,54.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 3.757 | Acc: 48.438,73.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.239 | Acc: 43.638,64.732,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.273 | Acc: 42.988,64.234,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.312 | Acc: 43.315,63.973,71.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.351 | Acc: 43.075,63.879,71.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.359 | Acc: 42.884,63.668,71.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.336 | Acc: 43.137,63.791,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.348 | Acc: 43.063,63.608,71.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.349 | Acc: 43.017,63.592,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.364 | Acc: 42.861,63.419,71.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.386 | Acc: 42.732,63.207,70.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.393 | Acc: 42.743,63.168,70.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.389 | Acc: 42.842,63.116,70.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.393 | Acc: 42.819,63.042,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.396 | Acc: 42.863,62.992,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.396 | Acc: 42.992,62.980,70.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.395 | Acc: 43.034,62.965,70.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.398 | Acc: 43.010,62.889,70.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.394 | Acc: 42.960,62.959,70.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.398 | Acc: 42.950,62.949,70.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.829 | Acc: 32.031,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.139 | Acc: 33.743,50.112,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.209 | Acc: 33.003,49.390,56.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.295 | Acc: 32.390,49.168,55.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 4.404 | Acc: 40.625,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.347 | Acc: 42.001,63.988,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.346 | Acc: 42.530,63.853,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.334 | Acc: 42.994,63.640,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.336 | Acc: 43.142,63.436,71.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.335 | Acc: 43.255,63.274,70.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.351 | Acc: 42.936,63.081,70.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.346 | Acc: 42.963,63.049,70.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.378 | Acc: 42.940,62.791,70.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.384 | Acc: 42.960,62.707,70.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.376 | Acc: 43.062,62.729,70.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.381 | Acc: 43.146,62.701,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.393 | Acc: 43.060,62.600,70.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.387 | Acc: 43.130,62.704,70.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.380 | Acc: 43.152,62.873,70.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.386 | Acc: 43.114,62.923,70.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.388 | Acc: 43.030,62.855,70.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.398 | Acc: 42.902,62.670,70.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.405 | Acc: 42.817,62.606,70.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.406 | Acc: 42.760,62.582,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.569 | Acc: 31.250,40.625,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.626 | Acc: 25.260,40.179,49.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.628 | Acc: 24.505,39.253,49.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.626 | Acc: 24.680,39.319,49.526,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 3.814 | Acc: 50.781,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.359 | Acc: 41.518,61.979,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.273 | Acc: 43.559,63.014,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.249 | Acc: 43.981,63.307,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.262 | Acc: 43.798,63.455,72.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.286 | Acc: 43.673,63.250,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.284 | Acc: 43.705,63.372,72.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.295 | Acc: 43.512,63.231,71.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.326 | Acc: 43.076,63.053,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.351 | Acc: 42.796,62.932,71.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.357 | Acc: 42.802,62.920,71.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.367 | Acc: 42.697,62.786,70.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.376 | Acc: 42.745,62.737,70.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.386 | Acc: 42.687,62.611,70.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.384 | Acc: 42.749,62.728,70.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.382 | Acc: 42.764,62.700,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.391 | Acc: 42.706,62.658,70.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.402 | Acc: 42.710,62.532,70.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.412 | Acc: 42.640,62.468,70.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.420 | Acc: 42.594,62.453,70.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.935 | Acc: 35.156,48.438,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.044 | Acc: 34.449,48.996,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.112 | Acc: 33.194,48.876,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.174 | Acc: 32.300,48.732,56.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 3.945 | Acc: 45.312,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.282 | Acc: 43.787,63.318,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.223 | Acc: 44.284,63.777,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.283 | Acc: 43.750,63.422,72.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.322 | Acc: 43.248,63.243,72.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.329 | Acc: 43.340,63.103,71.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.342 | Acc: 43.208,62.887,71.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.323 | Acc: 43.323,63.087,71.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.335 | Acc: 43.299,62.883,71.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.340 | Acc: 43.154,62.893,71.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.345 | Acc: 43.019,62.842,71.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.346 | Acc: 43.008,62.740,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.347 | Acc: 43.069,62.853,71.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.348 | Acc: 43.115,62.901,71.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.360 | Acc: 43.072,62.850,70.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.365 | Acc: 43.067,62.866,70.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.380 | Acc: 43.017,62.760,70.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.380 | Acc: 42.946,62.782,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.386 | Acc: 42.835,62.803,70.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.390 | Acc: 42.813,62.808,70.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.569 | Acc: 21.094,41.406,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 8.995 | Acc: 19.420,38.765,47.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 9.071 | Acc: 19.684,37.691,47.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 9.144 | Acc: 19.557,37.807,46.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 4.373 | Acc: 39.844,62.500,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.378 | Acc: 43.118,63.356,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.339 | Acc: 43.426,63.853,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.330 | Acc: 43.186,63.678,72.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.354 | Acc: 42.766,63.223,71.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.350 | Acc: 42.845,63.444,71.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.349 | Acc: 42.872,63.507,71.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.347 | Acc: 42.936,63.486,71.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.344 | Acc: 42.901,63.325,71.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.357 | Acc: 42.930,63.134,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.346 | Acc: 43.019,63.235,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.346 | Acc: 43.011,63.260,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.349 | Acc: 43.076,63.168,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.356 | Acc: 42.945,63.090,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.361 | Acc: 42.871,63.050,71.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.364 | Acc: 42.842,63.074,71.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.364 | Acc: 42.840,63.111,71.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.369 | Acc: 42.845,63.089,71.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.367 | Acc: 42.906,63.115,71.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.372 | Acc: 42.833,63.086,71.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.218 | Acc: 32.812,49.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.231 | Acc: 32.106,49.702,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.286 | Acc: 30.602,48.990,56.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.329 | Acc: 29.905,48.745,56.250,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 3.818 | Acc: 51.562,67.188,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.172 | Acc: 45.015,64.732,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.188 | Acc: 44.607,64.482,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.188 | Acc: 45.082,64.626,72.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 44.502,64.072,72.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 44.261,64.217,71.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.243 | Acc: 44.215,64.282,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.265 | Acc: 44.082,64.190,71.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.292 | Acc: 43.794,63.936,71.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.289 | Acc: 43.707,64.041,71.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.287 | Acc: 43.696,64.097,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.301 | Acc: 43.545,63.971,71.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.307 | Acc: 43.449,63.780,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.321 | Acc: 43.391,63.616,71.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.337 | Acc: 43.305,63.481,71.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.353 | Acc: 43.246,63.284,70.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.352 | Acc: 43.266,63.269,70.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.360 | Acc: 43.070,63.130,70.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.364 | Acc: 43.064,63.089,70.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.373 | Acc: 42.985,63.056,70.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.011 | Acc: 36.719,57.031,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.271 | Acc: 33.259,49.368,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.309 | Acc: 32.698,49.466,55.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.330 | Acc: 32.646,49.334,55.725,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 4.393 | Acc: 45.312,61.719,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.261 | Acc: 43.341,64.323,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.237 | Acc: 43.483,64.196,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.258 | Acc: 43.379,63.550,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.278 | Acc: 42.988,63.561,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.283 | Acc: 43.123,63.304,72.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.304 | Acc: 42.988,63.385,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.318 | Acc: 42.869,63.226,72.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.331 | Acc: 42.818,63.073,71.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.325 | Acc: 42.908,63.195,71.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.351 | Acc: 42.728,63.075,71.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.350 | Acc: 42.725,63.154,71.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.363 | Acc: 42.638,63.077,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.361 | Acc: 42.720,63.090,71.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.359 | Acc: 42.757,63.117,71.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.368 | Acc: 42.701,63.029,71.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.373 | Acc: 42.618,62.919,71.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.381 | Acc: 42.444,62.837,71.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.383 | Acc: 42.462,62.814,70.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.387 | Acc: 42.501,62.801,70.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.033 | Acc: 32.812,53.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.063 | Acc: 33.222,50.595,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.104 | Acc: 32.450,50.419,57.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.147 | Acc: 31.890,50.525,57.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 3.775 | Acc: 53.906,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.251 | Acc: 43.601,63.988,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.262 | Acc: 43.083,63.796,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 42.789,63.934,72.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.264 | Acc: 42.892,63.802,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.286 | Acc: 42.984,63.830,72.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.295 | Acc: 43.266,63.811,72.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.300 | Acc: 43.379,63.608,72.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.309 | Acc: 43.109,63.485,72.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.320 | Acc: 43.141,63.316,71.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.340 | Acc: 43.031,63.211,71.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.350 | Acc: 42.983,63.048,71.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.362 | Acc: 42.923,62.928,71.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.360 | Acc: 42.996,62.922,71.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.363 | Acc: 42.827,62.884,71.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.371 | Acc: 42.764,62.804,71.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.377 | Acc: 42.840,62.753,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.376 | Acc: 42.944,62.745,70.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.374 | Acc: 43.008,62.755,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.380 | Acc: 42.985,62.687,70.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.552 | Acc: 25.781,47.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.141 | Acc: 26.786,44.159,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.187 | Acc: 26.505,43.388,52.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.178 | Acc: 26.652,43.763,52.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 4.608 | Acc: 36.719,56.250,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.278 | Acc: 41.741,63.876,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.337 | Acc: 42.340,63.396,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.309 | Acc: 42.495,63.448,72.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.291 | Acc: 43.113,63.744,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.301 | Acc: 43.247,63.498,72.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.295 | Acc: 43.356,63.830,72.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.321 | Acc: 43.273,63.381,72.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.328 | Acc: 43.216,63.204,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.330 | Acc: 43.094,63.217,71.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.360 | Acc: 42.926,62.889,71.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.354 | Acc: 43.092,62.917,71.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.357 | Acc: 43.076,62.889,71.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.374 | Acc: 43.044,62.790,71.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.377 | Acc: 43.024,62.778,71.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.377 | Acc: 43.065,62.832,70.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.375 | Acc: 43.159,62.955,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.386 | Acc: 43.099,62.851,70.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.390 | Acc: 43.040,62.784,70.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.390 | Acc: 43.041,62.771,70.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.323 | Acc: 35.938,51.562,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.136 | Acc: 32.738,50.186,56.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.164 | Acc: 32.870,49.295,56.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.188 | Acc: 32.877,49.257,56.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 4.547 | Acc: 45.312,61.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.349 | Acc: 42.039,63.281,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.267 | Acc: 42.588,63.396,72.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.299 | Acc: 42.495,63.332,71.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.272 | Acc: 42.988,63.301,71.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.299 | Acc: 42.713,63.243,71.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.299 | Acc: 42.885,63.210,71.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.315 | Acc: 42.902,63.026,71.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.319 | Acc: 42.906,63.121,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.319 | Acc: 43.085,62.966,71.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.324 | Acc: 43.089,63.017,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.331 | Acc: 43.036,63.002,71.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.340 | Acc: 42.920,62.899,71.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.342 | Acc: 42.876,62.865,71.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.356 | Acc: 42.791,62.734,71.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.360 | Acc: 42.813,62.653,71.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.363 | Acc: 42.871,62.592,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.368 | Acc: 42.850,62.585,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.370 | Acc: 42.865,62.604,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.375 | Acc: 42.844,62.566,70.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.480 | Acc: 28.906,46.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.334 | Acc: 29.204,44.085,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.419 | Acc: 28.354,42.759,50.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.466 | Acc: 28.471,43.071,50.320,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 4.113 | Acc: 41.406,64.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.384 | Acc: 42.188,62.686,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.329 | Acc: 43.579,63.624,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.295 | Acc: 43.404,63.845,72.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.296 | Acc: 43.258,63.503,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.308 | Acc: 43.301,63.274,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.301 | Acc: 43.169,63.275,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.331 | Acc: 42.936,63.071,71.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.328 | Acc: 42.988,63.005,71.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.338 | Acc: 42.839,62.850,71.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.344 | Acc: 42.875,62.850,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.352 | Acc: 42.873,62.889,71.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.349 | Acc: 42.975,62.899,71.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.349 | Acc: 43.020,62.904,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.349 | Acc: 42.997,62.920,71.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.349 | Acc: 43.026,62.863,71.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.349 | Acc: 43.027,62.831,71.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.342 | Acc: 43.143,62.949,71.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.348 | Acc: 43.075,62.918,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.352 | Acc: 43.098,62.820,71.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.418 | Acc: 31.250,47.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.719 | Acc: 29.836,48.065,56.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.735 | Acc: 29.554,47.389,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.700 | Acc: 29.393,47.989,55.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 3.939 | Acc: 42.969,68.750,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.217 | Acc: 44.420,64.025,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.238 | Acc: 44.360,64.234,72.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.246 | Acc: 44.185,64.191,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.267 | Acc: 43.557,63.879,71.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.284 | Acc: 43.448,63.629,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.285 | Acc: 43.582,63.688,71.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.290 | Acc: 43.551,63.547,71.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.291 | Acc: 43.454,63.529,71.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.291 | Acc: 43.452,63.583,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.308 | Acc: 43.299,63.495,71.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.305 | Acc: 43.396,63.631,71.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.305 | Acc: 43.364,63.661,71.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.300 | Acc: 43.400,63.688,71.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.318 | Acc: 43.183,63.481,71.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.322 | Acc: 43.140,63.372,71.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.332 | Acc: 43.115,63.237,71.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.340 | Acc: 43.051,63.238,71.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.342 | Acc: 43.133,63.231,71.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.348 | Acc: 43.014,63.177,71.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.806 | Acc: 40.625,51.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.016 | Acc: 37.351,50.260,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.038 | Acc: 36.128,49.486,56.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.073 | Acc: 35.694,49.539,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 4.635 | Acc: 35.938,56.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.240 | Acc: 42.448,64.472,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.217 | Acc: 43.598,64.329,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.244 | Acc: 43.686,64.255,72.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.231 | Acc: 43.634,64.439,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.253 | Acc: 43.340,64.101,72.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.256 | Acc: 43.246,63.856,72.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.272 | Acc: 43.102,63.797,72.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.306 | Acc: 42.794,63.504,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.297 | Acc: 43.046,63.627,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.297 | Acc: 43.093,63.709,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.291 | Acc: 43.322,63.688,71.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.301 | Acc: 43.461,63.589,71.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.311 | Acc: 43.241,63.479,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.322 | Acc: 43.111,63.348,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.327 | Acc: 43.182,63.292,71.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.328 | Acc: 43.195,63.257,71.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.330 | Acc: 43.163,63.210,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.333 | Acc: 43.103,63.260,71.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.338 | Acc: 43.135,63.173,71.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.020 | Acc: 30.469,50.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.624 | Acc: 28.609,47.098,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.710 | Acc: 27.782,46.684,54.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.754 | Acc: 27.690,46.504,54.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 4.915 | Acc: 41.406,63.281,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.354 | Acc: 43.564,62.835,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.262 | Acc: 44.017,63.929,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.253 | Acc: 43.558,63.665,72.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.250 | Acc: 43.499,64.265,72.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.234 | Acc: 43.634,64.148,72.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.240 | Acc: 43.485,63.895,72.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.257 | Acc: 43.395,63.647,72.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.250 | Acc: 43.716,63.650,72.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.264 | Acc: 43.539,63.527,71.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.262 | Acc: 43.711,63.557,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.274 | Acc: 43.732,63.515,71.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.289 | Acc: 43.672,63.479,71.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.297 | Acc: 43.517,63.458,71.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.312 | Acc: 43.458,63.253,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.320 | Acc: 43.428,63.081,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.327 | Acc: 43.414,63.048,71.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.337 | Acc: 43.377,62.944,71.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.341 | Acc: 43.399,62.978,71.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.347 | Acc: 43.356,62.968,71.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.905 | Acc: 25.781,50.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.146 | Acc: 27.344,46.503,56.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.219 | Acc: 26.372,45.922,55.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.229 | Acc: 26.370,45.710,54.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 3.967 | Acc: 50.781,64.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 43.080,63.504,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.286 | Acc: 42.397,63.396,73.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.233 | Acc: 42.905,63.986,73.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.215 | Acc: 43.007,64.381,73.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.229 | Acc: 43.201,64.101,73.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.249 | Acc: 43.182,63.940,73.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.248 | Acc: 43.545,64.118,73.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.252 | Acc: 43.634,63.859,72.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.265 | Acc: 43.772,63.765,72.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.270 | Acc: 43.824,63.763,72.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.274 | Acc: 43.704,63.635,72.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.281 | Acc: 43.555,63.550,72.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.288 | Acc: 43.436,63.419,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.299 | Acc: 43.319,63.273,71.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.313 | Acc: 43.314,63.193,71.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.311 | Acc: 43.305,63.172,71.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.315 | Acc: 43.271,63.208,71.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.317 | Acc: 43.274,63.251,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.324 | Acc: 43.301,63.187,71.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.606 | Acc: 29.688,50.781,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.185 | Acc: 34.933,52.195,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.275 | Acc: 33.899,51.410,56.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.289 | Acc: 33.338,50.961,55.802,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 3.907 | Acc: 44.531,71.094,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.195 | Acc: 43.936,64.174,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.275 | Acc: 43.483,63.281,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.321 | Acc: 43.327,63.012,72.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.300 | Acc: 43.229,63.223,72.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.293 | Acc: 43.131,63.142,72.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.289 | Acc: 43.007,63.378,72.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.309 | Acc: 42.730,63.231,71.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.309 | Acc: 42.726,63.262,71.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.324 | Acc: 42.736,63.139,71.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.335 | Acc: 42.817,63.091,71.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.333 | Acc: 42.827,63.041,71.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.342 | Acc: 42.842,62.993,71.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.356 | Acc: 42.771,62.901,71.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.341 | Acc: 42.899,63.042,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.346 | Acc: 42.971,62.991,71.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.350 | Acc: 42.927,62.906,71.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.350 | Acc: 43.049,62.924,71.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.354 | Acc: 43.049,62.885,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.353 | Acc: 43.043,62.861,71.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.698 | Acc: 32.031,54.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.918 | Acc: 35.342,51.339,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.899 | Acc: 35.423,51.601,58.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.927 | Acc: 35.464,51.678,57.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 4.156 | Acc: 49.219,65.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.113 | Acc: 44.643,64.695,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.126 | Acc: 44.798,65.358,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.169 | Acc: 44.442,64.780,72.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.141 | Acc: 44.782,65.104,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.183 | Acc: 44.361,64.643,72.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.201 | Acc: 44.467,64.476,72.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.234 | Acc: 44.182,64.240,72.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.244 | Acc: 43.934,64.223,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.258 | Acc: 43.823,64.062,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.273 | Acc: 43.688,63.872,72.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.279 | Acc: 43.626,63.847,72.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.295 | Acc: 43.429,63.768,71.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.299 | Acc: 43.439,63.706,71.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.309 | Acc: 43.377,63.584,71.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.310 | Acc: 43.324,63.466,71.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.325 | Acc: 43.305,63.369,71.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.327 | Acc: 43.296,63.373,71.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.330 | Acc: 43.246,63.283,71.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.339 | Acc: 43.198,63.195,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.889 | Acc: 34.375,48.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.379 | Acc: 30.246,49.144,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.370 | Acc: 29.668,48.742,55.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.384 | Acc: 29.662,48.578,55.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 4.661 | Acc: 41.406,54.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.178 | Acc: 43.452,64.397,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.223 | Acc: 43.636,64.405,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.266 | Acc: 42.969,63.960,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.222 | Acc: 43.335,64.564,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.226 | Acc: 43.595,64.264,72.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.230 | Acc: 43.679,64.276,72.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.238 | Acc: 43.722,64.118,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.250 | Acc: 43.507,64.048,72.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.276 | Acc: 43.219,63.778,72.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.287 | Acc: 43.229,63.662,72.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.295 | Acc: 43.329,63.606,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.294 | Acc: 43.377,63.576,71.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.299 | Acc: 43.379,63.631,71.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.300 | Acc: 43.497,63.648,71.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.305 | Acc: 43.433,63.541,71.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.305 | Acc: 43.507,63.598,71.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.306 | Acc: 43.567,63.623,71.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.306 | Acc: 43.551,63.677,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.316 | Acc: 43.467,63.622,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.395 | Acc: 35.156,53.125,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.828 | Acc: 30.580,48.177,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.818 | Acc: 30.164,48.171,52.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.779 | Acc: 30.289,48.105,53.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 4.563 | Acc: 48.438,62.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.293 | Acc: 44.680,62.054,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.241 | Acc: 44.646,63.053,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.195 | Acc: 44.493,63.858,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.224 | Acc: 44.126,63.783,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.211 | Acc: 43.673,63.939,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.217 | Acc: 43.608,63.998,72.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.234 | Acc: 43.567,63.841,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.226 | Acc: 43.575,63.873,72.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.248 | Acc: 43.534,63.687,72.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.243 | Acc: 43.598,63.825,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.255 | Acc: 43.549,63.716,72.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.267 | Acc: 43.374,63.699,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.271 | Acc: 43.433,63.766,72.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.272 | Acc: 43.405,63.743,72.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 43.475,63.837,72.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.288 | Acc: 43.494,63.724,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.295 | Acc: 43.432,63.671,71.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.300 | Acc: 43.490,63.647,71.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.306 | Acc: 43.455,63.609,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.750 | Acc: 35.938,53.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.810 | Acc: 36.310,52.716,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.884 | Acc: 35.461,51.829,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.910 | Acc: 35.182,51.217,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 3.895 | Acc: 42.188,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.171 | Acc: 44.494,65.439,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.165 | Acc: 43.693,64.634,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.165 | Acc: 44.288,64.319,73.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.163 | Acc: 44.194,64.265,73.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 43.943,64.194,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.219 | Acc: 43.485,63.656,72.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.216 | Acc: 43.661,63.680,72.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.236 | Acc: 43.372,63.621,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.251 | Acc: 43.435,63.406,72.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.257 | Acc: 43.396,63.429,72.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.285 | Acc: 43.319,63.324,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.289 | Acc: 43.309,63.411,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.290 | Acc: 43.325,63.410,72.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.301 | Acc: 43.149,63.351,71.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.302 | Acc: 43.114,63.380,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.309 | Acc: 43.064,63.371,71.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.314 | Acc: 43.033,63.295,71.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.323 | Acc: 42.977,63.175,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.325 | Acc: 43.022,63.166,71.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.432 | Acc: 32.812,55.469,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.784 | Acc: 28.423,48.177,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.901 | Acc: 27.534,47.085,54.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.937 | Acc: 26.729,47.003,54.508,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 4.057 | Acc: 46.875,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.253 | Acc: 42.634,63.542,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 43.293,64.062,72.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.267 | Acc: 43.122,63.832,72.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.293 | Acc: 42.728,63.513,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.297 | Acc: 42.891,63.243,72.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.293 | Acc: 43.066,63.436,72.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.292 | Acc: 42.952,63.614,72.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.302 | Acc: 42.794,63.412,72.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.308 | Acc: 42.753,63.376,72.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.308 | Acc: 42.767,63.429,71.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.310 | Acc: 42.856,63.465,71.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.317 | Acc: 42.706,63.272,71.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.325 | Acc: 42.595,63.209,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.337 | Acc: 42.429,63.156,71.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.337 | Acc: 42.564,63.216,71.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.341 | Acc: 42.545,63.140,71.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.340 | Acc: 42.554,63.174,71.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.339 | Acc: 42.629,63.288,71.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.337 | Acc: 42.680,63.328,71.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.429 | Acc: 38.281,55.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.816 | Acc: 36.421,52.902,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.801 | Acc: 36.204,52.877,58.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.837 | Acc: 36.091,52.869,58.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 4.515 | Acc: 46.875,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.267 | Acc: 44.271,64.174,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.225 | Acc: 44.569,64.348,72.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.219 | Acc: 44.442,64.255,72.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.209 | Acc: 44.367,64.381,72.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.228 | Acc: 44.052,64.186,72.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.244 | Acc: 43.905,64.140,72.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.249 | Acc: 44.010,64.245,72.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.265 | Acc: 43.716,64.092,72.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.270 | Acc: 43.746,63.950,72.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.280 | Acc: 43.668,63.915,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.292 | Acc: 43.736,63.907,71.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.292 | Acc: 43.766,63.952,71.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.292 | Acc: 43.843,63.889,71.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.298 | Acc: 43.756,63.871,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.303 | Acc: 43.753,63.793,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.305 | Acc: 43.743,63.770,71.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.315 | Acc: 43.697,63.696,71.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.316 | Acc: 43.562,63.675,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.326 | Acc: 43.541,63.583,71.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.300 | Acc: 34.375,48.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.694 | Acc: 24.256,44.978,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.727 | Acc: 24.276,44.912,53.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.724 | Acc: 24.078,44.877,53.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 3.982 | Acc: 51.562,68.750,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.114 | Acc: 44.531,64.323,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.151 | Acc: 43.617,64.748,73.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.166 | Acc: 43.827,64.472,73.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.175 | Acc: 43.885,64.410,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 44.199,64.635,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.197 | Acc: 43.905,64.637,72.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.195 | Acc: 43.805,64.639,72.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.209 | Acc: 43.619,64.538,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.230 | Acc: 43.474,64.386,72.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.230 | Acc: 43.466,64.335,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.233 | Acc: 43.471,64.264,72.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.241 | Acc: 43.468,64.260,72.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.247 | Acc: 43.460,64.275,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.257 | Acc: 43.352,64.021,72.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.264 | Acc: 43.267,63.974,72.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.270 | Acc: 43.185,63.892,72.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 43.079,63.792,72.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.295 | Acc: 43.001,63.725,71.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.295 | Acc: 42.969,63.659,71.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.732 | Acc: 32.031,50.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.535 | Acc: 31.659,48.326,54.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.560 | Acc: 31.574,47.256,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.610 | Acc: 31.698,47.106,54.406,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 3.891 | Acc: 44.531,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.198 | Acc: 43.899,64.397,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.169 | Acc: 43.807,64.024,73.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.185 | Acc: 43.865,63.998,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.186 | Acc: 43.846,64.390,73.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.180 | Acc: 43.967,64.643,73.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.196 | Acc: 43.808,64.560,72.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.211 | Acc: 43.816,64.517,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.220 | Acc: 43.604,64.315,72.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.234 | Acc: 43.629,64.222,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.238 | Acc: 43.583,64.097,72.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.247 | Acc: 43.686,64.052,72.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.252 | Acc: 43.711,64.030,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.250 | Acc: 43.741,64.051,72.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.252 | Acc: 43.764,63.937,72.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.261 | Acc: 43.698,63.785,72.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.265 | Acc: 43.689,63.758,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.277 | Acc: 43.613,63.611,71.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.292 | Acc: 43.536,63.532,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.303 | Acc: 43.529,63.466,71.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.942 | Acc: 35.938,49.219,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.232 | Acc: 35.491,49.144,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.267 | Acc: 33.937,48.723,55.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.325 | Acc: 33.837,48.770,55.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 4.851 | Acc: 46.875,63.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.184 | Acc: 42.969,64.993,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.213 | Acc: 43.293,64.710,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.231 | Acc: 43.468,64.524,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.225 | Acc: 43.519,64.361,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.229 | Acc: 43.309,64.240,72.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.233 | Acc: 43.188,64.340,72.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.247 | Acc: 43.085,64.118,72.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.233 | Acc: 43.260,64.198,72.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.227 | Acc: 43.396,64.252,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.242 | Acc: 43.299,64.051,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.245 | Acc: 43.404,64.009,72.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.259 | Acc: 43.455,63.933,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.274 | Acc: 43.268,63.664,72.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.274 | Acc: 43.272,63.654,71.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.278 | Acc: 43.384,63.671,71.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.295 | Acc: 43.219,63.595,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.297 | Acc: 43.232,63.616,71.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.303 | Acc: 43.181,63.632,71.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.305 | Acc: 43.205,63.529,71.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.360 | Acc: 28.906,38.281,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.346 | Acc: 27.567,41.481,50.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.400 | Acc: 27.248,41.120,49.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.411 | Acc: 27.088,40.446,49.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 3.410 | Acc: 51.562,72.656,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.107 | Acc: 45.089,65.253,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.134 | Acc: 44.226,65.091,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.149 | Acc: 44.160,64.728,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.143 | Acc: 44.068,64.863,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.169 | Acc: 43.820,64.442,72.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.175 | Acc: 43.692,64.398,72.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.187 | Acc: 43.733,64.240,72.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.204 | Acc: 43.439,64.111,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.229 | Acc: 43.366,63.898,72.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.252 | Acc: 43.128,63.674,72.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.265 | Acc: 43.029,63.568,72.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.274 | Acc: 43.053,63.463,72.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.285 | Acc: 42.927,63.488,71.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.292 | Acc: 42.924,63.423,71.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.293 | Acc: 43.041,63.440,71.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.304 | Acc: 42.996,63.386,71.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.299 | Acc: 42.982,63.412,71.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.307 | Acc: 42.964,63.318,71.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.308 | Acc: 42.985,63.267,71.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.058 | Acc: 31.250,52.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.108 | Acc: 33.631,50.595,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.236 | Acc: 33.232,49.600,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.268 | Acc: 33.286,49.513,56.468,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 4.201 | Acc: 42.969,64.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.258 | Acc: 41.964,63.058,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.201 | Acc: 42.416,63.472,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.226 | Acc: 42.661,63.742,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.232 | Acc: 42.641,63.609,73.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.235 | Acc: 42.799,63.730,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.234 | Acc: 42.872,63.688,72.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.227 | Acc: 43.030,63.918,73.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.238 | Acc: 42.998,63.864,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.235 | Acc: 43.159,63.942,72.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.238 | Acc: 43.163,63.926,72.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.243 | Acc: 43.181,63.840,72.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.252 | Acc: 43.186,63.712,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.260 | Acc: 43.181,63.763,72.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.276 | Acc: 43.077,63.634,72.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.284 | Acc: 43.078,63.575,72.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.290 | Acc: 43.107,63.603,72.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.301 | Acc: 43.042,63.490,71.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.304 | Acc: 42.980,63.467,71.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.306 | Acc: 42.991,63.492,71.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.383 | Acc: 32.031,46.875,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.240 | Acc: 28.534,41.183,50.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.333 | Acc: 28.087,40.663,49.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.338 | Acc: 28.151,40.638,49.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 3.679 | Acc: 48.438,72.656,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.170 | Acc: 43.192,65.030,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.172 | Acc: 42.931,64.234,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.177 | Acc: 43.251,64.613,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.184 | Acc: 43.528,64.873,73.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.227 | Acc: 43.023,64.472,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.235 | Acc: 43.356,64.431,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.233 | Acc: 43.257,64.395,72.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.236 | Acc: 43.425,64.320,72.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.227 | Acc: 43.513,64.503,72.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.246 | Acc: 43.532,64.210,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.256 | Acc: 43.541,64.024,72.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.255 | Acc: 43.614,64.007,72.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.263 | Acc: 43.570,63.934,71.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.270 | Acc: 43.486,63.887,71.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.277 | Acc: 43.433,63.824,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.282 | Acc: 43.446,63.753,71.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.286 | Acc: 43.390,63.730,71.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.293 | Acc: 43.317,63.649,71.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.298 | Acc: 43.268,63.599,71.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.528 | Acc: 35.156,64.844,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.867 | Acc: 32.626,54.092,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.919 | Acc: 32.698,53.144,58.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.923 | Acc: 32.877,53.330,58.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 3.557 | Acc: 52.344,74.219,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.137 | Acc: 43.452,64.323,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.111 | Acc: 43.845,65.187,73.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.133 | Acc: 43.737,65.151,73.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.153 | Acc: 43.615,65.066,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.172 | Acc: 43.340,64.766,73.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.176 | Acc: 43.292,64.734,73.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.171 | Acc: 43.534,64.794,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.169 | Acc: 43.643,64.936,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.176 | Acc: 43.513,64.835,73.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.194 | Acc: 43.435,64.517,72.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.202 | Acc: 43.453,64.451,72.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.213 | Acc: 43.559,64.354,72.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.237 | Acc: 43.418,64.131,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.246 | Acc: 43.425,64.001,72.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.256 | Acc: 43.420,63.912,72.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.253 | Acc: 43.419,63.943,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.255 | Acc: 43.477,63.914,72.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.260 | Acc: 43.438,63.939,72.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.267 | Acc: 43.465,63.894,71.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 8.538 | Acc: 25.000,43.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.887 | Acc: 22.470,42.374,51.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 8.132 | Acc: 22.256,40.854,49.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 8.183 | Acc: 22.041,40.471,48.835,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 3.754 | Acc: 51.562,75.000,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.226 | Acc: 43.118,63.132,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.214 | Acc: 43.826,63.948,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.241 | Acc: 42.982,64.114,72.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.233 | Acc: 42.853,64.265,72.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.230 | Acc: 43.201,64.217,72.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.230 | Acc: 43.395,64.121,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.240 | Acc: 43.346,63.869,72.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.262 | Acc: 43.299,63.645,72.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.264 | Acc: 43.305,63.730,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.270 | Acc: 43.280,63.740,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.266 | Acc: 43.237,63.762,72.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.278 | Acc: 43.209,63.693,71.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.273 | Acc: 43.283,63.769,71.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.277 | Acc: 43.308,63.715,71.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.279 | Acc: 43.267,63.658,71.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 43.292,63.629,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.286 | Acc: 43.262,63.533,71.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 43.298,63.502,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.293 | Acc: 43.260,63.458,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.602 | Acc: 38.281,54.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.717 | Acc: 37.091,53.906,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.771 | Acc: 37.119,53.011,57.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.795 | Acc: 36.936,52.574,56.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 4.372 | Acc: 42.969,64.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.254 | Acc: 42.262,64.062,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.236 | Acc: 42.950,64.062,73.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.261 | Acc: 42.444,63.627,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.248 | Acc: 42.699,63.937,73.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.247 | Acc: 42.899,64.008,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.245 | Acc: 42.930,64.011,72.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.246 | Acc: 42.819,63.880,72.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.243 | Acc: 42.760,63.796,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.230 | Acc: 42.857,63.881,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.232 | Acc: 42.953,63.822,72.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.225 | Acc: 43.029,63.804,72.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.228 | Acc: 42.946,63.803,72.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.239 | Acc: 42.975,63.811,72.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.247 | Acc: 43.058,63.773,72.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.250 | Acc: 43.109,63.712,72.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.250 | Acc: 43.146,63.724,72.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.251 | Acc: 43.166,63.730,72.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.257 | Acc: 43.177,63.734,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.267 | Acc: 43.182,63.679,72.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.338 | Acc: 31.250,53.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.161 | Acc: 29.874,45.275,53.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.241 | Acc: 28.411,44.550,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.235 | Acc: 28.266,44.339,52.856,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 4.095 | Acc: 52.344,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.142 | Acc: 44.122,65.811,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.142 | Acc: 44.341,65.244,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.156 | Acc: 44.326,64.933,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.185 | Acc: 44.088,64.718,72.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.186 | Acc: 44.230,64.952,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.204 | Acc: 43.886,64.857,72.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.206 | Acc: 43.805,64.888,72.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.219 | Acc: 43.740,64.630,72.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.240 | Acc: 43.694,64.421,72.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.226 | Acc: 43.781,64.416,72.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.241 | Acc: 43.541,64.225,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.251 | Acc: 43.601,64.147,72.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.251 | Acc: 43.735,64.152,72.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.254 | Acc: 43.617,64.124,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.266 | Acc: 43.503,63.977,71.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 43.400,63.826,71.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.291 | Acc: 43.296,63.723,71.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.297 | Acc: 43.267,63.692,71.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.300 | Acc: 43.264,63.687,71.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.001 | Acc: 39.844,56.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.187 | Acc: 34.003,52.232,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.231 | Acc: 33.346,51.124,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.267 | Acc: 32.761,50.730,58.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 3.661 | Acc: 47.656,66.406,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.148 | Acc: 43.638,64.881,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.119 | Acc: 44.646,64.806,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.142 | Acc: 44.365,64.946,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.182 | Acc: 44.174,64.390,72.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.201 | Acc: 43.951,64.271,72.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.216 | Acc: 43.750,64.127,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.224 | Acc: 43.672,64.068,72.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.216 | Acc: 43.794,64.261,72.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.217 | Acc: 43.698,64.205,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.230 | Acc: 43.606,64.031,72.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.233 | Acc: 43.602,64.094,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.245 | Acc: 43.594,63.917,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.249 | Acc: 43.546,63.889,72.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.252 | Acc: 43.603,63.826,72.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.263 | Acc: 43.485,63.707,72.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.271 | Acc: 43.368,63.651,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 43.283,63.529,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.290 | Acc: 43.259,63.483,71.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.293 | Acc: 43.295,63.417,71.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.502 | Acc: 28.906,52.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.454 | Acc: 29.390,49.814,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.484 | Acc: 29.345,49.143,56.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.448 | Acc: 29.355,49.449,56.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 4.300 | Acc: 45.312,63.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.144 | Acc: 42.969,63.802,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.165 | Acc: 43.636,64.367,73.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.187 | Acc: 43.635,64.664,73.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.205 | Acc: 43.374,64.342,73.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.228 | Acc: 43.224,64.233,72.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 42.911,63.882,72.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.252 | Acc: 43.035,63.891,72.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.268 | Acc: 42.935,63.786,72.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.256 | Acc: 43.146,63.851,72.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.267 | Acc: 43.062,63.748,72.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.272 | Acc: 43.121,63.713,72.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.276 | Acc: 43.017,63.567,71.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.282 | Acc: 43.029,63.524,71.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.281 | Acc: 43.144,63.598,71.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.280 | Acc: 43.140,63.536,71.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.275 | Acc: 43.239,63.680,71.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.279 | Acc: 43.173,63.678,71.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.281 | Acc: 43.181,63.664,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 43.079,63.620,71.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.996 | Acc: 34.375,49.219,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.223 | Acc: 30.692,43.936,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.321 | Acc: 29.954,42.873,50.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.301 | Acc: 29.534,42.892,50.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 4.718 | Acc: 30.469,57.812,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.379 | Acc: 41.109,62.426,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.306 | Acc: 42.797,63.186,72.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.205 | Acc: 43.404,64.242,73.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.188 | Acc: 43.422,64.429,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.202 | Acc: 43.479,64.333,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.204 | Acc: 43.608,64.250,73.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.221 | Acc: 43.611,64.146,72.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.233 | Acc: 43.580,64.096,72.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.241 | Acc: 43.491,64.054,72.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.240 | Acc: 43.583,64.043,72.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.249 | Acc: 43.570,63.985,72.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.243 | Acc: 43.662,64.011,72.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.246 | Acc: 43.570,63.991,72.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.258 | Acc: 43.472,63.882,72.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.272 | Acc: 43.288,63.751,72.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.278 | Acc: 43.319,63.683,72.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.283 | Acc: 43.303,63.717,72.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.289 | Acc: 43.291,63.638,71.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.289 | Acc: 43.321,63.669,71.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.122 | Acc: 35.938,55.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.846 | Acc: 27.790,45.573,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.837 | Acc: 27.611,45.198,55.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.829 | Acc: 27.382,45.261,55.456,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 4.525 | Acc: 39.844,64.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.168 | Acc: 44.754,65.365,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.128 | Acc: 44.798,65.549,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.164 | Acc: 43.968,64.908,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.160 | Acc: 43.673,64.805,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.170 | Acc: 43.742,64.534,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.191 | Acc: 43.756,64.418,73.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.190 | Acc: 43.805,64.395,73.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.197 | Acc: 43.629,64.281,73.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.198 | Acc: 43.603,64.326,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.197 | Acc: 43.719,64.346,72.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.205 | Acc: 43.633,64.253,72.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.216 | Acc: 43.559,64.127,72.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.230 | Acc: 43.543,64.131,72.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.237 | Acc: 43.511,64.154,72.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.243 | Acc: 43.477,64.091,72.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.242 | Acc: 43.606,64.153,72.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.251 | Acc: 43.519,64.046,72.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.254 | Acc: 43.557,64.000,72.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.262 | Acc: 43.510,63.876,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 7.398 | Acc: 31.250,46.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 7.678 | Acc: 25.521,44.531,51.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 7.846 | Acc: 25.457,42.988,50.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 7.815 | Acc: 25.064,42.725,51.153,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 4.108 | Acc: 42.969,65.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.084 | Acc: 44.457,66.034,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.135 | Acc: 44.207,65.549,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.141 | Acc: 44.314,65.535,73.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.125 | Acc: 44.570,65.799,74.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.142 | Acc: 44.284,65.308,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.152 | Acc: 44.415,65.360,73.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.166 | Acc: 44.249,65.143,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.180 | Acc: 44.182,64.989,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.191 | Acc: 44.091,64.874,73.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.206 | Acc: 44.018,64.712,72.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.223 | Acc: 43.828,64.554,72.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.239 | Acc: 43.731,64.406,72.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.243 | Acc: 43.735,64.314,72.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.249 | Acc: 43.653,64.229,72.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.256 | Acc: 43.631,64.164,72.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.266 | Acc: 43.602,64.089,72.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.270 | Acc: 43.654,63.982,72.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.268 | Acc: 43.694,63.998,72.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.262 | Acc: 43.732,64.003,72.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 6.407 | Acc: 33.594,55.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 6.587 | Acc: 29.725,52.344,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 6.537 | Acc: 29.192,52.325,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 6.522 | Acc: 29.124,52.574,56.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 4.201 | Acc: 42.969,67.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.129 | Acc: 44.122,65.848,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.993 | Acc: 44.493,67.283,75.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.931 | Acc: 45.044,67.892,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.889 | Acc: 45.197,68.229,76.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.830 | Acc: 45.715,68.812,76.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.802 | Acc: 45.848,69.028,77.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.771 | Acc: 46.094,69.166,77.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.758 | Acc: 46.259,69.323,78.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.728 | Acc: 46.504,69.674,78.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.708 | Acc: 46.615,69.866,78.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.687 | Acc: 46.818,70.054,78.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.676 | Acc: 46.995,70.060,79.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.664 | Acc: 47.117,70.208,79.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.649 | Acc: 47.261,70.379,79.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.638 | Acc: 47.342,70.505,79.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.628 | Acc: 47.442,70.656,79.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.618 | Acc: 47.551,70.697,79.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.605 | Acc: 47.721,70.797,79.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.603 | Acc: 47.669,70.776,79.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.406 | Acc: 44.531,64.844,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.509 | Acc: 44.345,63.579,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 44.264,62.481,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.509 | Acc: 44.595,62.999,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 3.332 | Acc: 50.000,69.531,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.442 | Acc: 47.470,72.210,82.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.432 | Acc: 48.380,72.294,82.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.431 | Acc: 48.002,72.118,82.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.419 | Acc: 48.081,72.261,83.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.424 | Acc: 48.260,72.177,82.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.422 | Acc: 48.425,72.036,82.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.437 | Acc: 48.194,71.814,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.436 | Acc: 48.321,71.957,82.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.433 | Acc: 48.438,72.125,82.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.423 | Acc: 48.438,72.260,82.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.414 | Acc: 48.491,72.416,82.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.416 | Acc: 48.502,72.407,82.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.413 | Acc: 48.566,72.393,82.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.413 | Acc: 48.518,72.384,82.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.406 | Acc: 48.513,72.428,82.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.407 | Acc: 48.537,72.459,82.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.413 | Acc: 48.525,72.388,82.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.410 | Acc: 48.552,72.505,82.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.409 | Acc: 48.573,72.560,82.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 48.438,64.062,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.371 | Acc: 45.982,64.509,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.398 | Acc: 45.255,63.758,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.417 | Acc: 45.428,63.781,69.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 3.755 | Acc: 43.750,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.355 | Acc: 48.363,73.772,85.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.324 | Acc: 48.723,74.009,84.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.318 | Acc: 48.886,73.706,84.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.328 | Acc: 48.708,73.679,84.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.326 | Acc: 49.080,73.731,84.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.311 | Acc: 49.206,73.806,84.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.305 | Acc: 49.302,73.831,84.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.300 | Acc: 49.413,73.923,84.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.295 | Acc: 49.383,74.020,84.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.304 | Acc: 49.230,73.923,84.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.305 | Acc: 49.183,73.703,84.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.304 | Acc: 49.083,73.765,84.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.312 | Acc: 48.919,73.632,84.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.314 | Acc: 48.877,73.585,84.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.319 | Acc: 48.793,73.552,84.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.321 | Acc: 48.803,73.525,84.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.322 | Acc: 48.832,73.486,83.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.326 | Acc: 48.866,73.396,83.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.326 | Acc: 48.885,73.450,83.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.173 | Acc: 46.094,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.375 | Acc: 45.424,64.323,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.401 | Acc: 45.008,63.700,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.419 | Acc: 45.133,63.832,69.493,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 3.433 | Acc: 47.656,75.000,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.290 | Acc: 48.958,72.917,83.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.252 | Acc: 49.752,73.990,84.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.279 | Acc: 49.180,73.796,84.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.269 | Acc: 49.296,73.891,84.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.256 | Acc: 49.373,73.979,84.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.253 | Acc: 49.186,73.838,84.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.248 | Acc: 49.235,74.030,84.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.259 | Acc: 49.078,73.898,84.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.259 | Acc: 49.201,73.809,84.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.270 | Acc: 48.951,73.795,84.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.273 | Acc: 48.929,73.862,84.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.268 | Acc: 49.128,73.917,84.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.268 | Acc: 49.099,73.946,84.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.274 | Acc: 49.077,73.907,84.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.276 | Acc: 49.092,73.816,84.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.278 | Acc: 49.075,73.824,84.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.279 | Acc: 49.052,73.827,84.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.277 | Acc: 49.050,73.827,84.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.279 | Acc: 49.065,73.809,84.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.192 | Acc: 45.312,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.370 | Acc: 45.499,65.737,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.396 | Acc: 44.931,64.386,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.404 | Acc: 45.172,64.588,69.877,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 3.451 | Acc: 46.875,68.750,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.197 | Acc: 51.562,74.256,84.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.165 | Acc: 51.029,74.619,85.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.168 | Acc: 50.832,74.898,85.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.189 | Acc: 50.521,74.691,85.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.205 | Acc: 49.985,74.613,85.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.204 | Acc: 49.839,74.587,85.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.214 | Acc: 49.734,74.557,85.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.229 | Acc: 49.704,74.253,85.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.224 | Acc: 49.871,74.279,85.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.221 | Acc: 49.860,74.324,85.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.227 | Acc: 49.774,74.226,85.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.229 | Acc: 49.621,74.235,85.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.231 | Acc: 49.521,74.276,85.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.233 | Acc: 49.530,74.222,85.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.237 | Acc: 49.491,74.110,85.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.238 | Acc: 49.457,74.029,85.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.241 | Acc: 49.432,74.058,85.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.246 | Acc: 49.368,74.011,85.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.251 | Acc: 49.315,74.018,85.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.189 | Acc: 45.312,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.426 | Acc: 45.126,64.435,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.458 | Acc: 44.474,63.243,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.468 | Acc: 44.608,63.550,69.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 3.097 | Acc: 49.219,70.312,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.173 | Acc: 52.009,74.740,85.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.193 | Acc: 51.315,74.143,85.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.210 | Acc: 50.218,74.398,85.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.187 | Acc: 50.058,74.450,85.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.197 | Acc: 49.814,74.520,85.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.184 | Acc: 49.742,74.580,85.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.188 | Acc: 49.645,74.612,85.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.195 | Acc: 49.573,74.597,85.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.210 | Acc: 49.417,74.482,85.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.215 | Acc: 49.343,74.398,85.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.216 | Acc: 49.364,74.410,85.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.220 | Acc: 49.164,74.368,85.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.215 | Acc: 49.093,74.344,85.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.214 | Acc: 49.197,74.316,85.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.219 | Acc: 49.214,74.258,85.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.216 | Acc: 49.282,74.326,85.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.219 | Acc: 49.214,74.345,85.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.224 | Acc: 49.160,74.286,85.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.228 | Acc: 49.161,74.250,85.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.233 | Acc: 45.312,69.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.453 | Acc: 45.424,63.988,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.453 | Acc: 44.607,63.434,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.460 | Acc: 44.698,63.870,69.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 3.136 | Acc: 46.875,74.219,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.221 | Acc: 49.033,75.037,86.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.212 | Acc: 49.352,74.714,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.174 | Acc: 50.141,75.090,86.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.190 | Acc: 49.865,74.691,86.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.191 | Acc: 49.250,74.729,86.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.187 | Acc: 49.290,74.529,86.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.182 | Acc: 49.357,74.485,86.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.186 | Acc: 49.437,74.452,86.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.177 | Acc: 49.499,74.607,86.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.176 | Acc: 49.592,74.639,86.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.175 | Acc: 49.544,74.636,86.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.178 | Acc: 49.614,74.598,86.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.179 | Acc: 49.545,74.596,86.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.189 | Acc: 49.469,74.491,86.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.197 | Acc: 49.377,74.421,86.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.197 | Acc: 49.418,74.411,86.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.198 | Acc: 49.384,74.368,86.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.194 | Acc: 49.444,74.394,86.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.196 | Acc: 49.481,74.409,85.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.180 | Acc: 46.094,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.395 | Acc: 45.499,64.955,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.413 | Acc: 45.027,63.986,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.433 | Acc: 45.210,63.986,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 3.497 | Acc: 41.406,69.531,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.171 | Acc: 49.963,74.554,85.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.153 | Acc: 50.019,74.829,86.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.144 | Acc: 50.064,74.834,86.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.160 | Acc: 49.826,74.923,86.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.158 | Acc: 49.830,74.838,86.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.153 | Acc: 50.071,75.026,86.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.141 | Acc: 50.022,75.310,86.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.158 | Acc: 49.767,75.024,86.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.157 | Acc: 49.780,75.095,86.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.163 | Acc: 49.658,74.981,86.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.156 | Acc: 49.692,75.124,86.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.158 | Acc: 49.582,75.088,86.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.162 | Acc: 49.617,75.027,86.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.161 | Acc: 49.733,74.958,86.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.164 | Acc: 49.707,74.868,86.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.161 | Acc: 49.681,74.903,86.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.164 | Acc: 49.684,74.865,86.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.165 | Acc: 49.643,74.896,86.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.168 | Acc: 49.586,74.873,86.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.223 | Acc: 47.656,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.432 | Acc: 46.131,65.439,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.459 | Acc: 45.179,64.234,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.473 | Acc: 45.210,64.203,69.237,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 3.189 | Acc: 41.406,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.109 | Acc: 49.702,76.190,87.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.086 | Acc: 50.305,75.991,87.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.107 | Acc: 50.359,75.743,87.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.110 | Acc: 50.222,75.511,87.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.134 | Acc: 49.783,75.255,86.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.152 | Acc: 49.464,75.077,86.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.160 | Acc: 49.523,75.133,86.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.147 | Acc: 49.816,75.097,86.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.168 | Acc: 49.534,74.888,86.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.159 | Acc: 49.448,75.031,86.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.158 | Acc: 49.519,74.996,86.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.162 | Acc: 49.449,74.935,86.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.167 | Acc: 49.473,74.913,86.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.166 | Acc: 49.436,74.905,86.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.165 | Acc: 49.323,74.852,86.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.167 | Acc: 49.387,74.810,86.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.166 | Acc: 49.478,74.824,86.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.160 | Acc: 49.563,74.959,86.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.164 | Acc: 49.584,74.889,86.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.177 | Acc: 49.219,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.393 | Acc: 46.317,65.253,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.421 | Acc: 45.065,64.405,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.430 | Acc: 45.300,64.408,69.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 3.110 | Acc: 44.531,82.812,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.140 | Acc: 48.698,76.079,87.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.106 | Acc: 49.295,75.762,87.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.097 | Acc: 49.872,75.820,87.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.088 | Acc: 50.029,75.733,86.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.104 | Acc: 49.838,75.480,87.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.102 | Acc: 49.910,75.549,87.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.116 | Acc: 49.762,75.399,86.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.118 | Acc: 49.869,75.359,86.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.120 | Acc: 49.741,75.229,86.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.136 | Acc: 49.627,75.086,86.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.139 | Acc: 49.654,75.103,86.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.145 | Acc: 49.585,75.029,86.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.139 | Acc: 49.623,75.105,86.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.148 | Acc: 49.483,75.056,86.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.144 | Acc: 49.541,75.034,86.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.139 | Acc: 49.693,75.151,86.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.137 | Acc: 49.720,75.144,86.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.142 | Acc: 49.662,75.058,86.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.143 | Acc: 49.627,75.053,86.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.113 | Acc: 44.531,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.390 | Acc: 45.573,65.104,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.403 | Acc: 45.122,64.386,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.421 | Acc: 45.248,64.588,69.685,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 2.894 | Acc: 53.125,76.562,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.001 | Acc: 50.074,75.967,88.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.053 | Acc: 49.428,75.877,87.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.063 | Acc: 49.846,75.717,87.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.103 | Acc: 49.556,75.231,87.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.098 | Acc: 49.575,75.294,87.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.115 | Acc: 49.516,75.232,86.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.120 | Acc: 49.662,75.172,86.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.124 | Acc: 49.384,75.175,87.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.125 | Acc: 49.491,75.341,86.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.133 | Acc: 49.366,75.412,86.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.123 | Acc: 49.434,75.445,86.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.122 | Acc: 49.384,75.493,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.119 | Acc: 49.527,75.518,86.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.118 | Acc: 49.594,75.431,86.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.121 | Acc: 49.517,75.371,86.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.126 | Acc: 49.445,75.309,86.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.123 | Acc: 49.560,75.341,86.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.121 | Acc: 49.641,75.407,86.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.122 | Acc: 49.735,75.342,86.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.155 | Acc: 42.969,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.421 | Acc: 45.126,64.695,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.437 | Acc: 44.760,63.624,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.455 | Acc: 44.890,63.845,69.390,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 3.123 | Acc: 47.656,75.000,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.011 | Acc: 50.260,75.707,88.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.045 | Acc: 49.790,75.572,88.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.019 | Acc: 50.192,76.089,88.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 50.280,75.694,88.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.055 | Acc: 50.255,75.425,87.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.048 | Acc: 50.562,75.517,87.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.051 | Acc: 50.510,75.454,87.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.052 | Acc: 50.500,75.485,87.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.053 | Acc: 50.561,75.557,87.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.067 | Acc: 50.478,75.389,87.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.076 | Acc: 50.297,75.325,87.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.085 | Acc: 50.289,75.308,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.089 | Acc: 50.156,75.266,87.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.091 | Acc: 50.139,75.259,87.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.087 | Acc: 50.182,75.319,87.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.093 | Acc: 50.102,75.224,87.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.092 | Acc: 50.069,75.229,87.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.095 | Acc: 49.989,75.188,87.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.096 | Acc: 49.977,75.187,87.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.195 | Acc: 43.750,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 45.647,65.365,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.423 | Acc: 45.408,64.444,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.444 | Acc: 45.479,64.293,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 3.548 | Acc: 46.094,73.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.187 | Acc: 48.624,73.326,86.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.102 | Acc: 49.352,74.257,87.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.070 | Acc: 49.565,75.435,88.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.045 | Acc: 49.952,75.627,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.051 | Acc: 50.139,75.425,88.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.060 | Acc: 50.226,75.523,88.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.062 | Acc: 50.299,75.637,88.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.072 | Acc: 50.112,75.529,87.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.065 | Acc: 50.224,75.544,87.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.073 | Acc: 50.035,75.490,87.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.082 | Acc: 49.919,75.293,87.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.087 | Acc: 49.922,75.337,87.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.086 | Acc: 49.904,75.305,87.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.091 | Acc: 49.905,75.289,87.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.093 | Acc: 49.818,75.291,87.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.096 | Acc: 49.718,75.212,87.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.092 | Acc: 49.796,75.222,87.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.091 | Acc: 49.881,75.193,87.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.092 | Acc: 49.863,75.199,87.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.155 | Acc: 45.312,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.469 | Acc: 45.685,65.104,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.481 | Acc: 44.607,64.196,69.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.492 | Acc: 44.864,64.460,69.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 2.840 | Acc: 52.344,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.017 | Acc: 51.079,75.707,88.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.039 | Acc: 50.743,75.953,87.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.072 | Acc: 50.640,75.820,87.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.057 | Acc: 50.945,75.839,87.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.063 | Acc: 50.696,75.774,87.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.057 | Acc: 50.814,75.691,87.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.065 | Acc: 50.587,75.654,87.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.069 | Acc: 50.529,75.505,87.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.070 | Acc: 50.410,75.509,87.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.079 | Acc: 50.257,75.490,87.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.083 | Acc: 50.124,75.417,87.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.080 | Acc: 50.104,75.431,87.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.077 | Acc: 50.204,75.485,87.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.074 | Acc: 50.178,75.500,87.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.070 | Acc: 50.215,75.472,87.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.073 | Acc: 50.117,75.404,87.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.079 | Acc: 49.998,75.346,87.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.081 | Acc: 49.991,75.296,87.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.082 | Acc: 49.988,75.256,87.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.185 | Acc: 46.094,65.625,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.465 | Acc: 45.759,64.435,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.467 | Acc: 45.503,63.643,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 45.530,64.101,69.403,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 3.169 | Acc: 53.125,74.219,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.004 | Acc: 51.637,75.335,87.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.004 | Acc: 51.391,75.762,87.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.023 | Acc: 50.679,75.832,88.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.017 | Acc: 50.453,75.897,88.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.019 | Acc: 50.410,75.797,88.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.031 | Acc: 50.303,75.814,88.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.049 | Acc: 49.934,75.754,88.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.062 | Acc: 49.840,75.645,87.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.063 | Acc: 49.689,75.712,87.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.073 | Acc: 49.697,75.649,87.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.078 | Acc: 49.731,75.523,87.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.071 | Acc: 49.718,75.648,87.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.074 | Acc: 49.710,75.476,87.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.065 | Acc: 49.783,75.589,87.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.067 | Acc: 49.764,75.449,87.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.067 | Acc: 49.757,75.499,87.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.073 | Acc: 49.757,75.477,87.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.073 | Acc: 49.864,75.461,87.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.069 | Acc: 49.926,75.523,87.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.265 | Acc: 40.625,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.531 | Acc: 45.164,64.286,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.534 | Acc: 44.150,63.472,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.539 | Acc: 44.506,63.755,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 3.119 | Acc: 53.125,72.656,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.984 | Acc: 49.814,77.195,89.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.039 | Acc: 49.466,76.372,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.048 | Acc: 49.462,75.986,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.047 | Acc: 49.701,76.042,88.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.057 | Acc: 50.039,75.866,88.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.051 | Acc: 50.045,75.833,88.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.057 | Acc: 50.006,75.593,88.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.054 | Acc: 50.194,75.607,88.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.064 | Acc: 50.069,75.440,87.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.056 | Acc: 50.245,75.618,88.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.053 | Acc: 50.382,75.569,88.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.052 | Acc: 50.373,75.603,88.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.051 | Acc: 50.320,75.644,88.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.053 | Acc: 50.247,75.595,88.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.055 | Acc: 50.174,75.555,88.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.052 | Acc: 50.097,75.638,88.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.047 | Acc: 50.135,75.660,88.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.050 | Acc: 50.113,75.599,88.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.051 | Acc: 50.084,75.597,88.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.458 | Acc: 42.188,64.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.647 | Acc: 44.010,63.728,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.663 | Acc: 43.140,62.976,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.671 | Acc: 43.417,63.102,68.699,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 2.996 | Acc: 47.656,77.344,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.055 | Acc: 49.405,75.335,89.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.025 | Acc: 49.714,75.915,88.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 50.077,76.114,88.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.015 | Acc: 49.971,76.100,88.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.000 | Acc: 50.186,76.191,88.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.996 | Acc: 50.052,76.259,88.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.003 | Acc: 49.889,76.341,88.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.014 | Acc: 49.845,76.097,88.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.023 | Acc: 49.901,75.945,88.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.040 | Acc: 49.720,75.808,88.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.036 | Acc: 49.784,75.887,88.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.040 | Acc: 49.669,75.801,88.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.034 | Acc: 49.799,75.838,88.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.036 | Acc: 49.794,75.803,88.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.028 | Acc: 49.891,75.911,88.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.029 | Acc: 49.890,75.942,88.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.030 | Acc: 49.895,75.916,88.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.031 | Acc: 49.916,75.900,88.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.033 | Acc: 49.912,75.921,88.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.204 | Acc: 46.875,68.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.463 | Acc: 46.205,64.918,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.476 | Acc: 45.446,64.253,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.493 | Acc: 45.453,64.395,68.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 3.225 | Acc: 51.562,74.219,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.985 | Acc: 50.744,76.674,87.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.983 | Acc: 50.438,76.562,88.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.975 | Acc: 50.551,76.575,88.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.990 | Acc: 50.733,76.013,88.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.987 | Acc: 50.797,76.137,88.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.989 | Acc: 50.717,76.420,88.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.001 | Acc: 50.371,76.285,88.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.010 | Acc: 50.296,76.266,88.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.021 | Acc: 50.194,76.045,88.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.022 | Acc: 50.128,76.014,88.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.024 | Acc: 50.216,75.972,88.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.023 | Acc: 50.084,75.969,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.026 | Acc: 50.102,76.003,88.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.029 | Acc: 50.092,75.981,88.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.024 | Acc: 50.202,76.004,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.026 | Acc: 50.246,76.047,88.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.031 | Acc: 50.199,76.029,88.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.031 | Acc: 50.193,76.037,88.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.032 | Acc: 50.100,76.058,88.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.097 | Acc: 45.312,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.459 | Acc: 46.280,64.918,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.464 | Acc: 45.446,64.463,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.481 | Acc: 45.581,64.370,68.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 2.589 | Acc: 58.594,74.219,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 49.479,76.637,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.006 | Acc: 48.971,76.372,88.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.998 | Acc: 49.321,76.063,88.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.996 | Acc: 49.691,76.186,88.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.993 | Acc: 49.876,76.245,88.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.998 | Acc: 50.220,76.298,88.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.983 | Acc: 50.382,76.430,88.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.008 | Acc: 50.126,76.102,88.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.013 | Acc: 50.168,76.027,88.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.010 | Acc: 50.237,75.987,88.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.012 | Acc: 50.311,75.979,88.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.016 | Acc: 50.156,75.943,88.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.010 | Acc: 50.153,76.018,88.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.010 | Acc: 50.092,75.987,88.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.013 | Acc: 50.086,75.973,88.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.013 | Acc: 50.131,75.947,88.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.014 | Acc: 50.165,75.939,88.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.014 | Acc: 50.171,75.911,88.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.016 | Acc: 50.166,75.841,88.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.239 | Acc: 44.531,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.500 | Acc: 45.945,64.137,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.503 | Acc: 45.122,63.567,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.514 | Acc: 45.287,63.858,68.763,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 3.008 | Acc: 51.562,75.000,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.999 | Acc: 51.414,75.558,88.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.003 | Acc: 50.781,75.800,89.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.001 | Acc: 50.589,75.730,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.015 | Acc: 50.280,75.685,88.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.006 | Acc: 50.379,75.750,88.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.003 | Acc: 50.362,75.794,88.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.004 | Acc: 50.305,75.914,88.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.000 | Acc: 50.281,76.004,88.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.008 | Acc: 50.246,75.967,88.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.011 | Acc: 50.163,75.921,88.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.014 | Acc: 50.064,75.912,88.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.011 | Acc: 50.139,75.872,88.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.019 | Acc: 50.009,75.898,88.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.021 | Acc: 50.120,75.867,88.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.020 | Acc: 50.176,75.862,88.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.022 | Acc: 50.127,75.837,88.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.019 | Acc: 50.121,75.850,88.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.018 | Acc: 50.184,75.859,88.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.016 | Acc: 50.176,75.857,88.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.309 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 45.759,64.360,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 44.607,63.434,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 44.621,63.742,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 3.110 | Acc: 57.031,75.781,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.023 | Acc: 49.033,76.004,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.031 | Acc: 49.733,76.010,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 49.757,76.178,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.004 | Acc: 50.289,76.360,89.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.007 | Acc: 50.170,76.346,89.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.012 | Acc: 50.084,76.175,89.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.011 | Acc: 50.033,76.225,89.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.001 | Acc: 50.199,76.325,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.003 | Acc: 50.151,76.260,89.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.996 | Acc: 50.148,76.325,88.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.998 | Acc: 50.216,76.312,88.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.998 | Acc: 50.207,76.284,88.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.998 | Acc: 50.147,76.275,88.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.995 | Acc: 50.156,76.304,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.992 | Acc: 50.239,76.386,88.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.991 | Acc: 50.226,76.416,88.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.001 | Acc: 50.176,76.281,88.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.002 | Acc: 50.216,76.270,88.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.002 | Acc: 50.189,76.251,88.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 41.406,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.508 | Acc: 44.680,65.067,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.516 | Acc: 44.836,64.253,69.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.521 | Acc: 45.044,64.127,69.096,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 2.855 | Acc: 53.125,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.945 | Acc: 49.628,77.493,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.958 | Acc: 50.229,76.791,89.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.963 | Acc: 50.231,76.294,89.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.976 | Acc: 50.251,76.148,89.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.977 | Acc: 50.062,76.067,89.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.973 | Acc: 50.252,76.272,89.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.984 | Acc: 50.083,76.241,89.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.978 | Acc: 50.126,76.247,89.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.982 | Acc: 50.082,76.200,89.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.983 | Acc: 50.062,76.294,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.981 | Acc: 50.064,76.312,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.973 | Acc: 50.246,76.400,89.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.968 | Acc: 50.392,76.395,89.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.971 | Acc: 50.373,76.371,89.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.971 | Acc: 50.322,76.389,89.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.974 | Acc: 50.360,76.385,89.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.975 | Acc: 50.444,76.301,89.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.974 | Acc: 50.428,76.329,89.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.979 | Acc: 50.367,76.286,89.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.109 | Acc: 44.531,69.531,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.477 | Acc: 45.796,64.621,69.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.532 | Acc: 45.084,63.529,68.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.536 | Acc: 45.056,63.589,68.814,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 2.921 | Acc: 45.312,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.925 | Acc: 50.595,76.674,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.953 | Acc: 49.695,76.200,89.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.977 | Acc: 49.744,76.524,89.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.987 | Acc: 49.653,76.196,89.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 49.667,76.168,89.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.974 | Acc: 49.851,76.117,89.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.971 | Acc: 49.983,76.125,89.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.964 | Acc: 50.286,76.286,89.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.966 | Acc: 50.237,76.278,89.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.963 | Acc: 50.179,76.341,89.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.963 | Acc: 50.265,76.315,89.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.965 | Acc: 50.301,76.258,89.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.967 | Acc: 50.356,76.257,89.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.964 | Acc: 50.420,76.293,89.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.968 | Acc: 50.428,76.251,89.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.970 | Acc: 50.467,76.197,89.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.972 | Acc: 50.389,76.239,89.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.971 | Acc: 50.452,76.242,89.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.977 | Acc: 50.306,76.210,89.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.246 | Acc: 43.750,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 45.164,65.141,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.533 | Acc: 44.646,64.120,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.550 | Acc: 44.762,64.127,68.622,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 2.844 | Acc: 47.656,79.688,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.920 | Acc: 50.186,77.083,89.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.919 | Acc: 50.343,77.172,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.907 | Acc: 50.333,76.985,89.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.917 | Acc: 50.395,76.852,89.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.922 | Acc: 50.317,76.485,89.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.910 | Acc: 50.529,76.730,89.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.901 | Acc: 50.737,76.900,89.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.911 | Acc: 50.505,76.727,89.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.925 | Acc: 50.496,76.632,89.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.928 | Acc: 50.466,76.644,89.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.940 | Acc: 50.488,76.467,89.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.945 | Acc: 50.376,76.456,89.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.946 | Acc: 50.389,76.515,89.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.951 | Acc: 50.364,76.496,89.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.954 | Acc: 50.218,76.441,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.961 | Acc: 50.197,76.351,89.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.964 | Acc: 50.142,76.329,89.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.961 | Acc: 50.184,76.387,89.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.966 | Acc: 50.191,76.310,89.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.349 | Acc: 46.094,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.587 | Acc: 45.015,65.216,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 44.493,63.891,69.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.619 | Acc: 44.480,63.896,68.929,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 3.071 | Acc: 50.781,77.344,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.952 | Acc: 51.228,76.600,89.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.960 | Acc: 51.010,76.467,89.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.928 | Acc: 51.268,76.870,89.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.907 | Acc: 51.852,77.006,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.925 | Acc: 51.385,76.570,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.921 | Acc: 51.233,76.892,89.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.924 | Acc: 51.086,76.912,89.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.931 | Acc: 50.708,76.834,89.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 50.436,76.856,89.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.949 | Acc: 50.346,76.687,89.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.951 | Acc: 50.318,76.785,89.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.946 | Acc: 50.415,76.815,89.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.956 | Acc: 50.320,76.655,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.954 | Acc: 50.320,76.671,89.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.952 | Acc: 50.296,76.674,89.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.955 | Acc: 50.253,76.584,89.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.954 | Acc: 50.321,76.581,89.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.956 | Acc: 50.299,76.554,89.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.962 | Acc: 50.246,76.446,89.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.274 | Acc: 45.312,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 44.866,63.914,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 44.665,63.700,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.626 | Acc: 44.723,63.781,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 3.329 | Acc: 45.312,71.875,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.923 | Acc: 49.665,77.790,90.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.926 | Acc: 49.886,77.534,90.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.936 | Acc: 50.141,77.305,89.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.926 | Acc: 50.116,77.247,89.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.926 | Acc: 50.015,77.174,89.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.935 | Acc: 49.897,77.085,89.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.937 | Acc: 50.006,77.000,89.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.943 | Acc: 49.937,76.849,89.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.952 | Acc: 49.948,76.778,89.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.952 | Acc: 49.969,76.807,89.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.957 | Acc: 49.982,76.707,89.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.962 | Acc: 49.955,76.708,89.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.962 | Acc: 50.024,76.607,89.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.959 | Acc: 50.106,76.682,89.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.958 | Acc: 50.158,76.695,89.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.957 | Acc: 50.165,76.628,89.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.960 | Acc: 50.163,76.599,89.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.958 | Acc: 50.158,76.547,89.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.956 | Acc: 50.178,76.622,89.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.295 | Acc: 44.531,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 44.568,64.546,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.643 | Acc: 44.188,63.700,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 44.352,63.550,67.892,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 2.743 | Acc: 46.094,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.922 | Acc: 50.112,77.158,89.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 50.896,77.687,90.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.903 | Acc: 50.589,77.228,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.925 | Acc: 50.309,77.074,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.921 | Acc: 50.449,76.996,89.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.942 | Acc: 50.252,76.795,89.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.940 | Acc: 50.222,76.768,89.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.933 | Acc: 50.306,76.795,89.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.931 | Acc: 50.501,76.727,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.937 | Acc: 50.381,76.551,89.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.928 | Acc: 50.456,76.637,89.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.929 | Acc: 50.567,76.627,89.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.931 | Acc: 50.464,76.586,89.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.932 | Acc: 50.434,76.596,89.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.932 | Acc: 50.504,76.643,89.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.940 | Acc: 50.431,76.570,89.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.939 | Acc: 50.513,76.567,89.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.938 | Acc: 50.513,76.567,89.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.942 | Acc: 50.474,76.548,89.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.269 | Acc: 42.188,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.611 | Acc: 45.461,64.211,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.634 | Acc: 44.817,63.281,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 44.864,63.384,67.918,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 3.212 | Acc: 42.188,75.781,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.847 | Acc: 51.972,77.493,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.904 | Acc: 50.724,76.772,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.885 | Acc: 51.332,76.844,90.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.899 | Acc: 50.810,76.861,90.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.896 | Acc: 50.758,76.833,90.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.918 | Acc: 50.626,76.659,90.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.921 | Acc: 50.598,76.751,89.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.927 | Acc: 50.495,76.776,89.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.924 | Acc: 50.565,76.800,89.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.926 | Acc: 50.571,76.757,89.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.921 | Acc: 50.703,76.743,89.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.926 | Acc: 50.606,76.673,89.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.933 | Acc: 50.545,76.652,89.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.935 | Acc: 50.478,76.629,89.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.933 | Acc: 50.644,76.653,89.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.935 | Acc: 50.538,76.640,89.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.943 | Acc: 50.461,76.553,89.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.937 | Acc: 50.530,76.669,89.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.937 | Acc: 50.470,76.681,89.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.249 | Acc: 45.312,67.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.527 | Acc: 46.019,64.546,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.537 | Acc: 44.950,63.796,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.554 | Acc: 45.415,64.037,69.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 3.083 | Acc: 45.312,80.469,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.881 | Acc: 51.600,77.939,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.892 | Acc: 51.334,77.896,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.918 | Acc: 50.922,77.446,90.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.915 | Acc: 50.926,77.402,90.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.931 | Acc: 50.634,77.112,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.937 | Acc: 50.600,77.073,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.931 | Acc: 50.826,77.078,89.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.928 | Acc: 50.694,77.150,89.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.938 | Acc: 50.574,76.882,90.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.932 | Acc: 50.556,76.943,89.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.929 | Acc: 50.534,76.958,89.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.926 | Acc: 50.558,76.935,89.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.926 | Acc: 50.659,76.973,89.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.930 | Acc: 50.606,76.938,89.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.932 | Acc: 50.584,76.866,89.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.931 | Acc: 50.511,76.879,89.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.934 | Acc: 50.440,76.870,89.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.934 | Acc: 50.335,76.872,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.932 | Acc: 50.336,76.893,89.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 42.969,67.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 44.382,64.137,68.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 43.979,63.605,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.680 | Acc: 44.045,63.512,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 2.995 | Acc: 54.688,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 50.037,76.935,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.890 | Acc: 50.286,77.020,90.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.887 | Acc: 50.013,77.446,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.904 | Acc: 50.260,77.228,90.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.919 | Acc: 49.985,77.011,90.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.912 | Acc: 50.039,77.111,90.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.913 | Acc: 50.161,77.050,90.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.910 | Acc: 50.175,76.946,90.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.923 | Acc: 50.151,76.891,90.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.933 | Acc: 50.070,76.862,90.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.938 | Acc: 50.092,76.891,90.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.933 | Acc: 50.130,76.926,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.936 | Acc: 50.093,76.862,89.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.929 | Acc: 50.117,76.868,89.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.930 | Acc: 50.075,76.830,89.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.927 | Acc: 50.158,76.913,89.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.927 | Acc: 50.176,76.931,89.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.927 | Acc: 50.240,76.876,89.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.925 | Acc: 50.271,76.845,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.003 | Acc: 43.750,67.969,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.533 | Acc: 45.387,64.472,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.535 | Acc: 44.760,63.605,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.560 | Acc: 44.954,63.691,68.584,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 2.730 | Acc: 46.875,75.000,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.912 | Acc: 50.223,76.674,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.910 | Acc: 50.838,76.467,89.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.913 | Acc: 50.820,76.985,89.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.905 | Acc: 50.752,77.334,89.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.898 | Acc: 50.797,77.514,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.901 | Acc: 50.788,77.331,89.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.899 | Acc: 50.759,77.311,89.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.888 | Acc: 50.801,77.397,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 50.794,77.348,89.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.885 | Acc: 50.875,77.317,89.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 50.739,77.188,89.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.896 | Acc: 50.690,77.169,89.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.899 | Acc: 50.772,77.233,89.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.896 | Acc: 50.753,77.233,89.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.901 | Acc: 50.664,77.170,89.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.903 | Acc: 50.691,77.132,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.898 | Acc: 50.683,77.117,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.906 | Acc: 50.548,77.069,89.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.906 | Acc: 50.519,77.055,89.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.303 | Acc: 43.750,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 44.978,64.807,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.647 | Acc: 44.474,63.777,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 44.531,63.819,68.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 2.803 | Acc: 51.562,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.942 | Acc: 50.446,75.632,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.862 | Acc: 51.582,77.268,90.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.867 | Acc: 51.703,77.100,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.878 | Acc: 51.418,77.103,90.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.873 | Acc: 51.168,77.290,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.871 | Acc: 51.207,77.228,90.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.875 | Acc: 51.169,77.144,90.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 50.990,77.208,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.886 | Acc: 50.889,77.080,90.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.885 | Acc: 50.972,77.037,90.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 50.852,77.093,90.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.882 | Acc: 50.814,77.107,90.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.889 | Acc: 50.668,77.050,90.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.888 | Acc: 50.778,77.074,90.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.892 | Acc: 50.753,76.941,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.898 | Acc: 50.657,76.859,90.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.902 | Acc: 50.639,76.821,90.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.905 | Acc: 50.578,76.772,90.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.910 | Acc: 50.500,76.786,89.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.209 | Acc: 42.188,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.602 | Acc: 45.350,64.807,68.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.587 | Acc: 45.046,64.139,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.591 | Acc: 45.223,64.229,68.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 3.196 | Acc: 42.969,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.905 | Acc: 50.707,75.781,90.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 50.781,76.810,90.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.888 | Acc: 50.704,76.383,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.890 | Acc: 50.637,76.582,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.907 | Acc: 50.410,76.423,90.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.897 | Acc: 50.555,76.466,90.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.891 | Acc: 50.582,76.524,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.878 | Acc: 50.713,76.810,90.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.883 | Acc: 50.600,76.679,90.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.888 | Acc: 50.579,76.667,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.890 | Acc: 50.661,76.775,90.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.886 | Acc: 50.788,76.880,90.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.888 | Acc: 50.772,76.841,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.888 | Acc: 50.798,76.885,90.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.888 | Acc: 50.760,76.882,90.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 50.681,76.840,90.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.904 | Acc: 50.589,76.743,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.906 | Acc: 50.584,76.675,89.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.908 | Acc: 50.533,76.638,89.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.339 | Acc: 42.188,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.573 | Acc: 45.387,64.435,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.588 | Acc: 44.741,63.777,68.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 44.736,63.742,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 2.877 | Acc: 45.312,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.869 | Acc: 50.744,78.013,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.881 | Acc: 50.343,77.229,90.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.882 | Acc: 50.282,77.536,90.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.879 | Acc: 50.386,77.807,90.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.906 | Acc: 50.062,77.375,90.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.900 | Acc: 50.213,77.428,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.903 | Acc: 50.344,77.277,90.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.907 | Acc: 50.412,77.227,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.897 | Acc: 50.630,77.175,90.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.891 | Acc: 50.742,77.212,90.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.896 | Acc: 50.636,77.199,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.897 | Acc: 50.674,77.140,90.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.900 | Acc: 50.521,77.146,90.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.903 | Acc: 50.453,77.094,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.901 | Acc: 50.405,77.061,90.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.896 | Acc: 50.516,77.117,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.894 | Acc: 50.580,77.122,90.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.894 | Acc: 50.532,77.130,90.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.890 | Acc: 50.580,77.180,90.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.273 | Acc: 42.188,69.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.667 | Acc: 44.680,64.360,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.682 | Acc: 43.807,63.338,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.690 | Acc: 43.993,63.345,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 2.758 | Acc: 56.250,77.344,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.862 | Acc: 50.670,78.162,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.880 | Acc: 50.667,76.848,90.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.840 | Acc: 51.242,77.139,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.821 | Acc: 51.630,77.537,90.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.847 | Acc: 51.346,77.406,90.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.851 | Acc: 51.175,77.266,90.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.850 | Acc: 50.964,77.366,90.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.858 | Acc: 50.970,77.310,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.864 | Acc: 50.799,77.309,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.873 | Acc: 50.653,77.223,90.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.881 | Acc: 50.555,77.146,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 50.580,77.110,90.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.890 | Acc: 50.419,77.050,90.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.891 | Acc: 50.373,77.016,90.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.890 | Acc: 50.358,77.063,90.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.887 | Acc: 50.377,77.142,90.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.888 | Acc: 50.417,77.147,90.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.896 | Acc: 50.325,77.008,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.893 | Acc: 50.412,77.016,90.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.149 | Acc: 46.875,67.969,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.534 | Acc: 46.503,64.509,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.521 | Acc: 46.113,64.024,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.543 | Acc: 45.812,63.870,68.545,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 2.808 | Acc: 48.438,76.562,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.787 | Acc: 51.562,77.865,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.792 | Acc: 51.486,77.649,91.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.837 | Acc: 51.165,77.459,90.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.853 | Acc: 50.801,77.517,90.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.859 | Acc: 50.596,77.344,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.860 | Acc: 50.620,77.447,90.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.863 | Acc: 50.604,77.366,90.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.867 | Acc: 50.592,77.387,90.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.879 | Acc: 50.432,77.236,90.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.893 | Acc: 50.303,77.142,90.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.892 | Acc: 50.354,77.072,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.884 | Acc: 50.551,77.091,90.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.894 | Acc: 50.449,77.009,90.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.893 | Acc: 50.417,76.952,90.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.895 | Acc: 50.478,76.913,90.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.899 | Acc: 50.499,76.889,90.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.892 | Acc: 50.568,76.993,90.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.892 | Acc: 50.630,76.978,90.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.895 | Acc: 50.580,76.911,90.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 42.969,64.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.684 | Acc: 45.126,63.765,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.701 | Acc: 44.512,63.148,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.707 | Acc: 44.557,63.384,67.623,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 2.770 | Acc: 50.781,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.904 | Acc: 48.326,77.679,90.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.901 | Acc: 49.447,77.172,90.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.875 | Acc: 50.589,77.344,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.871 | Acc: 50.598,77.353,90.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.877 | Acc: 50.387,77.274,90.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.870 | Acc: 50.465,77.318,90.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.868 | Acc: 50.449,77.432,90.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.871 | Acc: 50.582,77.373,90.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.859 | Acc: 50.824,77.421,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.851 | Acc: 50.855,77.558,90.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 50.877,77.446,90.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.861 | Acc: 50.661,77.370,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.873 | Acc: 50.464,77.266,90.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.872 | Acc: 50.534,77.238,90.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.871 | Acc: 50.615,77.284,90.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.872 | Acc: 50.601,77.332,90.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.872 | Acc: 50.548,77.335,90.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.876 | Acc: 50.467,77.240,90.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.879 | Acc: 50.435,77.157,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.208 | Acc: 44.531,68.750,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.619 | Acc: 46.280,64.769,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.607 | Acc: 45.351,64.043,68.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.616 | Acc: 45.351,63.922,68.750,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 3.139 | Acc: 50.781,71.875,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 51.972,78.088,90.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.842 | Acc: 52.001,78.049,90.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.853 | Acc: 51.511,77.677,90.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.834 | Acc: 51.794,77.787,91.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.839 | Acc: 51.648,77.653,90.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.834 | Acc: 51.408,77.738,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.843 | Acc: 51.169,77.554,90.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.844 | Acc: 51.145,77.577,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.852 | Acc: 50.997,77.577,90.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.856 | Acc: 51.014,77.480,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.859 | Acc: 50.993,77.450,90.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.861 | Acc: 50.985,77.347,90.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.862 | Acc: 51.024,77.308,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.864 | Acc: 50.993,77.319,90.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.864 | Acc: 50.976,77.253,90.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.870 | Acc: 50.888,77.242,90.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.867 | Acc: 50.832,77.204,90.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.869 | Acc: 50.760,77.214,90.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.870 | Acc: 50.753,77.182,90.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.402 | Acc: 44.531,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.707 | Acc: 45.312,64.955,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.712 | Acc: 44.360,63.472,67.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.710 | Acc: 44.339,63.512,67.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 2.847 | Acc: 50.000,76.562,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.785 | Acc: 50.223,78.311,90.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.810 | Acc: 50.819,77.820,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.822 | Acc: 50.922,77.805,90.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 50.714,77.778,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.825 | Acc: 50.650,77.599,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.823 | Acc: 50.717,77.738,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.828 | Acc: 50.621,77.682,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.828 | Acc: 50.776,77.645,91.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.830 | Acc: 50.816,77.659,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.841 | Acc: 50.649,77.472,90.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.852 | Acc: 50.654,77.365,90.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.862 | Acc: 50.665,77.311,90.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.869 | Acc: 50.614,77.233,90.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.878 | Acc: 50.537,77.080,90.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.877 | Acc: 50.553,77.123,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.880 | Acc: 50.523,77.142,90.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.881 | Acc: 50.509,77.117,90.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.878 | Acc: 50.550,77.140,90.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.876 | Acc: 50.621,77.190,90.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.160 | Acc: 46.875,72.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 44.903,63.951,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 44.665,63.243,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 44.570,63.320,67.636,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 2.898 | Acc: 50.000,80.469,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.877 | Acc: 50.744,77.530,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.817 | Acc: 51.086,77.877,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 50.397,77.856,91.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.831 | Acc: 50.511,77.797,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.824 | Acc: 50.526,77.847,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.839 | Acc: 50.297,77.744,91.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.841 | Acc: 50.288,77.765,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.856 | Acc: 50.116,77.649,90.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.856 | Acc: 50.237,77.624,91.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.852 | Acc: 50.486,77.651,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.853 | Acc: 50.484,77.605,90.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.855 | Acc: 50.593,77.538,90.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.857 | Acc: 50.647,77.526,90.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.857 | Acc: 50.645,77.483,90.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.856 | Acc: 50.605,77.564,90.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.864 | Acc: 50.584,77.478,90.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.864 | Acc: 50.612,77.438,90.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.858 | Acc: 50.686,77.450,90.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 50.634,77.286,90.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.571 | Acc: 42.969,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.810 | Acc: 44.568,63.728,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.815 | Acc: 43.559,62.976,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 43.148,62.999,67.431,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 3.313 | Acc: 45.312,74.219,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 51.562,78.460,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.767 | Acc: 51.429,78.659,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.803 | Acc: 50.756,77.830,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.811 | Acc: 50.801,77.421,91.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.817 | Acc: 50.920,77.437,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.828 | Acc: 50.826,77.337,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.839 | Acc: 50.837,77.250,90.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.838 | Acc: 50.922,77.378,90.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.845 | Acc: 50.906,77.318,90.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.847 | Acc: 50.808,77.293,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.847 | Acc: 50.749,77.277,90.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.851 | Acc: 50.541,77.159,90.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.851 | Acc: 50.551,77.221,90.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 50.612,77.208,90.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.849 | Acc: 50.680,77.258,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.859 | Acc: 50.606,77.193,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.859 | Acc: 50.623,77.284,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.862 | Acc: 50.589,77.246,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.864 | Acc: 50.558,77.217,90.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.392 | Acc: 42.969,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.618 | Acc: 45.759,65.476,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.615 | Acc: 45.446,64.425,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.634 | Acc: 45.338,64.383,68.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 3.048 | Acc: 55.469,71.875,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.840 | Acc: 50.744,77.604,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 49.981,77.630,90.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.828 | Acc: 50.307,78.010,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 50.569,78.164,91.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.828 | Acc: 50.495,77.932,91.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.837 | Acc: 50.523,77.686,91.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.832 | Acc: 50.715,77.693,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.834 | Acc: 50.801,77.635,91.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.838 | Acc: 50.652,77.516,91.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 50.634,77.355,91.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 50.640,77.347,90.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.847 | Acc: 50.593,77.337,90.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.849 | Acc: 50.554,77.314,90.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.849 | Acc: 50.651,77.360,90.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.856 | Acc: 50.636,77.258,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.860 | Acc: 50.562,77.222,90.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.860 | Acc: 50.532,77.252,90.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.857 | Acc: 50.591,77.242,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.858 | Acc: 50.671,77.286,90.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.286 | Acc: 42.188,66.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.674 | Acc: 45.647,63.356,68.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.678 | Acc: 44.836,62.938,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.684 | Acc: 45.287,63.204,67.738,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 2.848 | Acc: 54.688,81.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 51.711,78.720,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.744 | Acc: 51.905,79.345,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.789 | Acc: 51.268,78.650,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 50.569,78.299,91.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.824 | Acc: 50.673,78.086,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.836 | Acc: 50.730,77.918,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.835 | Acc: 50.826,77.854,91.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.832 | Acc: 50.801,77.868,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.838 | Acc: 50.799,77.680,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.846 | Acc: 50.816,77.507,91.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.848 | Acc: 50.767,77.453,91.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.848 | Acc: 50.888,77.438,90.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.842 | Acc: 51.018,77.622,90.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.840 | Acc: 50.995,77.611,90.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.846 | Acc: 50.932,77.458,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.847 | Acc: 50.927,77.412,90.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.849 | Acc: 50.916,77.406,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.856 | Acc: 50.790,77.400,90.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.855 | Acc: 50.726,77.430,90.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.418 | Acc: 43.750,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.764 | Acc: 43.713,64.062,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.745 | Acc: 43.769,63.491,67.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.760 | Acc: 43.712,63.422,67.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 2.942 | Acc: 50.000,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.855 | Acc: 49.368,77.753,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.827 | Acc: 49.771,78.277,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.821 | Acc: 50.077,78.087,91.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.820 | Acc: 50.492,78.067,91.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.812 | Acc: 50.650,77.955,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.821 | Acc: 50.491,77.925,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.834 | Acc: 50.499,77.815,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.826 | Acc: 50.626,77.814,91.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 50.764,77.831,91.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.828 | Acc: 50.793,77.814,91.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.823 | Acc: 50.901,77.909,91.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.824 | Acc: 50.979,77.791,91.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.830 | Acc: 51.015,77.682,90.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.838 | Acc: 50.940,77.536,90.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.839 | Acc: 50.937,77.572,90.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.841 | Acc: 50.847,77.526,90.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.842 | Acc: 50.852,77.534,91.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.847 | Acc: 50.818,77.463,91.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.850 | Acc: 50.677,77.438,90.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.379 | Acc: 46.875,65.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.755 | Acc: 44.792,63.318,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.776 | Acc: 43.979,62.309,67.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.789 | Acc: 43.955,62.513,67.367,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 2.851 | Acc: 50.000,76.562,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.774 | Acc: 51.116,79.278,91.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.814 | Acc: 50.438,78.354,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.833 | Acc: 50.820,78.023,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.826 | Acc: 50.878,77.990,91.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.814 | Acc: 51.106,78.133,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.815 | Acc: 51.162,77.970,91.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.831 | Acc: 50.870,77.765,90.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.835 | Acc: 50.932,77.756,90.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.834 | Acc: 51.001,77.680,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.824 | Acc: 51.135,77.802,90.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.821 | Acc: 51.241,77.920,90.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.823 | Acc: 51.177,77.930,90.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.826 | Acc: 51.027,77.877,90.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 51.056,77.836,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 51.126,77.725,90.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.829 | Acc: 51.161,77.672,90.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.832 | Acc: 51.134,77.630,90.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.835 | Acc: 51.125,77.582,90.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.836 | Acc: 51.060,77.580,90.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.150 | Acc: 44.531,67.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.719 | Acc: 45.536,64.509,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.745 | Acc: 44.284,63.548,67.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.745 | Acc: 44.147,63.563,67.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 3.088 | Acc: 47.656,76.562,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 52.604,77.418,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.820 | Acc: 51.239,76.944,91.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.816 | Acc: 51.037,77.510,91.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.805 | Acc: 50.974,77.595,91.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 51.013,77.754,91.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.811 | Acc: 51.007,77.705,91.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.814 | Acc: 50.831,77.787,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.820 | Acc: 50.937,77.703,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.825 | Acc: 50.846,77.560,91.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.822 | Acc: 50.933,77.690,91.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.824 | Acc: 50.972,77.619,91.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.826 | Acc: 51.105,77.674,91.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.825 | Acc: 51.108,77.694,91.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.832 | Acc: 50.995,77.558,91.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.831 | Acc: 50.908,77.570,91.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.831 | Acc: 50.974,77.587,91.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 50.962,77.564,91.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.841 | Acc: 50.874,77.396,90.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.845 | Acc: 50.808,77.366,90.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.364 | Acc: 42.969,66.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.749 | Acc: 44.457,63.542,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.738 | Acc: 43.960,63.091,67.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.772 | Acc: 43.852,63.102,67.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 2.521 | Acc: 55.469,82.812,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.723 | Acc: 52.865,78.237,92.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 51.886,77.382,91.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 51.639,77.766,91.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.800 | Acc: 51.784,78.135,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.807 | Acc: 51.864,77.862,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 51.834,77.983,91.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.800 | Acc: 51.574,77.870,91.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.795 | Acc: 51.451,78.091,91.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 51.265,77.922,91.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.821 | Acc: 51.065,77.806,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.820 | Acc: 51.061,77.771,91.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.824 | Acc: 51.008,77.739,91.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.829 | Acc: 51.039,77.718,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.838 | Acc: 50.834,77.669,91.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.842 | Acc: 50.859,77.647,91.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.852 | Acc: 50.801,77.524,91.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.853 | Acc: 50.749,77.509,90.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.850 | Acc: 50.768,77.521,90.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.848 | Acc: 50.816,77.629,90.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.395 | Acc: 42.969,65.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.805 | Acc: 44.568,63.542,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.818 | Acc: 43.293,62.843,66.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.824 | Acc: 43.315,62.999,67.059,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 2.679 | Acc: 46.094,77.344,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.803 | Acc: 51.190,77.158,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.798 | Acc: 50.857,76.905,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.807 | Acc: 50.845,77.126,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 50.955,77.633,91.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.808 | Acc: 50.603,77.692,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.818 | Acc: 50.452,77.634,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.818 | Acc: 50.388,77.626,91.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.810 | Acc: 50.485,77.732,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.811 | Acc: 50.427,77.737,91.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.808 | Acc: 50.424,77.810,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.811 | Acc: 50.537,77.814,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.816 | Acc: 50.561,77.694,91.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.812 | Acc: 50.656,77.775,91.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.810 | Acc: 50.676,77.794,91.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.817 | Acc: 50.657,77.730,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 50.735,77.687,91.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.815 | Acc: 50.790,77.681,91.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.825 | Acc: 50.664,77.554,91.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.831 | Acc: 50.582,77.463,91.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.401 | Acc: 43.750,67.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.745 | Acc: 45.833,63.393,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.730 | Acc: 45.122,62.900,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.729 | Acc: 45.184,63.294,67.290,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 2.657 | Acc: 53.906,78.125,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 51.228,78.943,91.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.742 | Acc: 50.819,78.620,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 50.538,78.227,91.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.798 | Acc: 50.241,77.768,91.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.809 | Acc: 50.364,77.591,91.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.800 | Acc: 50.581,77.544,91.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 50.776,77.488,91.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.820 | Acc: 50.582,77.339,91.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.836 | Acc: 50.453,77.227,90.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.843 | Acc: 50.474,77.192,90.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.838 | Acc: 50.389,77.224,91.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.834 | Acc: 50.370,77.298,91.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 50.554,77.380,91.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.837 | Acc: 50.559,77.296,91.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.837 | Acc: 50.597,77.240,91.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.837 | Acc: 50.628,77.295,91.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.835 | Acc: 50.671,77.321,91.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.835 | Acc: 50.686,77.350,91.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.834 | Acc: 50.753,77.409,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.202 | Acc: 44.531,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.631 | Acc: 46.726,65.067,68.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.639 | Acc: 46.380,63.415,67.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.651 | Acc: 45.876,63.589,67.636,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 2.869 | Acc: 50.000,78.906,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.765 | Acc: 51.637,77.902,91.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 50.667,77.706,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.769 | Acc: 51.422,78.061,91.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.769 | Acc: 51.611,77.932,91.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.768 | Acc: 51.330,78.164,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 51.182,78.319,91.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.774 | Acc: 51.236,78.175,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.778 | Acc: 51.169,78.115,91.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 51.122,78.090,91.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.789 | Acc: 50.960,78.032,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.795 | Acc: 50.944,78.040,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.792 | Acc: 51.024,78.157,91.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.796 | Acc: 50.970,78.074,91.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.796 | Acc: 50.995,78.089,91.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.800 | Acc: 50.997,78.024,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 50.964,77.945,91.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.810 | Acc: 50.910,77.891,91.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.799,77.841,91.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 50.755,77.754,91.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.328 | Acc: 43.750,72.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.794 | Acc: 44.903,63.728,67.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.791 | Acc: 44.836,62.652,66.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.795 | Acc: 44.813,62.628,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 3.161 | Acc: 42.188,74.219,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 51.376,78.906,92.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.743 | Acc: 51.200,78.944,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 50.909,78.279,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 51.100,78.279,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.785 | Acc: 51.423,78.032,91.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.777 | Acc: 51.427,78.099,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.777 | Acc: 51.535,78.169,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.784 | Acc: 51.514,78.154,91.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.794 | Acc: 51.351,78.026,91.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.798 | Acc: 51.236,77.888,91.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.810 | Acc: 51.177,77.761,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.815 | Acc: 50.963,77.824,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.819 | Acc: 50.913,77.853,91.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.823 | Acc: 50.981,77.772,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.826 | Acc: 50.986,77.725,91.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 50.927,77.723,91.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.826 | Acc: 51.020,77.685,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.824 | Acc: 51.058,77.679,91.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.824 | Acc: 51.017,77.690,91.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 45.312,69.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.683 | Acc: 45.908,64.695,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.690 | Acc: 45.560,63.681,67.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.704 | Acc: 45.441,63.794,67.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 2.886 | Acc: 49.219,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.788 | Acc: 51.302,79.129,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.779 | Acc: 50.762,78.544,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.783 | Acc: 50.269,78.343,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.782 | Acc: 50.347,78.308,91.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.777 | Acc: 50.634,78.326,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.781 | Acc: 50.749,78.093,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.796 | Acc: 50.670,77.942,91.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.802 | Acc: 50.757,77.950,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.816 | Acc: 50.591,77.797,91.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.819 | Acc: 50.420,77.806,91.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.829 | Acc: 50.399,77.641,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.827 | Acc: 50.412,77.658,91.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.831 | Acc: 50.413,77.646,91.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.825 | Acc: 50.467,77.647,91.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.824 | Acc: 50.558,77.715,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.828 | Acc: 50.511,77.619,91.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.830 | Acc: 50.545,77.614,91.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.827 | Acc: 50.682,77.655,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.825 | Acc: 50.769,77.660,91.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.167 | Acc: 42.969,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 45.015,64.844,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 44.989,64.158,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.696 | Acc: 44.967,63.922,68.033,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 2.680 | Acc: 53.125,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.745 | Acc: 51.116,77.455,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.771 | Acc: 50.381,77.896,91.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.772 | Acc: 50.922,77.997,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.779 | Acc: 50.858,78.000,91.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.791 | Acc: 50.920,77.877,91.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.797 | Acc: 50.723,77.802,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.799 | Acc: 50.742,77.959,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.804 | Acc: 50.835,77.994,91.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.803 | Acc: 50.958,77.922,91.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.806 | Acc: 50.878,77.841,91.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.803 | Acc: 50.933,77.842,91.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.810 | Acc: 50.934,77.788,91.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.819 | Acc: 50.868,77.706,91.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.818 | Acc: 50.887,77.705,91.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.814 | Acc: 50.971,77.730,91.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.821 | Acc: 50.857,77.641,91.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.815 | Acc: 50.971,77.706,91.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.998,77.746,91.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.816 | Acc: 50.982,77.701,91.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.334 | Acc: 40.625,66.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.708 | Acc: 45.350,64.397,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.718 | Acc: 45.122,63.129,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.732 | Acc: 45.044,63.576,67.252,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 2.936 | Acc: 46.875,77.344,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.772 | Acc: 52.009,78.720,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.750 | Acc: 51.239,78.868,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.733 | Acc: 51.678,78.791,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.746 | Acc: 51.456,78.607,92.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.759 | Acc: 51.369,78.396,92.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.772 | Acc: 51.188,78.293,91.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.775 | Acc: 51.025,78.269,91.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.788 | Acc: 50.815,78.125,91.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.789 | Acc: 50.656,78.224,91.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.792 | Acc: 50.626,78.222,91.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.798 | Acc: 50.541,78.210,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.803 | Acc: 50.551,78.258,91.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.807 | Acc: 50.407,78.179,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.807 | Acc: 50.473,78.083,91.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.812 | Acc: 50.480,77.977,91.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.813 | Acc: 50.433,77.952,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.812 | Acc: 50.477,77.974,91.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.813 | Acc: 50.524,77.900,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.812 | Acc: 50.560,77.893,91.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.330 | Acc: 42.969,64.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.836 | Acc: 44.754,62.463,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.849 | Acc: 43.941,62.233,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.867 | Acc: 43.776,62.474,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 2.379 | Acc: 54.688,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.669 | Acc: 52.753,78.646,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 51.220,78.601,92.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 51.422,78.817,92.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.752 | Acc: 51.090,78.675,92.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.757 | Acc: 51.199,78.519,92.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.766 | Acc: 51.233,78.396,91.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.773 | Acc: 51.147,78.264,91.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.773 | Acc: 51.271,78.339,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.781 | Acc: 51.092,78.272,91.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.790 | Acc: 51.007,78.137,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.794 | Acc: 50.976,77.984,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.793 | Acc: 51.070,78.073,91.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.801 | Acc: 51.033,77.966,91.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.801 | Acc: 50.943,77.989,91.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.802 | Acc: 50.869,77.964,91.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 50.896,77.843,91.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.802 | Acc: 50.926,77.900,91.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.806 | Acc: 50.861,77.878,91.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.810 | Acc: 50.888,77.826,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.386 | Acc: 46.094,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.778 | Acc: 45.201,63.467,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.741 | Acc: 44.893,63.224,66.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.732 | Acc: 45.120,63.435,66.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 2.183 | Acc: 62.500,84.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.710 | Acc: 51.488,79.353,91.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.743 | Acc: 51.239,78.716,91.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 51.191,78.791,91.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.750 | Acc: 50.984,78.559,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.771 | Acc: 50.696,78.388,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.760 | Acc: 50.904,78.435,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.762 | Acc: 50.898,78.574,91.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.768 | Acc: 50.932,78.537,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.779 | Acc: 50.937,78.341,91.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.776 | Acc: 51.112,78.288,91.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 51.255,78.281,91.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.778 | Acc: 51.199,78.310,91.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.784 | Acc: 51.149,78.191,91.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.794 | Acc: 50.909,78.097,91.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.797 | Acc: 50.950,78.063,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 50.930,78.054,91.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.798 | Acc: 51.003,78.010,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.801 | Acc: 51.015,77.943,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.801 | Acc: 50.995,77.945,91.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.468 | Acc: 41.406,64.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.850 | Acc: 45.424,62.500,66.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.866 | Acc: 44.874,61.776,66.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.899 | Acc: 44.506,61.975,66.419,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 2.999 | Acc: 44.531,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.750 | Acc: 52.307,78.832,93.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.721 | Acc: 51.467,78.982,92.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 51.037,78.727,92.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.753 | Acc: 50.791,78.704,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.737 | Acc: 51.160,78.953,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.744 | Acc: 50.904,79.010,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.747 | Acc: 51.069,78.917,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.750 | Acc: 50.980,78.746,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.758 | Acc: 50.842,78.595,91.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.770 | Acc: 50.665,78.518,91.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.775 | Acc: 50.665,78.394,91.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.782 | Acc: 50.749,78.251,91.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.787 | Acc: 50.784,78.191,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.792 | Acc: 50.770,78.136,91.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.789 | Acc: 50.812,78.172,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.798 | Acc: 50.810,77.994,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 50.809,77.988,91.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.806 | Acc: 50.853,77.954,91.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.809 | Acc: 50.861,77.901,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.494 | Acc: 46.094,66.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.881 | Acc: 44.531,62.946,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.849 | Acc: 44.436,62.252,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.859 | Acc: 44.429,62.359,66.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 2.702 | Acc: 52.344,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.731 | Acc: 51.562,78.497,92.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 51.429,79.230,91.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.728 | Acc: 51.294,79.098,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.736 | Acc: 51.379,79.012,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 51.570,78.868,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.763 | Acc: 51.440,78.642,91.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.781 | Acc: 51.341,78.402,91.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.793 | Acc: 51.131,78.188,91.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.793 | Acc: 51.062,78.198,91.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.796 | Acc: 50.917,78.129,91.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.798 | Acc: 50.894,78.150,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.796 | Acc: 50.976,78.122,91.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.797 | Acc: 51.057,78.068,91.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.800 | Acc: 50.993,78.017,91.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.803 | Acc: 50.950,77.954,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.809 | Acc: 50.915,77.838,91.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.807 | Acc: 51.020,77.800,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.808 | Acc: 50.920,77.794,91.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.806 | Acc: 50.912,77.809,91.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.627 | Acc: 42.188,60.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.862 | Acc: 44.568,62.760,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.864 | Acc: 44.512,61.909,66.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.871 | Acc: 44.416,62.231,66.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 2.790 | Acc: 47.656,80.469,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.753 | Acc: 49.926,79.613,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.795 | Acc: 49.886,78.277,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.780 | Acc: 50.410,78.612,92.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.781 | Acc: 50.772,78.520,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.780 | Acc: 50.735,78.550,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.780 | Acc: 50.859,78.499,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.772 | Acc: 50.859,78.496,92.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.764 | Acc: 51.048,78.513,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 50.963,78.436,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 51.046,78.525,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.761 | Acc: 50.990,78.592,91.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.761 | Acc: 51.063,78.540,91.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.765 | Acc: 51.063,78.481,91.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.769 | Acc: 51.079,78.492,91.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.777 | Acc: 50.968,78.366,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.782 | Acc: 51.020,78.317,91.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.786 | Acc: 51.054,78.237,91.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.790 | Acc: 50.965,78.186,91.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.793 | Acc: 50.984,78.156,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.397 | Acc: 43.750,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.677 | Acc: 46.243,64.583,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.682 | Acc: 45.655,63.758,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.713 | Acc: 45.748,63.717,66.983,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 2.870 | Acc: 52.344,78.125,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.842 | Acc: 51.190,78.274,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.820 | Acc: 51.181,77.534,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.804 | Acc: 51.255,77.651,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.794 | Acc: 51.003,77.566,91.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.760 | Acc: 51.253,77.978,91.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.768 | Acc: 51.207,77.976,91.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.762 | Acc: 51.529,78.009,91.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.756 | Acc: 51.456,78.033,91.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.770 | Acc: 51.131,77.957,91.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.770 | Acc: 51.112,78.071,91.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.765 | Acc: 51.142,78.171,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.775 | Acc: 51.096,78.096,91.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.781 | Acc: 51.021,78.107,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.783 | Acc: 50.993,78.086,91.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.789 | Acc: 51.012,77.977,91.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.783 | Acc: 51.039,78.037,91.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.783 | Acc: 51.061,78.043,91.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.786 | Acc: 51.041,77.999,91.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.794 | Acc: 50.919,78.025,91.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.632 | Acc: 42.188,66.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.893 | Acc: 44.085,63.690,66.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.866 | Acc: 43.236,63.091,66.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.878 | Acc: 43.327,63.230,66.714,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 3.409 | Acc: 41.406,72.656,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.794 | Acc: 50.930,78.460,90.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.775 | Acc: 51.582,78.277,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.781 | Acc: 51.358,78.215,91.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.774 | Acc: 51.264,78.144,91.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.792 | Acc: 50.828,78.048,91.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 50.833,78.254,91.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.792 | Acc: 50.709,78.203,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.781 | Acc: 50.762,78.203,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.788 | Acc: 50.699,78.116,91.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.787 | Acc: 50.665,78.125,91.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.784 | Acc: 50.838,78.114,91.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 50.856,78.080,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.789 | Acc: 50.805,77.960,91.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.788 | Acc: 50.806,78.028,91.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.788 | Acc: 50.906,77.985,91.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.792 | Acc: 50.854,77.918,91.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.794 | Acc: 50.777,77.949,91.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.798 | Acc: 50.654,77.928,91.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.796 | Acc: 50.769,77.901,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.262 | Acc: 46.094,65.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.717 | Acc: 45.833,64.472,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.783 | Acc: 44.569,63.300,66.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.772 | Acc: 44.672,63.473,66.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 2.530 | Acc: 55.469,82.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.702 | Acc: 51.674,78.981,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.759 | Acc: 51.524,78.487,92.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.756 | Acc: 50.948,78.279,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.751 | Acc: 50.936,78.492,92.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.751 | Acc: 51.269,78.373,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.745 | Acc: 51.498,78.571,92.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.748 | Acc: 51.551,78.524,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.752 | Acc: 51.504,78.411,92.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.752 | Acc: 51.506,78.358,92.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.752 | Acc: 51.454,78.393,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.757 | Acc: 51.442,78.358,91.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.760 | Acc: 51.342,78.313,91.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.767 | Acc: 51.272,78.293,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.770 | Acc: 51.170,78.297,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.773 | Acc: 51.121,78.268,91.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.776 | Acc: 51.183,78.196,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.779 | Acc: 51.157,78.201,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.781 | Acc: 51.082,78.160,91.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.778 | Acc: 51.111,78.164,91.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.529 | Acc: 46.094,70.312,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.907 | Acc: 45.089,63.244,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.879 | Acc: 44.341,62.919,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.883 | Acc: 44.224,63.064,66.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 3.025 | Acc: 46.875,71.875,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.808 | Acc: 51.116,76.897,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 51.582,78.277,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.758 | Acc: 50.973,78.112,92.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.749 | Acc: 50.965,78.395,91.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.759 | Acc: 50.944,78.171,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.749 | Acc: 51.169,78.319,91.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.747 | Acc: 51.241,78.413,91.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.758 | Acc: 51.121,78.295,91.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.773 | Acc: 50.958,78.090,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.776 | Acc: 50.944,78.055,91.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.780 | Acc: 50.965,78.058,91.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.784 | Acc: 50.908,78.028,91.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 50.982,77.996,91.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.790 | Acc: 50.890,78.017,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.791 | Acc: 50.901,78.008,91.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.792 | Acc: 50.939,77.957,91.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.796 | Acc: 50.919,77.845,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.800 | Acc: 50.855,77.841,91.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.799 | Acc: 50.925,77.778,91.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.430 | Acc: 45.312,64.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.978 | Acc: 43.899,63.170,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.019 | Acc: 42.702,61.986,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.015 | Acc: 42.597,62.346,65.843,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 2.394 | Acc: 53.906,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.619 | Acc: 53.125,79.427,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.708 | Acc: 51.886,78.830,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.722 | Acc: 51.447,78.535,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.745 | Acc: 51.331,78.183,92.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.764 | Acc: 51.214,77.963,92.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.786 | Acc: 50.781,77.899,91.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.779 | Acc: 50.864,77.815,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.767 | Acc: 50.912,77.979,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.767 | Acc: 50.885,77.957,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.761 | Acc: 51.174,78.067,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.763 | Acc: 51.152,78.093,91.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.758 | Acc: 51.277,78.144,91.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.760 | Acc: 51.167,78.146,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.769 | Acc: 51.026,78.094,91.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.773 | Acc: 51.033,78.045,91.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.776 | Acc: 51.090,78.059,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.777 | Acc: 51.045,78.049,91.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.782 | Acc: 50.991,78.019,91.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.782 | Acc: 50.990,77.988,91.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.369 | Acc: 48.438,66.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.794 | Acc: 45.945,62.909,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.801 | Acc: 45.522,62.405,66.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.806 | Acc: 45.300,62.487,66.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 3.295 | Acc: 44.531,74.219,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.766 | Acc: 50.037,79.353,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.706 | Acc: 51.162,79.459,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.747 | Acc: 50.961,78.714,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.731 | Acc: 51.071,78.916,92.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.737 | Acc: 50.936,78.860,92.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.747 | Acc: 50.872,78.745,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.747 | Acc: 50.953,78.513,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.745 | Acc: 50.956,78.431,92.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.748 | Acc: 51.027,78.406,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.757 | Acc: 50.933,78.137,92.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.768 | Acc: 50.778,78.019,92.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.762 | Acc: 50.982,78.096,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.756 | Acc: 51.024,78.152,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.761 | Acc: 50.956,78.042,92.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.772 | Acc: 50.875,77.949,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.781 | Acc: 50.866,77.889,91.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.785 | Acc: 50.861,77.832,91.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.788 | Acc: 50.829,77.820,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 50.855,77.830,91.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.409 | Acc: 43.750,67.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.935 | Acc: 43.229,63.281,67.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.971 | Acc: 42.302,62.519,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.972 | Acc: 42.418,62.602,66.124,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 2.552 | Acc: 57.031,78.906,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.681 | Acc: 51.488,79.129,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.669 | Acc: 51.753,78.811,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.670 | Acc: 51.716,78.829,92.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.719 | Acc: 51.447,78.434,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.733 | Acc: 51.168,78.249,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.731 | Acc: 51.143,78.364,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.744 | Acc: 50.959,78.280,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.753 | Acc: 50.927,78.135,92.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.749 | Acc: 50.971,78.246,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 50.851,78.308,91.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.761 | Acc: 50.884,78.210,91.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.766 | Acc: 50.891,78.190,91.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.772 | Acc: 50.880,78.212,91.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.774 | Acc: 50.809,78.228,91.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.774 | Acc: 50.742,78.239,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.772 | Acc: 50.847,78.227,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.774 | Acc: 50.907,78.196,91.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.772 | Acc: 50.961,78.229,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.773 | Acc: 50.972,78.205,91.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.287 | Acc: 42.188,67.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.762 | Acc: 46.019,63.951,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.780 | Acc: 45.579,63.148,67.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.787 | Acc: 45.146,63.064,66.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 2.672 | Acc: 47.656,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.678 | Acc: 50.558,79.688,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.702 | Acc: 51.658,79.630,92.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.720 | Acc: 51.447,78.893,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.722 | Acc: 51.591,78.983,92.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.713 | Acc: 51.671,78.790,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.730 | Acc: 51.420,78.642,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.736 | Acc: 51.430,78.624,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.741 | Acc: 51.368,78.605,92.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.755 | Acc: 51.191,78.483,91.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.765 | Acc: 51.104,78.331,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.765 | Acc: 51.184,78.326,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.761 | Acc: 51.271,78.414,91.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.764 | Acc: 51.105,78.412,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.772 | Acc: 50.993,78.283,91.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.774 | Acc: 50.919,78.247,91.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.772 | Acc: 50.969,78.254,91.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.774 | Acc: 50.965,78.249,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 50.965,78.209,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.779 | Acc: 50.894,78.117,91.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.552 | Acc: 44.531,62.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.770 | Acc: 46.094,63.802,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.768 | Acc: 45.827,63.491,66.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.775 | Acc: 45.761,63.563,66.586,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 2.730 | Acc: 53.906,81.250,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 52.455,79.762,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.690 | Acc: 51.639,79.383,91.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.710 | Acc: 51.742,78.753,91.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.714 | Acc: 51.794,78.742,91.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.714 | Acc: 51.795,78.798,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.722 | Acc: 51.860,78.609,91.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.722 | Acc: 51.840,78.491,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.739 | Acc: 51.616,78.241,91.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.746 | Acc: 51.562,78.099,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.746 | Acc: 51.687,78.168,91.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.744 | Acc: 51.644,78.199,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.749 | Acc: 51.653,78.196,91.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.751 | Acc: 51.634,78.170,91.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 51.560,78.206,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.761 | Acc: 51.474,78.185,91.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.764 | Acc: 51.485,78.152,91.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.771 | Acc: 51.347,78.116,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.772 | Acc: 51.294,78.108,91.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.774 | Acc: 51.259,78.102,91.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.434 | Acc: 42.969,67.188,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.854 | Acc: 44.829,63.802,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.891 | Acc: 44.264,62.443,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.891 | Acc: 44.237,62.602,66.483,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 2.845 | Acc: 49.219,80.469,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.695 | Acc: 52.604,79.315,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.747 | Acc: 51.410,78.944,91.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.734 | Acc: 51.191,78.996,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 51.553,78.897,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.735 | Acc: 51.578,79.022,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.738 | Acc: 51.343,78.906,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.751 | Acc: 51.064,78.602,92.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.746 | Acc: 51.058,78.644,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.757 | Acc: 50.924,78.414,92.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.759 | Acc: 50.890,78.428,92.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.762 | Acc: 50.880,78.408,92.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.753 | Acc: 51.099,78.508,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.760 | Acc: 51.099,78.349,92.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.760 | Acc: 51.107,78.339,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.762 | Acc: 51.043,78.268,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.761 | Acc: 51.056,78.283,92.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.764 | Acc: 51.065,78.198,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.764 | Acc: 51.006,78.192,91.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.768 | Acc: 50.997,78.053,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.661 | Acc: 43.750,64.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.981 | Acc: 43.341,62.872,67.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.998 | Acc: 42.759,62.081,66.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.011 | Acc: 42.828,62.001,66.099,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 2.759 | Acc: 50.781,75.781,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.787 | Acc: 49.814,78.125,92.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 49.962,78.239,92.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.798 | Acc: 49.974,78.061,92.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.796 | Acc: 50.068,78.086,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.797 | Acc: 50.278,77.939,92.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.790 | Acc: 50.736,78.009,91.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.787 | Acc: 50.659,78.114,91.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.789 | Acc: 50.650,78.130,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.788 | Acc: 50.773,78.138,91.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.784 | Acc: 50.917,78.234,91.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.778 | Acc: 50.930,78.330,91.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.785 | Acc: 50.849,78.258,91.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.788 | Acc: 50.769,78.191,91.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.791 | Acc: 50.737,78.150,91.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.787 | Acc: 50.875,78.148,91.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.786 | Acc: 50.922,78.179,91.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.789 | Acc: 50.880,78.194,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.787 | Acc: 50.902,78.173,91.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.788 | Acc: 50.900,78.154,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.524 | Acc: 46.875,67.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.950 | Acc: 44.196,62.984,66.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.954 | Acc: 43.579,62.386,65.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.958 | Acc: 43.199,62.590,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 2.852 | Acc: 53.125,75.781,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.689 | Acc: 51.600,78.757,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.671 | Acc: 52.591,79.268,92.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 52.382,78.701,92.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.713 | Acc: 52.160,78.588,92.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.718 | Acc: 51.949,78.473,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.721 | Acc: 51.801,78.428,92.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.734 | Acc: 51.734,78.236,92.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.738 | Acc: 51.786,78.339,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.739 | Acc: 51.739,78.250,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.747 | Acc: 51.769,78.203,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.743 | Acc: 51.746,78.263,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.744 | Acc: 51.692,78.297,91.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.752 | Acc: 51.601,78.158,91.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.757 | Acc: 51.487,78.144,91.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.760 | Acc: 51.420,78.190,91.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.762 | Acc: 51.412,78.118,91.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.768 | Acc: 51.313,78.013,91.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.775 | Acc: 51.257,77.958,91.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.777 | Acc: 51.169,77.957,91.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.259 | Acc: 45.312,67.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.733 | Acc: 45.573,64.360,68.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.743 | Acc: 45.217,63.510,67.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.763 | Acc: 45.287,63.550,67.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 2.677 | Acc: 48.438,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.777 | Acc: 48.438,78.125,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.748 | Acc: 49.276,78.335,92.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.747 | Acc: 50.115,78.484,92.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.730 | Acc: 50.637,78.627,92.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.739 | Acc: 50.596,78.504,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.747 | Acc: 50.374,78.435,92.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.746 | Acc: 50.571,78.280,92.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.755 | Acc: 50.543,78.198,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.759 | Acc: 50.591,78.142,91.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.752 | Acc: 50.801,78.214,91.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.759 | Acc: 50.753,78.164,92.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.755 | Acc: 50.726,78.209,92.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.759 | Acc: 50.694,78.182,91.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.754 | Acc: 50.734,78.245,92.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.754 | Acc: 50.768,78.185,92.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.760 | Acc: 50.754,78.106,91.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 50.850,78.141,91.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.760 | Acc: 50.814,78.144,91.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.761 | Acc: 50.810,78.148,91.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.446 | Acc: 44.531,71.875,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.905 | Acc: 44.085,62.909,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.952 | Acc: 43.236,61.738,66.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.956 | Acc: 43.186,62.116,66.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 2.761 | Acc: 50.000,81.250,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.701 | Acc: 50.930,80.022,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 51.715,79.402,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.729 | Acc: 50.999,79.047,92.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.755 | Acc: 50.502,78.829,92.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.738 | Acc: 50.890,79.045,92.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.733 | Acc: 50.981,78.984,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.733 | Acc: 51.080,78.834,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.734 | Acc: 50.970,78.877,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.726 | Acc: 51.191,78.997,92.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.728 | Acc: 51.248,78.883,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.729 | Acc: 51.297,78.882,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.729 | Acc: 51.336,78.832,92.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.734 | Acc: 51.257,78.772,92.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.741 | Acc: 51.159,78.717,92.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.747 | Acc: 51.132,78.652,92.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.755 | Acc: 51.083,78.475,92.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 51.095,78.453,91.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.758 | Acc: 51.073,78.393,92.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.761 | Acc: 51.109,78.367,91.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.394 | Acc: 43.750,66.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.788 | Acc: 46.503,64.881,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.812 | Acc: 45.446,63.662,66.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.825 | Acc: 45.338,63.307,66.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 3.065 | Acc: 49.219,71.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.724 | Acc: 51.042,79.018,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.693 | Acc: 51.429,79.249,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.693 | Acc: 51.665,79.086,92.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.700 | Acc: 51.601,79.041,92.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.725 | Acc: 51.385,78.721,92.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.717 | Acc: 51.550,78.719,92.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.730 | Acc: 51.424,78.574,92.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.738 | Acc: 51.271,78.639,91.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.745 | Acc: 51.122,78.466,92.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.749 | Acc: 51.170,78.312,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.745 | Acc: 51.230,78.330,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.749 | Acc: 51.225,78.375,91.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.750 | Acc: 51.200,78.382,91.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.755 | Acc: 51.109,78.278,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.755 | Acc: 51.134,78.283,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.754 | Acc: 51.144,78.237,91.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.755 | Acc: 51.143,78.196,91.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.757 | Acc: 51.099,78.218,91.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.765 | Acc: 50.995,78.174,91.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.342 | Acc: 43.750,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.856 | Acc: 44.196,63.542,67.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.860 | Acc: 43.864,62.710,67.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.874 | Acc: 43.724,62.731,66.957,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 2.509 | Acc: 55.469,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.755 | Acc: 48.140,79.018,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 50.133,78.506,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 51.306,78.970,92.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.715 | Acc: 51.119,78.723,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.732 | Acc: 50.944,78.597,92.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.733 | Acc: 50.917,78.661,92.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.727 | Acc: 51.003,78.795,92.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.726 | Acc: 51.004,78.766,92.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.734 | Acc: 50.928,78.677,92.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.741 | Acc: 50.871,78.630,92.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.739 | Acc: 50.841,78.694,92.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.737 | Acc: 50.982,78.686,92.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.739 | Acc: 51.003,78.652,92.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.742 | Acc: 51.018,78.553,92.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.742 | Acc: 51.038,78.592,91.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.746 | Acc: 51.022,78.522,91.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.754 | Acc: 50.887,78.443,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.758 | Acc: 50.866,78.333,91.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.765 | Acc: 50.822,78.187,91.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.345 | Acc: 43.750,68.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.973 | Acc: 45.126,63.132,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.959 | Acc: 44.322,61.966,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.948 | Acc: 44.647,62.231,65.932,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 2.932 | Acc: 44.531,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.756 | Acc: 50.000,78.237,92.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.745 | Acc: 50.572,78.487,92.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.691 | Acc: 51.460,79.342,92.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.674 | Acc: 51.726,79.794,92.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.666 | Acc: 51.825,79.981,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.667 | Acc: 51.659,79.959,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.664 | Acc: 51.707,80.037,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.660 | Acc: 51.805,79.945,93.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.655 | Acc: 51.813,80.011,93.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.653 | Acc: 51.800,80.057,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.644 | Acc: 51.842,80.165,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.641 | Acc: 51.883,80.235,93.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.633 | Acc: 52.006,80.274,93.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.637 | Acc: 51.868,80.196,93.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.633 | Acc: 51.967,80.266,93.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.633 | Acc: 51.993,80.262,93.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.631 | Acc: 52.046,80.308,93.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.630 | Acc: 51.993,80.358,93.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.627 | Acc: 52.007,80.366,93.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.117 | Acc: 46.875,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 47.321,65.588,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.624 | Acc: 46.646,64.901,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.624 | Acc: 46.478,65.100,67.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 2.832 | Acc: 50.000,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.614 | Acc: 52.121,80.804,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.604 | Acc: 52.382,80.221,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.579 | Acc: 52.421,80.648,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.577 | Acc: 52.344,80.681,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.573 | Acc: 52.491,80.693,94.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.590 | Acc: 52.208,80.540,93.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.590 | Acc: 52.155,80.352,94.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.597 | Acc: 52.082,80.343,93.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.600 | Acc: 52.106,80.387,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.582 | Acc: 52.309,80.585,94.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.577 | Acc: 52.432,80.621,94.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.578 | Acc: 52.428,80.605,94.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.576 | Acc: 52.410,80.654,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.577 | Acc: 52.333,80.638,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.580 | Acc: 52.310,80.562,94.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.575 | Acc: 52.363,80.576,94.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.573 | Acc: 52.355,80.647,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.577 | Acc: 52.277,80.581,94.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.576 | Acc: 52.247,80.608,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.107 | Acc: 47.656,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.591 | Acc: 47.247,65.960,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.580 | Acc: 46.723,64.806,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.586 | Acc: 46.580,65.010,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 2.995 | Acc: 51.562,77.344,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.573 | Acc: 54.315,80.320,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.552 | Acc: 53.125,80.526,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.537 | Acc: 53.253,80.763,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.541 | Acc: 53.135,80.720,94.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.531 | Acc: 53.063,80.910,94.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.536 | Acc: 52.757,80.876,94.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 52.565,80.879,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 52.591,80.910,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.544 | Acc: 52.573,80.956,94.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 52.717,81.021,94.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.550 | Acc: 52.521,80.872,94.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.548 | Acc: 52.464,80.832,94.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.548 | Acc: 52.338,80.891,94.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.544 | Acc: 52.366,80.897,94.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.546 | Acc: 52.403,80.918,94.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.549 | Acc: 52.273,80.863,94.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.551 | Acc: 52.199,80.810,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.559 | Acc: 52.054,80.726,94.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.558 | Acc: 52.089,80.723,94.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.154 | Acc: 48.438,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 47.879,65.625,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.589 | Acc: 46.799,65.015,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.598 | Acc: 46.760,65.138,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 2.566 | Acc: 44.531,82.812,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.580 | Acc: 50.967,80.952,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.532 | Acc: 52.020,81.402,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 52.152,81.365,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.553 | Acc: 51.910,81.076,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.559 | Acc: 51.810,81.126,94.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.558 | Acc: 51.905,81.050,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.555 | Acc: 52.056,81.006,94.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.550 | Acc: 52.155,81.051,94.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.552 | Acc: 52.115,80.948,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.545 | Acc: 52.317,81.028,94.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.547 | Acc: 52.238,81.059,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.556 | Acc: 52.178,81.000,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.556 | Acc: 52.167,81.040,94.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.550 | Acc: 52.313,81.092,94.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.555 | Acc: 52.266,81.050,94.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.555 | Acc: 52.305,81.026,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.560 | Acc: 52.236,80.982,94.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.558 | Acc: 52.296,81.038,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.555 | Acc: 52.327,81.100,94.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.213 | Acc: 46.094,71.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.622 | Acc: 47.545,65.699,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.599 | Acc: 46.608,64.958,67.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.605 | Acc: 46.593,65.126,67.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 2.385 | Acc: 52.344,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 52.641,80.692,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.591 | Acc: 52.077,80.278,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.567 | Acc: 52.331,80.571,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.548 | Acc: 52.440,80.970,94.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.562 | Acc: 52.143,80.801,94.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.562 | Acc: 52.157,80.779,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.560 | Acc: 52.333,80.773,94.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.558 | Acc: 52.475,80.736,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.558 | Acc: 52.473,80.775,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.557 | Acc: 52.453,80.745,94.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.556 | Acc: 52.570,80.748,94.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.558 | Acc: 52.499,80.741,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.558 | Acc: 52.425,80.747,94.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.558 | Acc: 52.405,80.772,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.559 | Acc: 52.331,80.733,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.559 | Acc: 52.361,80.751,94.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.556 | Acc: 52.380,80.789,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.555 | Acc: 52.385,80.798,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 52.430,80.750,94.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.171 | Acc: 46.094,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.617 | Acc: 47.396,65.476,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.605 | Acc: 46.646,64.882,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.616 | Acc: 46.427,64.857,68.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 2.324 | Acc: 53.906,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.551 | Acc: 51.823,80.506,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 52.439,81.822,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 52.536,81.570,95.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.530 | Acc: 52.276,81.337,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.536 | Acc: 52.468,81.296,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.542 | Acc: 52.357,81.043,95.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.534 | Acc: 52.360,81.128,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 52.451,81.192,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.537 | Acc: 52.167,81.125,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.536 | Acc: 52.297,81.196,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 52.351,81.236,95.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.534 | Acc: 52.263,81.240,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.542 | Acc: 52.101,81.166,95.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.542 | Acc: 52.107,81.175,95.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.532 | Acc: 52.256,81.229,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.534 | Acc: 52.217,81.209,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.533 | Acc: 52.250,81.181,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 52.370,81.155,95.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.540 | Acc: 52.336,81.100,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.108 | Acc: 46.875,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.582 | Acc: 47.656,65.699,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.575 | Acc: 46.437,64.977,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 46.568,64.997,68.340,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 2.569 | Acc: 47.656,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.539 | Acc: 51.339,81.920,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.542 | Acc: 52.439,81.040,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.539 | Acc: 52.587,81.237,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.518 | Acc: 53.000,81.404,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 52.885,81.443,95.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.493 | Acc: 52.751,81.663,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 52.599,81.494,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.502 | Acc: 52.722,81.497,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.515 | Acc: 52.672,81.328,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 52.655,81.359,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 52.588,81.328,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 52.639,81.350,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.522 | Acc: 52.508,81.292,95.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.529 | Acc: 52.422,81.272,95.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.526 | Acc: 52.632,81.286,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.527 | Acc: 52.682,81.272,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.529 | Acc: 52.628,81.232,95.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 52.539,81.202,95.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.533 | Acc: 52.530,81.223,95.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.127 | Acc: 45.312,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.594 | Acc: 47.545,65.923,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.583 | Acc: 46.456,65.015,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.596 | Acc: 46.427,65.100,68.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 2.126 | Acc: 57.812,89.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.392 | Acc: 54.167,82.775,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.445 | Acc: 53.773,82.336,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.459 | Acc: 53.663,81.980,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.473 | Acc: 53.347,81.838,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.498 | Acc: 52.970,81.559,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.509 | Acc: 52.822,81.470,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.516 | Acc: 52.698,81.250,95.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.510 | Acc: 52.708,81.328,95.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 52.603,81.310,95.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.514 | Acc: 52.569,81.332,95.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.516 | Acc: 52.443,81.384,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.519 | Acc: 52.295,81.399,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.522 | Acc: 52.323,81.328,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.525 | Acc: 52.244,81.317,95.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 52.211,81.281,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 52.329,81.248,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.525 | Acc: 52.312,81.236,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.527 | Acc: 52.283,81.215,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.531 | Acc: 52.215,81.203,95.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.185 | Acc: 46.875,71.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.615 | Acc: 47.731,65.662,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 46.932,64.615,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 46.696,64.780,68.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 2.395 | Acc: 55.469,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 52.976,81.176,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 52.382,81.117,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.540 | Acc: 52.715,81.148,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.527 | Acc: 52.402,81.240,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.512 | Acc: 52.413,81.327,95.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.508 | Acc: 52.331,81.263,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.503 | Acc: 52.388,81.283,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.509 | Acc: 52.276,81.274,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.513 | Acc: 52.193,81.280,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.510 | Acc: 52.289,81.316,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 52.340,81.271,95.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 52.269,81.289,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.525 | Acc: 52.185,81.295,95.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.525 | Acc: 52.166,81.367,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.527 | Acc: 52.115,81.356,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 52.171,81.342,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.528 | Acc: 52.112,81.255,95.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.534 | Acc: 52.093,81.215,95.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.533 | Acc: 52.174,81.191,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.148 | Acc: 47.656,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.613 | Acc: 47.321,65.439,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.610 | Acc: 46.570,64.691,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.620 | Acc: 46.324,64.754,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 2.597 | Acc: 54.688,80.469,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.505 | Acc: 53.088,81.250,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.519 | Acc: 52.763,81.288,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.498 | Acc: 52.613,81.647,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.495 | Acc: 52.778,81.578,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.497 | Acc: 52.622,81.714,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.899,81.592,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.487 | Acc: 52.909,81.721,95.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 52.771,81.478,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.505 | Acc: 52.780,81.436,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 52.729,81.405,95.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.513 | Acc: 52.612,81.363,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.513 | Acc: 52.691,81.393,95.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.516 | Acc: 52.622,81.355,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.513 | Acc: 52.666,81.331,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.518 | Acc: 52.642,81.307,95.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 52.611,81.294,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 52.582,81.307,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.519 | Acc: 52.614,81.360,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 52.647,81.394,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.194 | Acc: 46.094,71.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.609 | Acc: 47.619,65.960,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.602 | Acc: 46.818,64.863,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.610 | Acc: 46.696,65.023,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 2.528 | Acc: 55.469,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.492 | Acc: 52.493,82.254,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.522 | Acc: 52.325,82.088,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.533 | Acc: 52.779,81.647,95.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.543 | Acc: 52.488,81.318,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 52.421,81.590,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.532 | Acc: 52.537,81.360,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.528 | Acc: 52.604,81.521,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.531 | Acc: 52.601,81.425,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.527 | Acc: 52.642,81.440,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.526 | Acc: 52.627,81.448,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.529 | Acc: 52.549,81.434,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.525 | Acc: 52.538,81.448,95.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.532 | Acc: 52.365,81.424,95.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.532 | Acc: 52.305,81.425,95.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.530 | Acc: 52.367,81.478,95.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.531 | Acc: 52.356,81.403,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.535 | Acc: 52.319,81.353,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.533 | Acc: 52.329,81.384,95.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.530 | Acc: 52.393,81.453,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 43.750,71.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 47.470,66.146,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.597 | Acc: 46.532,65.053,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.608 | Acc: 46.427,65.049,68.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 2.572 | Acc: 50.781,82.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 51.228,82.403,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 51.334,82.374,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 51.550,82.223,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.505 | Acc: 51.360,81.887,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.507 | Acc: 51.570,82.024,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 51.943,81.960,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.509 | Acc: 51.934,82.004,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 52.169,81.895,95.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 52.232,81.824,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.507 | Acc: 52.239,81.786,95.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.504 | Acc: 52.330,81.734,95.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.501 | Acc: 52.428,81.798,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.398,81.735,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.504 | Acc: 52.424,81.775,95.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.504 | Acc: 52.458,81.779,95.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 52.424,81.737,95.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 52.376,81.607,95.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.515 | Acc: 52.361,81.553,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.517 | Acc: 52.409,81.535,95.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.120 | Acc: 45.312,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.603 | Acc: 47.656,65.885,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.590 | Acc: 46.856,64.996,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.604 | Acc: 46.568,65.061,68.519,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 2.587 | Acc: 57.812,77.344,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.519 | Acc: 52.158,80.766,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 52.096,81.250,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 52.459,81.519,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.497 | Acc: 52.247,81.472,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.483 | Acc: 52.661,81.745,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.725,81.528,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.848,81.494,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 52.887,81.337,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.505 | Acc: 52.771,81.354,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.515 | Acc: 52.662,81.324,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.512 | Acc: 52.701,81.360,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.517 | Acc: 52.597,81.234,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.526 | Acc: 52.413,81.169,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.523 | Acc: 52.469,81.214,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 52.453,81.317,95.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.525 | Acc: 52.407,81.260,95.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.524 | Acc: 52.392,81.250,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.529 | Acc: 52.322,81.189,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.529 | Acc: 52.284,81.232,95.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.201 | Acc: 45.312,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.615 | Acc: 47.842,65.551,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.604 | Acc: 46.780,64.825,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.615 | Acc: 46.580,64.946,68.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 2.549 | Acc: 54.688,76.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 52.530,82.180,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 53.182,81.460,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.525 | Acc: 52.882,81.224,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.517 | Acc: 52.855,81.453,95.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.509 | Acc: 52.908,81.335,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.499 | Acc: 53.106,81.495,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.503 | Acc: 53.081,81.433,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.504 | Acc: 52.950,81.449,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 52.857,81.513,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.504 | Acc: 52.775,81.499,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.505 | Acc: 52.687,81.501,95.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.511 | Acc: 52.661,81.448,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.508 | Acc: 52.670,81.469,95.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 52.555,81.325,95.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.512 | Acc: 52.684,81.349,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.512 | Acc: 52.738,81.381,95.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.516 | Acc: 52.667,81.376,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 52.564,81.421,95.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.516 | Acc: 52.536,81.439,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 44.531,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.626 | Acc: 47.731,65.513,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 46.513,64.615,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 46.401,64.703,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 2.637 | Acc: 44.531,75.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.419 | Acc: 53.348,82.664,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 52.039,82.088,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.515 | Acc: 51.908,81.621,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.500 | Acc: 52.238,81.761,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.510 | Acc: 52.158,81.737,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.517 | Acc: 52.402,81.528,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.520 | Acc: 52.504,81.461,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.519 | Acc: 52.683,81.415,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.518 | Acc: 52.607,81.474,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.521 | Acc: 52.697,81.472,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.521 | Acc: 52.598,81.381,95.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.520 | Acc: 52.639,81.360,95.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.523 | Acc: 52.604,81.340,95.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.521 | Acc: 52.588,81.383,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.515 | Acc: 52.634,81.403,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.519 | Acc: 52.604,81.457,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 52.591,81.394,95.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.521 | Acc: 52.515,81.421,95.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.524 | Acc: 52.557,81.389,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.194 | Acc: 45.312,71.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 47.433,65.588,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 46.456,64.501,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.614 | Acc: 46.388,64.626,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 2.489 | Acc: 53.125,82.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.506 | Acc: 51.749,82.403,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.459 | Acc: 52.649,82.393,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 52.485,82.313,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.460 | Acc: 52.652,82.176,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.471 | Acc: 52.707,82.000,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.486 | Acc: 52.634,81.792,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.483 | Acc: 52.643,81.837,95.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.486 | Acc: 52.654,81.696,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 52.745,81.638,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.498 | Acc: 52.604,81.487,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.503 | Acc: 52.460,81.586,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.503 | Acc: 52.554,81.626,95.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.507 | Acc: 52.502,81.525,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 52.494,81.464,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.511 | Acc: 52.512,81.478,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.513 | Acc: 52.470,81.437,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.513 | Acc: 52.438,81.488,95.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.484,81.518,95.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.514 | Acc: 52.465,81.496,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.118 | Acc: 45.312,71.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.600 | Acc: 47.879,66.183,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.598 | Acc: 46.894,64.939,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 46.683,65.049,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 2.375 | Acc: 52.344,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.532 | Acc: 51.860,80.506,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 52.039,80.907,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 52.779,81.647,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 52.855,81.771,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 52.901,81.606,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.500 | Acc: 52.686,81.424,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.506 | Acc: 52.554,81.433,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.766,81.483,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.505 | Acc: 52.542,81.384,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.503 | Acc: 52.526,81.308,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.506 | Acc: 52.446,81.317,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.503 | Acc: 52.431,81.363,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.500 | Acc: 52.520,81.448,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.503 | Acc: 52.486,81.459,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.503 | Acc: 52.572,81.473,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.503 | Acc: 52.575,81.428,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.509 | Acc: 52.495,81.399,95.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.511 | Acc: 52.474,81.345,95.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.513 | Acc: 52.403,81.377,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.196 | Acc: 46.875,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.607 | Acc: 47.879,65.476,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.606 | Acc: 46.761,64.768,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.618 | Acc: 46.632,64.946,68.251,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 2.732 | Acc: 51.562,81.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 52.679,82.366,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.530 | Acc: 52.496,81.383,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.514 | Acc: 52.510,81.391,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.511 | Acc: 52.652,81.491,95.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 52.460,81.637,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.495 | Acc: 52.763,81.528,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.492 | Acc: 52.865,81.699,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.873,81.745,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 52.693,81.682,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.499 | Acc: 52.635,81.627,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.729,81.724,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.491 | Acc: 52.720,81.743,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.679,81.711,95.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 52.780,81.642,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.705,81.663,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 52.631,81.647,95.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.500 | Acc: 52.648,81.646,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.506 | Acc: 52.519,81.559,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.508 | Acc: 52.469,81.566,95.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.619 | Acc: 47.619,65.513,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.627 | Acc: 46.608,64.710,68.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 46.440,64.639,68.161,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 2.354 | Acc: 54.688,83.594,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.478 | Acc: 53.497,81.510,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 52.915,81.383,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.485 | Acc: 53.087,81.993,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.484 | Acc: 53.096,81.501,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.479 | Acc: 53.040,81.730,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.957,81.644,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.487 | Acc: 53.059,81.649,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.479 | Acc: 53.193,81.769,95.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.488 | Acc: 53.056,81.720,95.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.970,81.600,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.496 | Acc: 52.793,81.579,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 52.840,81.636,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.501 | Acc: 52.817,81.573,95.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.502 | Acc: 52.719,81.550,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.502 | Acc: 52.749,81.551,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.504 | Acc: 52.714,81.513,95.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 52.674,81.479,95.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.503 | Acc: 52.701,81.525,95.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 52.766,81.564,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.177 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.621 | Acc: 48.140,65.699,68.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 47.046,64.825,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.637 | Acc: 46.913,64.869,68.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 2.376 | Acc: 57.812,78.125,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.470 | Acc: 53.609,81.734,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 53.716,82.088,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.466 | Acc: 53.496,81.967,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.487 | Acc: 52.894,81.838,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.495 | Acc: 52.947,81.776,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.498 | Acc: 52.789,81.702,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.508 | Acc: 52.648,81.594,95.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.520 | Acc: 52.397,81.502,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.514 | Acc: 52.478,81.591,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.513 | Acc: 52.488,81.475,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 52.457,81.459,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.508 | Acc: 52.486,81.509,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.553,81.519,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.508 | Acc: 52.572,81.503,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.510 | Acc: 52.515,81.497,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.508 | Acc: 52.490,81.481,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.508 | Acc: 52.451,81.541,95.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.506 | Acc: 52.534,81.579,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.505 | Acc: 52.578,81.609,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.119 | Acc: 46.875,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.620 | Acc: 47.470,65.699,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.620 | Acc: 46.418,64.958,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.628 | Acc: 46.414,64.895,68.366,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 2.696 | Acc: 44.531,77.344,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.510 | Acc: 52.902,81.213,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.514 | Acc: 52.687,80.869,94.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 52.626,81.596,95.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.836,81.568,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 52.452,81.397,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.501 | Acc: 52.434,81.515,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.507 | Acc: 52.305,81.444,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.503 | Acc: 52.373,81.580,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.507 | Acc: 52.482,81.647,95.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.509 | Acc: 52.390,81.666,95.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.510 | Acc: 52.379,81.646,95.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.509 | Acc: 52.535,81.610,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.507 | Acc: 52.589,81.621,95.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.510 | Acc: 52.522,81.631,95.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.507 | Acc: 52.606,81.665,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.505 | Acc: 52.538,81.600,95.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.506 | Acc: 52.495,81.633,95.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.505 | Acc: 52.478,81.666,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.503 | Acc: 52.526,81.660,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.172 | Acc: 44.531,71.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 47.470,65.885,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.625 | Acc: 46.418,65.187,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.452,65.151,68.007,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 2.632 | Acc: 50.000,79.688,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.495 | Acc: 51.674,81.176,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.492 | Acc: 52.896,81.155,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.495 | Acc: 52.446,81.429,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.486 | Acc: 52.508,81.674,95.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.485 | Acc: 52.700,81.776,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.486 | Acc: 52.673,81.741,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.488 | Acc: 52.599,81.765,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.484 | Acc: 52.606,81.842,95.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.702,81.742,95.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 52.581,81.779,95.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 52.591,81.731,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.577,81.762,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.577,81.687,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.494 | Acc: 52.480,81.642,95.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.487,81.650,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.497 | Acc: 52.475,81.588,95.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.501 | Acc: 52.419,81.484,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 52.376,81.482,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.502 | Acc: 52.446,81.488,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.151 | Acc: 47.656,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.623 | Acc: 47.842,65.662,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 46.780,64.825,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.634 | Acc: 46.709,64.908,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 2.627 | Acc: 51.562,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.546 | Acc: 51.935,81.362,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.509 | Acc: 52.287,81.688,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 52.600,81.634,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.486 | Acc: 52.508,81.752,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.480 | Acc: 52.406,81.938,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 52.479,81.883,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.421,81.771,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.486 | Acc: 52.562,81.837,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 52.516,81.781,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.491 | Acc: 52.499,81.775,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.491 | Acc: 52.478,81.752,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.498 | Acc: 52.470,81.717,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.571,81.681,95.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.501 | Acc: 52.527,81.620,95.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.500 | Acc: 52.546,81.546,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.501 | Acc: 52.507,81.527,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.499 | Acc: 52.536,81.507,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.500 | Acc: 52.547,81.518,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 52.485,81.502,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.172 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.650 | Acc: 46.949,65.960,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 46.227,64.939,68.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 46.209,64.985,67.943,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 2.560 | Acc: 50.781,79.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.471 | Acc: 52.976,81.957,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.515,82.069,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 52.254,82.159,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.498 | Acc: 52.267,82.060,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.496 | Acc: 52.135,82.124,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.494 | Acc: 52.441,81.921,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 52.377,81.721,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.499 | Acc: 52.392,81.706,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.502 | Acc: 52.249,81.703,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.495 | Acc: 52.379,81.782,95.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.496 | Acc: 52.414,81.741,95.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.499 | Acc: 52.392,81.720,95.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.475,81.753,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.499 | Acc: 52.488,81.706,95.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.500 | Acc: 52.533,81.709,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.501 | Acc: 52.485,81.649,95.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.502 | Acc: 52.568,81.642,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.504 | Acc: 52.508,81.544,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.503 | Acc: 52.510,81.510,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.160 | Acc: 45.312,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.625 | Acc: 47.359,65.699,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.619 | Acc: 46.627,64.825,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.638 | Acc: 46.452,64.831,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 3.091 | Acc: 49.219,74.219,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.611 | Acc: 50.409,80.915,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.551 | Acc: 51.391,80.774,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 51.831,81.148,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 52.334,81.790,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.502 | Acc: 52.305,81.962,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 52.253,81.754,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.502 | Acc: 52.294,81.643,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.494 | Acc: 52.247,81.701,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.495 | Acc: 52.150,81.725,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.496 | Acc: 52.254,81.845,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.429,81.826,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 52.496,81.817,95.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.498 | Acc: 52.457,81.729,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.497 | Acc: 52.427,81.753,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.493 | Acc: 52.398,81.761,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.499 | Acc: 52.395,81.676,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 52.449,81.637,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.493,81.676,95.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.496 | Acc: 52.467,81.666,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.139 | Acc: 47.656,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 47.545,65.625,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 46.742,64.825,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.649 | Acc: 46.542,64.741,68.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 2.490 | Acc: 48.438,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.510 | Acc: 50.595,82.440,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.496 | Acc: 51.905,82.012,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.471 | Acc: 52.459,82.159,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.484 | Acc: 52.112,81.944,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 52.514,81.985,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 52.544,81.993,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 52.754,81.998,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.480 | Acc: 52.669,82.017,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.484 | Acc: 52.542,81.997,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.490 | Acc: 52.585,81.996,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.577,81.992,95.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.492 | Acc: 52.648,82.051,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.495 | Acc: 52.721,81.986,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.694,82.006,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.489 | Acc: 52.671,82.021,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.488 | Acc: 52.636,82.048,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.490 | Acc: 52.587,82.013,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.491 | Acc: 52.634,82.023,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.492 | Acc: 52.588,81.955,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.228 | Acc: 45.312,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.669 | Acc: 47.470,65.179,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.655 | Acc: 46.437,64.558,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.665 | Acc: 46.311,64.703,68.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 2.545 | Acc: 49.219,73.438,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.535 | Acc: 51.972,80.618,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.545 | Acc: 51.562,81.307,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 52.036,81.365,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.503 | Acc: 52.296,81.617,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.503 | Acc: 52.444,81.521,95.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.502 | Acc: 52.266,81.612,95.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.383,81.643,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.490 | Acc: 52.431,81.726,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.492 | Acc: 52.486,81.708,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 52.530,81.646,95.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.490 | Acc: 52.651,81.717,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 52.541,81.691,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.547,81.711,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.492 | Acc: 52.580,81.723,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.492 | Acc: 52.608,81.748,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.490 | Acc: 52.694,81.764,95.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.681,81.738,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.677,81.681,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.614,81.660,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.187 | Acc: 45.312,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 47.768,65.551,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 46.780,64.596,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.652 | Acc: 46.619,64.780,68.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 2.592 | Acc: 50.781,82.031,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 52.232,82.068,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 51.677,81.726,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 51.998,81.749,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.480 | Acc: 52.170,81.829,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 52.212,81.907,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.483 | Acc: 52.163,81.754,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 52.488,81.749,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.470 | Acc: 52.591,81.837,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.474 | Acc: 52.573,81.889,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.472 | Acc: 52.608,81.856,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 52.584,81.862,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 52.509,81.714,95.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.484 | Acc: 52.550,81.555,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.408,81.478,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 52.455,81.445,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.517,81.474,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.492 | Acc: 52.506,81.408,95.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 52.463,81.373,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.495 | Acc: 52.506,81.410,95.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.194 | Acc: 43.750,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 47.396,65.625,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.649 | Acc: 46.380,64.787,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.657 | Acc: 46.363,64.767,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 2.759 | Acc: 44.531,78.906,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.513 | Acc: 52.307,81.324,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 52.229,80.564,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 52.369,81.058,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.507 | Acc: 52.681,81.163,95.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.506 | Acc: 52.591,81.242,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.505 | Acc: 52.395,81.399,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.500 | Acc: 52.610,81.422,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.489 | Acc: 52.960,81.614,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.491 | Acc: 52.918,81.617,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.489 | Acc: 52.900,81.693,95.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.493 | Acc: 52.736,81.678,95.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.496 | Acc: 52.713,81.678,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.497 | Acc: 52.631,81.618,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.499 | Acc: 52.524,81.628,95.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.645,81.585,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 52.689,81.596,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 52.726,81.603,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.498 | Acc: 52.692,81.588,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.501 | Acc: 52.660,81.533,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.196 | Acc: 47.656,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.640 | Acc: 47.879,65.774,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 46.875,64.482,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 46.798,64.882,68.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 2.393 | Acc: 59.375,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.483 | Acc: 53.311,81.101,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 52.820,81.784,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.499 | Acc: 52.574,81.545,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.480 | Acc: 52.951,81.954,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.854,81.683,95.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.482 | Acc: 52.880,81.670,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.486 | Acc: 52.942,81.638,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.495 | Acc: 52.693,81.599,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.496 | Acc: 52.728,81.638,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.494 | Acc: 52.884,81.534,95.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.488 | Acc: 53.005,81.635,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.487 | Acc: 52.960,81.655,95.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.491 | Acc: 52.921,81.561,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.491 | Acc: 52.891,81.606,95.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.495 | Acc: 52.806,81.504,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.498 | Acc: 52.677,81.484,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.498 | Acc: 52.644,81.495,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.640,81.497,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.493 | Acc: 52.655,81.533,95.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.173 | Acc: 46.094,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.640 | Acc: 47.396,65.290,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.635 | Acc: 46.513,64.672,68.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 46.529,64.844,68.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 2.815 | Acc: 48.438,76.562,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.425 | Acc: 53.943,82.403,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.447 | Acc: 53.220,81.688,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.445 | Acc: 53.176,82.018,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.454 | Acc: 52.922,81.723,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.456 | Acc: 52.970,81.722,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.459 | Acc: 53.022,81.773,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.465 | Acc: 52.870,81.715,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 52.722,81.726,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 52.819,81.759,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.779,81.654,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.487 | Acc: 52.687,81.522,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.488 | Acc: 52.707,81.457,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.646,81.561,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.490 | Acc: 52.586,81.556,95.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.494 | Acc: 52.570,81.476,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.492 | Acc: 52.636,81.583,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.497 | Acc: 52.502,81.511,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.493 | Acc: 52.595,81.559,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.494 | Acc: 52.575,81.517,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.271 | Acc: 45.312,68.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 47.321,65.625,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.648 | Acc: 46.418,64.710,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.363,64.780,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 2.228 | Acc: 60.156,88.281,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.473 | Acc: 53.423,82.440,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 53.354,82.489,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 53.138,82.313,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.510 | Acc: 52.739,81.742,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.524 | Acc: 52.576,81.521,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.512 | Acc: 52.544,81.534,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.514 | Acc: 52.455,81.411,95.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.501 | Acc: 52.586,81.565,95.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.504 | Acc: 52.573,81.561,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.505 | Acc: 52.453,81.627,95.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.505 | Acc: 52.368,81.649,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.505 | Acc: 52.480,81.613,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.506 | Acc: 52.469,81.651,95.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.511 | Acc: 52.335,81.586,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.508 | Acc: 52.370,81.533,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.509 | Acc: 52.361,81.486,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.504 | Acc: 52.550,81.516,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.501 | Acc: 52.552,81.540,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 52.565,81.576,95.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.201 | Acc: 46.875,69.531,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 47.433,66.071,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.634 | Acc: 46.475,64.939,68.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 46.401,64.959,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 2.653 | Acc: 53.125,80.469,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.510 | Acc: 51.786,81.287,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.468 | Acc: 52.801,81.860,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.481 | Acc: 53.061,81.468,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.477 | Acc: 52.739,81.674,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.481 | Acc: 52.707,81.575,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.484 | Acc: 52.608,81.708,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.494 | Acc: 52.604,81.671,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.496 | Acc: 52.460,81.575,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.485 | Acc: 52.784,81.815,95.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.483 | Acc: 52.740,81.907,95.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.487 | Acc: 52.740,81.961,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.495 | Acc: 52.687,81.892,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.489 | Acc: 52.748,81.909,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.488 | Acc: 52.761,81.859,95.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.491 | Acc: 52.684,81.865,95.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.491 | Acc: 52.728,81.910,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.495 | Acc: 52.697,81.811,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.495 | Acc: 52.668,81.843,95.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.662,81.828,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.194 | Acc: 43.750,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.680 | Acc: 47.582,65.625,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.664 | Acc: 46.608,64.806,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 46.644,64.844,67.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 2.609 | Acc: 49.219,86.719,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.459 | Acc: 52.679,81.324,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.478 | Acc: 52.915,81.536,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.493 | Acc: 52.971,81.429,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.497 | Acc: 52.922,81.453,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.473 | Acc: 53.125,81.969,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.482 | Acc: 52.989,81.954,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.489 | Acc: 52.914,81.937,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.487 | Acc: 52.911,82.017,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.487 | Acc: 52.831,81.975,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.488 | Acc: 52.569,81.860,95.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.494 | Acc: 52.475,81.780,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.497 | Acc: 52.460,81.639,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.494 | Acc: 52.523,81.624,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.496 | Acc: 52.441,81.595,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.496 | Acc: 52.393,81.634,95.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.493 | Acc: 52.485,81.610,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.491 | Acc: 52.564,81.669,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.496 | Acc: 52.458,81.594,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.497 | Acc: 52.469,81.613,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.143 | Acc: 48.438,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.610 | Acc: 47.656,65.625,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.603 | Acc: 46.742,64.748,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.611 | Acc: 46.670,64.844,68.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 2.192 | Acc: 57.031,87.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.432 | Acc: 52.827,82.812,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 52.268,82.317,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.477 | Acc: 52.574,82.249,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.472 | Acc: 52.845,82.166,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 52.537,82.093,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.482 | Acc: 52.563,82.051,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.488 | Acc: 52.510,82.048,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.481 | Acc: 52.664,82.157,95.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 52.573,82.191,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 52.616,82.245,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.475 | Acc: 52.535,82.250,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 52.632,82.177,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.479 | Acc: 52.634,82.124,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.484 | Acc: 52.533,82.104,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.485 | Acc: 52.458,82.096,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.489 | Acc: 52.366,82.034,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.486 | Acc: 52.429,82.052,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.485 | Acc: 52.428,82.031,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.487 | Acc: 52.498,81.982,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.180 | Acc: 46.094,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.632 | Acc: 47.693,65.923,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 46.723,64.958,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.631 | Acc: 46.606,64.972,68.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 2.271 | Acc: 57.031,85.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 53.385,81.808,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.446 | Acc: 53.449,81.803,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 53.023,81.442,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.463 | Acc: 52.807,81.809,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.462 | Acc: 52.901,81.799,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.464 | Acc: 52.905,81.838,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 52.709,81.937,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.466 | Acc: 52.732,81.988,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.468 | Acc: 52.659,82.010,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.462 | Acc: 52.810,82.117,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.471 | Acc: 52.743,81.999,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.472 | Acc: 52.752,81.970,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 52.781,82.028,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.841,82.006,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 52.832,81.888,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 52.860,81.827,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.476 | Acc: 52.866,81.825,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 52.839,81.802,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.476 | Acc: 52.795,81.797,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.244 | Acc: 46.094,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.658 | Acc: 47.210,65.960,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.661 | Acc: 46.303,64.710,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.672 | Acc: 46.286,64.793,68.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 2.527 | Acc: 52.344,83.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.517 | Acc: 52.493,80.841,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.503 | Acc: 52.363,80.697,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 52.305,81.301,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 52.662,81.385,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 52.800,81.335,95.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.976,81.373,95.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.485 | Acc: 52.937,81.272,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 52.892,81.488,95.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.474 | Acc: 52.771,81.466,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.465 | Acc: 52.981,81.553,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.468 | Acc: 52.860,81.589,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 52.820,81.613,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.473 | Acc: 52.811,81.531,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.469 | Acc: 52.833,81.592,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.842,81.595,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.477 | Acc: 52.779,81.576,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.479 | Acc: 52.820,81.582,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.481 | Acc: 52.761,81.559,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.488 | Acc: 52.633,81.478,95.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.200 | Acc: 44.531,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 47.321,66.183,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 46.361,65.053,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.644 | Acc: 46.465,64.959,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 2.718 | Acc: 47.656,82.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 54.055,83.222,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.450 | Acc: 53.468,82.279,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.443 | Acc: 52.984,81.826,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.471 | Acc: 52.816,81.713,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.456 | Acc: 53.032,82.085,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.460 | Acc: 53.002,82.102,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.462 | Acc: 52.798,82.053,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.463 | Acc: 52.824,82.172,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.463 | Acc: 52.892,82.169,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.467 | Acc: 52.833,82.152,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.469 | Acc: 52.651,82.063,95.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.476 | Acc: 52.548,81.960,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.473 | Acc: 52.505,81.986,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.467 | Acc: 52.680,82.037,95.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.570,81.982,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.470 | Acc: 52.531,81.958,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.470 | Acc: 52.472,81.988,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.468 | Acc: 52.510,82.018,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.471 | Acc: 52.491,81.984,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.198 | Acc: 45.312,70.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.644 | Acc: 47.619,65.551,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.648 | Acc: 46.513,64.729,68.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.659 | Acc: 46.504,64.844,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 2.392 | Acc: 50.000,86.719,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 52.232,82.626,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.482 | Acc: 52.706,81.936,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 52.792,82.211,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.465 | Acc: 53.096,82.485,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.477 | Acc: 52.924,82.310,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 53.048,82.270,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.475 | Acc: 53.070,82.203,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 53.130,82.400,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 53.004,82.398,96.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 53.005,82.350,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 53.033,82.349,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.953,82.255,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.874,82.166,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 52.911,82.137,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.475 | Acc: 52.886,82.091,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.474 | Acc: 52.845,82.124,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.473 | Acc: 52.747,82.157,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 52.753,82.189,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 52.737,82.134,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.226 | Acc: 46.094,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 47.545,65.774,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.647 | Acc: 46.551,64.882,68.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 46.427,64.818,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 2.746 | Acc: 42.969,79.688,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.497 | Acc: 52.195,82.292,95.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.498 | Acc: 52.172,81.993,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 52.164,82.108,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 52.199,81.877,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.351,81.877,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.481 | Acc: 52.751,81.863,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.473 | Acc: 52.754,81.915,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.477 | Acc: 52.533,81.949,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.464 | Acc: 52.801,81.975,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.476 | Acc: 52.515,81.922,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.480 | Acc: 52.467,81.872,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.481 | Acc: 52.503,81.973,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.592,82.034,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 52.613,82.023,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.645,82.088,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.467 | Acc: 52.699,82.124,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 52.793,82.034,95.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.469 | Acc: 52.816,82.023,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.468 | Acc: 52.811,82.048,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.165 | Acc: 46.875,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.634 | Acc: 47.321,65.923,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.626 | Acc: 46.570,65.053,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 46.440,65.010,68.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 2.513 | Acc: 53.906,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.357 | Acc: 53.683,82.664,97.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.400 | Acc: 53.201,82.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.411 | Acc: 53.317,82.672,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.424 | Acc: 53.115,82.591,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.433 | Acc: 53.187,82.426,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.448 | Acc: 53.009,82.218,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.455 | Acc: 52.964,82.070,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.453 | Acc: 52.897,82.017,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.462 | Acc: 52.849,81.936,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.465 | Acc: 52.705,81.856,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.468 | Acc: 52.676,81.876,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 52.580,81.902,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.470 | Acc: 52.628,81.971,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.468 | Acc: 52.680,81.976,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 52.619,81.964,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.473 | Acc: 52.599,81.949,95.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.472 | Acc: 52.561,81.919,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.474 | Acc: 52.564,81.901,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 52.557,81.925,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.190 | Acc: 46.875,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 47.693,65.699,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 46.780,64.920,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.641 | Acc: 46.734,64.972,68.404,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 2.294 | Acc: 51.562,85.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.524 | Acc: 50.707,81.176,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.492 | Acc: 51.582,82.031,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.483 | Acc: 52.241,81.519,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.458 | Acc: 52.595,81.838,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.465 | Acc: 52.305,81.761,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.462 | Acc: 52.512,81.696,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.465 | Acc: 52.521,81.732,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.476 | Acc: 52.256,81.716,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.469 | Acc: 52.421,81.798,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.467 | Acc: 52.558,81.907,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.463 | Acc: 52.726,81.865,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.456 | Acc: 52.911,82.022,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.456 | Acc: 52.936,81.974,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.459 | Acc: 52.880,82.028,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.459 | Acc: 52.819,82.003,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.460 | Acc: 52.855,81.978,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.464 | Acc: 52.816,81.944,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.462 | Acc: 52.872,81.971,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.460 | Acc: 52.893,82.005,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.233 | Acc: 46.094,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.656 | Acc: 47.545,66.071,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.646 | Acc: 46.684,65.053,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 46.542,64.933,68.430,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 2.511 | Acc: 52.344,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.386 | Acc: 55.432,81.808,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.421 | Acc: 54.040,81.803,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.428 | Acc: 53.612,82.300,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.457 | Acc: 53.328,81.887,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 53.156,81.915,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.463 | Acc: 53.131,82.096,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.462 | Acc: 53.059,82.087,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.469 | Acc: 52.824,82.036,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 52.814,81.854,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.471 | Acc: 52.888,81.868,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.471 | Acc: 52.849,81.837,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 52.879,81.940,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.466 | Acc: 52.859,81.959,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.467 | Acc: 52.875,81.976,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.468 | Acc: 52.795,82.003,95.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 52.789,82.056,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.465 | Acc: 52.717,82.052,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.465 | Acc: 52.744,82.044,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.468 | Acc: 52.672,81.957,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.211 | Acc: 45.312,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.661 | Acc: 47.731,65.662,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.654 | Acc: 46.684,64.806,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.660 | Acc: 46.580,64.805,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 2.194 | Acc: 56.250,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.491 | Acc: 51.488,81.659,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.482 | Acc: 51.905,81.822,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.459 | Acc: 52.293,82.018,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.452 | Acc: 52.488,82.234,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.453 | Acc: 52.344,81.985,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.455 | Acc: 52.531,82.025,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 52.438,81.915,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.464 | Acc: 52.276,81.958,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.460 | Acc: 52.413,82.031,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.464 | Acc: 52.418,81.938,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.466 | Acc: 52.496,81.886,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.463 | Acc: 52.558,81.924,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.464 | Acc: 52.457,81.912,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.475 | Acc: 52.377,81.720,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.477 | Acc: 52.414,81.756,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 52.424,81.837,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.468 | Acc: 52.566,81.976,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.469 | Acc: 52.582,81.964,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.472 | Acc: 52.596,81.949,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.246 | Acc: 45.312,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.634 | Acc: 47.805,66.257,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 46.742,65.206,68.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 46.657,65.215,68.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 2.381 | Acc: 56.250,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.482 | Acc: 52.307,81.287,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.452 | Acc: 53.163,81.631,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 52.690,81.762,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.475 | Acc: 52.556,81.916,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.473 | Acc: 52.491,81.853,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 52.589,81.721,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 52.582,81.666,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 52.615,81.789,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 52.443,81.863,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.484 | Acc: 52.289,81.779,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.481 | Acc: 52.241,81.777,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.475 | Acc: 52.376,81.892,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.476 | Acc: 52.374,81.915,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.469 | Acc: 52.383,81.981,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 52.479,81.995,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 52.465,82.004,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 52.438,82.001,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.469 | Acc: 52.474,81.984,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 52.524,82.035,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.163 | Acc: 46.875,71.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 47.619,65.699,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.642 | Acc: 46.646,65.072,68.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.647 | Acc: 46.580,65.100,68.225,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 2.534 | Acc: 52.344,79.688,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.382 | Acc: 53.162,83.110,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.412 | Acc: 53.582,82.698,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.440 | Acc: 53.074,82.223,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.435 | Acc: 52.730,82.340,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.434 | Acc: 52.676,82.310,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.431 | Acc: 52.641,82.419,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.439 | Acc: 52.726,82.286,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.447 | Acc: 52.810,82.337,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.447 | Acc: 52.819,82.299,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.446 | Acc: 52.822,82.377,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.446 | Acc: 52.856,82.378,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.455 | Acc: 52.765,82.235,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.457 | Acc: 52.748,82.214,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.464 | Acc: 52.658,82.081,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.464 | Acc: 52.580,82.070,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.463 | Acc: 52.587,82.031,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.465 | Acc: 52.552,81.999,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.571,81.977,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.465 | Acc: 52.575,81.966,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.206 | Acc: 44.531,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.641 | Acc: 47.842,65.811,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 46.837,64.863,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.635 | Acc: 46.747,64.882,68.353,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 2.616 | Acc: 53.906,82.812,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.482 | Acc: 51.637,81.659,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.482 | Acc: 51.925,81.936,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.481 | Acc: 52.561,81.519,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.122,81.356,96.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.474 | Acc: 52.429,81.652,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.454 | Acc: 52.931,82.038,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.456 | Acc: 52.826,82.042,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.454 | Acc: 52.868,82.017,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.463 | Acc: 52.814,81.941,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.466 | Acc: 52.806,81.977,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 52.771,81.908,96.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.736,81.902,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.473 | Acc: 52.841,81.858,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.472 | Acc: 52.811,81.953,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.471 | Acc: 52.751,81.925,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 52.702,81.944,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.470 | Acc: 52.756,81.965,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.466 | Acc: 52.811,82.025,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 52.838,82.048,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.212 | Acc: 46.094,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.651 | Acc: 47.247,65.774,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.653 | Acc: 46.208,64.768,68.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 46.132,64.741,67.892,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 2.565 | Acc: 48.438,77.344,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.415 | Acc: 53.237,83.073,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.453 | Acc: 52.553,82.508,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 52.818,82.390,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.464 | Acc: 52.286,82.108,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.455 | Acc: 52.584,82.062,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.465 | Acc: 52.563,81.831,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.466 | Acc: 52.571,81.704,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.480,81.760,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.503,81.785,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.464 | Acc: 52.744,82.012,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.471 | Acc: 52.634,81.932,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.475 | Acc: 52.661,81.934,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 52.619,81.971,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.479 | Acc: 52.563,81.881,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.478 | Acc: 52.507,81.868,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.466 | Acc: 52.706,82.002,95.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.467 | Acc: 52.687,82.059,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.753,82.133,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 52.713,82.142,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.142 | Acc: 45.312,71.094,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.637 | Acc: 47.768,65.625,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.632 | Acc: 46.742,64.787,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.645 | Acc: 46.644,64.844,68.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 2.642 | Acc: 42.969,78.906,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 53.385,82.143,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.459 | Acc: 52.534,82.317,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 52.472,82.313,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.466 | Acc: 52.334,82.272,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.457 | Acc: 52.645,82.534,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.460 | Acc: 52.751,82.496,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.462 | Acc: 52.909,82.414,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.460 | Acc: 52.892,82.410,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.462 | Acc: 52.918,82.277,96.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.468 | Acc: 52.822,82.257,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 52.726,82.229,96.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 52.648,82.216,96.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.464 | Acc: 52.637,82.187,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.468 | Acc: 52.497,82.137,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 52.520,82.036,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.474 | Acc: 52.519,82.014,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 52.543,82.050,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.471 | Acc: 52.606,82.109,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.472 | Acc: 52.616,82.093,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.211 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.646 | Acc: 47.842,65.699,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.641 | Acc: 46.513,64.806,68.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.653 | Acc: 46.414,64.831,68.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 2.383 | Acc: 53.906,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 53.385,83.594,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.444 | Acc: 52.954,82.908,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.420 | Acc: 53.458,82.979,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.417 | Acc: 53.405,82.986,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.407 | Acc: 53.705,82.990,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.426 | Acc: 53.441,82.716,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.435 | Acc: 53.275,82.735,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.445 | Acc: 53.076,82.575,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.455 | Acc: 52.957,82.472,95.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.455 | Acc: 52.931,82.432,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.457 | Acc: 52.945,82.335,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.457 | Acc: 52.937,82.346,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.459 | Acc: 52.945,82.250,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.459 | Acc: 52.992,82.170,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.463 | Acc: 52.917,82.114,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 52.886,82.097,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.466 | Acc: 52.878,82.107,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.468 | Acc: 52.841,82.046,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 52.854,82.097,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.213 | Acc: 46.094,71.875,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.638 | Acc: 47.284,65.923,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.630 | Acc: 46.399,65.225,68.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.542,65.215,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 2.420 | Acc: 57.812,82.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 54.204,81.362,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 53.830,82.107,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.487 | Acc: 52.869,81.698,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.481 | Acc: 52.778,81.925,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.476 | Acc: 52.754,82.078,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.480 | Acc: 52.596,81.902,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.479 | Acc: 52.532,81.732,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 52.514,81.823,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.468 | Acc: 52.642,81.893,96.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.470 | Acc: 52.659,81.829,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.466 | Acc: 52.729,81.929,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 52.717,81.879,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.467 | Acc: 52.730,81.977,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.469 | Acc: 52.619,81.984,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 52.629,81.943,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.468 | Acc: 52.667,81.983,96.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 52.795,81.933,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.904,82.003,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 52.813,81.941,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.228 | Acc: 45.312,68.750,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.649 | Acc: 47.545,65.811,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.642 | Acc: 46.704,64.844,68.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.656 | Acc: 46.516,64.844,68.046,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 2.514 | Acc: 51.562,82.031,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.471 | Acc: 51.116,83.147,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.444 | Acc: 52.496,82.946,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.445 | Acc: 52.523,82.774,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.446 | Acc: 52.479,82.639,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.436 | Acc: 52.947,82.681,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.455 | Acc: 52.789,82.425,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 52.715,82.386,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.467 | Acc: 52.630,82.284,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.467 | Acc: 52.577,82.234,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.466 | Acc: 52.561,82.101,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.468 | Acc: 52.563,82.102,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.469 | Acc: 52.610,82.132,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.472 | Acc: 52.598,82.115,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.470 | Acc: 52.547,82.112,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.469 | Acc: 52.476,82.125,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.465 | Acc: 52.580,82.202,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.466 | Acc: 52.564,82.095,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.465 | Acc: 52.588,82.120,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.462 | Acc: 52.651,82.156,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.155 | Acc: 46.094,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 47.507,65.923,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 46.627,64.939,68.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 46.529,65.010,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 2.449 | Acc: 52.344,88.281,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.361 | Acc: 54.501,83.668,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.408 | Acc: 53.906,83.232,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.436 | Acc: 53.829,82.710,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.428 | Acc: 53.723,82.774,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.441 | Acc: 53.388,82.720,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.446 | Acc: 53.254,82.444,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.454 | Acc: 53.402,82.247,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.455 | Acc: 53.271,82.187,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.460 | Acc: 53.203,82.243,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.462 | Acc: 53.067,82.121,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.458 | Acc: 53.153,82.074,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.456 | Acc: 53.083,82.203,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.460 | Acc: 52.978,82.157,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.457 | Acc: 52.942,82.193,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.457 | Acc: 52.941,82.216,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.459 | Acc: 52.867,82.175,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.458 | Acc: 52.848,82.187,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.460 | Acc: 52.829,82.137,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.460 | Acc: 52.834,82.146,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.217 | Acc: 46.094,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 47.656,65.960,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.655 | Acc: 46.684,64.768,68.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.401,64.716,67.956,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 2.643 | Acc: 50.000,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 53.385,80.766,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 52.801,81.688,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.427 | Acc: 53.087,82.339,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.453 | Acc: 52.845,82.137,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.465 | Acc: 52.792,81.954,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.474 | Acc: 52.505,81.838,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.465 | Acc: 52.626,81.965,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.458 | Acc: 52.683,82.162,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.453 | Acc: 52.784,82.225,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.469 | Acc: 52.701,81.977,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.463 | Acc: 52.931,82.060,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.463 | Acc: 52.927,82.080,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.468 | Acc: 52.850,82.001,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.464 | Acc: 52.878,82.056,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.463 | Acc: 52.902,82.060,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 52.882,82.019,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.463 | Acc: 52.845,82.027,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.837,82.005,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.469 | Acc: 52.778,81.966,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.167 | Acc: 45.312,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.651 | Acc: 47.545,65.811,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.646 | Acc: 46.665,64.939,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.654 | Acc: 46.504,64.985,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 2.195 | Acc: 54.688,88.281,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 52.641,82.292,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 52.630,82.184,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 52.574,82.313,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.478 | Acc: 52.488,82.147,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.479 | Acc: 52.452,82.248,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 52.563,82.341,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 52.815,82.475,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.469 | Acc: 52.916,82.473,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.465 | Acc: 52.935,82.428,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.462 | Acc: 52.907,82.443,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.463 | Acc: 52.849,82.452,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.461 | Acc: 52.781,82.534,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.467 | Acc: 52.739,82.426,96.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.461 | Acc: 52.853,82.487,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.463 | Acc: 52.821,82.421,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.463 | Acc: 52.860,82.401,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.467 | Acc: 52.703,82.368,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.467 | Acc: 52.757,82.349,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.468 | Acc: 52.772,82.310,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.211 | Acc: 46.094,69.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.653 | Acc: 48.140,65.588,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 46.894,64.844,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 46.606,64.946,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 2.303 | Acc: 59.375,87.500,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.447 | Acc: 54.204,82.924,95.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.453 | Acc: 53.506,82.374,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.463 | Acc: 52.843,81.993,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.455 | Acc: 52.874,82.369,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.460 | Acc: 52.545,82.550,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.467 | Acc: 52.376,82.651,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.469 | Acc: 52.466,82.602,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.465 | Acc: 52.606,82.550,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.463 | Acc: 52.564,82.579,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.465 | Acc: 52.569,82.428,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.466 | Acc: 52.701,82.325,96.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.473 | Acc: 52.623,82.245,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 52.607,82.202,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 52.577,82.248,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 52.572,82.288,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 52.573,82.241,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.473 | Acc: 52.584,82.187,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 52.666,82.148,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 52.737,82.183,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.211 | Acc: 45.312,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.635 | Acc: 47.768,65.774,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 46.704,65.015,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 46.580,65.138,68.238,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 2.674 | Acc: 57.031,81.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.495 | Acc: 52.976,81.734,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.442 | Acc: 53.144,82.698,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.471 | Acc: 52.946,82.031,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.468 | Acc: 53.193,81.954,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.465 | Acc: 53.164,81.954,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.466 | Acc: 52.880,82.083,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.456 | Acc: 52.942,82.197,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.459 | Acc: 52.858,82.148,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.470 | Acc: 52.624,82.005,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.470 | Acc: 52.620,82.000,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.472 | Acc: 52.542,82.035,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 52.785,82.106,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.464 | Acc: 52.856,82.058,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.463 | Acc: 52.844,82.070,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.463 | Acc: 52.839,82.049,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.462 | Acc: 52.823,82.104,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.460 | Acc: 52.873,82.109,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.460 | Acc: 52.930,82.055,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.458 | Acc: 52.936,82.124,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.192 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 47.656,65.885,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.635 | Acc: 46.646,64.748,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.646 | Acc: 46.478,64.844,67.879,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 2.859 | Acc: 59.375,78.125,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.473 | Acc: 53.013,81.920,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.427 | Acc: 53.239,82.336,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.433 | Acc: 53.138,82.147,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.455 | Acc: 52.845,82.205,96.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.465 | Acc: 52.707,82.078,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.462 | Acc: 52.757,82.160,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.459 | Acc: 52.798,82.203,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.463 | Acc: 52.582,82.056,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.463 | Acc: 52.521,82.118,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.456 | Acc: 52.729,82.179,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.455 | Acc: 52.761,82.250,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.456 | Acc: 52.671,82.203,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.454 | Acc: 52.664,82.235,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.457 | Acc: 52.608,82.301,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.453 | Acc: 52.611,82.356,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.456 | Acc: 52.611,82.321,96.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.456 | Acc: 52.612,82.315,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.461 | Acc: 52.517,82.222,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.460 | Acc: 52.588,82.290,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.184 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.637 | Acc: 47.545,65.811,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.633 | Acc: 46.761,64.844,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.639 | Acc: 46.644,64.933,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 2.818 | Acc: 48.438,71.875,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.500 | Acc: 52.567,81.548,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.464 | Acc: 53.106,81.955,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.476 | Acc: 52.651,81.814,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.476 | Acc: 52.691,82.022,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.472 | Acc: 52.707,82.000,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.471 | Acc: 52.841,81.928,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.476 | Acc: 52.715,81.959,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.481 | Acc: 52.664,81.818,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.483 | Acc: 52.642,81.815,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.491 | Acc: 52.491,81.720,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.482 | Acc: 52.595,81.805,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.478 | Acc: 52.704,81.869,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.476 | Acc: 52.745,81.864,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.473 | Acc: 52.791,81.839,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.816,81.837,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.474 | Acc: 52.770,81.817,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.474 | Acc: 52.843,81.788,95.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.472 | Acc: 52.805,81.804,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.470 | Acc: 52.815,81.836,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.210 | Acc: 44.531,70.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 47.805,65.699,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.643 | Acc: 46.723,64.710,68.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.659 | Acc: 46.491,64.677,68.020,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 2.544 | Acc: 50.000,79.688,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.430 | Acc: 52.269,82.440,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.451 | Acc: 52.344,82.031,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.442 | Acc: 53.240,82.236,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.439 | Acc: 52.768,82.166,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.449 | Acc: 52.692,82.008,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.433 | Acc: 52.738,82.264,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.448 | Acc: 52.671,82.103,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.451 | Acc: 52.805,81.992,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.452 | Acc: 53.000,82.031,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.452 | Acc: 53.051,82.020,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.457 | Acc: 52.980,82.003,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.461 | Acc: 52.885,81.976,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.463 | Acc: 52.847,81.965,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.465 | Acc: 52.825,81.981,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.464 | Acc: 52.917,81.982,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 52.899,81.970,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 52.818,81.974,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.466 | Acc: 52.841,82.012,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 52.815,82.023,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.185 | Acc: 45.312,70.312,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.631 | Acc: 47.507,65.513,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.625 | Acc: 46.723,64.996,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.734,65.074,68.417,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 2.578 | Acc: 47.656,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.426 | Acc: 53.385,82.552,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.423 | Acc: 53.201,82.736,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.424 | Acc: 53.701,82.902,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.429 | Acc: 53.501,82.533,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.442 | Acc: 53.164,82.279,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.450 | Acc: 52.854,82.206,96.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.447 | Acc: 52.892,82.159,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.456 | Acc: 52.824,82.114,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.461 | Acc: 52.719,82.018,96.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.459 | Acc: 52.818,82.031,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.461 | Acc: 52.711,82.028,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.459 | Acc: 52.746,82.184,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.459 | Acc: 52.811,82.175,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.463 | Acc: 52.872,82.109,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.461 | Acc: 52.855,82.130,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 52.823,82.004,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.463 | Acc: 52.827,82.040,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.803,82.023,96.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 52.756,82.035,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.146 | Acc: 45.312,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.619 | Acc: 47.656,65.923,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.621 | Acc: 46.704,65.034,68.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.633 | Acc: 46.747,64.959,68.289,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 2.329 | Acc: 57.812,84.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.499 | Acc: 52.307,81.957,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 52.210,81.974,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 52.382,81.852,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.494 | Acc: 52.276,81.829,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.478 | Acc: 52.437,81.923,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.482 | Acc: 52.408,81.857,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.472 | Acc: 52.510,81.965,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.463 | Acc: 52.669,82.099,96.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.469 | Acc: 52.637,82.036,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.465 | Acc: 52.620,82.175,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.471 | Acc: 52.634,82.042,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.468 | Acc: 52.759,82.083,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 52.754,82.091,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.470 | Acc: 52.789,82.065,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.467 | Acc: 52.860,82.073,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.468 | Acc: 52.886,82.065,95.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.467 | Acc: 52.880,82.144,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.463 | Acc: 52.954,82.181,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.462 | Acc: 53.018,82.140,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.219 | Acc: 46.094,71.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 48.028,65.737,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.653 | Acc: 46.742,64.768,68.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.666 | Acc: 46.670,64.869,68.315,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 2.722 | Acc: 51.562,82.812,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.383 | Acc: 54.315,83.073,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 53.525,82.603,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.450 | Acc: 53.163,82.864,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.446 | Acc: 53.250,82.735,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.449 | Acc: 52.955,82.782,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.454 | Acc: 52.847,82.716,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.468 | Acc: 52.449,82.458,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.462 | Acc: 52.528,82.410,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.460 | Acc: 52.788,82.467,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.456 | Acc: 52.880,82.494,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.460 | Acc: 52.849,82.367,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.458 | Acc: 52.934,82.365,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.456 | Acc: 52.957,82.334,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.459 | Acc: 52.903,82.298,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.458 | Acc: 52.969,82.286,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.458 | Acc: 53.003,82.238,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.465 | Acc: 52.928,82.130,95.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.945,82.126,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.465 | Acc: 52.914,82.115,95.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.177 | Acc: 44.531,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.642 | Acc: 47.545,65.662,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.631 | Acc: 46.627,65.091,68.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.643 | Acc: 46.580,65.074,68.174,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 2.192 | Acc: 52.344,86.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.442 | Acc: 52.976,83.036,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.457 | Acc: 52.534,82.965,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.754,82.633,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.456 | Acc: 52.922,82.523,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.457 | Acc: 53.063,82.580,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.459 | Acc: 52.776,82.496,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.461 | Acc: 52.632,82.314,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.463 | Acc: 52.538,82.322,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.469 | Acc: 52.460,82.135,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.467 | Acc: 52.577,82.171,95.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.469 | Acc: 52.556,82.077,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.471 | Acc: 52.587,82.086,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.471 | Acc: 52.667,82.064,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.470 | Acc: 52.555,82.201,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.467 | Acc: 52.632,82.210,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.466 | Acc: 52.733,82.192,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.469 | Acc: 52.703,82.118,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.473 | Acc: 52.649,82.081,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.475 | Acc: 52.623,82.031,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.205 | Acc: 44.531,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.659 | Acc: 47.619,65.662,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.650 | Acc: 46.532,64.787,68.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.660 | Acc: 46.324,64.908,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 2.653 | Acc: 49.219,80.469,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.387 | Acc: 54.576,83.036,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.438 | Acc: 53.659,82.374,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 53.356,82.172,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.468 | Acc: 53.164,82.079,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.458 | Acc: 53.249,82.116,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.456 | Acc: 53.338,82.109,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.463 | Acc: 53.258,81.926,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.468 | Acc: 52.999,81.886,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.466 | Acc: 52.974,81.880,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.462 | Acc: 52.845,81.938,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.469 | Acc: 52.810,81.915,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.470 | Acc: 52.859,81.918,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.464 | Acc: 52.957,81.974,96.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.468 | Acc: 52.964,81.934,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.467 | Acc: 52.995,81.927,96.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.464 | Acc: 53.008,82.041,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.462 | Acc: 53.008,82.072,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.459 | Acc: 53.151,82.075,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.460 | Acc: 53.066,82.056,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.208 | Acc: 44.531,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.639 | Acc: 47.582,66.034,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.636 | Acc: 46.780,64.996,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.650 | Acc: 46.670,64.857,68.379,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 2.226 | Acc: 57.031,83.594,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 53.274,81.585,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.486 | Acc: 53.125,81.517,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.500 | Acc: 52.984,81.212,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.499 | Acc: 52.701,81.366,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.491 | Acc: 52.336,81.606,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.479 | Acc: 52.744,81.702,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.480 | Acc: 52.626,81.699,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 52.698,81.823,96.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.470 | Acc: 52.844,81.928,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.473 | Acc: 52.717,81.907,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.473 | Acc: 52.683,81.865,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.476 | Acc: 52.616,81.811,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.477 | Acc: 52.580,81.840,96.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.647,81.962,96.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.472 | Acc: 52.634,81.920,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.471 | Acc: 52.650,81.956,96.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.468 | Acc: 52.651,81.988,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.462 | Acc: 52.816,82.064,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.460 | Acc: 52.885,82.119,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.200 | Acc: 46.094,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.648 | Acc: 47.619,65.699,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 46.684,64.901,68.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.662 | Acc: 46.529,64.869,68.122,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 2.231 | Acc: 55.469,87.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.485 | Acc: 52.753,82.292,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 53.525,82.508,95.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 53.227,81.954,95.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.480 | Acc: 53.086,81.973,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.458 | Acc: 53.272,82.263,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.460 | Acc: 53.312,82.367,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.458 | Acc: 53.219,82.347,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.454 | Acc: 53.241,82.313,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.452 | Acc: 53.440,82.333,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.452 | Acc: 53.397,82.323,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.458 | Acc: 53.365,82.197,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.452 | Acc: 53.307,82.223,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.454 | Acc: 53.170,82.184,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.455 | Acc: 53.083,82.181,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.460 | Acc: 53.032,82.125,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.459 | Acc: 53.088,82.146,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.460 | Acc: 52.988,82.118,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.459 | Acc: 52.984,82.172,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.462 | Acc: 52.893,82.099,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.177 | Acc: 45.312,69.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 47.619,65.811,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 46.780,64.920,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 46.542,64.921,67.994,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 2.282 | Acc: 57.812,79.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.412 | Acc: 52.827,81.845,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.437 | Acc: 52.420,81.841,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 52.331,82.006,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.429 | Acc: 52.623,82.099,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.437 | Acc: 52.630,81.969,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.441 | Acc: 52.608,81.986,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.434 | Acc: 52.732,82.153,96.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.435 | Acc: 52.848,82.274,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.442 | Acc: 52.689,82.256,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.443 | Acc: 52.666,82.272,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.445 | Acc: 52.570,82.293,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.448 | Acc: 52.648,82.206,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.450 | Acc: 52.700,82.247,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.451 | Acc: 52.727,82.315,96.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.454 | Acc: 52.629,82.247,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.452 | Acc: 52.772,82.270,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.455 | Acc: 52.639,82.240,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.456 | Acc: 52.649,82.204,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.458 | Acc: 52.645,82.195,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.185 | Acc: 43.750,71.094,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.633 | Acc: 47.768,65.923,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.629 | Acc: 46.704,65.149,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.636 | Acc: 46.555,65.087,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 2.574 | Acc: 49.219,78.906,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.496 | Acc: 52.679,82.589,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 53.125,82.317,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.502 | Acc: 52.536,81.890,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.485 | Acc: 52.623,82.234,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.482 | Acc: 52.777,82.186,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.478 | Acc: 52.815,82.154,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.474 | Acc: 52.870,82.103,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.476 | Acc: 52.810,82.065,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.468 | Acc: 52.840,82.049,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.469 | Acc: 52.857,81.884,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.467 | Acc: 52.927,81.830,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.466 | Acc: 52.882,81.853,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.456 | Acc: 53.029,81.977,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.463 | Acc: 52.925,81.884,96.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.462 | Acc: 52.767,81.920,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.465 | Acc: 52.716,81.873,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.464 | Acc: 52.694,81.930,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.466 | Acc: 52.697,81.871,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 52.740,81.925,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.199 | Acc: 45.312,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.651 | Acc: 47.731,65.848,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 46.627,65.053,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.516,64.882,68.071,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 2.566 | Acc: 44.531,84.375,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.532 | Acc: 50.893,82.887,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.470 | Acc: 52.439,83.098,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.471 | Acc: 52.690,82.838,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.461 | Acc: 52.816,82.803,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.449 | Acc: 52.978,82.843,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.463 | Acc: 52.751,82.722,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.464 | Acc: 52.654,82.580,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.459 | Acc: 52.916,82.648,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.454 | Acc: 52.922,82.592,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.459 | Acc: 52.795,82.502,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.468 | Acc: 52.619,82.364,96.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.467 | Acc: 52.710,82.411,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.468 | Acc: 52.712,82.313,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.466 | Acc: 52.675,82.320,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.461 | Acc: 52.842,82.363,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.459 | Acc: 52.908,82.304,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.456 | Acc: 52.990,82.267,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.460 | Acc: 52.872,82.170,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.461 | Acc: 52.850,82.165,96.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.181 | Acc: 46.094,68.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 47.582,65.699,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 46.380,64.768,68.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.452,64.793,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 2.321 | Acc: 57.031,85.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.435 | Acc: 53.199,82.403,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.433 | Acc: 53.582,82.146,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 53.330,82.134,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.498 | Acc: 52.633,81.665,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 52.653,81.660,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.488 | Acc: 52.602,81.857,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.481 | Acc: 52.920,81.859,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.472 | Acc: 53.028,81.905,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.473 | Acc: 52.948,81.915,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 52.927,81.864,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.479 | Acc: 52.916,81.801,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 52.849,81.940,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.469 | Acc: 52.766,82.022,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.471 | Acc: 52.722,81.953,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.470 | Acc: 52.715,81.940,95.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.468 | Acc: 52.770,81.951,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.468 | Acc: 52.697,81.972,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.462 | Acc: 52.837,81.997,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.462 | Acc: 52.838,82.017,96.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.210 | Acc: 44.531,69.531,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.659 | Acc: 47.619,65.625,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.655 | Acc: 46.646,64.729,68.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.664 | Acc: 46.555,64.780,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 2.510 | Acc: 52.344,78.125,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.368 | Acc: 53.609,82.180,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.435 | Acc: 52.934,81.669,95.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 52.792,81.519,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.441 | Acc: 52.990,81.838,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.438 | Acc: 53.001,82.186,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.453 | Acc: 52.763,81.857,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.445 | Acc: 52.892,82.059,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.444 | Acc: 52.965,82.143,95.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.457 | Acc: 52.655,81.975,95.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.458 | Acc: 52.767,82.016,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.457 | Acc: 52.832,81.992,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.454 | Acc: 52.840,82.041,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.462 | Acc: 52.706,81.971,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.461 | Acc: 52.733,81.892,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.462 | Acc: 52.710,81.850,95.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.463 | Acc: 52.723,81.795,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.461 | Acc: 52.795,81.871,95.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.671,81.856,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.467 | Acc: 52.709,81.834,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.169 | Acc: 46.094,70.312,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.654 | Acc: 47.731,65.588,69.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.652 | Acc: 46.589,64.806,68.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.661 | Acc: 46.644,64.857,68.058,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 2.045 | Acc: 57.812,85.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.418 | Acc: 52.902,82.552,96.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.401 | Acc: 53.620,82.336,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.453 | Acc: 52.651,81.826,96.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.466 | Acc: 52.604,82.002,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.446 | Acc: 53.094,82.194,96.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.458 | Acc: 53.060,81.973,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.454 | Acc: 53.175,82.026,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.450 | Acc: 53.271,82.114,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.457 | Acc: 53.069,82.001,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.455 | Acc: 53.039,81.992,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.462 | Acc: 52.892,82.042,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.460 | Acc: 52.901,82.009,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.463 | Acc: 52.901,81.995,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.466 | Acc: 52.844,82.001,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.469 | Acc: 52.712,81.920,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.472 | Acc: 52.607,81.841,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.470 | Acc: 52.706,81.846,96.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.464 | Acc: 52.764,81.914,96.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.461 | Acc: 52.803,81.951,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.216 | Acc: 44.531,70.312,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.650 | Acc: 47.731,65.811,69.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.648 | Acc: 46.704,64.768,68.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.663 | Acc: 46.593,64.793,68.097,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 2.197 | Acc: 54.688,80.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.432 | Acc: 52.939,81.994,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 52.553,81.364,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.452 | Acc: 52.805,81.685,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.451 | Acc: 53.029,81.655,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.446 | Acc: 52.885,81.938,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.452 | Acc: 52.751,82.038,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.444 | Acc: 52.854,82.103,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.436 | Acc: 52.892,82.211,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.442 | Acc: 52.970,82.049,96.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.438 | Acc: 52.954,82.074,96.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.437 | Acc: 52.977,82.162,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.442 | Acc: 52.930,82.090,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.448 | Acc: 52.847,82.025,96.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.445 | Acc: 52.883,82.059,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.447 | Acc: 52.933,82.026,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.454 | Acc: 52.845,81.949,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.456 | Acc: 52.827,81.960,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.463 | Acc: 52.735,81.878,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.464 | Acc: 52.783,81.859,96.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.187 | Acc: 45.312,71.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.652 | Acc: 47.991,65.625,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.644 | Acc: 46.799,64.996,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.652 | Acc: 46.709,65.061,68.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 2.525 | Acc: 45.312,81.250,96.875,% | Adaptive Acc: 86.719% | clf_exit: 0.305 0.500 0.195
Batch: 20 | Loss: 2.460 | Acc: 50.893,81.957,95.610,% | Adaptive Acc: 86.198% | clf_exit: 0.364 0.447 0.189
Batch: 40 | Loss: 2.459 | Acc: 51.791,81.993,95.598,% | Adaptive Acc: 86.471% | clf_exit: 0.365 0.445 0.190
Batch: 60 | Loss: 2.432 | Acc: 52.357,82.569,96.004,% | Adaptive Acc: 86.501% | clf_exit: 0.371 0.442 0.187
Batch: 80 | Loss: 2.440 | Acc: 52.392,82.832,96.026,% | Adaptive Acc: 86.690% | clf_exit: 0.372 0.441 0.188
Batch: 100 | Loss: 2.441 | Acc: 52.560,82.673,95.955,% | Adaptive Acc: 86.711% | clf_exit: 0.371 0.440 0.190
Batch: 120 | Loss: 2.433 | Acc: 52.660,82.606,96.036,% | Adaptive Acc: 86.822% | clf_exit: 0.371 0.439 0.190
Batch: 140 | Loss: 2.442 | Acc: 52.521,82.408,96.061,% | Adaptive Acc: 86.741% | clf_exit: 0.371 0.438 0.191
Batch: 160 | Loss: 2.440 | Acc: 52.596,82.512,96.089,% | Adaptive Acc: 86.855% | clf_exit: 0.371 0.437 0.191
Batch: 180 | Loss: 2.443 | Acc: 52.672,82.390,96.042,% | Adaptive Acc: 86.904% | clf_exit: 0.370 0.440 0.191
Batch: 200 | Loss: 2.445 | Acc: 52.624,82.327,96.035,% | Adaptive Acc: 86.839% | clf_exit: 0.368 0.441 0.191
Batch: 220 | Loss: 2.442 | Acc: 52.641,82.402,96.097,% | Adaptive Acc: 86.857% | clf_exit: 0.370 0.440 0.190
Batch: 240 | Loss: 2.445 | Acc: 52.674,82.326,96.081,% | Adaptive Acc: 86.780% | clf_exit: 0.371 0.440 0.189
Batch: 260 | Loss: 2.440 | Acc: 52.829,82.399,96.109,% | Adaptive Acc: 86.856% | clf_exit: 0.371 0.440 0.189
Batch: 280 | Loss: 2.440 | Acc: 52.833,82.448,96.099,% | Adaptive Acc: 86.888% | clf_exit: 0.371 0.440 0.189
Batch: 300 | Loss: 2.445 | Acc: 52.819,82.319,96.081,% | Adaptive Acc: 86.817% | clf_exit: 0.371 0.440 0.189
Batch: 320 | Loss: 2.452 | Acc: 52.789,82.206,96.082,% | Adaptive Acc: 86.819% | clf_exit: 0.371 0.440 0.189
Batch: 340 | Loss: 2.455 | Acc: 52.690,82.178,96.059,% | Adaptive Acc: 86.774% | clf_exit: 0.370 0.441 0.189
Batch: 360 | Loss: 2.457 | Acc: 52.699,82.094,96.029,% | Adaptive Acc: 86.708% | clf_exit: 0.370 0.441 0.189
Batch: 380 | Loss: 2.459 | Acc: 52.672,82.126,96.024,% | Adaptive Acc: 86.737% | clf_exit: 0.369 0.442 0.189
Batch: 0 | Loss: 4.214 | Acc: 46.094,70.312,73.438,% | Adaptive Acc: 63.281% | clf_exit: 0.422 0.383 0.195
Batch: 20 | Loss: 4.650 | Acc: 47.545,66.034,69.420,% | Adaptive Acc: 63.356% | clf_exit: 0.423 0.371 0.206
Batch: 40 | Loss: 4.641 | Acc: 46.627,64.901,68.483,% | Adaptive Acc: 63.357% | clf_exit: 0.413 0.369 0.218
Batch: 60 | Loss: 4.653 | Acc: 46.401,64.895,68.199,% | Adaptive Acc: 62.935% | clf_exit: 0.415 0.370 0.215
model is save as models/resnet56_h12_cifar100_adaptive0_circles4_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 59.474 | Acc: 1.562,1.562,2.344,% | Adaptive Acc: 0.781% | clf_exit: 0.953 0.047 0.000
Batch: 20 | Loss: 59.685 | Acc: 1.786,1.079,1.637,% | Adaptive Acc: 1.749% | clf_exit: 0.928 0.072 0.000
Batch: 40 | Loss: 59.793 | Acc: 2.001,1.067,1.639,% | Adaptive Acc: 1.886% | clf_exit: 0.930 0.070 0.000
Batch: 60 | Loss: 59.486 | Acc: 1.703,1.076,1.627,% | Adaptive Acc: 1.601% | clf_exit: 0.930 0.070 0.000
Batch: 0 | Loss: 42.297 | Acc: 3.125,2.344,2.344,% | Adaptive Acc: 2.344% | clf_exit: 0.812 0.188 0.000
Batch: 20 | Loss: 42.731 | Acc: 2.902,1.562,2.381,% | Adaptive Acc: 2.455% | clf_exit: 0.821 0.179 0.000
Batch: 40 | Loss: 42.848 | Acc: 3.258,1.486,2.477,% | Adaptive Acc: 2.973% | clf_exit: 0.821 0.179 0.000
Batch: 60 | Loss: 42.643 | Acc: 2.869,1.665,2.433,% | Adaptive Acc: 2.690% | clf_exit: 0.819 0.181 0.000
Batch: 0 | Loss: 24.642 | Acc: 6.250,7.812,11.719,% | Adaptive Acc: 8.594% | clf_exit: 0.766 0.219 0.016
Batch: 20 | Loss: 25.420 | Acc: 5.841,6.362,10.900,% | Adaptive Acc: 6.362% | clf_exit: 0.726 0.242 0.032
Batch: 40 | Loss: 25.558 | Acc: 5.755,6.612,10.595,% | Adaptive Acc: 6.307% | clf_exit: 0.714 0.256 0.030
Batch: 60 | Loss: 25.442 | Acc: 5.443,6.762,10.323,% | Adaptive Acc: 6.122% | clf_exit: 0.711 0.258 0.030
Batch: 0 | Loss: 9.724 | Acc: 20.312,49.219,59.375,% | Adaptive Acc: 38.281% | clf_exit: 0.508 0.242 0.250
Batch: 20 | Loss: 10.419 | Acc: 13.281,42.485,52.827,% | Adaptive Acc: 30.506% | clf_exit: 0.522 0.264 0.214
Batch: 40 | Loss: 10.529 | Acc: 12.881,40.854,52.229,% | Adaptive Acc: 30.412% | clf_exit: 0.521 0.262 0.216
Batch: 60 | Loss: 10.476 | Acc: 12.641,40.523,52.369,% | Adaptive Acc: 30.225% | clf_exit: 0.524 0.265 0.211
Batch: 0 | Loss: 4.214 | Acc: 46.094,70.312,73.438,% | Adaptive Acc: 63.281% | clf_exit: 0.422 0.383 0.195
Batch: 20 | Loss: 4.650 | Acc: 47.545,66.034,69.420,% | Adaptive Acc: 63.356% | clf_exit: 0.423 0.371 0.206
Batch: 40 | Loss: 4.641 | Acc: 46.627,64.901,68.483,% | Adaptive Acc: 63.357% | clf_exit: 0.413 0.369 0.218
Batch: 60 | Loss: 4.653 | Acc: 46.401,64.895,68.199,% | Adaptive Acc: 62.935% | clf_exit: 0.415 0.370 0.215







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 13.688 |  Acc: 1.988,3.348,1.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 13.375 |  Acc: 3.080,4.670,1.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 12.963 |  Acc: 3.632,6.696,2.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 12.734 |  Acc: 4.050,6.920,3.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 12.031 |  Acc: 5.694,9.240,8.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 11.899 |  Acc: 5.520,9.670,8.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 11.345 |  Acc: 7.598,12.292,13.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 11.319 |  Acc: 7.470,11.410,14.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 10.762 |  Acc: 9.708,15.090,17.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 12.046 |  Acc: 4.630,10.520,14.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 10.130 |  Acc: 11.650,18.432,21.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 10.793 |  Acc: 10.660,13.620,17.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 9.608 |  Acc: 13.708,21.646,25.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 9.982 |  Acc: 11.430,19.620,23.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 9.171 |  Acc: 15.718,24.242,28.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 9.774 |  Acc: 12.130,20.200,26.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 8.811 |  Acc: 17.544,26.540,31.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 9.148 |  Acc: 14.910,23.090,29.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 8.492 |  Acc: 19.438,28.308,33.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 9.507 |  Acc: 15.060,23.600,28.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 8.214 |  Acc: 20.908,30.046,36.304,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 8.876 |  Acc: 18.030,26.110,31.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 7.965 |  Acc: 22.842,31.854,38.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 10.353 |  Acc: 12.610,18.700,28.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 7.761 |  Acc: 23.694,33.054,39.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 8.885 |  Acc: 18.620,23.470,33.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 7.564 |  Acc: 24.950,34.516,41.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 9.171 |  Acc: 17.100,23.820,33.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 7.389 |  Acc: 26.158,35.890,42.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 7.643 |  Acc: 23.450,33.460,42.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 7.212 |  Acc: 27.098,37.372,44.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 9.248 |  Acc: 16.780,26.310,33.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 7.056 |  Acc: 28.004,38.506,45.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 7.976 |  Acc: 20.900,32.420,41.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 6.914 |  Acc: 28.694,39.756,47.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 8.244 |  Acc: 20.160,31.330,41.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 6.779 |  Acc: 29.288,40.746,48.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 7.846 |  Acc: 23.030,34.660,40.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 6.654 |  Acc: 30.108,41.976,49.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 7.721 |  Acc: 24.340,35.200,43.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 6.540 |  Acc: 30.956,43.042,50.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 7.890 |  Acc: 23.470,32.560,41.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 6.443 |  Acc: 31.478,44.014,51.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 7.359 |  Acc: 23.190,36.990,46.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 6.351 |  Acc: 31.796,44.592,51.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 7.530 |  Acc: 25.000,36.810,44.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 6.261 |  Acc: 32.638,45.438,52.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 8.156 |  Acc: 17.110,34.430,43.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 6.145 |  Acc: 33.030,46.658,53.638,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 7.770 |  Acc: 22.990,34.380,44.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 6.086 |  Acc: 33.482,47.248,54.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 8.345 |  Acc: 20.200,32.550,40.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 6.021 |  Acc: 33.854,47.818,54.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 8.253 |  Acc: 22.070,31.510,42.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 5.939 |  Acc: 34.050,48.592,55.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 7.907 |  Acc: 24.330,37.260,43.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 5.888 |  Acc: 34.760,49.030,55.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 7.701 |  Acc: 22.920,37.900,45.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 5.810 |  Acc: 34.932,49.668,56.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 7.538 |  Acc: 25.810,39.020,45.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 5.779 |  Acc: 35.286,50.130,57.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 7.394 |  Acc: 23.120,39.980,48.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 5.725 |  Acc: 35.754,50.660,57.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 8.633 |  Acc: 17.720,35.120,41.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 5.691 |  Acc: 35.542,50.438,57.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 7.498 |  Acc: 24.000,39.760,47.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 5.612 |  Acc: 36.106,51.584,58.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 7.313 |  Acc: 23.970,39.960,49.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 5.589 |  Acc: 36.156,51.604,59.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 6.882 |  Acc: 25.990,43.590,50.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 5.540 |  Acc: 36.506,52.254,59.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 7.249 |  Acc: 25.700,42.870,49.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 5.485 |  Acc: 36.594,52.644,59.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 6.967 |  Acc: 27.460,42.400,49.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 5.449 |  Acc: 36.794,52.996,60.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 7.269 |  Acc: 27.200,39.730,46.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 5.428 |  Acc: 37.120,53.008,60.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 7.609 |  Acc: 23.460,41.190,46.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 5.400 |  Acc: 37.036,53.390,60.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 6.961 |  Acc: 29.390,41.260,51.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 5.358 |  Acc: 37.408,53.892,61.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 6.540 |  Acc: 30.540,44.510,53.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 5.320 |  Acc: 37.512,54.164,61.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 6.691 |  Acc: 28.050,44.560,52.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 5.295 |  Acc: 37.824,54.414,61.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 7.538 |  Acc: 25.380,40.140,48.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 5.279 |  Acc: 37.616,54.574,61.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 7.500 |  Acc: 24.210,40.030,49.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 5.248 |  Acc: 37.906,54.902,62.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 6.769 |  Acc: 28.790,45.740,51.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 5.218 |  Acc: 38.140,55.216,62.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 7.486 |  Acc: 28.650,38.780,47.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 5.176 |  Acc: 38.596,55.668,62.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 7.165 |  Acc: 26.440,40.460,49.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 5.156 |  Acc: 38.658,55.744,63.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 6.779 |  Acc: 29.580,44.040,52.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 5.146 |  Acc: 38.370,55.856,63.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 6.886 |  Acc: 27.150,44.230,51.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 5.104 |  Acc: 38.772,56.156,63.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 7.015 |  Acc: 27.880,42.280,49.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 5.086 |  Acc: 38.726,56.216,63.816,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 7.738 |  Acc: 26.790,39.410,46.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 5.053 |  Acc: 39.074,56.504,64.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 6.608 |  Acc: 30.990,44.970,51.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 5.062 |  Acc: 38.978,56.428,63.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 7.140 |  Acc: 26.190,43.740,49.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 5.034 |  Acc: 39.170,56.956,64.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 8.069 |  Acc: 19.620,38.810,48.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 5.006 |  Acc: 39.336,57.100,64.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 6.978 |  Acc: 24.140,45.550,53.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 4.998 |  Acc: 39.380,56.996,64.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 7.059 |  Acc: 27.280,42.740,51.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 4.964 |  Acc: 39.524,57.500,65.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 7.198 |  Acc: 24.910,42.630,50.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 4.957 |  Acc: 39.756,57.516,65.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 6.431 |  Acc: 32.550,46.680,54.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 4.918 |  Acc: 39.698,58.046,65.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 6.804 |  Acc: 27.220,44.140,53.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 4.908 |  Acc: 39.958,57.688,65.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 7.416 |  Acc: 25.730,42.980,52.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 4.909 |  Acc: 40.032,57.856,65.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 6.304 |  Acc: 34.120,47.340,54.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 4.895 |  Acc: 40.072,58.356,65.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 6.600 |  Acc: 29.150,47.290,53.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 4.886 |  Acc: 39.882,57.982,65.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 7.204 |  Acc: 27.870,40.280,48.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 4.834 |  Acc: 40.204,58.646,66.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 6.659 |  Acc: 28.330,46.180,54.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 4.847 |  Acc: 39.910,58.756,66.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 7.634 |  Acc: 23.580,40.030,48.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 4.821 |  Acc: 40.274,58.788,66.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 7.563 |  Acc: 20.830,43.940,52.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 4.816 |  Acc: 40.342,59.006,66.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 7.067 |  Acc: 24.860,44.180,50.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 4.795 |  Acc: 40.382,59.040,66.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 7.237 |  Acc: 27.750,40.750,49.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 4.797 |  Acc: 40.396,59.166,66.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 6.734 |  Acc: 29.610,43.900,52.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 4.790 |  Acc: 40.412,59.022,66.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 6.694 |  Acc: 29.320,47.570,54.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 4.741 |  Acc: 40.624,59.544,67.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 7.647 |  Acc: 23.420,41.350,48.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 4.754 |  Acc: 40.804,59.482,67.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 6.339 |  Acc: 29.660,48.900,56.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 4.749 |  Acc: 40.716,59.338,67.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 6.403 |  Acc: 32.590,47.660,53.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 4.730 |  Acc: 40.984,59.492,67.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 6.503 |  Acc: 28.950,47.030,55.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 4.733 |  Acc: 40.866,59.608,67.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 8.326 |  Acc: 21.730,37.880,47.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 4.701 |  Acc: 41.170,59.838,67.764,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 7.534 |  Acc: 24.960,41.470,49.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 4.702 |  Acc: 40.834,60.302,67.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 6.814 |  Acc: 28.240,46.270,52.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 4.683 |  Acc: 40.972,60.150,67.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 6.514 |  Acc: 30.040,46.580,53.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 4.672 |  Acc: 41.328,60.114,68.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 6.862 |  Acc: 27.940,44.990,53.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 4.663 |  Acc: 41.274,60.140,67.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 6.594 |  Acc: 28.570,46.660,53.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 4.656 |  Acc: 41.248,60.542,68.038,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 7.081 |  Acc: 26.230,41.980,52.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 4.646 |  Acc: 41.318,60.254,68.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 6.131 |  Acc: 30.220,50.550,57.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 4.611 |  Acc: 41.550,60.910,68.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 7.324 |  Acc: 28.430,42.250,50.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 4.629 |  Acc: 41.690,60.458,68.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 8.156 |  Acc: 23.280,39.100,47.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 4.596 |  Acc: 41.706,60.934,68.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 8.154 |  Acc: 16.850,38.060,50.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 4.594 |  Acc: 41.560,60.982,68.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 7.168 |  Acc: 29.940,39.450,49.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 4.615 |  Acc: 41.546,60.676,68.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 6.853 |  Acc: 28.710,46.230,54.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 4.582 |  Acc: 41.678,60.932,68.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 6.459 |  Acc: 29.600,49.280,55.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 4.587 |  Acc: 41.720,61.120,68.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 6.223 |  Acc: 30.050,49.530,56.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 4.568 |  Acc: 41.678,61.078,69.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 6.741 |  Acc: 29.100,48.610,55.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 4.572 |  Acc: 41.700,61.262,68.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 6.525 |  Acc: 31.570,46.520,53.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 4.543 |  Acc: 42.048,61.264,69.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 6.771 |  Acc: 27.400,46.030,53.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 4.562 |  Acc: 41.972,61.252,69.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 5.710 |  Acc: 33.930,53.380,60.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 4.535 |  Acc: 42.086,61.330,69.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 7.009 |  Acc: 27.050,45.890,52.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 4.518 |  Acc: 42.274,61.858,69.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 5.980 |  Acc: 32.350,51.480,58.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 4.517 |  Acc: 42.034,61.780,69.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 7.945 |  Acc: 21.710,41.550,48.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 4.537 |  Acc: 41.860,61.690,69.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 6.113 |  Acc: 33.540,50.550,57.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 4.490 |  Acc: 42.266,61.868,69.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 6.339 |  Acc: 30.830,47.560,54.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 4.483 |  Acc: 42.296,62.022,69.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 6.671 |  Acc: 27.610,46.220,54.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 4.492 |  Acc: 42.254,61.754,69.846,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 6.241 |  Acc: 31.340,49.630,56.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 4.482 |  Acc: 42.218,62.030,69.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 7.001 |  Acc: 27.810,43.810,52.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 4.484 |  Acc: 42.144,61.816,69.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 6.290 |  Acc: 30.310,49.540,56.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 4.481 |  Acc: 42.318,61.750,69.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 6.656 |  Acc: 31.860,45.240,52.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 4.473 |  Acc: 42.314,62.158,70.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 7.668 |  Acc: 23.670,42.240,51.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 4.454 |  Acc: 42.276,61.976,69.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 6.593 |  Acc: 28.020,49.900,56.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 4.458 |  Acc: 42.188,62.260,70.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 6.992 |  Acc: 27.910,44.390,52.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 4.461 |  Acc: 42.502,62.018,70.266,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 7.513 |  Acc: 24.310,43.110,50.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 4.444 |  Acc: 42.478,62.116,70.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 6.709 |  Acc: 28.270,46.600,55.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 4.449 |  Acc: 42.198,62.426,70.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 6.153 |  Acc: 30.640,50.800,57.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 4.414 |  Acc: 42.588,62.596,70.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 7.550 |  Acc: 20.990,42.840,52.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 4.418 |  Acc: 42.734,62.760,70.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 7.008 |  Acc: 27.200,44.390,52.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 4.440 |  Acc: 42.116,62.200,70.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 8.087 |  Acc: 18.280,41.320,53.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 4.411 |  Acc: 42.814,62.682,70.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 6.866 |  Acc: 26.260,48.320,54.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 4.401 |  Acc: 42.936,62.970,70.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 6.270 |  Acc: 32.260,49.120,56.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 4.413 |  Acc: 42.678,62.490,70.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 7.603 |  Acc: 24.560,39.650,49.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 4.425 |  Acc: 42.568,62.430,70.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 6.154 |  Acc: 32.150,48.660,56.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 4.396 |  Acc: 42.800,62.792,70.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 9.192 |  Acc: 19.450,37.600,46.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 4.376 |  Acc: 42.834,63.022,71.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 6.277 |  Acc: 30.130,49.150,56.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 4.376 |  Acc: 42.938,63.024,70.774,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 6.335 |  Acc: 32.840,49.350,55.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 4.390 |  Acc: 42.506,62.806,70.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 6.104 |  Acc: 32.210,50.750,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 4.385 |  Acc: 42.988,62.672,70.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 7.152 |  Acc: 26.450,43.710,52.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 4.387 |  Acc: 43.086,62.784,70.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 6.176 |  Acc: 32.790,49.290,57.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 4.374 |  Acc: 42.826,62.604,70.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 7.471 |  Acc: 28.300,42.950,50.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 4.355 |  Acc: 43.062,62.836,71.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 6.639 |  Acc: 29.590,48.020,55.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 4.347 |  Acc: 42.982,63.130,71.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 6.059 |  Acc: 35.500,49.790,55.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 4.341 |  Acc: 43.106,63.178,71.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 6.682 |  Acc: 28.110,46.900,54.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 4.346 |  Acc: 43.394,62.950,71.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 7.292 |  Acc: 26.030,45.370,53.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 4.324 |  Acc: 43.306,63.206,71.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 6.260 |  Acc: 33.310,50.960,55.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 4.352 |  Acc: 43.054,62.874,71.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 5.936 |  Acc: 35.230,51.670,57.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 4.341 |  Acc: 43.242,63.178,71.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 6.377 |  Acc: 29.470,48.390,55.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 4.317 |  Acc: 43.488,63.622,71.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 6.757 |  Acc: 30.340,47.900,53.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 4.305 |  Acc: 43.472,63.614,71.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 5.912 |  Acc: 35.050,51.200,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 4.330 |  Acc: 42.936,63.100,71.500,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 6.954 |  Acc: 26.850,46.680,54.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 4.335 |  Acc: 42.770,63.314,71.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 5.791 |  Acc: 36.120,53.160,58.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 4.326 |  Acc: 43.472,63.570,71.346,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 7.717 |  Acc: 24.020,44.800,53.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 4.299 |  Acc: 42.990,63.636,71.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 6.568 |  Acc: 31.420,47.290,54.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 4.310 |  Acc: 43.426,63.422,71.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 6.298 |  Acc: 33.910,48.840,56.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 4.303 |  Acc: 43.224,63.508,71.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 7.362 |  Acc: 27.460,40.600,49.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 4.311 |  Acc: 42.950,63.226,71.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 6.268 |  Acc: 33.360,49.460,56.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 4.310 |  Acc: 43.014,63.454,71.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 7.315 |  Acc: 28.000,40.920,49.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 4.296 |  Acc: 43.294,63.624,71.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 5.921 |  Acc: 32.770,53.590,58.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 4.274 |  Acc: 43.396,63.750,71.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 8.176 |  Acc: 21.690,40.540,49.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 4.298 |  Acc: 43.268,63.432,71.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 5.763 |  Acc: 37.230,53.060,56.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 4.271 |  Acc: 43.182,63.638,72.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 7.220 |  Acc: 28.320,44.310,53.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 4.300 |  Acc: 43.326,63.688,71.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 6.290 |  Acc: 32.540,50.750,58.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 4.293 |  Acc: 43.314,63.374,71.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 6.408 |  Acc: 29.340,49.570,56.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 4.294 |  Acc: 43.080,63.600,71.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 7.315 |  Acc: 29.470,43.030,50.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 4.291 |  Acc: 43.344,63.636,71.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 6.745 |  Acc: 27.890,45.670,55.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 4.262 |  Acc: 43.518,63.874,72.090,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 7.720 |  Acc: 25.450,43.050,51.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 4.267 |  Acc: 43.712,63.956,72.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 6.512 |  Acc: 29.010,52.340,56.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 3.601 |  Acc: 47.724,70.796,80.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 4.477 |  Acc: 44.510,63.280,69.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 3.407 |  Acc: 48.578,72.600,82.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 4.394 |  Acc: 45.270,64.010,69.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 3.330 |  Acc: 48.856,73.452,83.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 4.395 |  Acc: 45.030,64.240,69.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 3.283 |  Acc: 49.032,73.780,84.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 4.380 |  Acc: 44.970,64.810,70.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 3.251 |  Acc: 49.292,74.012,85.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 4.446 |  Acc: 44.640,63.750,69.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 3.228 |  Acc: 49.170,74.262,85.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 4.435 |  Acc: 44.640,64.000,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 3.196 |  Acc: 49.444,74.416,85.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 4.406 |  Acc: 45.170,64.160,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 3.167 |  Acc: 49.606,74.844,86.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 4.441 |  Acc: 45.120,64.330,69.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 3.163 |  Acc: 49.582,74.868,86.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 4.406 |  Acc: 45.310,64.600,69.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 3.144 |  Acc: 49.626,75.022,86.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 4.404 |  Acc: 45.340,64.740,69.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 3.126 |  Acc: 49.690,75.288,86.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 4.426 |  Acc: 44.870,64.060,69.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 3.098 |  Acc: 49.924,75.148,87.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 4.415 |  Acc: 45.570,64.470,69.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 3.093 |  Acc: 49.854,75.150,87.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 4.461 |  Acc: 44.900,64.670,69.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 3.086 |  Acc: 49.914,75.240,87.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 4.449 |  Acc: 45.340,64.310,69.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 3.071 |  Acc: 49.902,75.506,87.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 4.514 |  Acc: 44.490,64.030,69.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 3.053 |  Acc: 50.042,75.590,88.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 4.643 |  Acc: 43.530,63.500,68.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 3.032 |  Acc: 49.948,75.914,88.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 4.464 |  Acc: 45.450,64.520,69.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 3.030 |  Acc: 50.152,76.076,88.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 4.458 |  Acc: 45.500,64.460,68.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 3.015 |  Acc: 50.146,75.836,88.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 4.489 |  Acc: 45.400,64.140,68.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 3.017 |  Acc: 50.150,75.844,88.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 4.590 |  Acc: 44.700,64.020,68.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 3.002 |  Acc: 50.150,76.244,88.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 4.503 |  Acc: 45.030,64.270,69.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 2.975 |  Acc: 50.372,76.328,89.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 4.520 |  Acc: 45.070,63.770,68.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 2.982 |  Acc: 50.250,76.162,89.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 4.533 |  Acc: 44.820,64.210,68.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 2.967 |  Acc: 50.170,76.270,89.206,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 4.590 |  Acc: 44.480,64.010,69.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 2.965 |  Acc: 50.226,76.406,89.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 4.617 |  Acc: 44.600,63.850,68.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 2.956 |  Acc: 50.200,76.642,89.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 4.634 |  Acc: 44.360,63.860,68.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 2.945 |  Acc: 50.502,76.550,89.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 4.623 |  Acc: 44.820,63.600,68.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 2.937 |  Acc: 50.496,76.658,89.628,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 4.540 |  Acc: 45.390,64.150,68.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 2.935 |  Acc: 50.346,76.876,89.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 4.677 |  Acc: 43.920,63.430,68.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 2.925 |  Acc: 50.284,76.832,89.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 4.541 |  Acc: 44.920,63.920,68.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 2.909 |  Acc: 50.466,77.066,89.684,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 4.637 |  Acc: 44.400,64.020,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 2.912 |  Acc: 50.494,76.750,89.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 4.573 |  Acc: 45.000,64.240,68.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 2.909 |  Acc: 50.538,76.624,89.928,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 4.584 |  Acc: 44.880,63.920,68.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 2.895 |  Acc: 50.504,77.156,90.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 4.686 |  Acc: 44.120,63.590,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 2.894 |  Acc: 50.392,77.012,90.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 4.521 |  Acc: 45.850,63.960,68.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 2.896 |  Acc: 50.560,76.910,90.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 4.680 |  Acc: 44.600,63.510,67.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 2.881 |  Acc: 50.412,77.146,90.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 4.602 |  Acc: 45.290,64.080,68.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 2.870 |  Acc: 50.722,77.178,90.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 4.691 |  Acc: 44.470,63.630,67.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 2.878 |  Acc: 50.560,77.148,90.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 4.652 |  Acc: 44.440,63.690,67.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 2.869 |  Acc: 50.576,77.190,90.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 4.804 |  Acc: 43.090,63.250,67.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 2.863 |  Acc: 50.586,77.260,90.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 4.609 |  Acc: 45.470,64.380,68.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 2.859 |  Acc: 50.638,77.316,90.732,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 4.657 |  Acc: 45.320,63.360,67.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 2.859 |  Acc: 50.720,77.336,90.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 4.747 |  Acc: 43.660,63.280,67.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 2.851 |  Acc: 50.660,77.430,90.912,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 4.776 |  Acc: 43.820,62.790,67.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 2.839 |  Acc: 50.980,77.566,90.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 4.718 |  Acc: 44.170,63.660,67.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 2.845 |  Acc: 50.834,77.388,90.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 4.749 |  Acc: 43.780,63.170,67.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 2.849 |  Acc: 50.820,77.648,90.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 4.800 |  Acc: 43.280,63.250,67.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 2.829 |  Acc: 50.552,77.484,91.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 4.711 |  Acc: 45.140,63.410,67.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 2.832 |  Acc: 50.810,77.444,91.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 4.637 |  Acc: 45.760,63.620,67.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 2.821 |  Acc: 50.748,77.708,91.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 4.763 |  Acc: 44.640,62.740,66.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 2.826 |  Acc: 50.958,77.644,91.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 4.685 |  Acc: 45.420,63.920,67.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 2.825 |  Acc: 50.778,77.620,91.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 4.695 |  Acc: 44.990,64.040,67.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 2.818 |  Acc: 50.944,77.716,91.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 4.717 |  Acc: 45.140,63.730,67.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 2.812 |  Acc: 50.560,77.892,91.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 4.835 |  Acc: 43.640,62.640,66.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 2.811 |  Acc: 50.932,77.812,91.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 4.709 |  Acc: 45.110,63.550,67.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 2.804 |  Acc: 51.032,77.880,91.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 4.886 |  Acc: 44.310,62.030,66.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 2.812 |  Acc: 50.816,77.884,91.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 4.856 |  Acc: 44.280,62.530,67.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 2.807 |  Acc: 50.898,77.754,91.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 4.846 |  Acc: 44.470,62.310,66.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 2.795 |  Acc: 50.984,78.134,91.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 4.686 |  Acc: 45.670,63.750,67.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 2.795 |  Acc: 50.932,77.994,91.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 4.860 |  Acc: 43.440,63.320,66.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 2.798 |  Acc: 50.808,77.874,91.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 4.764 |  Acc: 44.770,63.500,66.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 2.781 |  Acc: 51.042,78.130,91.750,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 4.876 |  Acc: 44.110,63.340,66.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 2.800 |  Acc: 50.946,77.742,91.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 4.985 |  Acc: 42.660,62.540,66.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 2.783 |  Acc: 50.960,77.972,91.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 4.796 |  Acc: 45.420,62.610,66.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 2.790 |  Acc: 50.812,77.830,91.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 4.978 |  Acc: 42.510,62.850,66.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 2.774 |  Acc: 50.974,78.184,91.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 4.769 |  Acc: 45.160,63.130,66.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 2.779 |  Acc: 50.910,78.114,91.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 4.756 |  Acc: 45.950,63.600,66.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 2.779 |  Acc: 51.166,78.042,91.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 4.871 |  Acc: 44.120,62.820,66.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 2.772 |  Acc: 50.964,78.012,91.862,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 4.997 |  Acc: 42.920,61.810,66.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 2.786 |  Acc: 50.916,78.170,91.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 4.948 |  Acc: 43.230,62.840,65.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 2.779 |  Acc: 51.134,77.924,91.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 4.738 |  Acc: 45.420,63.600,67.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 2.765 |  Acc: 50.770,78.154,91.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 4.961 |  Acc: 43.150,62.060,66.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 2.763 |  Acc: 51.126,78.346,91.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 4.809 |  Acc: 45.280,63.340,66.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 2.763 |  Acc: 51.020,78.176,91.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 4.874 |  Acc: 43.600,62.960,67.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 2.768 |  Acc: 50.806,78.146,91.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 4.919 |  Acc: 44.590,62.440,66.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 2.624 |  Acc: 52.044,80.400,93.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 4.606 |  Acc: 46.420,65.110,67.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 2.577 |  Acc: 52.232,80.640,94.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 4.572 |  Acc: 46.510,65.150,68.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 2.561 |  Acc: 52.060,80.704,94.636,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 4.579 |  Acc: 46.570,65.230,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 2.557 |  Acc: 52.314,81.072,94.746,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 4.590 |  Acc: 46.540,65.160,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 2.552 |  Acc: 52.444,80.768,94.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 4.597 |  Acc: 46.340,64.960,68.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 2.540 |  Acc: 52.336,81.066,95.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 4.568 |  Acc: 46.450,64.990,68.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 2.535 |  Acc: 52.482,81.232,95.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 4.578 |  Acc: 46.360,65.210,68.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 2.530 |  Acc: 52.240,81.246,95.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 4.598 |  Acc: 46.710,64.890,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 2.533 |  Acc: 52.142,81.184,95.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 4.608 |  Acc: 46.290,64.830,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 2.518 |  Acc: 52.612,81.360,95.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 4.594 |  Acc: 46.560,65.120,68.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 2.528 |  Acc: 52.462,81.460,95.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 4.598 |  Acc: 46.360,65.150,68.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 2.518 |  Acc: 52.424,81.522,95.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 4.590 |  Acc: 46.410,65.070,68.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 2.535 |  Acc: 52.214,81.218,95.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 4.602 |  Acc: 46.380,65.020,68.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 2.516 |  Acc: 52.546,81.414,95.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 4.624 |  Acc: 46.380,64.910,68.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 2.524 |  Acc: 52.582,81.362,95.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 4.602 |  Acc: 46.360,64.790,67.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 2.513 |  Acc: 52.482,81.492,95.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 4.595 |  Acc: 46.620,65.190,68.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 2.516 |  Acc: 52.354,81.316,95.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 4.607 |  Acc: 46.490,64.970,68.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 2.512 |  Acc: 52.428,81.532,95.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 4.629 |  Acc: 46.470,64.830,68.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 2.502 |  Acc: 52.710,81.544,95.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 4.629 |  Acc: 46.760,65.050,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 2.504 |  Acc: 52.608,81.622,95.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 4.619 |  Acc: 46.220,65.030,68.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 2.502 |  Acc: 52.562,81.668,95.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 4.625 |  Acc: 46.290,65.130,68.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 2.503 |  Acc: 52.440,81.478,95.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 4.622 |  Acc: 46.590,64.980,68.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 2.500 |  Acc: 52.496,81.534,95.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 4.639 |  Acc: 46.120,64.990,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 2.502 |  Acc: 52.564,81.518,95.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 4.626 |  Acc: 46.320,64.970,67.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 2.494 |  Acc: 52.510,81.702,95.622,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 4.637 |  Acc: 46.370,64.870,68.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 2.493 |  Acc: 52.588,81.952,95.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 4.649 |  Acc: 46.220,64.810,68.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 2.496 |  Acc: 52.636,81.648,95.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 4.636 |  Acc: 46.540,64.960,68.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 2.495 |  Acc: 52.506,81.434,95.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 4.644 |  Acc: 46.410,64.960,68.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 2.501 |  Acc: 52.620,81.562,95.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 4.633 |  Acc: 46.720,65.000,68.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 2.494 |  Acc: 52.618,81.540,95.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 4.629 |  Acc: 46.400,64.980,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 2.496 |  Acc: 52.526,81.526,95.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 4.650 |  Acc: 46.210,64.940,68.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 2.496 |  Acc: 52.598,81.588,95.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 4.634 |  Acc: 46.350,64.990,68.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 2.497 |  Acc: 52.672,81.786,95.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 4.655 |  Acc: 46.480,64.910,67.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 2.497 |  Acc: 52.486,81.626,95.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 4.600 |  Acc: 46.630,64.920,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 2.488 |  Acc: 52.480,81.976,95.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 4.616 |  Acc: 46.550,65.050,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 2.478 |  Acc: 52.762,81.778,95.844,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 4.659 |  Acc: 46.210,64.960,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 2.487 |  Acc: 52.674,81.486,95.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 4.630 |  Acc: 46.440,64.990,68.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 2.472 |  Acc: 52.510,81.980,95.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 4.645 |  Acc: 46.430,64.860,68.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 2.474 |  Acc: 52.674,82.162,95.972,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 4.643 |  Acc: 46.360,64.910,68.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 2.471 |  Acc: 52.710,81.986,95.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 4.629 |  Acc: 46.460,65.090,68.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 2.473 |  Acc: 52.600,81.954,95.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 4.628 |  Acc: 46.610,64.990,68.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 2.463 |  Acc: 52.846,81.990,95.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 4.643 |  Acc: 46.420,64.970,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 2.468 |  Acc: 52.722,81.948,95.906,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 4.648 |  Acc: 46.480,64.900,68.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 2.474 |  Acc: 52.558,81.948,95.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 4.631 |  Acc: 46.500,65.210,67.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 2.467 |  Acc: 52.500,82.012,95.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 4.635 |  Acc: 46.550,65.060,68.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 2.466 |  Acc: 52.562,81.960,95.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 4.622 |  Acc: 46.680,64.940,68.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 2.463 |  Acc: 52.864,82.070,96.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 4.650 |  Acc: 46.150,64.910,68.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 2.465 |  Acc: 52.658,82.118,95.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 4.634 |  Acc: 46.570,64.910,68.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 2.471 |  Acc: 52.632,82.114,96.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 4.638 |  Acc: 46.360,64.910,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 2.468 |  Acc: 52.824,82.074,95.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 4.628 |  Acc: 46.580,65.280,68.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 2.467 |  Acc: 52.796,81.950,96.032,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 4.638 |  Acc: 46.440,65.060,68.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 2.461 |  Acc: 52.698,82.158,96.050,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 4.633 |  Acc: 46.410,65.120,68.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 2.460 |  Acc: 52.816,82.134,96.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 4.654 |  Acc: 46.290,64.850,67.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 2.466 |  Acc: 52.786,81.996,96.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 4.642 |  Acc: 46.480,65.020,68.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 2.467 |  Acc: 52.738,82.310,96.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 4.646 |  Acc: 46.530,64.990,67.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 2.464 |  Acc: 52.750,82.202,96.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 4.632 |  Acc: 46.540,65.190,68.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 2.457 |  Acc: 52.904,82.144,96.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 4.632 |  Acc: 46.420,64.990,67.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 2.460 |  Acc: 52.604,82.314,96.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 4.625 |  Acc: 46.650,65.070,68.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 2.470 |  Acc: 52.784,81.850,95.954,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 4.646 |  Acc: 46.390,64.830,68.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 2.468 |  Acc: 52.780,81.998,95.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 4.623 |  Acc: 46.630,65.170,68.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 2.460 |  Acc: 52.856,82.072,96.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 4.622 |  Acc: 46.670,64.950,68.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 2.464 |  Acc: 52.982,82.126,96.002,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 4.653 |  Acc: 46.520,65.050,68.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 2.466 |  Acc: 52.856,82.132,95.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 4.634 |  Acc: 46.510,65.140,68.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 2.476 |  Acc: 52.610,82.020,95.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 4.649 |  Acc: 46.240,64.980,68.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 2.460 |  Acc: 53.038,82.084,96.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 4.636 |  Acc: 46.530,64.940,68.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 2.460 |  Acc: 52.924,82.108,96.028,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 4.647 |  Acc: 46.400,65.050,68.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 2.463 |  Acc: 52.916,82.092,96.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 4.649 |  Acc: 46.430,65.040,67.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 2.459 |  Acc: 52.648,82.172,96.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 4.622 |  Acc: 46.500,65.030,68.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 2.466 |  Acc: 52.706,81.946,96.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 4.650 |  Acc: 46.470,65.050,68.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 2.459 |  Acc: 52.880,82.178,96.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 4.654 |  Acc: 46.390,64.810,68.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 2.463 |  Acc: 52.782,81.998,96.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 4.651 |  Acc: 46.450,64.880,68.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 2.470 |  Acc: 52.672,81.814,95.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 4.650 |  Acc: 46.570,64.930,68.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 2.460 |  Acc: 52.852,81.960,96.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 4.653 |  Acc: 46.510,64.800,68.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 2.468 |  Acc: 52.732,81.804,95.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 4.640 |  Acc: 46.660,65.090,68.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56_h12', batch_size=128, circles=4, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=0, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 2.460 |  Acc: 52.660,82.142,96.020,% | Adaptive Acc:86.728% | clf_exit: 0.370 0.441 0.189
Testing: Epoch=299 | Loss: 4.640 |  Acc: 46.300,64.980,68.100,% | Adaptive Acc:62.940% | clf_exit: 0.417 0.365 0.218

circles: 0
Testing: Epoch=299 | Loss: 59.611 |  Acc: 1.780,1.000,1.580,% | Adaptive Acc:1.680% | clf_exit: 0.932 0.068 0.000
circles: 1
Testing: Epoch=299 | Loss: 42.725 |  Acc: 2.940,1.620,2.390,% | Adaptive Acc:2.770% | clf_exit: 0.819 0.181 0.001
circles: 2
Testing: Epoch=299 | Loss: 25.489 |  Acc: 5.420,6.780,10.230,% | Adaptive Acc:6.210% | clf_exit: 0.705 0.264 0.031
circles: 3
Testing: Epoch=299 | Loss: 10.484 |  Acc: 12.570,40.700,51.900,% | Adaptive Acc:29.870% | clf_exit: 0.525 0.264 0.212
circles: 4
Testing: Epoch=299 | Loss: 4.640 |  Acc: 46.300,64.980,68.100,% | Adaptive Acc:62.940% | clf_exit: 0.417 0.365 0.218
