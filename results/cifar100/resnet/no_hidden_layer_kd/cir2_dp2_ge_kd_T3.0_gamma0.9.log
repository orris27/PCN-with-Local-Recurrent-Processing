==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=16, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=132, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=132, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=164, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=164, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 5.842 | Acc: 0.000,1.562,2.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.768 | Acc: 0.818,0.930,1.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.683 | Acc: 0.991,0.953,2.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.617 | Acc: 0.948,1.127,3.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.569 | Acc: 0.993,1.148,3.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.529 | Acc: 1.060,1.230,3.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.487 | Acc: 1.136,1.285,4.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.447 | Acc: 1.202,1.330,4.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.405 | Acc: 1.213,1.412,4.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.371 | Acc: 1.286,1.429,5.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.338 | Acc: 1.349,1.504,5.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.307 | Acc: 1.446,1.566,5.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.278 | Acc: 1.475,1.627,6.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.249 | Acc: 1.530,1.715,6.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.224 | Acc: 1.579,1.813,6.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.201 | Acc: 1.635,1.884,6.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.179 | Acc: 1.713,2.010,6.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.159 | Acc: 1.785,2.099,7.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.139 | Acc: 1.857,2.199,7.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.121 | Acc: 1.964,2.327,7.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.771 | Acc: 0.781,4.688,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.823 | Acc: 3.311,4.650,10.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.808 | Acc: 3.125,4.592,10.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.807 | Acc: 3.074,4.611,10.169,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 4.760 | Acc: 1.562,3.906,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.702 | Acc: 3.348,5.208,13.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.700 | Acc: 3.392,5.259,12.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.711 | Acc: 3.484,4.956,12.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.705 | Acc: 3.443,5.015,12.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.693 | Acc: 3.380,5.206,12.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.677 | Acc: 3.416,5.294,12.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.674 | Acc: 3.430,5.380,12.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.671 | Acc: 3.460,5.474,12.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.667 | Acc: 3.470,5.559,12.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.661 | Acc: 3.494,5.562,13.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.654 | Acc: 3.638,5.660,13.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.644 | Acc: 3.709,5.777,13.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.638 | Acc: 3.757,5.891,13.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.629 | Acc: 3.834,5.989,13.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.622 | Acc: 3.909,6.099,13.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.617 | Acc: 3.899,6.160,13.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.609 | Acc: 3.945,6.232,13.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.601 | Acc: 3.932,6.269,13.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.595 | Acc: 3.925,6.373,14.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.478 | Acc: 5.469,10.938,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.451 | Acc: 5.171,7.961,15.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.452 | Acc: 4.840,7.984,16.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.461 | Acc: 4.700,7.812,15.599,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 4.541 | Acc: 5.469,8.594,9.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.437 | Acc: 5.022,7.775,17.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.405 | Acc: 4.954,8.155,17.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.406 | Acc: 4.700,8.671,17.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.410 | Acc: 4.581,8.729,17.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.400 | Acc: 4.842,8.694,17.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.394 | Acc: 4.842,8.697,17.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.390 | Acc: 4.754,8.727,17.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.388 | Acc: 4.852,8.715,17.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.381 | Acc: 4.830,8.784,17.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.371 | Acc: 4.843,8.843,17.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.365 | Acc: 4.801,8.806,17.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.363 | Acc: 4.876,8.853,17.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.357 | Acc: 4.876,8.809,17.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.351 | Acc: 4.918,8.819,18.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.347 | Acc: 4.913,8.825,18.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.341 | Acc: 4.928,8.869,18.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.336 | Acc: 4.935,8.827,18.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.332 | Acc: 4.967,8.866,18.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.327 | Acc: 4.968,8.866,18.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.311 | Acc: 6.250,14.844,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.283 | Acc: 5.357,9.189,18.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.272 | Acc: 5.126,9.375,18.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.277 | Acc: 5.213,9.401,17.982,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 4.368 | Acc: 2.344,3.125,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.180 | Acc: 5.469,9.970,20.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.170 | Acc: 5.602,10.271,21.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.153 | Acc: 5.533,10.220,21.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.149 | Acc: 5.623,10.233,21.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.151 | Acc: 5.647,10.071,21.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.147 | Acc: 5.611,10.027,21.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.150 | Acc: 5.574,9.996,21.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.145 | Acc: 5.609,9.933,21.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.143 | Acc: 5.598,9.940,21.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.141 | Acc: 5.655,9.911,21.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.141 | Acc: 5.624,9.955,21.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.137 | Acc: 5.715,9.994,21.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.135 | Acc: 5.699,10.060,21.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.132 | Acc: 5.741,10.153,21.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.129 | Acc: 5.718,10.180,21.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.125 | Acc: 5.698,10.188,21.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.122 | Acc: 5.725,10.186,21.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.115 | Acc: 5.733,10.234,21.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.110 | Acc: 5.746,10.205,21.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.988 | Acc: 6.250,15.625,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.949 | Acc: 6.064,10.789,24.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.946 | Acc: 5.793,11.014,24.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.957 | Acc: 5.622,10.925,24.193,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 4.058 | Acc: 5.469,7.812,21.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.022 | Acc: 6.548,10.193,24.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.002 | Acc: 6.707,10.499,24.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.982 | Acc: 6.737,10.669,24.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.978 | Acc: 6.626,10.706,24.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.977 | Acc: 6.536,10.481,24.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.976 | Acc: 6.424,10.608,24.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.972 | Acc: 6.383,10.622,24.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.964 | Acc: 6.483,10.748,24.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.957 | Acc: 6.466,10.873,24.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.951 | Acc: 6.557,11.054,24.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.947 | Acc: 6.501,11.100,24.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.942 | Acc: 6.516,11.061,24.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.938 | Acc: 6.528,11.087,25.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.934 | Acc: 6.542,11.107,25.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.929 | Acc: 6.530,11.122,25.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.925 | Acc: 6.527,11.164,25.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.920 | Acc: 6.539,11.137,25.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.916 | Acc: 6.603,11.230,25.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.912 | Acc: 6.574,11.270,25.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.797 | Acc: 7.812,11.719,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.873 | Acc: 6.920,10.231,26.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.882 | Acc: 6.574,10.080,25.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.892 | Acc: 6.212,9.939,25.730,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 3.576 | Acc: 8.594,14.062,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.739 | Acc: 7.068,11.533,29.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.754 | Acc: 7.241,11.795,28.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.756 | Acc: 7.275,11.655,28.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.767 | Acc: 6.973,11.574,28.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.775 | Acc: 6.776,11.580,27.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.772 | Acc: 6.889,11.757,28.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.773 | Acc: 6.843,11.818,27.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.771 | Acc: 6.813,11.787,27.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.770 | Acc: 6.759,11.771,27.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.771 | Acc: 6.713,11.762,27.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.768 | Acc: 6.727,11.835,27.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.763 | Acc: 6.749,11.978,28.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.762 | Acc: 6.786,12.015,28.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.761 | Acc: 6.851,12.072,27.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.760 | Acc: 6.868,12.186,28.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.756 | Acc: 6.897,12.274,28.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.751 | Acc: 6.963,12.296,28.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.747 | Acc: 6.988,12.316,28.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.746 | Acc: 6.998,12.340,28.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.566 | Acc: 5.469,15.625,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.705 | Acc: 7.515,12.091,28.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.716 | Acc: 7.222,12.252,28.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.723 | Acc: 7.159,12.410,28.778,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 3.819 | Acc: 10.156,14.062,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.664 | Acc: 7.664,12.537,30.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.670 | Acc: 7.203,12.576,29.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.652 | Acc: 7.480,12.999,30.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.640 | Acc: 7.427,12.905,30.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.630 | Acc: 7.588,13.188,30.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.627 | Acc: 7.406,13.230,30.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.619 | Acc: 7.369,13.226,30.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.613 | Acc: 7.381,13.204,30.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.612 | Acc: 7.463,13.286,30.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.613 | Acc: 7.498,13.235,30.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.609 | Acc: 7.551,13.334,30.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.606 | Acc: 7.521,13.408,30.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.603 | Acc: 7.510,13.350,30.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.603 | Acc: 7.484,13.329,30.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.602 | Acc: 7.467,13.429,30.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.599 | Acc: 7.511,13.498,30.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.596 | Acc: 7.593,13.513,30.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.594 | Acc: 7.583,13.560,30.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.594 | Acc: 7.558,13.585,30.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.461 | Acc: 10.156,17.188,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.480 | Acc: 8.594,13.579,32.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.485 | Acc: 8.308,14.043,31.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.489 | Acc: 8.043,13.883,31.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 3.529 | Acc: 7.031,19.531,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.486 | Acc: 8.185,14.025,34.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.461 | Acc: 7.946,14.615,33.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.478 | Acc: 7.889,14.447,33.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.469 | Acc: 8.063,14.728,33.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.477 | Acc: 7.921,14.480,33.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.471 | Acc: 7.993,14.237,33.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.466 | Acc: 8.029,14.367,33.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.462 | Acc: 8.186,14.485,33.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.462 | Acc: 8.244,14.455,33.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.464 | Acc: 8.166,14.436,33.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.468 | Acc: 8.127,14.441,33.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.466 | Acc: 8.085,14.370,33.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.463 | Acc: 8.082,14.359,33.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.457 | Acc: 8.188,14.466,33.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.455 | Acc: 8.165,14.512,33.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.455 | Acc: 8.221,14.484,33.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.453 | Acc: 8.243,14.445,33.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.451 | Acc: 8.241,14.389,33.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.446 | Acc: 8.260,14.436,33.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.313 | Acc: 4.688,19.531,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.393 | Acc: 9.040,14.695,34.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.399 | Acc: 8.727,14.844,33.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.406 | Acc: 8.619,14.549,33.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 3.506 | Acc: 3.906,12.500,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.342 | Acc: 8.631,14.286,36.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.348 | Acc: 7.908,14.310,36.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.328 | Acc: 8.184,14.959,36.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.329 | Acc: 8.275,15.066,36.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.332 | Acc: 8.424,15.130,36.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.337 | Acc: 8.368,15.018,36.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.336 | Acc: 8.344,15.010,36.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.335 | Acc: 8.497,15.028,36.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.333 | Acc: 8.598,15.034,36.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.332 | Acc: 8.683,15.143,36.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.329 | Acc: 8.626,15.158,36.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.328 | Acc: 8.717,15.165,36.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.325 | Acc: 8.785,15.200,36.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.323 | Acc: 8.794,15.197,36.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.321 | Acc: 8.726,15.225,36.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.318 | Acc: 8.715,15.231,36.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.313 | Acc: 8.759,15.247,36.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.310 | Acc: 8.808,15.305,36.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.308 | Acc: 8.801,15.344,36.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.304 | Acc: 7.812,17.969,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.455 | Acc: 9.226,14.174,34.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.476 | Acc: 9.070,14.653,33.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.478 | Acc: 9.068,14.255,33.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 3.029 | Acc: 5.469,15.625,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.158 | Acc: 9.821,16.964,38.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.173 | Acc: 9.756,17.035,38.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.200 | Acc: 9.490,16.586,38.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.179 | Acc: 9.742,16.590,38.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.180 | Acc: 9.878,16.839,38.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.190 | Acc: 9.717,16.619,37.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.188 | Acc: 9.630,16.600,38.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.187 | Acc: 9.647,16.663,38.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.182 | Acc: 9.630,16.613,38.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.184 | Acc: 9.608,16.523,38.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.186 | Acc: 9.545,16.336,38.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.185 | Acc: 9.501,16.283,38.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.183 | Acc: 9.435,16.200,38.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.183 | Acc: 9.425,16.162,38.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.183 | Acc: 9.411,16.173,38.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.182 | Acc: 9.455,16.265,38.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.180 | Acc: 9.409,16.260,38.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.179 | Acc: 9.436,16.289,38.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.178 | Acc: 9.467,16.298,38.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.119 | Acc: 10.938,21.875,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.187 | Acc: 9.301,15.402,38.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.212 | Acc: 9.375,15.396,37.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 9.554,15.292,37.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 3.251 | Acc: 11.719,15.625,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.073 | Acc: 10.379,16.629,41.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.059 | Acc: 9.966,16.387,41.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.093 | Acc: 9.977,15.984,41.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.083 | Acc: 9.770,16.136,41.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.090 | Acc: 9.824,16.112,40.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.082 | Acc: 9.937,16.245,40.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.080 | Acc: 9.896,16.318,40.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.087 | Acc: 9.783,16.387,40.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.090 | Acc: 9.707,16.497,40.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.087 | Acc: 9.779,16.667,40.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.090 | Acc: 9.690,16.618,40.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.086 | Acc: 9.667,16.572,40.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.082 | Acc: 9.743,16.589,40.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.083 | Acc: 9.773,16.604,40.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.079 | Acc: 9.749,16.650,40.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.077 | Acc: 9.755,16.613,40.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.076 | Acc: 9.767,16.725,40.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.074 | Acc: 9.771,16.707,41.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.074 | Acc: 9.777,16.646,41.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.020 | Acc: 8.594,22.656,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.296 | Acc: 8.891,16.183,37.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.290 | Acc: 9.146,16.406,37.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.290 | Acc: 9.093,15.894,36.783,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 2.792 | Acc: 8.594,14.844,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.014 | Acc: 10.417,16.518,43.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.972 | Acc: 10.156,17.283,43.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.981 | Acc: 10.323,17.418,43.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.975 | Acc: 10.253,17.506,43.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.973 | Acc: 10.373,17.551,43.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.979 | Acc: 10.331,17.504,43.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.973 | Acc: 10.262,17.503,43.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.970 | Acc: 10.379,17.566,43.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.970 | Acc: 10.316,17.503,43.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.972 | Acc: 10.331,17.619,43.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.980 | Acc: 10.273,17.509,43.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.981 | Acc: 10.266,17.388,43.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.982 | Acc: 10.264,17.415,43.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.980 | Acc: 10.234,17.354,43.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.978 | Acc: 10.257,17.307,43.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.978 | Acc: 10.224,17.285,43.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.976 | Acc: 10.236,17.275,43.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.971 | Acc: 10.249,17.296,43.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.971 | Acc: 10.271,17.323,43.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.816 | Acc: 8.594,22.656,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.099 | Acc: 9.747,17.374,40.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.089 | Acc: 9.756,17.435,40.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.092 | Acc: 9.939,17.213,40.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 2.797 | Acc: 14.062,29.688,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.882 | Acc: 10.751,17.894,44.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.879 | Acc: 10.499,17.912,44.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.893 | Acc: 10.489,17.328,44.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.889 | Acc: 10.378,17.660,45.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.885 | Acc: 10.597,17.907,45.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.883 | Acc: 10.692,18.001,45.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.879 | Acc: 10.660,18.046,45.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.881 | Acc: 10.632,18.042,45.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.885 | Acc: 10.700,18.012,45.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.888 | Acc: 10.623,18.004,44.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.883 | Acc: 10.549,17.884,45.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.885 | Acc: 10.503,17.904,45.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.885 | Acc: 10.533,17.906,45.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.883 | Acc: 10.626,17.988,45.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.884 | Acc: 10.590,18.023,45.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.882 | Acc: 10.560,18.034,45.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.883 | Acc: 10.566,18.065,45.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.881 | Acc: 10.539,18.101,45.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.882 | Acc: 10.540,18.065,45.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.147 | Acc: 8.594,17.969,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.297 | Acc: 9.301,15.625,37.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.290 | Acc: 9.889,15.339,37.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.275 | Acc: 9.990,15.343,37.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 2.939 | Acc: 8.594,21.094,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.795 | Acc: 11.421,19.382,46.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 10.518,18.274,46.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.813 | Acc: 10.758,18.135,47.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.813 | Acc: 10.880,18.345,47.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.799 | Acc: 10.938,18.518,47.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.794 | Acc: 10.750,18.453,47.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.799 | Acc: 10.688,18.490,47.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.806 | Acc: 10.685,18.391,47.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.808 | Acc: 10.769,18.379,47.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.809 | Acc: 10.724,18.501,46.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.809 | Acc: 10.789,18.580,47.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.811 | Acc: 10.775,18.513,46.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.808 | Acc: 10.857,18.552,46.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.809 | Acc: 10.832,18.572,46.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.807 | Acc: 10.818,18.490,46.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.805 | Acc: 10.801,18.497,46.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.805 | Acc: 10.839,18.482,46.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.806 | Acc: 10.851,18.503,46.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.805 | Acc: 10.888,18.516,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.193 | Acc: 13.281,17.188,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.175 | Acc: 9.821,18.304,40.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.169 | Acc: 9.870,17.969,39.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.172 | Acc: 10.041,17.585,39.716,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 2.632 | Acc: 14.844,20.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.670 | Acc: 11.235,18.564,49.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.689 | Acc: 11.338,19.226,48.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 11.744,19.442,49.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.696 | Acc: 11.410,19.252,48.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.704 | Acc: 11.200,19.206,48.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.709 | Acc: 11.202,19.208,48.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.721 | Acc: 11.336,19.276,48.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.722 | Acc: 11.316,19.289,48.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.732 | Acc: 11.235,19.160,48.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.732 | Acc: 11.268,19.193,48.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.730 | Acc: 11.185,19.142,48.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.731 | Acc: 11.242,19.126,48.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.730 | Acc: 11.255,19.127,48.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.733 | Acc: 11.193,19.022,48.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.734 | Acc: 11.181,19.038,48.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.735 | Acc: 11.105,18.964,48.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.736 | Acc: 11.155,19.002,48.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.734 | Acc: 11.184,19.111,48.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.735 | Acc: 11.214,19.103,48.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.101 | Acc: 12.500,21.875,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.136 | Acc: 10.975,17.783,40.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.149 | Acc: 10.957,17.683,39.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.147 | Acc: 10.886,17.316,39.869,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 2.625 | Acc: 16.406,18.750,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.687 | Acc: 11.235,18.601,49.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.671 | Acc: 11.643,19.036,49.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.672 | Acc: 11.616,19.134,49.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.671 | Acc: 11.680,19.271,49.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.680 | Acc: 11.494,19.237,49.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.675 | Acc: 11.564,19.196,49.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.673 | Acc: 11.591,19.348,49.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.673 | Acc: 11.617,19.284,49.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.673 | Acc: 11.619,19.415,49.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.672 | Acc: 11.676,19.454,49.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.681 | Acc: 11.546,19.277,49.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.677 | Acc: 11.524,19.356,49.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.673 | Acc: 11.509,19.492,49.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.673 | Acc: 11.371,19.478,49.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.673 | Acc: 11.306,19.479,49.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.670 | Acc: 11.342,19.551,49.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.669 | Acc: 11.398,19.696,49.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.668 | Acc: 11.392,19.642,49.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.671 | Acc: 11.417,19.650,49.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.748 | Acc: 10.156,17.969,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.907 | Acc: 10.751,18.713,45.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 11.052,18.807,45.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.902 | Acc: 11.104,18.404,45.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 2.718 | Acc: 7.812,17.188,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.578 | Acc: 11.830,18.899,51.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.594 | Acc: 11.719,19.436,51.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.614 | Acc: 11.616,19.416,51.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.610 | Acc: 11.497,19.570,51.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.609 | Acc: 11.340,19.415,51.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.603 | Acc: 11.383,19.693,51.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.611 | Acc: 11.475,19.897,51.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.619 | Acc: 11.398,19.720,51.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.619 | Acc: 11.447,19.838,51.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.618 | Acc: 11.548,19.967,51.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.614 | Acc: 11.553,19.991,51.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.613 | Acc: 11.589,20.079,51.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.612 | Acc: 11.548,20.160,51.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.615 | Acc: 11.594,20.115,50.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.616 | Acc: 11.631,20.094,50.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.612 | Acc: 11.617,20.101,50.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.613 | Acc: 11.586,20.086,50.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.613 | Acc: 11.582,20.118,50.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.613 | Acc: 11.592,20.171,50.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.961 | Acc: 10.938,23.438,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.037 | Acc: 10.938,18.304,43.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.036 | Acc: 11.414,18.331,42.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.024 | Acc: 11.514,18.084,42.777,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 2.489 | Acc: 11.719,18.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.547 | Acc: 11.905,20.201,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.555 | Acc: 12.005,20.960,51.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.547 | Acc: 12.334,21.286,52.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.542 | Acc: 12.191,21.152,52.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.539 | Acc: 12.175,21.225,52.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.536 | Acc: 12.209,21.036,52.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.535 | Acc: 12.217,20.867,52.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.534 | Acc: 12.160,20.890,52.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.541 | Acc: 12.081,20.761,52.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.539 | Acc: 12.158,20.690,52.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.540 | Acc: 12.203,20.723,52.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.541 | Acc: 12.173,20.695,52.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.545 | Acc: 12.174,20.714,52.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.545 | Acc: 12.105,20.627,52.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.549 | Acc: 12.069,20.637,52.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.551 | Acc: 12.033,20.634,52.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.551 | Acc: 12.017,20.603,52.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.552 | Acc: 12.002,20.572,52.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.552 | Acc: 11.975,20.575,52.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.785 | Acc: 10.156,19.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.965 | Acc: 9.077,17.411,44.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.949 | Acc: 9.394,17.816,44.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.953 | Acc: 9.721,17.687,44.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 2.703 | Acc: 7.812,14.844,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.475 | Acc: 13.356,20.982,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.457 | Acc: 12.309,21.075,54.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.466 | Acc: 12.410,20.556,53.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.464 | Acc: 12.278,20.660,54.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.464 | Acc: 12.152,20.761,54.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.473 | Acc: 12.158,20.894,53.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.470 | Acc: 12.123,20.950,54.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.474 | Acc: 12.219,21.094,53.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 12.090,21.016,53.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.487 | Acc: 12.053,20.923,53.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.496 | Acc: 12.058,20.868,53.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.494 | Acc: 12.092,20.977,53.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.493 | Acc: 12.057,20.860,53.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.495 | Acc: 12.050,20.857,53.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.497 | Acc: 12.020,20.850,53.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.496 | Acc: 12.045,20.850,53.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.496 | Acc: 12.019,20.828,53.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.498 | Acc: 12.015,20.802,53.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.499 | Acc: 12.045,20.774,53.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.592 | Acc: 12.500,24.219,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.738 | Acc: 11.272,19.308,48.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.738 | Acc: 11.776,19.493,49.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.736 | Acc: 11.988,19.390,48.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 2.206 | Acc: 22.656,30.469,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.409 | Acc: 12.463,21.354,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.421 | Acc: 12.519,20.827,55.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.422 | Acc: 12.218,20.735,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.408 | Acc: 12.539,20.853,55.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.419 | Acc: 12.531,20.738,55.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.435 | Acc: 12.487,20.752,54.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.438 | Acc: 12.445,20.656,54.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.442 | Acc: 12.558,20.890,54.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.445 | Acc: 12.543,20.882,54.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.444 | Acc: 12.574,21.047,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.450 | Acc: 12.585,21.012,54.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.451 | Acc: 12.623,21.087,54.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.455 | Acc: 12.581,21.088,54.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.457 | Acc: 12.561,21.144,54.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.457 | Acc: 12.492,21.138,54.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.461 | Acc: 12.432,21.125,54.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.461 | Acc: 12.431,21.227,54.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.458 | Acc: 12.331,21.250,54.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.458 | Acc: 12.342,21.289,54.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.593 | Acc: 11.719,24.219,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 11.793,19.903,49.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.724 | Acc: 11.395,20.503,48.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.721 | Acc: 11.603,20.146,48.553,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 2.692 | Acc: 10.938,17.969,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.387 | Acc: 12.351,20.610,56.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.376 | Acc: 12.671,21.532,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.377 | Acc: 12.756,21.401,56.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.378 | Acc: 12.876,21.383,56.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.384 | Acc: 12.601,21.357,56.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.390 | Acc: 12.668,21.423,56.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.397 | Acc: 12.627,21.443,56.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.398 | Acc: 12.582,21.448,56.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.402 | Acc: 12.647,21.482,56.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.403 | Acc: 12.683,21.568,56.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.407 | Acc: 12.705,21.631,55.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.407 | Acc: 12.662,21.606,55.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.407 | Acc: 12.641,21.555,55.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.407 | Acc: 12.633,21.458,55.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.409 | Acc: 12.656,21.460,55.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.411 | Acc: 12.624,21.525,55.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.413 | Acc: 12.640,21.527,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.416 | Acc: 12.604,21.546,55.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.414 | Acc: 12.574,21.580,55.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.684 | Acc: 13.281,25.000,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.733 | Acc: 11.496,20.647,49.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.747 | Acc: 11.909,20.865,48.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.754 | Acc: 11.898,20.543,48.015,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 2.406 | Acc: 13.281,17.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.304 | Acc: 11.905,21.503,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.345 | Acc: 12.062,20.979,57.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.365 | Acc: 12.423,21.158,56.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.360 | Acc: 12.674,21.316,56.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.359 | Acc: 12.763,21.450,56.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.361 | Acc: 12.668,21.475,56.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.356 | Acc: 12.771,21.637,57.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.352 | Acc: 12.825,21.836,57.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.353 | Acc: 12.772,21.828,57.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.348 | Acc: 12.792,22.023,57.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.348 | Acc: 12.776,22.006,57.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.350 | Acc: 12.769,21.904,57.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.356 | Acc: 12.823,21.935,56.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.359 | Acc: 12.920,21.914,56.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.361 | Acc: 12.913,21.992,56.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.361 | Acc: 12.894,22.036,56.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.361 | Acc: 12.892,22.008,56.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.364 | Acc: 12.859,21.975,56.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.366 | Acc: 12.875,21.947,56.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.883 | Acc: 8.594,18.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.039 | Acc: 10.268,18.155,46.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.057 | Acc: 10.347,18.159,44.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.039 | Acc: 10.502,18.353,44.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 2.123 | Acc: 13.281,22.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.364 | Acc: 13.393,20.833,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.323 | Acc: 13.186,21.303,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.321 | Acc: 13.064,21.734,57.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.317 | Acc: 12.876,21.904,57.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.325 | Acc: 12.995,22.316,57.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.328 | Acc: 13.062,22.346,57.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.329 | Acc: 13.093,22.285,57.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.328 | Acc: 12.990,22.152,57.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.328 | Acc: 12.932,22.311,57.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.331 | Acc: 12.951,22.225,57.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.335 | Acc: 12.917,22.324,57.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.334 | Acc: 12.986,22.309,57.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.338 | Acc: 13.003,22.465,57.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.340 | Acc: 12.945,22.373,57.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.342 | Acc: 12.970,22.376,57.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.344 | Acc: 13.033,22.418,57.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.346 | Acc: 12.965,22.395,56.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.347 | Acc: 12.950,22.362,56.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.343 | Acc: 13.002,22.412,56.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 11.719,23.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.587 | Acc: 12.946,19.792,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.597 | Acc: 13.167,20.198,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.610 | Acc: 13.089,20.108,52.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.233 | Acc: 13.281,20.312,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.279 | Acc: 13.690,23.363,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.291 | Acc: 13.072,22.542,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.280 | Acc: 13.384,22.605,58.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.281 | Acc: 13.465,22.608,57.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.283 | Acc: 13.250,22.386,58.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.288 | Acc: 13.359,22.379,58.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.291 | Acc: 13.420,22.390,58.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.287 | Acc: 13.272,22.549,58.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.291 | Acc: 13.229,22.384,58.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.290 | Acc: 13.207,22.462,58.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.293 | Acc: 13.193,22.550,58.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.296 | Acc: 13.158,22.591,58.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.295 | Acc: 13.200,22.650,58.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.298 | Acc: 13.262,22.653,58.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.301 | Acc: 13.172,22.586,58.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.301 | Acc: 13.245,22.678,58.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.300 | Acc: 13.233,22.620,58.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.303 | Acc: 13.223,22.602,57.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.303 | Acc: 13.195,22.615,57.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.385 | Acc: 14.062,18.750,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 11.496,20.126,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.556 | Acc: 11.585,20.922,52.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.561 | Acc: 11.655,20.607,52.690,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 2.088 | Acc: 13.281,21.094,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.277 | Acc: 13.021,21.949,58.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.264 | Acc: 12.710,21.799,59.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.258 | Acc: 12.795,22.131,59.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.241 | Acc: 12.847,22.502,59.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.245 | Acc: 12.763,22.378,59.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.244 | Acc: 12.797,22.456,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.249 | Acc: 12.716,22.158,59.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.246 | Acc: 12.714,22.477,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.255 | Acc: 12.802,22.617,59.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.261 | Acc: 12.823,22.645,58.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.260 | Acc: 12.864,22.854,58.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.260 | Acc: 12.912,22.893,58.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.263 | Acc: 12.853,22.848,58.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.264 | Acc: 12.834,22.801,58.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.267 | Acc: 12.832,22.734,58.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.267 | Acc: 12.909,22.773,58.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.269 | Acc: 12.958,22.741,58.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.272 | Acc: 12.959,22.658,58.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.273 | Acc: 13.039,22.675,58.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.480 | Acc: 12.500,27.344,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.591 | Acc: 10.826,20.573,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.608 | Acc: 11.090,20.655,51.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.620 | Acc: 10.835,20.236,51.345,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 2.297 | Acc: 14.062,22.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.179 | Acc: 13.021,22.731,61.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.194 | Acc: 12.748,22.790,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.207 | Acc: 12.756,23.105,60.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.211 | Acc: 12.838,23.061,60.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.216 | Acc: 12.925,23.213,60.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.213 | Acc: 13.159,23.315,60.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.214 | Acc: 13.259,23.271,60.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.218 | Acc: 13.320,23.413,60.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.219 | Acc: 13.363,23.459,60.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.216 | Acc: 13.507,23.507,60.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.218 | Acc: 13.465,23.377,60.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.219 | Acc: 13.463,23.386,60.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.220 | Acc: 13.491,23.357,60.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.219 | Acc: 13.520,23.362,60.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.221 | Acc: 13.533,23.243,60.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.222 | Acc: 13.522,23.194,60.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.225 | Acc: 13.506,23.151,60.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.226 | Acc: 13.526,23.128,60.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.229 | Acc: 13.495,23.095,59.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.404 | Acc: 14.844,25.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 12.798,21.503,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.542 | Acc: 12.576,21.684,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 12.833,21.504,53.266,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.050 | Acc: 16.406,23.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.193 | Acc: 12.984,23.028,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.169 | Acc: 13.357,23.628,61.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.178 | Acc: 13.358,23.425,60.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.190 | Acc: 13.426,23.659,60.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.189 | Acc: 13.598,23.546,60.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.188 | Acc: 13.740,23.612,60.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.190 | Acc: 13.658,23.426,60.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.194 | Acc: 13.553,23.374,60.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.193 | Acc: 13.648,23.502,60.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.191 | Acc: 13.627,23.558,60.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.197 | Acc: 13.667,23.544,60.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.198 | Acc: 13.670,23.486,60.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.203 | Acc: 13.703,23.485,60.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.204 | Acc: 13.673,23.504,60.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.204 | Acc: 13.626,23.432,60.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.207 | Acc: 13.603,23.396,60.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.210 | Acc: 13.607,23.318,60.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.212 | Acc: 13.586,23.286,60.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.214 | Acc: 13.558,23.292,60.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.253 | Acc: 10.156,24.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.569 | Acc: 12.798,20.461,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.577 | Acc: 12.691,21.113,52.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.593 | Acc: 12.679,20.722,52.216,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.376 | Acc: 12.500,20.312,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.209 | Acc: 12.872,21.429,61.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.190 | Acc: 13.434,22.752,61.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.184 | Acc: 13.730,22.861,61.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.182 | Acc: 13.609,22.965,61.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.176 | Acc: 13.575,23.105,61.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.175 | Acc: 13.617,23.379,61.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.173 | Acc: 13.769,23.266,61.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.173 | Acc: 13.810,23.282,61.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.179 | Acc: 13.760,23.230,61.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.178 | Acc: 13.720,23.270,61.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.178 | Acc: 13.652,23.261,61.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.174 | Acc: 13.774,23.373,61.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.172 | Acc: 13.736,23.393,61.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.174 | Acc: 13.729,23.293,61.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.176 | Acc: 13.754,23.360,61.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.180 | Acc: 13.719,23.284,61.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.181 | Acc: 13.776,23.408,61.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.183 | Acc: 13.809,23.435,61.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.183 | Acc: 13.812,23.454,61.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.595 | Acc: 13.281,19.531,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.623 | Acc: 11.719,20.089,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.628 | Acc: 11.833,20.503,52.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.617 | Acc: 12.001,20.133,52.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 1.957 | Acc: 17.969,29.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.114 | Acc: 14.062,23.103,62.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.156 | Acc: 13.815,23.190,61.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.151 | Acc: 13.986,23.143,61.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.135 | Acc: 13.812,23.438,61.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.138 | Acc: 14.047,23.530,61.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.145 | Acc: 13.985,23.747,61.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.146 | Acc: 13.857,23.753,61.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.150 | Acc: 14.135,23.937,61.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.152 | Acc: 14.067,23.886,61.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.154 | Acc: 14.090,23.904,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.153 | Acc: 14.140,23.968,61.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.151 | Acc: 14.101,23.972,61.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.155 | Acc: 14.060,24.066,61.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.157 | Acc: 14.001,24.102,61.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.159 | Acc: 14.008,24.024,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.157 | Acc: 13.953,24.019,61.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.158 | Acc: 13.980,24.008,61.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.156 | Acc: 13.991,24.072,61.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.156 | Acc: 13.989,24.022,61.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.466 | Acc: 14.062,25.781,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.597 | Acc: 12.054,23.177,53.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.601 | Acc: 11.966,23.114,52.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.604 | Acc: 12.154,22.848,52.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.081 | Acc: 17.969,19.531,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.114 | Acc: 13.504,23.326,62.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.104 | Acc: 13.910,24.028,63.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.101 | Acc: 14.024,24.206,63.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.086 | Acc: 13.985,24.392,63.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.085 | Acc: 13.985,24.443,63.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.085 | Acc: 14.050,24.419,63.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.095 | Acc: 14.018,24.357,63.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.098 | Acc: 13.956,24.233,63.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.101 | Acc: 13.873,24.137,63.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.107 | Acc: 13.845,24.048,62.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.107 | Acc: 13.780,24.038,62.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.110 | Acc: 13.907,24.005,62.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.110 | Acc: 13.856,24.090,62.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.115 | Acc: 13.840,24.057,62.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.117 | Acc: 13.912,24.001,62.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.119 | Acc: 13.929,23.973,62.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.121 | Acc: 13.959,24.001,62.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.121 | Acc: 13.956,24.043,62.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.123 | Acc: 13.950,24.049,62.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.367 | Acc: 16.406,26.562,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 12.463,21.317,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 12.748,22.008,54.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.501 | Acc: 12.756,21.990,54.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 1.821 | Acc: 17.969,31.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.035 | Acc: 13.467,24.256,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.040 | Acc: 14.272,24.638,64.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.052 | Acc: 14.267,24.603,64.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.066 | Acc: 14.255,24.653,63.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.073 | Acc: 14.171,24.691,63.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.075 | Acc: 14.211,24.542,63.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.069 | Acc: 14.323,24.734,63.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.075 | Acc: 14.329,24.607,63.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.080 | Acc: 14.321,24.603,63.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.089 | Acc: 14.303,24.452,63.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.092 | Acc: 14.243,24.385,63.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.095 | Acc: 14.179,24.335,63.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.093 | Acc: 14.251,24.467,63.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.097 | Acc: 14.271,24.455,62.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.100 | Acc: 14.260,24.504,62.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.103 | Acc: 14.255,24.365,62.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.105 | Acc: 14.218,24.322,62.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.111 | Acc: 14.175,24.269,62.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.114 | Acc: 14.169,24.219,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.289 | Acc: 12.500,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.455 | Acc: 11.049,22.061,56.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.446 | Acc: 11.261,22.351,56.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 11.450,22.259,56.212,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 2.098 | Acc: 12.500,21.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.061 | Acc: 13.988,24.070,63.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.018 | Acc: 14.386,24.257,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 14.319,24.206,64.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.023 | Acc: 14.342,24.228,65.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.028 | Acc: 14.148,23.987,64.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.037 | Acc: 14.224,24.109,64.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.044 | Acc: 14.140,24.169,64.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.047 | Acc: 14.116,24.578,64.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.055 | Acc: 14.175,24.594,64.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.056 | Acc: 14.257,24.588,64.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.060 | Acc: 14.211,24.622,63.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.063 | Acc: 14.254,24.617,63.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.066 | Acc: 14.221,24.602,63.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.069 | Acc: 14.210,24.650,63.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.072 | Acc: 14.182,24.605,63.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.075 | Acc: 14.165,24.579,63.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.076 | Acc: 14.172,24.510,63.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.078 | Acc: 14.186,24.600,63.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.078 | Acc: 14.186,24.612,63.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.396 | Acc: 13.281,30.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.373 | Acc: 12.984,21.615,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.398 | Acc: 13.110,21.589,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.421 | Acc: 13.256,21.440,55.674,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.130 | Acc: 12.500,21.094,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.028 | Acc: 14.211,24.591,64.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 13.910,23.819,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 13.858,24.052,65.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.039 | Acc: 13.821,24.190,64.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.040 | Acc: 13.830,24.134,64.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.040 | Acc: 13.953,24.251,64.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.047 | Acc: 14.068,24.125,64.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.052 | Acc: 14.223,24.282,63.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.055 | Acc: 14.304,24.266,63.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.056 | Acc: 14.327,24.378,63.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.059 | Acc: 14.268,24.219,63.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.059 | Acc: 14.309,24.293,63.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.060 | Acc: 14.344,24.231,63.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.060 | Acc: 14.382,24.291,63.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.060 | Acc: 14.366,24.278,63.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.064 | Acc: 14.362,24.355,63.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.066 | Acc: 14.353,24.370,63.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.067 | Acc: 14.355,24.377,63.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.068 | Acc: 14.352,24.444,63.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.349 | Acc: 17.188,28.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.456 | Acc: 13.356,21.280,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.504 | Acc: 13.034,21.818,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.496 | Acc: 12.987,21.427,54.470,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.102 | Acc: 7.031,22.656,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 14.695,24.479,65.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 14.634,24.085,65.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 14.613,24.168,65.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.996 | Acc: 14.525,24.363,65.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.003 | Acc: 14.310,24.234,65.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.998 | Acc: 14.353,24.490,65.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.005 | Acc: 14.539,24.568,65.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.016 | Acc: 14.528,24.423,64.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.022 | Acc: 14.490,24.409,64.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.023 | Acc: 14.443,24.277,64.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.026 | Acc: 14.367,24.261,64.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.030 | Acc: 14.416,24.232,64.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.031 | Acc: 14.494,24.294,64.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.035 | Acc: 14.530,24.280,64.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.034 | Acc: 14.545,24.356,64.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.038 | Acc: 14.522,24.350,64.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.040 | Acc: 14.463,24.347,64.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.039 | Acc: 14.443,24.455,64.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.041 | Acc: 14.499,24.459,64.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.415 | Acc: 14.844,25.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.441 | Acc: 13.207,22.842,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.462 | Acc: 12.862,22.942,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 12.897,22.720,55.264,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 1.939 | Acc: 12.500,24.219,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 14.695,25.186,66.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 14.787,25.076,66.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 14.921,24.769,66.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.977 | Acc: 14.805,24.711,65.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.982 | Acc: 15.006,24.783,65.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.985 | Acc: 15.251,25.110,65.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.982 | Acc: 15.160,25.094,65.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.984 | Acc: 15.174,24.995,65.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.990 | Acc: 15.021,24.750,65.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.993 | Acc: 15.081,24.895,65.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.996 | Acc: 14.996,24.940,65.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.002 | Acc: 14.951,24.851,65.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.003 | Acc: 14.966,24.865,65.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.008 | Acc: 14.894,24.817,65.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.011 | Acc: 14.906,24.888,64.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.015 | Acc: 14.858,24.893,64.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.017 | Acc: 14.924,24.956,64.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.019 | Acc: 14.896,24.939,64.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.021 | Acc: 14.887,24.941,64.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.378 | Acc: 14.062,22.656,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.413 | Acc: 12.612,23.140,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.421 | Acc: 12.138,22.999,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.417 | Acc: 12.641,23.040,56.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 1.774 | Acc: 16.406,30.469,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.913 | Acc: 15.476,27.493,68.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 15.301,26.448,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 15.241,26.230,67.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.965 | Acc: 15.133,25.955,66.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.971 | Acc: 14.875,25.727,66.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.970 | Acc: 14.850,25.517,66.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.968 | Acc: 14.805,25.587,66.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.974 | Acc: 14.669,25.311,66.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.975 | Acc: 14.598,25.250,66.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.977 | Acc: 14.638,25.218,66.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.982 | Acc: 14.625,25.156,66.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.985 | Acc: 14.678,25.120,65.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.988 | Acc: 14.649,25.030,65.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.989 | Acc: 14.619,24.994,65.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.990 | Acc: 14.543,24.966,65.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.994 | Acc: 14.564,24.968,65.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.997 | Acc: 14.690,24.943,65.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.998 | Acc: 14.651,24.896,65.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.999 | Acc: 14.702,24.926,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.202 | Acc: 17.188,26.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.378 | Acc: 12.612,22.210,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.372 | Acc: 12.557,22.866,57.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 12.935,22.515,57.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.004 | Acc: 14.062,29.688,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.896 | Acc: 15.179,27.307,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.910 | Acc: 14.444,25.495,67.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.917 | Acc: 14.728,25.897,67.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.925 | Acc: 14.921,25.858,66.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.936 | Acc: 14.960,25.804,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.942 | Acc: 15.018,25.988,66.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.945 | Acc: 14.877,25.754,66.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.957 | Acc: 14.771,25.660,66.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.964 | Acc: 14.762,25.609,66.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.970 | Acc: 14.820,25.525,66.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.972 | Acc: 14.731,25.456,66.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.971 | Acc: 14.811,25.454,66.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.973 | Acc: 14.868,25.470,65.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.979 | Acc: 14.760,25.345,65.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.982 | Acc: 14.807,25.343,65.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.986 | Acc: 14.827,25.309,65.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.989 | Acc: 14.846,25.305,65.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.990 | Acc: 14.848,25.281,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.991 | Acc: 14.928,25.338,65.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.236 | Acc: 14.844,25.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.398 | Acc: 13.132,22.917,56.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.406 | Acc: 13.014,23.056,56.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.428 | Acc: 13.140,22.938,55.686,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 1.932 | Acc: 14.844,16.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.910 | Acc: 14.695,24.628,68.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.919 | Acc: 14.444,25.438,67.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.921 | Acc: 14.511,25.435,67.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.923 | Acc: 14.670,25.530,67.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.928 | Acc: 14.875,25.789,67.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.930 | Acc: 14.973,25.633,67.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.941 | Acc: 14.860,25.493,66.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.947 | Acc: 14.897,25.480,66.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.947 | Acc: 15.098,25.656,66.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.949 | Acc: 15.089,25.599,66.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.954 | Acc: 14.989,25.283,66.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.957 | Acc: 14.935,25.104,66.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.954 | Acc: 14.955,25.216,66.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.958 | Acc: 14.902,25.128,66.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.960 | Acc: 14.979,25.215,66.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.963 | Acc: 15.046,25.287,66.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.965 | Acc: 15.034,25.236,65.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.968 | Acc: 15.075,25.197,65.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.973 | Acc: 15.075,25.170,65.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.349 | Acc: 16.406,25.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.429 | Acc: 13.170,24.033,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.443 | Acc: 13.434,24.238,55.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.457 | Acc: 13.742,23.988,55.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 1.725 | Acc: 14.062,32.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.931 | Acc: 15.439,26.711,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 15.454,26.582,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.910 | Acc: 15.254,26.652,68.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.904 | Acc: 15.538,26.746,68.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.913 | Acc: 15.323,26.300,67.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 15.309,26.072,67.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.928 | Acc: 15.248,25.881,67.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.931 | Acc: 15.266,25.723,67.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.937 | Acc: 15.267,25.578,67.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.940 | Acc: 15.213,25.548,67.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.942 | Acc: 15.282,25.594,66.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.947 | Acc: 15.148,25.451,66.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.946 | Acc: 15.176,25.530,66.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.951 | Acc: 15.130,25.470,66.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.954 | Acc: 15.114,25.397,66.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.957 | Acc: 15.141,25.436,66.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.957 | Acc: 15.126,25.431,66.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.957 | Acc: 15.181,25.392,66.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.959 | Acc: 15.258,25.406,66.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.349 | Acc: 14.062,28.125,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.475 | Acc: 12.798,20.871,56.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.473 | Acc: 12.633,21.437,56.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 12.807,21.388,56.276,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 1.901 | Acc: 10.156,24.219,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.873 | Acc: 15.179,25.893,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.879 | Acc: 15.053,25.648,68.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.904 | Acc: 15.318,25.628,67.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.912 | Acc: 15.336,25.579,67.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.916 | Acc: 15.377,25.541,67.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 15.612,25.743,67.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.926 | Acc: 15.592,25.759,66.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.927 | Acc: 15.562,25.679,66.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.924 | Acc: 15.565,25.755,66.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.932 | Acc: 15.536,25.871,66.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.937 | Acc: 15.395,25.785,66.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.937 | Acc: 15.285,25.668,66.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.936 | Acc: 15.323,25.688,66.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.938 | Acc: 15.378,25.781,66.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.942 | Acc: 15.324,25.740,66.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.944 | Acc: 15.275,25.720,66.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.948 | Acc: 15.295,25.644,66.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.950 | Acc: 15.277,25.554,66.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.954 | Acc: 15.274,25.558,66.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.320 | Acc: 13.281,27.344,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.340 | Acc: 14.546,23.586,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.379 | Acc: 14.234,24.333,57.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.388 | Acc: 14.511,24.168,57.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 1.918 | Acc: 14.844,25.781,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.834 | Acc: 15.476,26.004,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.845 | Acc: 15.854,26.258,69.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.864 | Acc: 15.292,25.205,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.865 | Acc: 15.432,25.656,68.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.888 | Acc: 15.362,25.572,68.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.887 | Acc: 15.315,25.814,68.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.896 | Acc: 15.348,25.776,68.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.903 | Acc: 15.382,25.670,67.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.903 | Acc: 15.392,25.686,67.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.909 | Acc: 15.380,25.614,67.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.910 | Acc: 15.462,25.718,67.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.912 | Acc: 15.463,25.678,67.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.917 | Acc: 15.472,25.673,67.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.918 | Acc: 15.450,25.762,67.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.923 | Acc: 15.391,25.729,67.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.926 | Acc: 15.372,25.691,67.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.929 | Acc: 15.304,25.580,67.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.928 | Acc: 15.376,25.591,67.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.931 | Acc: 15.395,25.582,67.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.265 | Acc: 17.969,24.219,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.426 | Acc: 12.984,22.731,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.394 | Acc: 13.014,23.075,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.400 | Acc: 13.230,22.887,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 1.895 | Acc: 14.844,18.750,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.856 | Acc: 16.183,26.339,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.853 | Acc: 15.949,26.677,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.856 | Acc: 15.958,26.806,68.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.866 | Acc: 16.088,26.447,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.880 | Acc: 15.888,26.516,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.886 | Acc: 15.748,26.169,68.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.888 | Acc: 15.625,25.959,68.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.888 | Acc: 15.610,25.907,68.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.886 | Acc: 15.759,26.049,68.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.886 | Acc: 15.827,26.116,68.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.888 | Acc: 15.773,26.050,68.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.892 | Acc: 15.683,25.995,68.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.895 | Acc: 15.571,25.931,68.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.900 | Acc: 15.619,25.968,67.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.903 | Acc: 15.589,25.885,67.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.907 | Acc: 15.557,25.874,67.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.911 | Acc: 15.561,25.884,67.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.914 | Acc: 15.608,25.915,67.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.916 | Acc: 15.596,25.910,67.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.259 | Acc: 14.844,22.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.489 | Acc: 12.649,21.838,55.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.512 | Acc: 12.443,22.142,54.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.521 | Acc: 12.961,21.977,54.611,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 1.681 | Acc: 14.062,25.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 14.769,25.930,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.834 | Acc: 15.492,26.143,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 15.369,25.794,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.846 | Acc: 15.316,25.666,70.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.848 | Acc: 15.347,25.804,69.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.859 | Acc: 15.186,25.620,69.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.862 | Acc: 15.376,26.025,69.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.875 | Acc: 15.445,25.801,68.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.885 | Acc: 15.452,25.544,68.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.889 | Acc: 15.613,25.653,68.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.893 | Acc: 15.544,25.583,68.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.893 | Acc: 15.531,25.613,68.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.896 | Acc: 15.466,25.518,68.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.898 | Acc: 15.505,25.639,68.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.897 | Acc: 15.526,25.646,68.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.899 | Acc: 15.518,25.550,67.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.901 | Acc: 15.526,25.589,67.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.904 | Acc: 15.603,25.673,67.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.904 | Acc: 15.570,25.748,67.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.284 | Acc: 16.406,25.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.404 | Acc: 14.397,23.475,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.425 | Acc: 13.662,24.409,56.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.436 | Acc: 13.870,24.116,56.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 1.927 | Acc: 10.938,23.438,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.842 | Acc: 15.848,25.893,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.847 | Acc: 15.720,25.781,69.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.854 | Acc: 15.497,25.961,68.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.849 | Acc: 15.557,25.993,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.853 | Acc: 15.586,25.828,69.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.854 | Acc: 15.580,25.775,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.858 | Acc: 15.691,25.898,69.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.865 | Acc: 15.707,25.941,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.869 | Acc: 15.824,25.928,68.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.870 | Acc: 15.827,25.983,68.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.873 | Acc: 15.918,26.057,68.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.875 | Acc: 15.868,25.940,68.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.875 | Acc: 15.876,26.036,68.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.878 | Acc: 15.825,25.981,68.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.882 | Acc: 15.763,25.919,68.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.883 | Acc: 15.790,25.944,68.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.887 | Acc: 15.753,25.882,68.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.889 | Acc: 15.794,25.853,68.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.891 | Acc: 15.697,25.753,68.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.426 | Acc: 14.844,25.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.439 | Acc: 12.723,23.475,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.453 | Acc: 12.367,23.361,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.462 | Acc: 12.692,23.130,56.455,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 1.731 | Acc: 17.188,32.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.791 | Acc: 16.071,26.562,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.814 | Acc: 15.606,26.296,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.828 | Acc: 15.727,26.089,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.834 | Acc: 15.963,26.051,69.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.839 | Acc: 15.996,26.153,69.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.840 | Acc: 16.154,26.337,69.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.848 | Acc: 16.035,26.191,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.845 | Acc: 16.076,26.393,69.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.846 | Acc: 16.039,26.316,69.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.855 | Acc: 16.084,26.267,68.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.859 | Acc: 16.120,26.276,68.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.861 | Acc: 16.043,26.268,68.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.865 | Acc: 16.038,26.233,68.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.864 | Acc: 16.114,26.201,68.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.867 | Acc: 16.165,26.215,68.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.873 | Acc: 16.117,26.176,68.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.877 | Acc: 16.127,26.194,68.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.879 | Acc: 16.177,26.203,68.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 16.150,26.232,68.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.157 | Acc: 14.844,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.605 | Acc: 12.984,22.731,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.626 | Acc: 12.443,23.266,53.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.637 | Acc: 12.795,23.169,53.291,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 1.732 | Acc: 12.500,23.438,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.842 | Acc: 14.918,24.516,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 15.511,25.324,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.822 | Acc: 15.587,25.845,69.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.824 | Acc: 15.866,26.408,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.830 | Acc: 15.842,26.501,69.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.832 | Acc: 15.916,26.427,69.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.833 | Acc: 16.179,26.524,69.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.839 | Acc: 16.193,26.431,69.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.839 | Acc: 16.272,26.424,69.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.841 | Acc: 16.294,26.426,69.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.843 | Acc: 16.385,26.372,69.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.842 | Acc: 16.429,26.462,69.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 16.385,26.338,69.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.855 | Acc: 16.362,26.360,68.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.857 | Acc: 16.256,26.280,68.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.859 | Acc: 16.268,26.346,68.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.858 | Acc: 16.195,26.354,68.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.862 | Acc: 16.190,26.396,68.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.865 | Acc: 16.230,26.446,68.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.480 | Acc: 12.500,20.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.562 | Acc: 14.658,23.028,53.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.575 | Acc: 14.329,23.418,53.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.573 | Acc: 14.600,23.271,53.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 1.775 | Acc: 22.656,32.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.839 | Acc: 15.625,26.525,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.845 | Acc: 15.739,25.915,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.852 | Acc: 15.727,26.063,69.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.843 | Acc: 16.329,26.071,69.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.841 | Acc: 16.228,26.021,69.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.838 | Acc: 16.296,26.317,69.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.843 | Acc: 16.362,26.213,69.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.848 | Acc: 16.397,26.388,68.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.854 | Acc: 16.363,26.278,68.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.860 | Acc: 16.383,26.232,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.860 | Acc: 16.205,26.145,68.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.863 | Acc: 16.221,26.144,68.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.862 | Acc: 16.197,26.111,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.866 | Acc: 16.234,26.140,68.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.867 | Acc: 16.305,26.210,68.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.872 | Acc: 16.238,26.127,68.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.872 | Acc: 16.241,26.198,68.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.874 | Acc: 16.253,26.260,68.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.876 | Acc: 16.203,26.210,68.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.269 | Acc: 16.406,27.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.366 | Acc: 14.807,25.484,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.367 | Acc: 14.463,25.724,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 14.844,25.410,57.672,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 1.715 | Acc: 13.281,24.219,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.727 | Acc: 14.993,25.744,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.776 | Acc: 15.320,26.353,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.776 | Acc: 15.574,26.524,70.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.775 | Acc: 15.702,26.572,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.782 | Acc: 15.880,26.648,70.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.787 | Acc: 16.045,26.776,70.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.801 | Acc: 15.919,26.601,70.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.816 | Acc: 15.931,26.499,69.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.819 | Acc: 16.013,26.472,69.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.819 | Acc: 16.138,26.508,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.822 | Acc: 16.120,26.527,69.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.823 | Acc: 16.192,26.410,69.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.826 | Acc: 16.295,26.631,69.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.830 | Acc: 16.270,26.632,69.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.834 | Acc: 16.279,26.583,69.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.837 | Acc: 16.289,26.587,69.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.840 | Acc: 16.193,26.565,69.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.844 | Acc: 16.235,26.597,69.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.847 | Acc: 16.207,26.499,69.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.274 | Acc: 14.062,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.334 | Acc: 13.951,24.033,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.345 | Acc: 13.377,24.295,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.352 | Acc: 13.768,24.193,58.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 2.060 | Acc: 9.375,21.875,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.808 | Acc: 15.439,26.004,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.812 | Acc: 16.082,26.410,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.795 | Acc: 16.432,26.332,70.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.793 | Acc: 16.445,26.688,70.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.794 | Acc: 16.105,26.663,70.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.791 | Acc: 16.064,26.491,70.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.792 | Acc: 16.129,26.413,70.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.798 | Acc: 16.227,26.485,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.802 | Acc: 16.264,26.554,69.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.813 | Acc: 16.208,26.279,69.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.815 | Acc: 16.321,26.340,69.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.819 | Acc: 16.299,26.485,69.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.820 | Acc: 16.379,26.488,69.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 16.323,26.482,69.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.827 | Acc: 16.323,26.453,69.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.829 | Acc: 16.338,26.434,69.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.832 | Acc: 16.338,26.462,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.837 | Acc: 16.222,26.420,69.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.839 | Acc: 16.240,26.405,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.167 | Acc: 16.406,25.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.357 | Acc: 13.542,22.284,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.377 | Acc: 13.777,22.694,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.392 | Acc: 13.845,22.451,57.941,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 1.888 | Acc: 13.281,24.219,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.823 | Acc: 15.588,25.260,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.807 | Acc: 16.139,26.181,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.822 | Acc: 15.984,26.217,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.811 | Acc: 16.406,26.601,70.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.809 | Acc: 16.460,26.779,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.813 | Acc: 16.342,26.575,70.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.809 | Acc: 16.356,26.513,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.807 | Acc: 16.416,26.461,70.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.810 | Acc: 16.432,26.476,70.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.811 | Acc: 16.476,26.528,70.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.809 | Acc: 16.608,26.633,70.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.810 | Acc: 16.520,26.540,70.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.811 | Acc: 16.577,26.637,70.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.817 | Acc: 16.570,26.646,70.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.819 | Acc: 16.572,26.708,70.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.822 | Acc: 16.501,26.648,69.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.824 | Acc: 16.415,26.537,69.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.827 | Acc: 16.389,26.508,69.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.828 | Acc: 16.421,26.483,69.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.239 | Acc: 15.625,22.656,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.439 | Acc: 13.951,21.987,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.411 | Acc: 13.586,22.237,57.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.432 | Acc: 13.845,21.888,56.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 1.684 | Acc: 17.969,21.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.809 | Acc: 16.629,26.079,69.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.794 | Acc: 16.349,26.315,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.793 | Acc: 16.855,26.447,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.792 | Acc: 16.551,26.148,70.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.795 | Acc: 16.685,26.354,70.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.799 | Acc: 16.781,26.524,70.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.797 | Acc: 16.800,26.529,70.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 16.697,26.572,70.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.798 | Acc: 16.644,26.614,70.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.802 | Acc: 16.779,26.776,70.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.802 | Acc: 16.767,26.884,70.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.806 | Acc: 16.627,26.806,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.806 | Acc: 16.744,26.859,70.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.805 | Acc: 16.681,26.849,70.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.811 | Acc: 16.757,26.941,70.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.814 | Acc: 16.713,26.833,69.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.817 | Acc: 16.674,26.817,69.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.818 | Acc: 16.716,26.889,69.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.819 | Acc: 16.796,26.971,69.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.309 | Acc: 17.188,24.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.449 | Acc: 13.914,23.549,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 14.177,23.666,55.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.506 | Acc: 14.229,23.207,55.494,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 1.606 | Acc: 19.531,26.562,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.775 | Acc: 17.671,27.865,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.781 | Acc: 17.168,27.534,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.762 | Acc: 17.444,27.984,71.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.770 | Acc: 17.216,27.517,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.782 | Acc: 16.917,26.926,70.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.784 | Acc: 16.981,27.079,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.782 | Acc: 17.093,27.388,70.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.785 | Acc: 17.032,27.237,70.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.789 | Acc: 17.093,27.262,70.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.787 | Acc: 17.118,27.227,70.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.795 | Acc: 17.004,27.100,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.799 | Acc: 17.006,27.159,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.801 | Acc: 16.987,27.041,70.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.806 | Acc: 16.985,26.957,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.809 | Acc: 17.034,26.884,70.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.811 | Acc: 17.022,26.850,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.813 | Acc: 17.050,26.842,70.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.816 | Acc: 16.939,26.820,70.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.817 | Acc: 16.919,26.854,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.297 | Acc: 19.531,26.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.359 | Acc: 15.365,24.665,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.369 | Acc: 15.225,24.924,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.378 | Acc: 15.177,24.296,57.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 1.722 | Acc: 17.969,26.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 16.853,26.488,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.741 | Acc: 16.902,26.181,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.735 | Acc: 17.059,26.575,71.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 17.072,26.871,71.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.748 | Acc: 17.164,27.065,71.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.754 | Acc: 16.929,27.182,71.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.764 | Acc: 17.171,27.045,71.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.768 | Acc: 17.221,26.970,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.777 | Acc: 17.123,26.809,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.780 | Acc: 17.133,26.858,70.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.783 | Acc: 17.177,26.912,70.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.784 | Acc: 17.158,26.913,70.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.787 | Acc: 17.107,26.952,70.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.790 | Acc: 17.140,26.991,70.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.792 | Acc: 17.138,27.071,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.795 | Acc: 17.183,27.105,70.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.797 | Acc: 17.162,27.064,70.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.800 | Acc: 17.153,26.993,70.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.801 | Acc: 17.155,26.934,70.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.078 | Acc: 18.750,24.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.287 | Acc: 14.844,23.400,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.286 | Acc: 14.996,24.028,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.305 | Acc: 15.074,23.489,59.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 1.827 | Acc: 23.438,25.781,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.762 | Acc: 17.671,26.042,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.765 | Acc: 17.511,26.486,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.751 | Acc: 16.957,26.857,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 16.686,27.199,71.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.742 | Acc: 17.095,27.452,71.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.751 | Acc: 17.084,27.486,71.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.761 | Acc: 17.088,27.554,71.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.765 | Acc: 17.056,27.436,71.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.767 | Acc: 16.946,27.396,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.771 | Acc: 16.978,27.317,70.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.781 | Acc: 16.937,27.167,70.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 16.873,27.114,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.787 | Acc: 16.858,27.104,70.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.789 | Acc: 16.882,27.035,70.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.790 | Acc: 16.938,27.012,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.792 | Acc: 17.000,27.086,70.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.794 | Acc: 16.958,27.005,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.793 | Acc: 16.930,27.030,70.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.794 | Acc: 16.902,27.001,70.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.174 | Acc: 16.406,25.000,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.399 | Acc: 12.165,22.173,58.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.404 | Acc: 12.195,23.152,57.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 12.500,23.117,57.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 1.764 | Acc: 13.281,25.781,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.708 | Acc: 15.067,25.298,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.705 | Acc: 16.482,26.353,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 16.893,26.972,73.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.723 | Acc: 16.898,27.112,72.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.727 | Acc: 17.041,27.235,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 17.091,27.350,72.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.742 | Acc: 16.938,27.294,72.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.747 | Acc: 16.882,27.286,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.749 | Acc: 17.006,27.296,71.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.753 | Acc: 16.939,27.324,71.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 16.852,27.337,71.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.761 | Acc: 16.805,27.201,71.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.766 | Acc: 16.843,27.059,71.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.769 | Acc: 16.968,27.160,70.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.771 | Acc: 17.011,27.131,70.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.776 | Acc: 16.978,27.108,70.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.780 | Acc: 16.972,27.128,70.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.782 | Acc: 17.047,27.201,70.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.786 | Acc: 17.042,27.266,70.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.200 | Acc: 17.188,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.287 | Acc: 15.476,25.744,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.328 | Acc: 15.091,25.953,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.332 | Acc: 15.446,25.474,58.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 1.773 | Acc: 18.750,33.594,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.744 | Acc: 16.778,27.307,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 16.902,27.439,72.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.724 | Acc: 17.380,27.613,72.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.725 | Acc: 17.351,27.874,72.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.729 | Acc: 17.242,27.669,72.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.729 | Acc: 17.297,27.615,72.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.736 | Acc: 17.287,27.576,72.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.737 | Acc: 17.260,27.533,72.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.742 | Acc: 17.188,27.421,71.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.748 | Acc: 17.160,27.340,71.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.750 | Acc: 17.184,27.397,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.756 | Acc: 17.200,27.357,71.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.760 | Acc: 17.161,27.170,71.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.761 | Acc: 17.140,27.074,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.767 | Acc: 17.185,27.048,71.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.769 | Acc: 17.263,27.049,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.773 | Acc: 17.272,27.039,70.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.771 | Acc: 17.367,27.153,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 17.341,27.126,70.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.459 | Acc: 18.750,31.250,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.578 | Acc: 15.439,23.289,55.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.589 | Acc: 15.873,24.162,54.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.607 | Acc: 15.868,23.681,54.098,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 1.752 | Acc: 16.406,31.250,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 17.485,26.674,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.725 | Acc: 17.645,26.886,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.747 | Acc: 17.751,27.164,71.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.742 | Acc: 17.757,27.074,71.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.744 | Acc: 17.667,27.197,71.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.745 | Acc: 17.620,26.950,71.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.743 | Acc: 17.492,27.017,71.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.743 | Acc: 17.532,27.121,71.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.742 | Acc: 17.567,27.296,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.741 | Acc: 17.514,27.297,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.741 | Acc: 17.456,27.436,71.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.746 | Acc: 17.379,27.396,71.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.752 | Acc: 17.418,27.440,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.755 | Acc: 17.343,27.322,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.758 | Acc: 17.335,27.310,71.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.762 | Acc: 17.331,27.339,71.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 17.236,27.284,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.764 | Acc: 17.276,27.361,71.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.764 | Acc: 17.317,27.428,71.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.192 | Acc: 16.406,28.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.356 | Acc: 14.509,26.339,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.368 | Acc: 14.520,26.143,58.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.369 | Acc: 14.959,26.165,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 1.787 | Acc: 12.500,23.438,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.664 | Acc: 15.997,28.051,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.677 | Acc: 17.207,28.144,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 17.367,27.754,73.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.703 | Acc: 17.274,27.701,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.706 | Acc: 17.296,27.645,72.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 17.291,27.673,72.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.720 | Acc: 17.509,27.743,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.725 | Acc: 17.488,27.698,72.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.732 | Acc: 17.442,27.491,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.735 | Acc: 17.530,27.674,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 17.548,27.764,72.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.740 | Acc: 17.551,27.629,71.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.743 | Acc: 17.604,27.679,71.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.747 | Acc: 17.493,27.541,71.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.749 | Acc: 17.559,27.551,71.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.753 | Acc: 17.565,27.575,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.757 | Acc: 17.586,27.593,71.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.758 | Acc: 17.558,27.603,71.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.762 | Acc: 17.464,27.536,71.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.059 | Acc: 15.625,26.562,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.304 | Acc: 15.476,25.595,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.296 | Acc: 14.958,26.086,58.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.310 | Acc: 15.177,25.832,58.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 1.737 | Acc: 14.844,28.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 15.402,28.199,73.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.674 | Acc: 15.968,27.477,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 16.880,27.818,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.678 | Acc: 17.043,27.797,73.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.696 | Acc: 17.327,27.955,73.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.704 | Acc: 17.181,27.660,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 17.143,27.532,72.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.713 | Acc: 17.202,27.441,72.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.715 | Acc: 17.270,27.400,72.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.721 | Acc: 17.219,27.379,72.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.728 | Acc: 17.347,27.414,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.732 | Acc: 17.531,27.632,71.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.735 | Acc: 17.544,27.592,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.736 | Acc: 17.621,27.700,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.736 | Acc: 17.694,27.736,71.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.741 | Acc: 17.623,27.646,71.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.741 | Acc: 17.650,27.648,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.744 | Acc: 17.668,27.588,71.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.747 | Acc: 17.649,27.575,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.108 | Acc: 15.625,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.322 | Acc: 14.844,23.661,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.344 | Acc: 14.844,24.905,59.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.347 | Acc: 14.985,24.603,59.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 1.575 | Acc: 18.750,32.031,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.689 | Acc: 17.820,28.683,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.692 | Acc: 17.626,27.268,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 17.495,27.203,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.702 | Acc: 17.400,27.652,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.710 | Acc: 17.497,27.831,72.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 17.252,27.421,72.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 17.265,27.344,72.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 17.183,27.392,72.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.728 | Acc: 17.075,27.206,72.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.729 | Acc: 17.067,27.239,71.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.739 | Acc: 17.081,27.209,71.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.738 | Acc: 17.022,27.243,71.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.741 | Acc: 17.190,27.278,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.743 | Acc: 17.201,27.410,71.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.741 | Acc: 17.309,27.453,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.742 | Acc: 17.338,27.436,71.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.745 | Acc: 17.346,27.454,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.749 | Acc: 17.343,27.445,71.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.750 | Acc: 17.370,27.440,71.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.191 | Acc: 15.625,24.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.311 | Acc: 15.551,24.554,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.320 | Acc: 15.187,25.324,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.342 | Acc: 15.548,25.038,58.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 1.479 | Acc: 18.750,25.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.714 | Acc: 17.448,28.162,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.719 | Acc: 17.378,27.096,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.711 | Acc: 17.764,27.472,72.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.716 | Acc: 17.737,27.479,72.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.712 | Acc: 17.775,27.498,72.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.716 | Acc: 17.659,27.434,72.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.723 | Acc: 17.647,27.504,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.723 | Acc: 17.707,27.480,71.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.719 | Acc: 17.813,27.521,72.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.726 | Acc: 17.837,27.445,71.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.728 | Acc: 17.764,27.478,71.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.728 | Acc: 17.654,27.451,71.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.732 | Acc: 17.741,27.535,71.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.731 | Acc: 17.769,27.672,71.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.732 | Acc: 17.764,27.738,71.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.736 | Acc: 17.699,27.675,71.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.737 | Acc: 17.685,27.681,71.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.737 | Acc: 17.724,27.707,71.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.742 | Acc: 17.684,27.657,71.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.091 | Acc: 15.625,25.781,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.305 | Acc: 14.881,25.186,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.298 | Acc: 14.539,25.857,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.314 | Acc: 14.767,25.576,59.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.576 | Acc: 16.406,23.438,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.609 | Acc: 17.894,28.609,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.631 | Acc: 17.893,28.220,74.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.640 | Acc: 18.046,28.074,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.662 | Acc: 17.911,27.778,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 18.000,27.839,73.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 18.066,27.918,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 17.947,27.743,73.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.687 | Acc: 18.008,27.742,73.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.693 | Acc: 18.038,27.598,72.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.694 | Acc: 17.879,27.752,72.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.699 | Acc: 17.887,27.757,72.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.705 | Acc: 17.865,27.684,72.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.710 | Acc: 17.876,27.721,72.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.714 | Acc: 17.805,27.683,72.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.716 | Acc: 17.896,27.738,72.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.719 | Acc: 17.876,27.743,72.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 17.827,27.669,72.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.728 | Acc: 17.793,27.632,72.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 17.753,27.621,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.172 | Acc: 15.625,24.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.400 | Acc: 14.137,24.033,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.404 | Acc: 14.062,24.466,57.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.404 | Acc: 14.511,24.193,56.967,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 1.740 | Acc: 12.500,24.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.717 | Acc: 18.080,27.939,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 18.026,28.544,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.660 | Acc: 18.033,28.381,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.667 | Acc: 17.969,28.250,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 17.922,28.102,73.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.681 | Acc: 17.943,28.086,73.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.684 | Acc: 17.985,28.214,73.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 18.095,28.217,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.693 | Acc: 18.090,28.194,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.691 | Acc: 18.008,28.269,72.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.694 | Acc: 18.022,28.086,72.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.691 | Acc: 18.066,28.070,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.695 | Acc: 18.011,28.029,72.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 17.994,28.019,72.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.710 | Acc: 17.930,27.878,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.713 | Acc: 17.927,27.852,72.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.717 | Acc: 17.863,27.855,72.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.721 | Acc: 17.874,27.926,72.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.725 | Acc: 17.911,27.986,72.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.256 | Acc: 16.406,28.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.394 | Acc: 14.360,24.516,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.400 | Acc: 14.062,25.191,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.396 | Acc: 14.306,25.000,57.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 1.899 | Acc: 15.625,25.000,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 16.220,25.781,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.723 | Acc: 16.806,26.543,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.711 | Acc: 17.354,27.126,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.692 | Acc: 17.679,27.575,72.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 17.713,27.870,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.691 | Acc: 17.704,27.873,72.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.695 | Acc: 17.692,27.959,72.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 17.901,28.072,72.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.693 | Acc: 17.822,27.905,72.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.697 | Acc: 17.774,27.806,72.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.698 | Acc: 17.948,27.991,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.701 | Acc: 17.930,27.992,72.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.703 | Acc: 17.999,28.035,72.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.708 | Acc: 17.941,27.953,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.711 | Acc: 18.005,27.969,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.715 | Acc: 18.000,28.033,72.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.719 | Acc: 17.941,27.951,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.721 | Acc: 17.863,27.854,72.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.725 | Acc: 17.850,27.840,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.163 | Acc: 17.188,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.320 | Acc: 16.369,24.814,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.342 | Acc: 16.578,24.886,58.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.357 | Acc: 16.983,24.296,58.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 1.794 | Acc: 19.531,20.312,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.687 | Acc: 18.750,28.720,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.685 | Acc: 18.502,28.601,72.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 18.122,28.304,72.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.687 | Acc: 18.162,28.183,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 18.023,28.272,72.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 17.956,28.067,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.679 | Acc: 17.963,27.992,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.684 | Acc: 17.959,28.043,72.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.687 | Acc: 17.852,27.974,72.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.690 | Acc: 18.089,28.074,72.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 18.061,28.111,72.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.694 | Acc: 18.079,28.083,72.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.692 | Acc: 18.082,28.107,72.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.697 | Acc: 18.172,28.142,72.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.698 | Acc: 18.187,28.231,72.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.699 | Acc: 18.176,28.308,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.701 | Acc: 18.058,28.207,72.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.704 | Acc: 18.053,28.186,72.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.708 | Acc: 18.090,28.203,72.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.344 | Acc: 10.156,22.656,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.479 | Acc: 12.388,22.954,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.476 | Acc: 12.290,23.133,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.486 | Acc: 12.423,22.797,56.711,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 1.759 | Acc: 14.844,21.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.657 | Acc: 17.783,27.939,73.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.644 | Acc: 18.255,28.620,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.642 | Acc: 18.174,28.138,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.655 | Acc: 18.210,28.135,73.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.669 | Acc: 18.007,27.731,73.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.667 | Acc: 18.137,27.802,73.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.665 | Acc: 18.152,27.743,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 18.231,27.751,73.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 18.340,27.758,73.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.676 | Acc: 18.287,27.814,73.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.680 | Acc: 18.252,27.782,73.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.681 | Acc: 18.371,27.918,73.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.684 | Acc: 18.328,27.969,73.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 18.347,27.944,72.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.688 | Acc: 18.304,27.832,72.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 18.300,27.938,72.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.694 | Acc: 18.349,27.930,72.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.696 | Acc: 18.378,27.993,72.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.703 | Acc: 18.299,27.951,72.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.175 | Acc: 20.312,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.361 | Acc: 15.774,25.223,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.377 | Acc: 16.025,25.534,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.388 | Acc: 16.291,25.320,58.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 1.577 | Acc: 20.312,28.906,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.680 | Acc: 18.490,27.232,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.661 | Acc: 18.979,28.201,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.656 | Acc: 18.724,28.163,73.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.650 | Acc: 18.750,28.511,74.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.658 | Acc: 18.866,28.759,73.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.662 | Acc: 18.899,28.855,73.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 18.844,28.818,73.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.663 | Acc: 18.784,28.814,73.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.670 | Acc: 18.862,28.772,73.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.676 | Acc: 18.820,28.751,73.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.677 | Acc: 18.923,28.722,73.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.683 | Acc: 18.750,28.585,73.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.686 | Acc: 18.573,28.457,73.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.688 | Acc: 18.555,28.428,73.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 18.490,28.385,73.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 18.421,28.373,73.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.689 | Acc: 18.470,28.432,73.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.696 | Acc: 18.341,28.328,72.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.698 | Acc: 18.334,28.318,72.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.077 | Acc: 21.094,25.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.342 | Acc: 16.518,23.289,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.354 | Acc: 16.425,23.780,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.355 | Acc: 16.534,23.297,58.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 1.612 | Acc: 18.750,28.906,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.659 | Acc: 19.308,30.097,73.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.672 | Acc: 18.960,29.173,73.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 18.673,28.650,73.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.669 | Acc: 18.528,28.328,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.665 | Acc: 18.549,28.388,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 18.414,28.241,73.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 18.473,28.191,73.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.674 | Acc: 18.512,28.110,73.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 18.344,28.047,73.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 18.280,28.001,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 18.361,28.146,73.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.687 | Acc: 18.442,28.154,72.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.691 | Acc: 18.421,28.089,72.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.694 | Acc: 18.419,28.117,72.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.695 | Acc: 18.426,28.068,72.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.698 | Acc: 18.426,28.113,72.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.700 | Acc: 18.390,28.015,72.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.702 | Acc: 18.460,27.982,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.705 | Acc: 18.467,28.061,72.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.136 | Acc: 16.406,25.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.323 | Acc: 15.662,25.149,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.345 | Acc: 15.796,25.000,58.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.334 | Acc: 15.843,24.821,58.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 1.768 | Acc: 14.062,25.000,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.678 | Acc: 17.262,27.232,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 17.969,27.934,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.628 | Acc: 17.841,27.766,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.633 | Acc: 17.911,27.768,74.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.628 | Acc: 18.332,28.481,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.631 | Acc: 18.195,28.325,74.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 18.462,28.496,74.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.632 | Acc: 18.216,28.387,74.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.640 | Acc: 18.280,28.324,74.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.646 | Acc: 18.291,28.315,74.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.648 | Acc: 18.206,28.309,74.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.650 | Acc: 18.192,28.268,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.654 | Acc: 18.226,28.278,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.657 | Acc: 18.297,28.289,73.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.663 | Acc: 18.340,28.343,73.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.668 | Acc: 18.385,28.322,73.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.672 | Acc: 18.500,28.343,73.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.674 | Acc: 18.544,28.341,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 18.516,28.342,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.286 | Acc: 14.844,23.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.254 | Acc: 15.216,23.475,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.283 | Acc: 14.653,23.590,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.294 | Acc: 14.844,23.642,60.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 1.501 | Acc: 24.219,31.250,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.656 | Acc: 17.634,28.237,73.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.640 | Acc: 17.416,28.639,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 17.789,28.599,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.644 | Acc: 18.133,28.684,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.644 | Acc: 18.154,28.643,73.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.646 | Acc: 18.001,28.596,73.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.649 | Acc: 18.218,28.718,73.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.646 | Acc: 18.381,28.625,73.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.650 | Acc: 18.327,28.544,73.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.654 | Acc: 18.373,28.514,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.654 | Acc: 18.450,28.528,73.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.658 | Acc: 18.387,28.495,73.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.661 | Acc: 18.451,28.520,73.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.666 | Acc: 18.450,28.464,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.669 | Acc: 18.433,28.385,73.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.671 | Acc: 18.487,28.407,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.670 | Acc: 18.564,28.421,73.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.672 | Acc: 18.609,28.404,73.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 18.611,28.412,73.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.324 | Acc: 17.188,25.000,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.433 | Acc: 15.699,23.996,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.422 | Acc: 16.025,24.390,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.421 | Acc: 16.509,24.232,56.993,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 1.698 | Acc: 21.094,28.906,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.626 | Acc: 17.932,29.092,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 18.598,29.040,74.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.629 | Acc: 18.545,29.098,74.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 18.239,29.147,74.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.633 | Acc: 18.154,29.007,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.644 | Acc: 18.253,28.990,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.653 | Acc: 18.185,28.784,73.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.660 | Acc: 18.289,28.698,73.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.663 | Acc: 18.284,28.565,73.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.664 | Acc: 18.295,28.529,73.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.670 | Acc: 18.308,28.542,73.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.674 | Acc: 18.306,28.449,73.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.674 | Acc: 18.325,28.469,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.673 | Acc: 18.361,28.498,73.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.674 | Acc: 18.392,28.514,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.674 | Acc: 18.387,28.510,73.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.678 | Acc: 18.429,28.505,73.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 18.382,28.434,72.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.687 | Acc: 18.340,28.361,72.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.185 | Acc: 13.281,22.656,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.250 | Acc: 15.290,25.223,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.274 | Acc: 15.263,25.248,61.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.290 | Acc: 15.394,24.795,60.464,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 1.703 | Acc: 18.750,27.344,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.627 | Acc: 19.159,27.753,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.615 | Acc: 18.788,28.201,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.631 | Acc: 18.340,27.497,74.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.634 | Acc: 18.364,27.884,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.638 | Acc: 18.100,27.746,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 18.324,28.002,74.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.641 | Acc: 18.379,28.374,74.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.644 | Acc: 18.386,28.397,74.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.647 | Acc: 18.500,28.341,74.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.651 | Acc: 18.548,28.467,74.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.652 | Acc: 18.662,28.648,73.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.652 | Acc: 18.604,28.589,73.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 18.654,28.469,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.659 | Acc: 18.686,28.536,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 18.641,28.499,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.667 | Acc: 18.582,28.478,73.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.669 | Acc: 18.580,28.533,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.671 | Acc: 18.570,28.508,73.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.671 | Acc: 18.551,28.572,73.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.156 | Acc: 17.188,28.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.293 | Acc: 15.551,24.814,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.289 | Acc: 15.282,24.619,60.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.290 | Acc: 15.420,24.232,59.964,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.552 | Acc: 20.312,31.250,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.590 | Acc: 17.857,29.129,75.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.590 | Acc: 18.369,29.707,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.609 | Acc: 18.302,29.636,75.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.609 | Acc: 18.364,29.620,75.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.620 | Acc: 18.502,29.502,74.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.621 | Acc: 18.447,29.449,74.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.625 | Acc: 18.390,29.194,74.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.628 | Acc: 18.449,29.125,74.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.632 | Acc: 18.513,29.018,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.631 | Acc: 18.536,28.937,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.636 | Acc: 18.559,28.797,74.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.641 | Acc: 18.627,28.799,74.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.646 | Acc: 18.648,28.843,74.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 18.644,28.809,73.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.653 | Acc: 18.734,28.828,73.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 18.733,28.850,73.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.657 | Acc: 18.807,28.865,73.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.658 | Acc: 18.785,28.766,73.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 18.785,28.734,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.164 | Acc: 17.969,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.306 | Acc: 15.365,26.674,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.329 | Acc: 14.958,26.715,59.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.349 | Acc: 15.151,26.358,58.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 1.568 | Acc: 18.750,28.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.608 | Acc: 19.196,28.199,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 19.150,28.678,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.595 | Acc: 18.699,28.804,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.594 | Acc: 18.827,28.848,75.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.605 | Acc: 18.843,28.821,75.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.610 | Acc: 18.563,28.558,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.618 | Acc: 18.573,28.502,74.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.617 | Acc: 18.609,28.610,74.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.623 | Acc: 18.612,28.626,74.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.627 | Acc: 18.672,28.685,74.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.630 | Acc: 18.697,28.825,74.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.629 | Acc: 18.601,28.799,74.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.636 | Acc: 18.585,28.739,74.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.639 | Acc: 18.683,28.770,74.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.643 | Acc: 18.638,28.719,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.644 | Acc: 18.701,28.680,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.646 | Acc: 18.658,28.643,74.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 18.666,28.679,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.653 | Acc: 18.713,28.734,73.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.053 | Acc: 14.062,23.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.287 | Acc: 15.513,25.112,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.319 | Acc: 15.396,25.419,59.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.319 | Acc: 15.830,25.179,59.746,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 1.648 | Acc: 22.656,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.571 | Acc: 19.680,29.576,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.604 | Acc: 19.093,29.268,75.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.605 | Acc: 19.121,29.201,75.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.612 | Acc: 18.924,29.070,75.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.616 | Acc: 18.897,29.053,75.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.618 | Acc: 18.821,28.926,74.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.618 | Acc: 18.961,28.901,74.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.625 | Acc: 19.080,29.052,74.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.633 | Acc: 18.832,28.949,74.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.634 | Acc: 18.851,28.926,74.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.640 | Acc: 18.909,28.963,74.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.647 | Acc: 18.922,28.922,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.651 | Acc: 18.948,28.861,73.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.651 | Acc: 19.020,28.909,73.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.650 | Acc: 19.025,29.046,73.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.651 | Acc: 19.074,29.023,73.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.651 | Acc: 19.096,29.057,73.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.655 | Acc: 19.083,29.025,73.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 19.127,29.093,73.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.099 | Acc: 17.969,23.438,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.308 | Acc: 16.815,26.339,60.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.304 | Acc: 16.311,25.934,60.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.307 | Acc: 16.278,25.820,60.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.348 | Acc: 20.312,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.572 | Acc: 19.085,29.911,76.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.584 | Acc: 19.741,29.592,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.596 | Acc: 19.185,29.175,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.602 | Acc: 19.174,29.282,75.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.595 | Acc: 19.168,29.378,75.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.603 | Acc: 19.267,29.423,75.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.612 | Acc: 19.132,29.283,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.615 | Acc: 19.138,29.197,75.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.616 | Acc: 19.082,29.113,75.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.623 | Acc: 18.859,29.038,74.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.628 | Acc: 18.796,29.065,74.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.634 | Acc: 18.763,29.026,74.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.635 | Acc: 18.669,28.918,74.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.638 | Acc: 18.733,28.884,74.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.640 | Acc: 18.797,28.800,74.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.643 | Acc: 18.794,28.714,74.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.647 | Acc: 18.805,28.794,74.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.646 | Acc: 18.808,28.876,74.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.650 | Acc: 18.873,28.898,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.085 | Acc: 21.875,24.219,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.330 | Acc: 18.638,25.298,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.339 | Acc: 18.407,25.762,58.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.331 | Acc: 18.584,25.205,59.221,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.618 | Acc: 18.750,28.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 19.643,31.101,74.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.608 | Acc: 19.303,29.745,74.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.596 | Acc: 19.531,30.020,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.607 | Acc: 19.348,29.803,74.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.618 | Acc: 19.199,29.649,74.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.616 | Acc: 19.247,29.507,74.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.621 | Acc: 19.304,29.410,74.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.618 | Acc: 19.434,29.668,74.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.629 | Acc: 19.307,29.433,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.629 | Acc: 19.298,29.377,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.628 | Acc: 19.241,29.316,74.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.632 | Acc: 19.145,29.175,74.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.636 | Acc: 18.980,29.083,74.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.642 | Acc: 18.939,29.040,74.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.646 | Acc: 18.914,28.906,73.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.647 | Acc: 18.862,28.843,73.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.650 | Acc: 18.858,28.876,73.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.654 | Acc: 18.854,28.921,73.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.654 | Acc: 18.908,28.982,73.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.961 | Acc: 16.406,30.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.241 | Acc: 16.481,27.716,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.272 | Acc: 16.463,27.458,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.287 | Acc: 16.624,27.049,60.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 1.666 | Acc: 11.719,25.781,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.628 | Acc: 17.932,28.906,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.611 | Acc: 18.026,29.002,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.602 | Acc: 18.801,29.636,75.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.596 | Acc: 18.981,29.630,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.599 | Acc: 18.912,29.308,75.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.607 | Acc: 18.782,29.165,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.607 | Acc: 18.811,29.106,75.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.610 | Acc: 18.920,29.139,74.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.611 | Acc: 18.905,29.200,74.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.616 | Acc: 18.964,29.244,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.618 | Acc: 19.036,29.362,74.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.622 | Acc: 19.055,29.328,74.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.626 | Acc: 18.933,29.289,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.628 | Acc: 18.972,29.273,74.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.630 | Acc: 18.978,29.264,74.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.632 | Acc: 18.981,29.257,74.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.638 | Acc: 18.952,29.161,74.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.640 | Acc: 18.893,29.136,74.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.642 | Acc: 18.904,29.177,74.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.010 | Acc: 17.188,28.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.370 | Acc: 16.220,26.116,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.399 | Acc: 16.521,26.258,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.401 | Acc: 16.790,26.012,58.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 1.425 | Acc: 25.000,40.625,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.543 | Acc: 19.717,30.729,76.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.549 | Acc: 19.588,30.755,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.568 | Acc: 19.582,30.225,76.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.564 | Acc: 19.927,30.401,76.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.569 | Acc: 19.570,29.819,76.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.568 | Acc: 19.635,29.784,76.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.578 | Acc: 19.365,29.344,75.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.580 | Acc: 19.323,29.236,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.588 | Acc: 19.216,29.182,75.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.596 | Acc: 19.216,29.225,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.602 | Acc: 19.241,29.330,75.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.611 | Acc: 19.197,29.276,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.614 | Acc: 19.145,29.239,74.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.618 | Acc: 19.053,29.276,74.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.618 | Acc: 19.054,29.241,74.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.624 | Acc: 18.996,29.181,74.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.627 | Acc: 19.050,29.193,74.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.629 | Acc: 19.034,29.162,74.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.631 | Acc: 19.008,29.161,74.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.168 | Acc: 14.844,22.656,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.332 | Acc: 16.406,26.674,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.371 | Acc: 15.911,26.467,58.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.387 | Acc: 16.483,26.012,57.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 1.825 | Acc: 19.531,30.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.564 | Acc: 19.829,29.315,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.556 | Acc: 19.665,29.992,76.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.562 | Acc: 19.736,29.713,76.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.558 | Acc: 19.608,30.141,76.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.565 | Acc: 19.446,30.128,76.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.583 | Acc: 19.286,29.720,75.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.584 | Acc: 19.398,29.809,75.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.593 | Acc: 19.332,29.789,75.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.597 | Acc: 19.259,29.670,75.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.600 | Acc: 19.275,29.618,75.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.605 | Acc: 19.319,29.613,75.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.610 | Acc: 19.327,29.558,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.611 | Acc: 19.403,29.595,74.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.614 | Acc: 19.323,29.548,74.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.616 | Acc: 19.305,29.527,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.618 | Acc: 19.358,29.563,74.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.620 | Acc: 19.309,29.497,74.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.621 | Acc: 19.332,29.460,74.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.624 | Acc: 19.281,29.353,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.952 | Acc: 16.406,27.344,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.324 | Acc: 15.551,27.158,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.326 | Acc: 15.320,26.963,59.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.333 | Acc: 15.817,26.422,59.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 1.514 | Acc: 17.969,25.000,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.574 | Acc: 19.271,29.315,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.586 | Acc: 18.998,29.002,75.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.591 | Acc: 18.929,29.201,75.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.587 | Acc: 18.846,29.244,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.586 | Acc: 19.067,29.308,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.592 | Acc: 18.950,29.216,75.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.591 | Acc: 19.021,29.194,75.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.591 | Acc: 18.993,29.260,75.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.596 | Acc: 19.022,29.303,75.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.603 | Acc: 19.003,29.357,75.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.603 | Acc: 18.980,29.486,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.607 | Acc: 19.039,29.555,75.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.613 | Acc: 19.112,29.604,74.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.617 | Acc: 19.223,29.596,74.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.616 | Acc: 19.132,29.576,74.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.618 | Acc: 19.208,29.588,74.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.623 | Acc: 19.222,29.548,74.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.624 | Acc: 19.256,29.555,74.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.628 | Acc: 19.203,29.454,74.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.171 | Acc: 17.969,30.469,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.316 | Acc: 14.844,24.591,60.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.336 | Acc: 14.977,24.809,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.348 | Acc: 15.587,24.590,59.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.720 | Acc: 21.875,26.562,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.574 | Acc: 18.899,29.464,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.587 | Acc: 18.674,28.639,76.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.576 | Acc: 18.878,29.393,76.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.575 | Acc: 19.290,29.938,76.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.572 | Acc: 19.291,29.974,76.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.572 | Acc: 19.350,30.081,76.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.579 | Acc: 19.210,29.953,76.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.587 | Acc: 19.138,29.775,75.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.592 | Acc: 19.126,29.735,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.595 | Acc: 19.045,29.738,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.598 | Acc: 19.118,29.723,75.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.604 | Acc: 19.188,29.736,75.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.609 | Acc: 19.079,29.673,74.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.615 | Acc: 19.078,29.604,74.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.620 | Acc: 19.103,29.675,74.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.623 | Acc: 19.132,29.666,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.627 | Acc: 19.126,29.532,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.629 | Acc: 19.133,29.534,74.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.629 | Acc: 19.099,29.476,74.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.282 | Acc: 23.438,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.399 | Acc: 15.513,25.074,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.426 | Acc: 15.034,24.924,57.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.424 | Acc: 14.895,24.885,57.467,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 1.739 | Acc: 23.438,30.469,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.567 | Acc: 19.606,29.985,75.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.541 | Acc: 19.017,29.135,76.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.559 | Acc: 19.365,29.060,76.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.559 | Acc: 19.493,28.993,76.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.558 | Acc: 19.686,29.200,76.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.573 | Acc: 19.480,29.229,75.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.584 | Acc: 19.299,28.967,75.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.586 | Acc: 19.313,28.940,75.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.590 | Acc: 19.372,28.962,75.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.590 | Acc: 19.306,29.035,75.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.595 | Acc: 19.358,29.175,75.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.594 | Acc: 19.496,29.192,75.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.599 | Acc: 19.328,29.080,74.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.603 | Acc: 19.370,29.123,74.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.605 | Acc: 19.347,29.270,74.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.607 | Acc: 19.300,29.157,74.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.609 | Acc: 19.320,29.312,74.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.614 | Acc: 19.341,29.421,74.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.617 | Acc: 19.363,29.489,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.206 | Acc: 20.312,25.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.313 | Acc: 16.778,26.897,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.281 | Acc: 16.749,27.172,60.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.301 | Acc: 16.880,26.870,60.092,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.502 | Acc: 17.188,33.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.574 | Acc: 18.750,29.018,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.582 | Acc: 19.284,29.478,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.584 | Acc: 19.326,29.508,75.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.584 | Acc: 19.734,29.823,75.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.586 | Acc: 19.686,29.618,75.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.588 | Acc: 19.628,29.662,75.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.597 | Acc: 19.686,29.621,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.603 | Acc: 19.648,29.678,75.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.606 | Acc: 19.643,29.813,74.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.605 | Acc: 19.578,29.785,74.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.606 | Acc: 19.560,29.843,74.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.607 | Acc: 19.538,29.830,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.608 | Acc: 19.522,29.768,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.608 | Acc: 19.542,29.907,74.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.607 | Acc: 19.596,29.973,74.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.611 | Acc: 19.577,29.882,74.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.614 | Acc: 19.511,29.830,74.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.616 | Acc: 19.458,29.718,74.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.615 | Acc: 19.455,29.798,74.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.224 | Acc: 14.844,25.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.339 | Acc: 16.034,24.963,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.354 | Acc: 15.930,25.438,58.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.377 | Acc: 15.984,25.295,58.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 1.501 | Acc: 22.656,28.125,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.573 | Acc: 21.094,29.874,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.584 | Acc: 20.027,29.154,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.574 | Acc: 20.248,29.611,75.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.575 | Acc: 20.245,29.745,75.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.577 | Acc: 19.995,29.703,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.579 | Acc: 19.893,29.675,75.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.578 | Acc: 19.758,29.815,75.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.579 | Acc: 19.759,29.809,75.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.581 | Acc: 19.648,29.657,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.586 | Acc: 19.574,29.579,75.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.594 | Acc: 19.609,29.652,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.601 | Acc: 19.629,29.516,74.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.604 | Acc: 19.660,29.517,74.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.604 | Acc: 19.726,29.593,74.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.608 | Acc: 19.749,29.514,74.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.612 | Acc: 19.687,29.522,74.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.612 | Acc: 19.719,29.541,74.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.614 | Acc: 19.672,29.510,74.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.614 | Acc: 19.671,29.489,74.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.264 | Acc: 13.281,23.438,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.348 | Acc: 16.146,23.438,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.378 | Acc: 15.244,23.857,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.392 | Acc: 15.394,23.809,58.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 1.267 | Acc: 18.750,28.125,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.531 | Acc: 20.312,30.022,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.537 | Acc: 20.046,30.011,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.553 | Acc: 20.274,29.419,76.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.551 | Acc: 20.293,29.842,76.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.564 | Acc: 20.135,29.881,76.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.571 | Acc: 19.944,29.778,76.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.574 | Acc: 19.825,29.632,75.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.575 | Acc: 19.842,29.726,75.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.576 | Acc: 19.769,29.618,75.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.582 | Acc: 19.706,29.551,75.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.586 | Acc: 19.818,29.539,75.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.588 | Acc: 19.800,29.606,75.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.592 | Acc: 19.804,29.607,75.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.593 | Acc: 19.729,29.690,75.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.595 | Acc: 19.747,29.690,75.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.599 | Acc: 19.736,29.709,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.603 | Acc: 19.701,29.736,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.605 | Acc: 19.761,29.729,74.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.606 | Acc: 19.740,29.710,74.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.174 | Acc: 19.531,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.420 | Acc: 15.923,25.037,58.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.413 | Acc: 15.968,25.248,57.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.416 | Acc: 16.278,24.731,57.057,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.510 | Acc: 18.750,26.562,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.564 | Acc: 19.122,29.353,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.566 | Acc: 19.131,29.802,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.570 | Acc: 19.096,29.188,76.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.574 | Acc: 18.953,29.572,76.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.570 | Acc: 19.330,29.541,76.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.570 | Acc: 19.570,29.578,75.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.574 | Acc: 19.930,29.959,75.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.576 | Acc: 19.919,29.867,75.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.577 | Acc: 19.864,29.852,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.582 | Acc: 19.908,29.909,75.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.587 | Acc: 19.796,29.783,75.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.586 | Acc: 19.807,29.794,75.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.587 | Acc: 19.747,29.870,75.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.594 | Acc: 19.651,29.790,75.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.597 | Acc: 19.666,29.885,75.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.600 | Acc: 19.655,29.899,75.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.601 | Acc: 19.715,29.985,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.602 | Acc: 19.761,29.962,74.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.607 | Acc: 19.753,29.962,74.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.411 | Acc: 17.188,25.781,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 15.216,24.740,56.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.456 | Acc: 15.225,24.466,57.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 15.510,24.296,57.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 1.514 | Acc: 20.312,24.219,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 20.201,29.688,78.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.524 | Acc: 19.874,29.364,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.540 | Acc: 19.762,29.828,76.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.541 | Acc: 19.695,29.765,77.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 19.377,29.726,76.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.555 | Acc: 19.279,29.591,76.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.560 | Acc: 19.371,29.471,76.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.565 | Acc: 19.352,29.251,76.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.570 | Acc: 19.406,29.407,76.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.574 | Acc: 19.407,29.458,75.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.578 | Acc: 19.453,29.465,75.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.582 | Acc: 19.450,29.464,75.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.587 | Acc: 19.429,29.520,75.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.590 | Acc: 19.440,29.551,75.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.591 | Acc: 19.583,29.519,75.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.593 | Acc: 19.587,29.607,75.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.596 | Acc: 19.671,29.699,75.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.598 | Acc: 19.707,29.718,75.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.599 | Acc: 19.656,29.692,75.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.168 | Acc: 18.750,28.125,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 15.662,24.963,56.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 15.663,25.610,56.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 15.715,25.141,56.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 1.438 | Acc: 21.875,28.906,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.558 | Acc: 18.676,27.790,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.539 | Acc: 19.245,28.944,76.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.537 | Acc: 19.723,29.188,77.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 19.695,29.659,76.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.538 | Acc: 19.817,29.896,76.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.541 | Acc: 19.622,29.926,76.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.547 | Acc: 19.853,30.147,76.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.552 | Acc: 19.856,29.974,76.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.558 | Acc: 19.902,30.041,76.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.564 | Acc: 19.928,30.018,76.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.572 | Acc: 19.963,29.907,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.577 | Acc: 19.920,29.830,75.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.578 | Acc: 19.950,29.951,75.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.583 | Acc: 19.962,30.007,75.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.585 | Acc: 19.985,30.028,75.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.590 | Acc: 19.853,29.963,75.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.594 | Acc: 19.847,29.976,75.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.596 | Acc: 19.856,30.060,75.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.598 | Acc: 19.824,30.040,74.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.164 | Acc: 22.656,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.245 | Acc: 17.336,27.344,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.260 | Acc: 17.130,27.687,60.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.263 | Acc: 17.431,27.139,60.579,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 1.380 | Acc: 21.875,33.594,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 18.452,28.795,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.518 | Acc: 18.769,29.554,77.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.517 | Acc: 19.352,30.059,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 19.406,29.948,76.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.543 | Acc: 19.415,30.036,76.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.553 | Acc: 19.596,30.107,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.560 | Acc: 19.764,30.170,76.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.568 | Acc: 19.677,29.988,75.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.574 | Acc: 19.570,29.864,75.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.576 | Acc: 19.640,29.820,75.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.575 | Acc: 19.549,29.737,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.576 | Acc: 19.616,29.905,75.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.578 | Acc: 19.651,29.822,75.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.581 | Acc: 19.634,29.915,75.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.583 | Acc: 19.632,29.934,75.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.582 | Acc: 19.677,29.953,75.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.583 | Acc: 19.660,29.923,75.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.586 | Acc: 19.685,29.973,75.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.588 | Acc: 19.716,30.063,75.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.343 | Acc: 17.969,22.656,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.383 | Acc: 15.402,24.702,58.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.411 | Acc: 14.920,24.486,57.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.436 | Acc: 15.330,24.014,57.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.418 | Acc: 23.438,32.031,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.544 | Acc: 19.159,29.129,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.563 | Acc: 19.436,29.821,76.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.566 | Acc: 19.634,29.982,76.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.563 | Acc: 19.522,30.006,76.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.559 | Acc: 19.377,30.105,76.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.564 | Acc: 19.467,30.010,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.563 | Acc: 19.653,30.136,76.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.571 | Acc: 19.517,30.051,76.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.570 | Acc: 19.700,30.076,76.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.570 | Acc: 19.710,30.208,76.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.576 | Acc: 19.630,30.115,75.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.579 | Acc: 19.580,30.047,75.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.581 | Acc: 19.558,30.035,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.583 | Acc: 19.592,29.991,75.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.588 | Acc: 19.578,29.898,75.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.590 | Acc: 19.473,29.765,75.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.592 | Acc: 19.474,29.745,75.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.595 | Acc: 19.449,29.720,75.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.595 | Acc: 19.431,29.747,75.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.108 | Acc: 22.656,28.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.191 | Acc: 17.225,28.683,61.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.201 | Acc: 17.245,28.849,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.199 | Acc: 17.559,28.368,61.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 1.530 | Acc: 19.531,34.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.559 | Acc: 20.089,30.618,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.548 | Acc: 19.874,30.926,76.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.540 | Acc: 19.467,30.251,76.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 19.859,30.604,77.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.523 | Acc: 20.158,30.562,77.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 20.306,30.546,77.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.537 | Acc: 20.202,30.535,76.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.541 | Acc: 20.055,30.469,76.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.543 | Acc: 20.092,30.469,76.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.549 | Acc: 19.943,30.484,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.557 | Acc: 19.768,30.218,76.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.561 | Acc: 19.761,30.171,76.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 19.810,30.163,75.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.577 | Acc: 19.720,30.157,75.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.580 | Acc: 19.723,30.165,75.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.584 | Acc: 19.694,30.155,75.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 19.671,30.093,75.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.586 | Acc: 19.605,30.042,75.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.588 | Acc: 19.624,30.089,75.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.239 | Acc: 20.312,28.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.395 | Acc: 16.481,25.558,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.390 | Acc: 16.883,26.315,58.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.386 | Acc: 16.790,26.127,57.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.772 | Acc: 20.312,22.656,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.554 | Acc: 21.466,30.915,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 20.903,31.059,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.529 | Acc: 20.402,30.597,77.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.531 | Acc: 20.332,30.681,77.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.536 | Acc: 20.274,30.608,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.541 | Acc: 20.106,30.507,76.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.544 | Acc: 19.969,30.458,76.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.547 | Acc: 19.808,30.333,76.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.553 | Acc: 19.898,30.374,76.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.558 | Acc: 19.920,30.407,76.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 19.931,30.349,75.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.570 | Acc: 19.914,30.320,75.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.576 | Acc: 19.858,30.316,75.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.579 | Acc: 19.898,30.307,75.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.579 | Acc: 19.887,30.349,75.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.577 | Acc: 19.884,30.352,75.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.579 | Acc: 19.916,30.373,75.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.579 | Acc: 19.903,30.384,75.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.581 | Acc: 19.952,30.393,75.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.356 | Acc: 20.312,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.285 | Acc: 16.183,27.046,59.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.303 | Acc: 16.101,26.448,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.302 | Acc: 16.150,26.178,59.375,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.381 | Acc: 20.312,31.250,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.514 | Acc: 19.085,29.613,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.521 | Acc: 19.836,29.935,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.532 | Acc: 19.749,29.764,77.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.542 | Acc: 19.724,30.093,76.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.553 | Acc: 19.524,30.012,76.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.550 | Acc: 19.454,30.307,76.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.552 | Acc: 19.609,30.269,76.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.545 | Acc: 19.740,30.527,76.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.549 | Acc: 19.574,30.408,76.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.553 | Acc: 19.590,30.508,76.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.556 | Acc: 19.644,30.511,76.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.562 | Acc: 19.635,30.443,75.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.568 | Acc: 19.600,30.424,75.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.570 | Acc: 19.590,30.413,75.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.573 | Acc: 19.614,30.502,75.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.578 | Acc: 19.614,30.405,75.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.584 | Acc: 19.653,30.354,75.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.585 | Acc: 19.778,30.371,75.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.587 | Acc: 19.736,30.346,75.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.109 | Acc: 16.406,25.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.301 | Acc: 16.146,25.409,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.310 | Acc: 15.930,25.781,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.319 | Acc: 15.958,25.538,59.490,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 1.233 | Acc: 23.438,34.375,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.542 | Acc: 20.759,31.101,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.517 | Acc: 20.865,31.288,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.532 | Acc: 20.505,31.186,76.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 20.361,30.642,76.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.539 | Acc: 20.637,30.809,76.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.541 | Acc: 20.622,30.908,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 20.700,31.128,76.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.550 | Acc: 20.706,31.177,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.548 | Acc: 20.576,31.004,76.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 20.526,30.900,76.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.549 | Acc: 20.376,30.787,76.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.553 | Acc: 20.280,30.618,76.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.557 | Acc: 20.172,30.544,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.558 | Acc: 20.224,30.574,75.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.562 | Acc: 20.172,30.531,75.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.565 | Acc: 20.145,30.469,75.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.564 | Acc: 20.113,30.492,75.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.566 | Acc: 20.111,30.454,75.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.567 | Acc: 20.138,30.557,75.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.145 | Acc: 22.656,32.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.319 | Acc: 18.490,27.902,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.291 | Acc: 18.540,27.877,59.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.281 | Acc: 18.724,27.600,59.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 1.600 | Acc: 17.188,22.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.520 | Acc: 19.382,30.580,76.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 18.598,29.764,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.528 | Acc: 19.057,29.995,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.530 | Acc: 19.280,29.736,76.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.533 | Acc: 19.400,29.873,76.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 19.576,30.068,76.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.535 | Acc: 19.637,30.280,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.540 | Acc: 19.575,30.318,76.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.542 | Acc: 19.557,30.158,76.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 19.617,30.216,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.545 | Acc: 19.662,30.331,76.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.551 | Acc: 19.739,30.384,76.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.553 | Acc: 19.858,30.505,75.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.556 | Acc: 19.865,30.569,75.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.560 | Acc: 19.827,30.510,75.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.563 | Acc: 19.882,30.588,75.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.569 | Acc: 19.948,30.524,75.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.572 | Acc: 19.914,30.480,75.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.573 | Acc: 19.886,30.477,75.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 21.094,30.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.142 | Acc: 17.783,27.641,64.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.162 | Acc: 17.988,28.544,63.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.177 | Acc: 18.186,28.048,62.679,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 1.317 | Acc: 21.094,30.469,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 19.457,30.283,79.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.476 | Acc: 19.417,30.259,78.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 19.262,29.892,77.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 19.763,30.334,77.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 19.725,30.229,77.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.522 | Acc: 19.764,30.301,77.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.530 | Acc: 19.830,30.286,76.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.535 | Acc: 19.968,30.318,76.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.539 | Acc: 19.820,30.309,76.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 19.819,30.243,76.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 19.800,30.317,76.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.555 | Acc: 19.872,30.466,76.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.556 | Acc: 19.807,30.523,76.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.558 | Acc: 19.751,30.399,75.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.561 | Acc: 19.736,30.375,75.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.563 | Acc: 19.753,30.539,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.565 | Acc: 19.749,30.560,75.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.567 | Acc: 19.784,30.590,75.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.571 | Acc: 19.740,30.555,75.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.451 | Acc: 17.188,27.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.385 | Acc: 18.043,27.679,59.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.401 | Acc: 17.873,27.992,58.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.398 | Acc: 18.238,27.613,58.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 1.450 | Acc: 17.969,29.688,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.520 | Acc: 20.015,30.878,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.513 | Acc: 20.293,31.174,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.520 | Acc: 19.890,30.686,77.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 19.898,30.739,77.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.528 | Acc: 19.995,30.531,76.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 20.067,30.495,76.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.532 | Acc: 19.930,30.463,76.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 19.910,30.483,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.535 | Acc: 19.855,30.555,76.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.539 | Acc: 19.889,30.488,76.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.542 | Acc: 19.888,30.635,76.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.543 | Acc: 19.878,30.621,76.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.541 | Acc: 19.995,30.756,76.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.546 | Acc: 19.937,30.674,76.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 20.035,30.806,76.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.552 | Acc: 19.957,30.676,76.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.555 | Acc: 19.996,30.684,76.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.560 | Acc: 19.929,30.653,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.563 | Acc: 19.870,30.602,75.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.001 | Acc: 20.312,26.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.313 | Acc: 17.299,26.637,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.288 | Acc: 16.825,27.191,60.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.301 | Acc: 16.995,26.883,59.810,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.389 | Acc: 17.188,30.469,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.482 | Acc: 20.461,30.060,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 20.122,30.450,77.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.500 | Acc: 20.325,30.622,77.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 20.235,30.816,77.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.519 | Acc: 20.142,30.623,77.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 19.938,30.436,77.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.533 | Acc: 20.152,30.585,76.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.536 | Acc: 20.152,30.595,76.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.537 | Acc: 20.084,30.680,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.542 | Acc: 20.099,30.578,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.543 | Acc: 20.086,30.592,76.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.545 | Acc: 20.112,30.611,76.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.548 | Acc: 20.151,30.618,76.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.548 | Acc: 20.176,30.605,76.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.552 | Acc: 20.105,30.536,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.557 | Acc: 19.996,30.388,76.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.562 | Acc: 19.973,30.306,75.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.564 | Acc: 19.994,30.371,75.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 20.030,30.471,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.146 | Acc: 21.094,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.229 | Acc: 16.592,26.153,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.223 | Acc: 16.578,26.658,62.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.226 | Acc: 16.662,26.178,62.385,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.311 | Acc: 30.469,42.969,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 20.982,31.101,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.476 | Acc: 20.332,30.297,77.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 20.044,30.405,77.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 19.859,30.382,77.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.497 | Acc: 20.274,30.739,77.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.502 | Acc: 20.261,30.733,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.510 | Acc: 20.107,30.735,77.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 20.206,30.745,76.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 20.079,30.680,76.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.529 | Acc: 20.064,30.702,76.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.531 | Acc: 20.047,30.762,76.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 20.018,30.806,76.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.538 | Acc: 19.858,30.648,76.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.541 | Acc: 19.943,30.677,76.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.543 | Acc: 20.004,30.767,76.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.546 | Acc: 20.091,30.727,76.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.551 | Acc: 19.999,30.698,76.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.556 | Acc: 20.027,30.707,75.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.561 | Acc: 20.050,30.768,75.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.163 | Acc: 21.094,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.333 | Acc: 17.746,27.232,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.335 | Acc: 17.530,27.611,59.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.354 | Acc: 17.431,27.331,59.618,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 1.413 | Acc: 18.750,32.812,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 19.829,31.622,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.494 | Acc: 20.522,31.993,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.499 | Acc: 20.044,31.788,77.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.504 | Acc: 20.139,31.935,77.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 20.297,31.946,77.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 20.461,31.818,77.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 20.307,31.616,76.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 20.322,31.531,76.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.528 | Acc: 20.274,31.461,76.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 20.243,31.367,76.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.537 | Acc: 20.076,31.116,76.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.537 | Acc: 20.005,31.004,76.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.541 | Acc: 20.013,31.040,76.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.543 | Acc: 19.968,31.019,76.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.547 | Acc: 19.853,30.985,76.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.549 | Acc: 19.857,31.029,76.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.552 | Acc: 19.909,31.092,76.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.554 | Acc: 19.962,31.159,76.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.556 | Acc: 19.952,31.199,76.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.096 | Acc: 17.969,30.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.230 | Acc: 16.853,28.348,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.243 | Acc: 16.749,27.934,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.246 | Acc: 16.906,27.792,61.283,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 1.525 | Acc: 20.312,34.375,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.495 | Acc: 19.903,30.878,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.511 | Acc: 20.179,30.316,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 20.044,30.341,77.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 20.149,30.411,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 20.034,30.384,77.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.511 | Acc: 20.074,30.540,77.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.515 | Acc: 19.997,30.718,77.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.515 | Acc: 20.162,30.833,77.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.518 | Acc: 19.993,30.780,77.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 20.009,30.885,77.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 19.973,30.790,77.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.525 | Acc: 20.047,30.842,76.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 20.013,30.864,76.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.528 | Acc: 19.990,30.833,76.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.532 | Acc: 20.074,30.801,76.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.533 | Acc: 20.128,30.817,76.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.535 | Acc: 20.161,30.870,76.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.537 | Acc: 20.120,30.852,76.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.541 | Acc: 20.126,30.901,76.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.000 | Acc: 21.875,28.906,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.372 | Acc: 18.043,28.051,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.397 | Acc: 17.702,27.763,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.411 | Acc: 17.764,27.241,58.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.482 | Acc: 17.969,29.688,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 20.089,30.506,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.487 | Acc: 19.912,30.240,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.486 | Acc: 19.531,30.225,78.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 20.023,30.498,77.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 19.895,30.585,77.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.519 | Acc: 19.899,30.527,77.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 19.930,30.674,76.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.526 | Acc: 20.133,30.648,76.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.528 | Acc: 20.118,30.715,76.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.532 | Acc: 20.239,30.686,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.533 | Acc: 20.160,30.872,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.538 | Acc: 20.115,30.780,76.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.539 | Acc: 20.262,30.915,76.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.539 | Acc: 20.199,30.852,76.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.544 | Acc: 20.144,30.741,76.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.547 | Acc: 20.093,30.736,76.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.550 | Acc: 20.164,30.753,76.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.554 | Acc: 20.213,30.800,76.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.556 | Acc: 20.257,30.895,75.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.969 | Acc: 23.438,29.688,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.274 | Acc: 17.336,26.972,61.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.282 | Acc: 17.645,26.963,61.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.291 | Acc: 17.866,26.895,61.027,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.592 | Acc: 17.188,20.312,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.485 | Acc: 20.350,30.320,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 20.046,30.793,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 20.351,31.301,77.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.493 | Acc: 20.312,31.260,77.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.501 | Acc: 20.328,31.273,77.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 20.461,31.302,77.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.512 | Acc: 20.434,31.128,77.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.514 | Acc: 20.497,31.294,77.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.517 | Acc: 20.425,31.276,76.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.521 | Acc: 20.429,31.266,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 20.394,31.123,76.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.528 | Acc: 20.364,31.081,76.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.530 | Acc: 20.318,31.034,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.534 | Acc: 20.268,31.011,76.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.536 | Acc: 20.318,31.045,76.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.539 | Acc: 20.390,31.082,76.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.542 | Acc: 20.367,31.030,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.542 | Acc: 20.384,31.051,76.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.547 | Acc: 20.413,30.998,76.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.864 | Acc: 21.875,24.219,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.223 | Acc: 18.564,27.976,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.211 | Acc: 18.064,28.049,62.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.228 | Acc: 18.315,27.856,61.527,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.427 | Acc: 20.312,26.562,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.494 | Acc: 21.131,31.101,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 20.922,31.460,78.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 20.786,31.519,77.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 20.428,31.192,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 20.374,31.335,77.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 20.261,31.231,77.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.503 | Acc: 20.180,31.051,77.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 20.196,30.993,77.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.509 | Acc: 20.200,30.974,77.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.510 | Acc: 20.429,31.188,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 20.369,31.193,77.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.517 | Acc: 20.287,31.072,76.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 20.241,31.073,76.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.527 | Acc: 20.154,30.961,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.533 | Acc: 20.102,30.923,76.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.537 | Acc: 20.113,30.975,76.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.538 | Acc: 20.150,31.030,76.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 20.079,31.042,76.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.545 | Acc: 20.093,31.106,76.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.163 | Acc: 17.188,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.280 | Acc: 16.704,27.418,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.289 | Acc: 16.311,27.268,61.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.319 | Acc: 16.726,26.870,60.400,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.509 | Acc: 18.750,33.594,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.481 | Acc: 20.052,30.208,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 20.046,30.850,77.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.492 | Acc: 20.236,31.250,77.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 20.081,30.845,77.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 20.026,31.095,77.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.506 | Acc: 20.074,31.063,77.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 20.191,31.084,77.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 20.264,30.964,77.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.523 | Acc: 20.343,30.969,77.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 20.351,31.021,77.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 20.284,30.896,77.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.526 | Acc: 20.283,30.874,76.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 20.321,30.861,76.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 20.332,30.830,76.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.534 | Acc: 20.312,30.931,76.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.533 | Acc: 20.349,30.956,76.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.537 | Acc: 20.267,30.927,76.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.540 | Acc: 20.254,30.969,76.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.543 | Acc: 20.356,30.990,76.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.144 | Acc: 19.531,32.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 19.010,28.423,61.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.266 | Acc: 18.693,28.411,60.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.272 | Acc: 18.827,28.151,60.476,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.325 | Acc: 26.562,39.062,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.504 | Acc: 20.796,32.887,78.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.494 | Acc: 20.808,31.917,78.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 20.530,31.621,77.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 20.390,31.163,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 20.730,31.165,77.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.499 | Acc: 20.797,31.289,77.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 20.617,31.278,77.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.503 | Acc: 20.594,31.396,77.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 20.412,31.297,77.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.510 | Acc: 20.546,31.440,77.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.520 | Acc: 20.482,31.349,76.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.523 | Acc: 20.595,31.315,76.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 20.609,31.352,76.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.532 | Acc: 20.532,31.283,76.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.533 | Acc: 20.502,31.343,76.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.536 | Acc: 20.451,31.274,76.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.538 | Acc: 20.480,31.291,76.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.538 | Acc: 20.475,31.278,76.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 20.477,31.256,76.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.150 | Acc: 25.000,26.562,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.297 | Acc: 17.932,29.018,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.304 | Acc: 17.778,28.982,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.317 | Acc: 17.841,28.701,59.631,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.452 | Acc: 17.188,32.031,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.521 | Acc: 20.238,29.353,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.512 | Acc: 20.293,30.431,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.530 | Acc: 20.120,30.546,76.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 20.042,30.285,76.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.529 | Acc: 20.305,30.492,76.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.530 | Acc: 20.093,30.430,76.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.525 | Acc: 20.202,30.624,76.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 20.230,30.668,76.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 20.166,30.672,76.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.527 | Acc: 20.103,30.500,76.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 20.221,30.646,76.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 20.348,30.761,76.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 20.312,30.789,76.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 20.415,30.775,76.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.527 | Acc: 20.403,30.824,76.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.532 | Acc: 20.334,30.802,76.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.535 | Acc: 20.292,30.838,76.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.540 | Acc: 20.289,30.856,76.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.544 | Acc: 20.261,30.834,76.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.498 | Acc: 19.531,28.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.404 | Acc: 16.406,26.451,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.398 | Acc: 16.444,26.658,58.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.391 | Acc: 16.496,26.345,57.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 1.595 | Acc: 18.750,28.125,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 20.387,30.580,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 21.037,31.517,78.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 20.966,31.801,77.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 20.698,31.771,77.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.505 | Acc: 20.506,31.799,77.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 20.610,31.883,77.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.498 | Acc: 20.490,31.710,77.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.501 | Acc: 20.439,31.779,77.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 20.403,31.725,77.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.511 | Acc: 20.433,31.751,77.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.513 | Acc: 20.394,31.646,77.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.514 | Acc: 20.403,31.782,77.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 20.534,31.675,76.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.519 | Acc: 20.510,31.581,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.520 | Acc: 20.544,31.478,76.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 20.600,31.479,76.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.523 | Acc: 20.562,31.454,76.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.526 | Acc: 20.583,31.427,76.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 20.538,31.266,76.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.185 | Acc: 20.312,28.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.332 | Acc: 19.048,27.418,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.333 | Acc: 19.474,27.534,59.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.353 | Acc: 19.352,27.241,59.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.723 | Acc: 16.406,28.125,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.518 | Acc: 19.382,31.473,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 20.351,32.107,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 20.453,32.223,77.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.501 | Acc: 20.563,32.369,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.497 | Acc: 20.429,32.372,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.498 | Acc: 20.487,32.238,77.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 20.490,32.081,77.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 20.623,32.041,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.507 | Acc: 20.649,32.005,77.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 20.690,31.903,77.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.509 | Acc: 20.592,31.932,77.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.513 | Acc: 20.559,31.876,77.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 20.444,31.825,77.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.524 | Acc: 20.452,31.748,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 20.427,31.754,76.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.525 | Acc: 20.420,31.700,76.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 20.416,31.676,76.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 20.427,31.648,76.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.534 | Acc: 20.339,31.611,76.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.428 | Acc: 17.188,29.688,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.332 | Acc: 17.225,26.823,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.348 | Acc: 16.673,26.677,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.354 | Acc: 17.162,26.703,59.093,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 1.431 | Acc: 21.094,39.844,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.504 | Acc: 20.647,32.440,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 20.579,32.641,78.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 20.722,32.198,78.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.478 | Acc: 20.650,32.099,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.484 | Acc: 20.374,31.877,78.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.490 | Acc: 20.506,32.089,77.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 20.578,32.236,77.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.493 | Acc: 20.710,32.322,77.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.501 | Acc: 20.718,32.316,77.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 20.674,32.245,77.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.504 | Acc: 20.595,32.105,77.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.509 | Acc: 20.458,31.957,77.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.512 | Acc: 20.576,31.906,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.518 | Acc: 20.532,31.753,77.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.519 | Acc: 20.489,31.655,76.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 20.456,31.656,76.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.527 | Acc: 20.468,31.635,76.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 20.425,31.635,76.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.534 | Acc: 20.395,31.609,76.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.004 | Acc: 21.094,30.469,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.249 | Acc: 17.894,29.129,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.261 | Acc: 17.702,29.497,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.274 | Acc: 17.828,28.868,60.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.583 | Acc: 19.531,35.156,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.468 | Acc: 21.243,32.217,79.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.478 | Acc: 20.960,31.364,78.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.465 | Acc: 20.364,31.084,79.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.478 | Acc: 20.438,31.221,78.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 20.606,31.111,78.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.493 | Acc: 20.480,31.063,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 20.656,31.150,77.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.496 | Acc: 20.541,31.221,78.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.495 | Acc: 20.541,31.263,78.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 20.651,31.277,78.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 20.680,31.275,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 20.731,31.266,77.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.508 | Acc: 20.720,31.298,77.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.514 | Acc: 20.679,31.214,77.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.519 | Acc: 20.624,31.292,77.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 20.746,31.357,77.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.522 | Acc: 20.872,31.463,77.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.528 | Acc: 20.858,31.453,76.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.530 | Acc: 20.809,31.445,76.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.085 | Acc: 25.000,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.350 | Acc: 17.411,25.521,59.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.329 | Acc: 17.454,26.315,60.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.332 | Acc: 17.367,26.114,59.964,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.505 | Acc: 14.844,32.812,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 19.792,31.734,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.465 | Acc: 20.293,31.841,78.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.464 | Acc: 20.312,31.762,78.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.460 | Acc: 20.197,31.703,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 20.405,31.575,78.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.474 | Acc: 20.442,31.470,78.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 20.285,31.444,78.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 20.172,31.337,78.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 20.330,31.483,78.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 20.367,31.452,77.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 20.373,31.512,77.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 20.381,31.545,77.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 20.333,31.457,77.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 20.435,31.561,77.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.513 | Acc: 20.372,31.510,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.515 | Acc: 20.398,31.420,77.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 20.436,31.410,76.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.521 | Acc: 20.546,31.464,76.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.521 | Acc: 20.552,31.531,76.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.968 | Acc: 24.219,28.125,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.196 | Acc: 18.266,27.046,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.208 | Acc: 18.102,27.096,62.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.211 | Acc: 18.712,27.177,61.834,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.498 | Acc: 19.531,30.469,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 18.713,30.432,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 19.455,30.926,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 19.877,31.801,77.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.491 | Acc: 19.782,31.453,77.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.491 | Acc: 20.096,31.467,77.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 20.125,31.553,77.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 20.346,31.649,77.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 20.414,31.619,76.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.503 | Acc: 20.321,31.552,77.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.513 | Acc: 20.138,31.440,76.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.519 | Acc: 20.270,31.398,76.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.520 | Acc: 20.364,31.600,76.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.523 | Acc: 20.429,31.633,76.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 20.440,31.645,76.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.528 | Acc: 20.460,31.691,76.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 20.432,31.710,76.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.532 | Acc: 20.427,31.720,76.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.535 | Acc: 20.362,31.564,76.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.537 | Acc: 20.323,31.570,76.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.175 | Acc: 25.000,29.688,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.129 | Acc: 18.490,29.911,62.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.130 | Acc: 18.159,29.935,62.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.134 | Acc: 18.366,29.623,63.140,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.292 | Acc: 23.438,31.250,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.444 | Acc: 19.866,33.110,79.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.456 | Acc: 19.550,32.736,78.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.466 | Acc: 19.839,32.339,78.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 20.042,32.243,78.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 20.166,32.317,78.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.479 | Acc: 20.351,32.231,78.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 20.484,32.148,78.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.494 | Acc: 20.458,32.119,77.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.498 | Acc: 20.546,32.001,77.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 20.557,31.895,77.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.503 | Acc: 20.475,31.840,77.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.508 | Acc: 20.513,31.769,77.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.509 | Acc: 20.618,31.816,77.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 20.488,31.714,77.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.515 | Acc: 20.476,31.621,77.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.518 | Acc: 20.490,31.613,76.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.522 | Acc: 20.516,31.614,76.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 20.518,31.618,76.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.526 | Acc: 20.513,31.625,76.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.233 | Acc: 22.656,28.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.318 | Acc: 16.071,27.269,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.325 | Acc: 16.540,27.248,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.328 | Acc: 16.355,26.434,60.233,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.437 | Acc: 16.406,29.688,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.452 | Acc: 20.759,31.771,79.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 20.408,31.726,78.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.452 | Acc: 20.441,31.929,78.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.465 | Acc: 20.853,32.330,78.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 20.792,32.356,78.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 20.810,32.147,77.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 20.883,32.059,77.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 20.861,32.119,77.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.497 | Acc: 20.826,32.036,77.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.503 | Acc: 20.725,31.849,77.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.512 | Acc: 20.751,31.773,76.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.513 | Acc: 20.724,31.707,76.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.517 | Acc: 20.699,31.801,76.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.518 | Acc: 20.654,31.734,76.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.517 | Acc: 20.699,31.769,76.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 20.704,31.654,76.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 20.713,31.612,76.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.519 | Acc: 20.700,31.657,76.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.521 | Acc: 20.655,31.638,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.182 | Acc: 20.312,27.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.275 | Acc: 16.667,27.195,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.253 | Acc: 16.139,27.725,61.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.249 | Acc: 16.483,27.433,61.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.492 | Acc: 25.000,32.812,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.447 | Acc: 21.429,33.743,78.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 20.617,33.232,78.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.462 | Acc: 20.569,32.620,78.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.460 | Acc: 20.737,32.706,78.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 20.568,32.619,78.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.472 | Acc: 20.190,32.425,78.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.480 | Acc: 20.047,32.164,77.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.480 | Acc: 20.356,32.313,77.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.482 | Acc: 20.317,32.221,77.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 20.367,32.175,77.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 20.390,32.042,77.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 20.478,32.154,77.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.499 | Acc: 20.543,32.127,77.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 20.563,32.104,77.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 20.531,31.930,76.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 20.558,31.905,76.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.521 | Acc: 20.576,31.908,76.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.523 | Acc: 20.598,31.934,76.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.525 | Acc: 20.626,31.955,76.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.138 | Acc: 20.312,33.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.357 | Acc: 17.820,27.269,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.379 | Acc: 18.159,26.944,59.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.385 | Acc: 18.315,26.473,59.746,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.532 | Acc: 25.000,39.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 22.247,31.585,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 20.598,31.307,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 20.300,30.930,76.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.483 | Acc: 20.361,30.990,77.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.484 | Acc: 20.251,30.995,77.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 20.319,31.205,77.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 20.340,31.416,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 20.482,31.391,77.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 20.438,31.643,77.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.490 | Acc: 20.612,31.810,77.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 20.677,31.844,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.497 | Acc: 20.643,31.808,77.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.498 | Acc: 20.528,31.777,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.503 | Acc: 20.554,31.851,77.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 20.536,31.798,77.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 20.517,31.761,76.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 20.542,31.816,76.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.518 | Acc: 20.518,31.780,76.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 20.507,31.767,76.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.159 | Acc: 22.656,31.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.163 | Acc: 18.676,29.874,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.184 | Acc: 18.617,29.630,62.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.195 | Acc: 18.981,29.226,62.321,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 1.487 | Acc: 22.656,29.688,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.442 | Acc: 19.940,30.655,79.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.463 | Acc: 19.989,30.431,78.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.453 | Acc: 20.812,31.685,78.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.468 | Acc: 20.505,31.510,78.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 20.722,31.575,78.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.473 | Acc: 20.526,31.547,78.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.483 | Acc: 20.462,31.411,77.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 20.550,31.638,77.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.491 | Acc: 20.477,31.582,77.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 20.530,31.487,77.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 20.475,31.639,77.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 20.491,31.681,77.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.500 | Acc: 20.399,31.636,77.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 20.418,31.645,77.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 20.424,31.652,77.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 20.361,31.586,77.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 20.404,31.690,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.508 | Acc: 20.455,31.711,77.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 20.516,31.734,77.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.365 | Acc: 17.188,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 16.555,25.558,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.500 | Acc: 16.120,24.695,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.523 | Acc: 16.483,24.539,56.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.437 | Acc: 21.875,36.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 21.577,31.696,79.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.461 | Acc: 21.189,31.764,78.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 20.338,31.378,78.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.465 | Acc: 20.332,31.279,78.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.463 | Acc: 20.514,31.335,78.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.467 | Acc: 20.467,31.153,78.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.475 | Acc: 20.423,31.361,78.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.479 | Acc: 20.337,31.352,78.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.478 | Acc: 20.425,31.522,78.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.484 | Acc: 20.452,31.491,77.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 20.482,31.596,77.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 20.497,31.665,77.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.492 | Acc: 20.558,31.816,77.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.494 | Acc: 20.560,31.706,77.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 20.577,31.824,77.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 20.605,31.854,77.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 20.649,31.869,77.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.508 | Acc: 20.596,31.761,77.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 20.612,31.822,77.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.232 | Acc: 20.312,29.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.284 | Acc: 16.741,28.199,61.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.287 | Acc: 15.968,27.973,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.301 | Acc: 16.227,27.728,60.156,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.561 | Acc: 24.219,32.812,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.481 | Acc: 19.382,32.366,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.468 | Acc: 20.198,32.812,78.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.466 | Acc: 19.685,31.634,78.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.459 | Acc: 20.168,31.973,78.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.464 | Acc: 20.135,31.722,78.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.460 | Acc: 20.332,31.741,78.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.466 | Acc: 20.268,31.638,78.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.470 | Acc: 20.196,31.653,78.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.475 | Acc: 20.174,31.781,77.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 20.274,31.849,77.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.477 | Acc: 20.394,31.922,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.479 | Acc: 20.342,31.876,77.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 20.321,31.861,77.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.485 | Acc: 20.290,31.806,77.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 20.336,31.821,77.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 20.330,31.822,77.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.496 | Acc: 20.397,31.965,77.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 20.421,31.940,77.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 20.380,31.929,77.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.115 | Acc: 24.219,32.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.209 | Acc: 18.229,29.911,62.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.210 | Acc: 18.693,29.554,61.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.202 | Acc: 19.083,29.342,61.898,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 1.333 | Acc: 24.219,39.062,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 20.871,31.287,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.476 | Acc: 20.694,32.012,78.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.481 | Acc: 20.492,31.557,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.474 | Acc: 20.775,32.051,78.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.479 | Acc: 20.645,32.070,78.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 20.474,31.909,77.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.486 | Acc: 20.301,31.987,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 20.317,32.012,77.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 20.252,31.962,77.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 20.305,31.973,77.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 20.274,31.854,77.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 20.355,31.915,77.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 20.405,31.989,77.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 20.340,31.940,77.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.506 | Acc: 20.325,31.909,77.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.506 | Acc: 20.334,31.917,77.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 20.301,31.871,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 20.332,31.847,77.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.515 | Acc: 20.374,31.921,76.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.067 | Acc: 21.094,33.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.189 | Acc: 17.150,27.753,62.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.214 | Acc: 16.273,27.439,62.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.224 | Acc: 16.650,27.408,61.936,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.415 | Acc: 21.875,30.469,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 20.982,32.515,78.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.446 | Acc: 20.694,31.650,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 20.620,31.673,78.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.454 | Acc: 20.669,31.665,78.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.469 | Acc: 20.490,31.846,78.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.469 | Acc: 20.732,31.967,78.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.470 | Acc: 20.628,31.915,78.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.470 | Acc: 20.769,32.094,78.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.474 | Acc: 20.822,32.282,78.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.473 | Acc: 21.000,32.303,78.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.477 | Acc: 20.995,32.268,78.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 20.932,32.125,77.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.492 | Acc: 20.815,32.052,77.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 20.832,32.070,77.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 20.904,32.109,77.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 20.867,32.056,77.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 20.865,32.043,77.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 20.825,32.049,77.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 20.862,32.113,77.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.084 | Acc: 17.969,31.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.172 | Acc: 17.039,28.385,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.179 | Acc: 17.168,28.068,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.165 | Acc: 17.418,27.561,62.731,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.437 | Acc: 24.219,37.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.459 | Acc: 19.866,31.845,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.456 | Acc: 20.503,31.555,78.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 20.287,31.685,78.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.463 | Acc: 20.158,31.916,78.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.458 | Acc: 20.196,32.294,78.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.466 | Acc: 20.022,32.122,78.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 20.107,31.992,78.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 20.448,32.288,78.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.476 | Acc: 20.485,32.161,78.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 20.639,32.257,78.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.480 | Acc: 20.645,32.229,78.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 20.737,32.265,78.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.488 | Acc: 20.714,32.109,77.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.493 | Acc: 20.788,32.081,77.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.496 | Acc: 20.769,32.096,77.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.499 | Acc: 20.772,32.053,77.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 20.833,32.132,77.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.504 | Acc: 20.810,32.088,77.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.505 | Acc: 20.751,32.042,77.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.300 | Acc: 19.531,31.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.183 | Acc: 16.815,28.162,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.212 | Acc: 16.406,27.744,61.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.210 | Acc: 16.701,27.779,61.488,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.440 | Acc: 21.875,28.125,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.442 | Acc: 18.490,31.734,78.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 19.607,31.955,78.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 20.108,32.057,78.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.449 | Acc: 20.062,32.311,78.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.449 | Acc: 20.429,32.464,78.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.448 | Acc: 20.364,32.528,78.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.456 | Acc: 20.490,32.386,78.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.463 | Acc: 20.565,32.376,78.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.465 | Acc: 20.416,32.295,78.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.471 | Acc: 20.511,32.366,78.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.480 | Acc: 20.415,32.261,77.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.484 | Acc: 20.416,32.235,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 20.573,32.181,77.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.492 | Acc: 20.613,32.176,77.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.492 | Acc: 20.645,32.091,77.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.496 | Acc: 20.717,32.075,77.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.498 | Acc: 20.597,31.988,77.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 20.641,32.010,77.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.506 | Acc: 20.671,32.000,77.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.091 | Acc: 20.312,29.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.324 | Acc: 16.815,25.930,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.332 | Acc: 16.730,26.162,59.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.343 | Acc: 16.867,25.884,59.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 1.331 | Acc: 24.219,35.156,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 21.317,31.882,78.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 21.303,32.279,78.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.458 | Acc: 20.902,32.249,78.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 20.997,32.224,78.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.464 | Acc: 20.792,32.240,78.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.458 | Acc: 20.855,32.451,78.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.461 | Acc: 20.911,32.358,78.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.466 | Acc: 20.948,32.322,78.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.465 | Acc: 21.102,32.390,78.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.469 | Acc: 21.067,32.404,78.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.473 | Acc: 21.012,32.466,77.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 20.984,32.518,77.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 20.962,32.465,77.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 20.905,32.418,77.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.491 | Acc: 20.837,32.395,77.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.496 | Acc: 20.809,32.379,77.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.500 | Acc: 20.826,32.343,77.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.503 | Acc: 20.765,32.239,77.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.508 | Acc: 20.753,32.220,77.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.017 | Acc: 21.875,27.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.302 | Acc: 18.787,28.237,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.281 | Acc: 18.426,28.335,60.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.292 | Acc: 18.519,28.010,60.118,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 1.550 | Acc: 21.094,32.031,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.434 | Acc: 21.838,32.924,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.443 | Acc: 21.113,32.622,78.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 21.350,32.723,79.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.432 | Acc: 21.566,32.832,79.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.442 | Acc: 21.040,32.441,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.439 | Acc: 21.049,32.767,78.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.444 | Acc: 20.933,32.585,78.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.452 | Acc: 20.846,32.531,78.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.458 | Acc: 20.982,32.657,78.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.465 | Acc: 21.047,32.688,78.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.469 | Acc: 20.959,32.639,77.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.474 | Acc: 20.864,32.514,77.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.479 | Acc: 20.899,32.492,77.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.481 | Acc: 20.899,32.493,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 20.832,32.506,77.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 20.897,32.511,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.492 | Acc: 20.835,32.421,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.496 | Acc: 20.854,32.451,77.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.497 | Acc: 20.852,32.507,77.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.069 | Acc: 21.094,32.812,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.124 | Acc: 18.155,29.799,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.149 | Acc: 18.236,29.459,63.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.141 | Acc: 18.404,29.316,63.601,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.437 | Acc: 26.562,34.375,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 21.019,32.106,78.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.429 | Acc: 21.246,32.527,79.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 21.580,32.608,78.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.446 | Acc: 21.528,32.340,78.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 21.767,32.441,78.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.465 | Acc: 21.236,32.173,78.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.463 | Acc: 21.393,32.192,78.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.465 | Acc: 21.307,32.293,78.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 21.392,32.273,78.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.473 | Acc: 21.389,32.253,78.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.477 | Acc: 21.189,32.286,77.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 21.149,32.278,77.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.475 | Acc: 21.091,32.310,77.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.479 | Acc: 20.910,32.323,77.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 20.863,32.192,77.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.488 | Acc: 20.916,32.258,77.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 20.938,32.292,77.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.495 | Acc: 20.888,32.336,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.497 | Acc: 20.831,32.365,77.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.152 | Acc: 19.531,31.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.221 | Acc: 17.225,28.088,61.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.236 | Acc: 16.673,27.915,61.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.255 | Acc: 16.765,27.702,61.194,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.275 | Acc: 26.562,39.062,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.398 | Acc: 22.321,34.598,79.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 21.037,33.689,79.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.435 | Acc: 20.761,33.363,79.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.443 | Acc: 20.689,32.861,78.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.441 | Acc: 20.622,32.882,78.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.446 | Acc: 20.661,32.967,78.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.454 | Acc: 20.562,32.691,78.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 20.487,32.652,78.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 20.515,32.472,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.465 | Acc: 20.588,32.470,78.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 20.546,32.519,77.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.476 | Acc: 20.588,32.440,77.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.477 | Acc: 20.576,32.340,77.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.479 | Acc: 20.529,32.181,77.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.480 | Acc: 20.544,32.151,77.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.483 | Acc: 20.512,32.104,77.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 20.585,32.105,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.485 | Acc: 20.620,32.170,77.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 20.653,32.144,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.253 | Acc: 22.656,32.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.338 | Acc: 19.234,29.427,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.334 | Acc: 18.655,29.097,60.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.322 | Acc: 18.801,29.060,59.977,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.358 | Acc: 24.219,34.375,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.498 | Acc: 21.354,31.138,77.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.485 | Acc: 21.418,32.317,78.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.477 | Acc: 21.132,32.326,78.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.463 | Acc: 20.959,32.436,78.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 20.993,32.426,78.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 21.132,32.561,78.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.472 | Acc: 21.299,32.569,78.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.476 | Acc: 21.084,32.487,78.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.480 | Acc: 21.025,32.515,78.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.484 | Acc: 21.164,32.641,77.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 21.090,32.547,77.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.489 | Acc: 21.084,32.443,77.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.494 | Acc: 20.953,32.319,77.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.494 | Acc: 20.966,32.301,77.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.495 | Acc: 20.946,32.304,77.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.496 | Acc: 20.967,32.335,77.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.497 | Acc: 20.970,32.347,77.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.501 | Acc: 20.983,32.345,77.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.501 | Acc: 20.977,32.359,77.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.031 | Acc: 16.406,25.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.283 | Acc: 17.448,27.976,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.305 | Acc: 17.435,27.744,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.311 | Acc: 17.469,27.715,59.746,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.437 | Acc: 25.000,39.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.460 | Acc: 21.838,33.631,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.437 | Acc: 21.246,33.727,78.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.440 | Acc: 21.337,33.171,78.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.447 | Acc: 20.920,32.745,78.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 20.939,32.666,78.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.453 | Acc: 20.823,32.722,78.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.454 | Acc: 20.811,32.657,78.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 20.871,32.696,78.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.460 | Acc: 20.852,32.679,78.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.463 | Acc: 20.876,32.653,78.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 20.885,32.777,78.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 20.753,32.628,77.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.476 | Acc: 20.726,32.618,77.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.483 | Acc: 20.702,32.534,77.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 20.715,32.511,77.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.486 | Acc: 20.687,32.430,77.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.489 | Acc: 20.688,32.428,77.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.491 | Acc: 20.654,32.412,77.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.493 | Acc: 20.606,32.415,77.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.098 | Acc: 17.188,28.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.253 | Acc: 16.443,27.344,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.296 | Acc: 15.530,26.715,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.285 | Acc: 15.894,26.614,61.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.413 | Acc: 21.094,31.250,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.408 | Acc: 20.908,33.147,79.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.442 | Acc: 20.865,33.041,78.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.444 | Acc: 20.505,32.877,78.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.445 | Acc: 20.534,32.735,78.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.451 | Acc: 20.436,32.611,78.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.457 | Acc: 20.467,32.703,78.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 20.573,32.591,78.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 20.997,32.735,78.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.477 | Acc: 21.055,32.860,77.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 20.969,32.661,77.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.479 | Acc: 20.931,32.593,77.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.480 | Acc: 21.003,32.612,77.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 20.818,32.420,77.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 20.835,32.370,77.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.487 | Acc: 20.852,32.343,77.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 20.863,32.338,77.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 20.876,32.389,77.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.493 | Acc: 20.843,32.369,77.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.495 | Acc: 20.844,32.382,77.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.206 | Acc: 16.406,23.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.379 | Acc: 15.997,24.442,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.436 | Acc: 16.120,24.428,58.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.427 | Acc: 15.868,24.475,58.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.429 | Acc: 25.000,40.625,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.472 | Acc: 21.912,32.887,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.452 | Acc: 20.751,32.603,78.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.442 | Acc: 20.658,32.313,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.444 | Acc: 20.467,31.973,79.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.442 | Acc: 20.630,32.395,78.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.447 | Acc: 20.545,32.451,78.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.449 | Acc: 20.767,32.641,78.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.458 | Acc: 20.895,32.745,78.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.465 | Acc: 20.813,32.605,78.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 20.841,32.754,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.472 | Acc: 20.793,32.689,78.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.476 | Acc: 20.760,32.722,78.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.480 | Acc: 20.642,32.627,77.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 20.774,32.701,77.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.485 | Acc: 20.806,32.667,77.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 20.843,32.759,77.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.487 | Acc: 20.842,32.664,77.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 20.815,32.689,77.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.489 | Acc: 20.850,32.743,77.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.415 | Acc: 20.312,31.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.304 | Acc: 20.201,30.283,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.309 | Acc: 19.912,30.507,60.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.300 | Acc: 19.582,30.289,60.400,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.548 | Acc: 17.969,29.688,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.479 | Acc: 21.205,32.254,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.425 | Acc: 21.932,33.327,78.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.419 | Acc: 21.542,32.800,79.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.427 | Acc: 21.229,32.803,79.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.428 | Acc: 21.233,33.029,79.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.438 | Acc: 21.049,32.832,79.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.443 | Acc: 21.072,32.995,78.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.447 | Acc: 21.089,32.953,78.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.455 | Acc: 21.085,32.834,78.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.459 | Acc: 21.059,32.812,78.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.461 | Acc: 21.073,32.752,78.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.464 | Acc: 21.116,32.748,78.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.468 | Acc: 21.160,32.714,78.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.474 | Acc: 21.035,32.598,77.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.474 | Acc: 21.050,32.561,77.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.478 | Acc: 21.028,32.530,77.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 21.032,32.464,77.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 20.986,32.390,77.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 20.940,32.406,77.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.237 | Acc: 18.750,32.031,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.276 | Acc: 18.638,30.208,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.310 | Acc: 18.255,29.802,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.318 | Acc: 18.225,29.623,59.311,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.444 | Acc: 19.531,32.812,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.435 | Acc: 21.987,32.403,78.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 21.780,32.260,78.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 21.491,32.941,78.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.455 | Acc: 21.557,33.131,78.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.461 | Acc: 21.233,32.944,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.460 | Acc: 21.197,32.929,78.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.463 | Acc: 21.099,32.829,78.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.465 | Acc: 21.026,32.779,78.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.461 | Acc: 21.064,32.964,78.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.464 | Acc: 20.965,32.917,78.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.464 | Acc: 21.009,32.989,78.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.470 | Acc: 21.155,32.965,78.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.473 | Acc: 21.234,33.049,77.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.476 | Acc: 21.224,32.993,77.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.479 | Acc: 21.182,32.937,77.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.480 | Acc: 21.201,33.073,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 21.222,32.975,77.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.485 | Acc: 21.152,32.912,77.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 21.075,32.915,77.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.205 | Acc: 21.875,29.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.313 | Acc: 17.039,26.302,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.311 | Acc: 17.378,27.115,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.300 | Acc: 17.713,27.049,59.810,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.454 | Acc: 16.406,26.562,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 20.945,32.031,79.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.435 | Acc: 21.646,32.984,79.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.433 | Acc: 20.927,32.941,79.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.428 | Acc: 20.737,32.812,79.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.434 | Acc: 20.730,32.774,79.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 20.668,32.528,79.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.451 | Acc: 20.817,32.569,78.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.453 | Acc: 20.798,32.594,78.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.460 | Acc: 20.813,32.454,78.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.464 | Acc: 21.082,32.739,78.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.463 | Acc: 21.076,32.784,78.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.466 | Acc: 21.003,32.764,78.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.467 | Acc: 20.893,32.786,78.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.469 | Acc: 20.952,32.896,78.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.472 | Acc: 20.904,32.888,78.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 20.914,32.805,78.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 20.819,32.636,77.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.484 | Acc: 20.804,32.700,77.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.486 | Acc: 20.772,32.730,77.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.181 | Acc: 19.531,29.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.266 | Acc: 17.150,29.167,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.294 | Acc: 16.502,29.211,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.290 | Acc: 16.790,29.162,60.976,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.486 | Acc: 21.875,33.594,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 21.019,32.329,79.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.436 | Acc: 21.284,32.812,79.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.440 | Acc: 21.440,32.812,79.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.447 | Acc: 21.296,32.398,79.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.450 | Acc: 21.148,32.642,78.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.451 | Acc: 21.094,32.658,79.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.449 | Acc: 20.806,32.535,79.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.456 | Acc: 20.812,32.589,78.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.456 | Acc: 20.757,32.631,78.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.460 | Acc: 20.701,32.630,78.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.462 | Acc: 20.705,32.576,78.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.464 | Acc: 20.714,32.508,78.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.466 | Acc: 20.729,32.609,78.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.470 | Acc: 20.749,32.679,78.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.473 | Acc: 20.746,32.678,78.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.478 | Acc: 20.775,32.647,77.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.481 | Acc: 20.755,32.604,77.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.483 | Acc: 20.815,32.691,77.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 20.755,32.685,77.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.172 | Acc: 21.094,32.812,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.160 | Acc: 18.378,29.836,62.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.164 | Acc: 18.559,29.364,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.175 | Acc: 18.686,29.239,62.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.447 | Acc: 21.094,32.031,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.463 | Acc: 21.391,34.152,78.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 20.922,32.717,78.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 20.748,32.864,78.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.442 | Acc: 20.959,32.967,78.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.443 | Acc: 20.885,33.052,78.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 20.674,32.871,78.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.446 | Acc: 20.778,32.757,78.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.449 | Acc: 20.730,32.837,78.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.450 | Acc: 20.921,33.002,78.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 20.981,33.108,78.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.453 | Acc: 20.970,33.120,78.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.455 | Acc: 20.922,33.043,78.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.458 | Acc: 20.899,33.157,78.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.464 | Acc: 20.799,32.999,78.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.469 | Acc: 20.769,32.906,78.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.472 | Acc: 20.906,33.012,78.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.476 | Acc: 20.931,33.005,77.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 20.901,33.057,77.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.479 | Acc: 20.932,33.108,77.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.063 | Acc: 26.562,31.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.197 | Acc: 18.527,29.836,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.215 | Acc: 18.064,30.297,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.220 | Acc: 18.251,30.289,61.872,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.518 | Acc: 17.188,32.812,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.413 | Acc: 20.573,32.403,79.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.406 | Acc: 21.018,33.537,79.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.414 | Acc: 20.838,33.120,79.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.422 | Acc: 21.046,33.372,79.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.417 | Acc: 21.040,33.485,79.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.424 | Acc: 21.068,33.497,79.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.434 | Acc: 20.955,33.466,78.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.437 | Acc: 21.026,33.550,78.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.445 | Acc: 20.930,33.546,78.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.451 | Acc: 20.841,33.469,78.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.453 | Acc: 20.822,33.413,78.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.457 | Acc: 20.744,33.260,78.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.457 | Acc: 20.800,33.172,78.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.463 | Acc: 20.910,33.160,78.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 20.873,33.134,78.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.468 | Acc: 20.855,33.175,78.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.470 | Acc: 20.890,33.138,77.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.472 | Acc: 20.923,33.107,77.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.476 | Acc: 20.924,33.081,77.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.158 | Acc: 17.969,32.031,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.342 | Acc: 17.820,29.539,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.338 | Acc: 17.778,29.325,59.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.316 | Acc: 17.969,29.188,59.618,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.553 | Acc: 24.219,40.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 21.763,34.561,79.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.423 | Acc: 20.789,33.727,79.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.422 | Acc: 20.312,33.184,79.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.429 | Acc: 20.476,33.227,79.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.436 | Acc: 20.668,33.261,78.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 20.681,33.458,78.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.440 | Acc: 20.711,33.317,78.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.446 | Acc: 20.919,33.390,78.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.448 | Acc: 20.869,33.309,78.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.448 | Acc: 20.845,33.205,78.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.448 | Acc: 20.956,33.339,78.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.456 | Acc: 20.737,33.137,78.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.457 | Acc: 20.717,33.085,78.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.461 | Acc: 20.627,32.988,78.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.465 | Acc: 20.691,32.909,78.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 20.675,32.883,77.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.471 | Acc: 20.746,32.945,77.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.473 | Acc: 20.763,32.925,77.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.473 | Acc: 20.790,32.954,77.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.197 | Acc: 19.531,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.221 | Acc: 16.964,29.129,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.231 | Acc: 16.692,28.354,61.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.223 | Acc: 17.111,27.959,61.552,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.496 | Acc: 19.531,27.344,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.439 | Acc: 20.015,30.915,79.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.429 | Acc: 20.141,32.222,79.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 20.184,32.684,78.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.430 | Acc: 20.515,33.179,78.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 20.498,33.617,79.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.442 | Acc: 20.642,33.381,78.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.456 | Acc: 20.451,33.200,78.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 20.453,33.055,78.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.464 | Acc: 20.533,33.015,78.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.463 | Acc: 20.406,32.875,78.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.467 | Acc: 20.422,32.816,78.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.467 | Acc: 20.627,32.978,78.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.468 | Acc: 20.815,33.100,78.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.473 | Acc: 20.882,33.124,77.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.476 | Acc: 20.912,33.062,77.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.476 | Acc: 20.957,33.063,77.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 20.963,33.014,77.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.479 | Acc: 20.996,33.053,77.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 21.022,32.999,77.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.019 | Acc: 22.656,33.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.149 | Acc: 18.304,30.134,64.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.189 | Acc: 18.274,30.126,63.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.202 | Acc: 18.033,30.020,62.666,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.417 | Acc: 26.562,39.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.388 | Acc: 20.573,33.259,80.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.403 | Acc: 20.427,33.117,80.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.415 | Acc: 20.402,33.350,79.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.418 | Acc: 20.515,33.285,79.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.419 | Acc: 20.351,33.277,79.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.422 | Acc: 20.325,33.045,79.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.428 | Acc: 20.385,32.901,79.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.436 | Acc: 20.463,32.973,78.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.444 | Acc: 20.360,32.899,78.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.446 | Acc: 20.503,33.053,78.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.450 | Acc: 20.701,33.166,78.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.457 | Acc: 20.763,33.111,78.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.456 | Acc: 20.767,33.118,78.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.457 | Acc: 20.791,33.110,78.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.463 | Acc: 20.756,33.127,78.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.467 | Acc: 20.736,33.068,78.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.468 | Acc: 20.821,33.092,78.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.472 | Acc: 20.799,33.102,77.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.475 | Acc: 20.796,33.067,77.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.340 | Acc: 21.875,28.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.278 | Acc: 16.964,28.757,60.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.267 | Acc: 16.730,29.021,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.273 | Acc: 16.752,28.586,60.630,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.334 | Acc: 21.875,39.062,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 21.801,34.226,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.430 | Acc: 21.837,33.422,78.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.441 | Acc: 21.273,33.427,78.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.445 | Acc: 21.200,33.150,78.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.446 | Acc: 21.109,33.261,78.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.448 | Acc: 21.113,33.077,78.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.444 | Acc: 21.149,33.150,78.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.447 | Acc: 21.249,33.196,78.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.453 | Acc: 21.245,33.106,78.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.452 | Acc: 21.253,33.096,78.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.451 | Acc: 21.306,33.148,78.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.454 | Acc: 21.091,32.975,78.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.455 | Acc: 21.058,32.947,78.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.459 | Acc: 20.916,32.888,78.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.462 | Acc: 20.925,32.906,78.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 20.926,32.847,77.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.473 | Acc: 20.947,32.886,77.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.475 | Acc: 20.886,32.858,77.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.480 | Acc: 20.883,32.778,77.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.976 | Acc: 21.094,34.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.291 | Acc: 17.894,31.324,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.305 | Acc: 18.045,31.040,60.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.300 | Acc: 18.558,30.661,60.169,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.572 | Acc: 20.312,36.719,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.427 | Acc: 20.461,32.254,79.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.442 | Acc: 20.808,32.489,78.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.427 | Acc: 21.119,33.555,79.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.424 | Acc: 20.872,33.430,79.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.423 | Acc: 20.838,33.501,79.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.424 | Acc: 21.132,33.568,79.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.430 | Acc: 21.121,33.411,79.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.432 | Acc: 21.118,33.385,79.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.437 | Acc: 21.115,33.417,78.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.439 | Acc: 21.024,33.345,78.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.438 | Acc: 20.998,33.297,78.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.441 | Acc: 20.990,33.328,78.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.445 | Acc: 20.995,33.315,78.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.453 | Acc: 20.949,33.193,78.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.456 | Acc: 21.037,33.303,78.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.457 | Acc: 21.023,33.241,78.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.461 | Acc: 20.991,33.158,78.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.467 | Acc: 20.953,33.128,77.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.471 | Acc: 20.917,33.132,77.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.131 | Acc: 20.312,28.125,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.264 | Acc: 17.411,29.092,62.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.239 | Acc: 16.997,29.192,61.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.240 | Acc: 17.290,28.932,61.668,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.388 | Acc: 26.562,38.281,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.436 | Acc: 20.573,33.110,79.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.416 | Acc: 21.151,33.651,79.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.411 | Acc: 21.568,33.799,79.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.424 | Acc: 21.653,33.796,79.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.437 | Acc: 21.341,33.586,78.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 21.042,33.361,78.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.454 | Acc: 20.983,33.206,78.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.455 | Acc: 20.938,33.191,78.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.455 | Acc: 20.982,33.257,78.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.455 | Acc: 20.954,33.186,78.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.456 | Acc: 20.885,33.240,78.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.459 | Acc: 20.760,33.179,78.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.465 | Acc: 20.872,33.256,77.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.467 | Acc: 21.038,33.238,77.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.467 | Acc: 21.115,33.303,77.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 21.128,33.324,77.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.470 | Acc: 21.089,33.310,77.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.471 | Acc: 21.141,33.306,77.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.472 | Acc: 21.125,33.358,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.547 | Acc: 17.969,32.812,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 16.890,26.749,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.476 | Acc: 17.188,26.620,56.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 17.341,26.101,56.724,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.409 | Acc: 25.781,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.409 | Acc: 20.573,33.371,79.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.413 | Acc: 20.617,32.412,79.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.415 | Acc: 20.684,32.889,79.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.422 | Acc: 20.390,32.745,79.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.434 | Acc: 20.784,33.060,79.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.438 | Acc: 20.848,33.174,78.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.441 | Acc: 20.795,33.167,78.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.441 | Acc: 20.900,33.220,78.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.444 | Acc: 21.094,33.214,78.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.445 | Acc: 21.121,33.182,78.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.450 | Acc: 21.012,33.124,78.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.454 | Acc: 21.065,33.095,78.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.459 | Acc: 20.968,33.016,78.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.459 | Acc: 21.030,33.085,78.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.464 | Acc: 20.961,32.992,78.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.466 | Acc: 20.897,32.990,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.468 | Acc: 20.993,32.998,78.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.471 | Acc: 20.953,33.022,77.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.473 | Acc: 20.965,32.983,77.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.180 | Acc: 20.312,32.031,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.261 | Acc: 16.667,29.204,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.239 | Acc: 16.311,28.678,61.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.251 | Acc: 16.419,28.599,61.232,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.273 | Acc: 21.875,38.281,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.432 | Acc: 22.135,33.743,78.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.438 | Acc: 21.475,34.108,79.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.427 | Acc: 21.452,34.247,79.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.428 | Acc: 21.489,34.250,79.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 21.457,33.996,79.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.431 | Acc: 21.081,34.039,79.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.436 | Acc: 21.038,33.826,79.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.438 | Acc: 21.011,33.788,78.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.443 | Acc: 21.120,33.844,78.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.443 | Acc: 21.137,33.741,78.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.445 | Acc: 21.062,33.714,78.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.449 | Acc: 21.185,33.681,78.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.449 | Acc: 21.222,33.788,78.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.455 | Acc: 21.163,33.727,78.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.459 | Acc: 21.257,33.692,78.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.462 | Acc: 21.252,33.618,78.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.463 | Acc: 21.327,33.646,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.466 | Acc: 21.247,33.570,78.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.471 | Acc: 21.248,33.483,77.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.186 | Acc: 24.219,33.594,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.290 | Acc: 17.560,29.018,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.300 | Acc: 17.854,28.830,60.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.302 | Acc: 17.418,28.676,60.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.521 | Acc: 20.312,32.031,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.451 | Acc: 22.507,34.115,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.425 | Acc: 21.704,33.994,78.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.437 | Acc: 21.247,33.901,78.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.434 | Acc: 21.480,33.854,78.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.443 | Acc: 21.388,33.547,78.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.442 | Acc: 21.307,33.684,78.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.441 | Acc: 21.221,33.444,78.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.448 | Acc: 21.113,33.278,78.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.454 | Acc: 21.111,33.132,78.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.458 | Acc: 21.261,33.252,78.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.459 | Acc: 21.232,33.223,78.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.459 | Acc: 21.253,33.214,78.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.461 | Acc: 21.213,33.169,78.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.462 | Acc: 21.230,33.188,78.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.467 | Acc: 21.172,33.220,77.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.469 | Acc: 21.113,33.178,77.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.472 | Acc: 21.151,33.278,77.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.474 | Acc: 21.148,33.206,77.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.477 | Acc: 21.137,33.208,77.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.232 | Acc: 22.656,31.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.222 | Acc: 18.899,31.362,62.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.213 | Acc: 18.883,31.059,61.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.218 | Acc: 18.993,30.584,61.821,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.505 | Acc: 17.188,23.438,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.374 | Acc: 21.019,34.152,80.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.371 | Acc: 21.246,34.223,81.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.371 | Acc: 21.260,34.516,80.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.394 | Acc: 20.939,34.008,80.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.405 | Acc: 21.210,33.741,79.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.409 | Acc: 21.158,33.923,79.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.418 | Acc: 21.216,33.976,79.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.425 | Acc: 21.128,33.730,79.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.431 | Acc: 20.986,33.624,79.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.436 | Acc: 20.888,33.582,78.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.441 | Acc: 20.945,33.597,78.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.444 | Acc: 21.000,33.633,78.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.448 | Acc: 21.058,33.705,78.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.452 | Acc: 21.019,33.666,78.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.453 | Acc: 20.951,33.589,78.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.456 | Acc: 20.953,33.548,78.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.459 | Acc: 20.904,33.463,78.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.462 | Acc: 20.834,33.373,78.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.465 | Acc: 20.878,33.344,78.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.225 | Acc: 18.750,25.781,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.321 | Acc: 17.113,26.600,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.330 | Acc: 17.378,26.810,60.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.358 | Acc: 17.738,26.678,59.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.347 | Acc: 28.906,43.750,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.410 | Acc: 20.759,33.705,80.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.399 | Acc: 20.808,33.632,80.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.412 | Acc: 20.838,33.568,79.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.415 | Acc: 21.103,33.970,79.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.422 | Acc: 20.869,33.934,79.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.422 | Acc: 20.932,34.052,79.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.421 | Acc: 20.867,33.904,79.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.422 | Acc: 20.909,33.919,79.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.424 | Acc: 20.900,34.017,79.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.426 | Acc: 20.931,33.792,79.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.435 | Acc: 20.882,33.488,79.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.436 | Acc: 20.938,33.620,78.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.441 | Acc: 20.932,33.495,78.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.444 | Acc: 21.035,33.521,78.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.446 | Acc: 21.239,33.674,78.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.451 | Acc: 21.269,33.686,78.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.452 | Acc: 21.252,33.646,78.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.454 | Acc: 21.178,33.615,78.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.458 | Acc: 21.192,33.604,78.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.271 | Acc: 17.188,32.031,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 16.964,28.646,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.426 | Acc: 16.273,27.973,58.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.410 | Acc: 16.867,27.830,59.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.378 | Acc: 21.094,32.812,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.417 | Acc: 19.680,32.589,78.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.368 | Acc: 20.446,33.098,80.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.342 | Acc: 20.812,33.555,81.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.330 | Acc: 20.804,33.738,81.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.312 | Acc: 20.753,33.586,82.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.301 | Acc: 20.990,33.794,82.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.291 | Acc: 21.182,33.965,83.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.283 | Acc: 21.210,33.870,83.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.274 | Acc: 21.323,33.930,83.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.264 | Acc: 21.335,34.153,83.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.257 | Acc: 21.341,34.191,84.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.253 | Acc: 21.392,34.193,84.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.249 | Acc: 21.459,34.378,84.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.242 | Acc: 21.505,34.289,84.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.237 | Acc: 21.587,34.455,84.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.232 | Acc: 21.615,34.424,84.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.229 | Acc: 21.593,34.398,85.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.225 | Acc: 21.721,34.503,85.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.222 | Acc: 21.740,34.531,85.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.571 | Acc: 22.656,37.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 20.573,35.528,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.794 | Acc: 20.617,34.813,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.791 | Acc: 20.850,34.900,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.102 | Acc: 24.219,42.188,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.127 | Acc: 21.429,35.491,87.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.137 | Acc: 21.627,35.537,87.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.133 | Acc: 22.387,35.681,87.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.127 | Acc: 22.068,35.667,88.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.124 | Acc: 22.037,35.605,88.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.122 | Acc: 22.120,35.466,88.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.123 | Acc: 22.069,35.616,88.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.124 | Acc: 22.113,35.578,88.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.124 | Acc: 22.164,35.588,88.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.123 | Acc: 22.182,35.681,88.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.120 | Acc: 22.211,35.732,88.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.120 | Acc: 22.167,35.727,88.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.120 | Acc: 22.213,35.806,88.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.119 | Acc: 22.142,35.746,88.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.119 | Acc: 22.137,35.691,88.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.120 | Acc: 22.118,35.582,88.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.119 | Acc: 22.145,35.557,88.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.117 | Acc: 22.109,35.660,88.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.117 | Acc: 22.140,35.698,88.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.624 | Acc: 22.656,35.156,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.777 | Acc: 20.722,34.933,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.788 | Acc: 20.389,34.604,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.784 | Acc: 20.645,34.529,72.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.082 | Acc: 22.656,34.375,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.053 | Acc: 22.842,35.565,90.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.068 | Acc: 22.923,35.709,90.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.074 | Acc: 22.336,35.669,90.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.071 | Acc: 22.184,35.802,90.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.070 | Acc: 22.107,35.992,90.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.073 | Acc: 22.262,35.976,90.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.073 | Acc: 22.196,35.865,90.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.073 | Acc: 22.127,35.874,90.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.073 | Acc: 22.294,36.024,89.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.073 | Acc: 22.240,36.004,89.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.074 | Acc: 22.218,35.849,89.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.078 | Acc: 22.264,35.895,89.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.076 | Acc: 22.234,35.905,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.078 | Acc: 22.223,35.876,89.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.078 | Acc: 22.186,35.875,89.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.079 | Acc: 22.184,35.867,89.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.082 | Acc: 22.212,35.837,89.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.082 | Acc: 22.293,35.948,89.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.084 | Acc: 22.170,35.841,89.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.668 | Acc: 23.438,36.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 20.685,34.821,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.804 | Acc: 20.617,34.566,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.794 | Acc: 20.850,34.734,72.387,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.052 | Acc: 29.688,42.188,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.053 | Acc: 23.475,35.863,89.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.050 | Acc: 22.713,35.633,90.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.053 | Acc: 22.528,35.438,90.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.053 | Acc: 22.608,35.754,90.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.055 | Acc: 22.563,35.752,90.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.057 | Acc: 22.527,35.750,90.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.062 | Acc: 22.279,35.633,90.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.063 | Acc: 22.200,35.506,90.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.064 | Acc: 22.130,35.553,90.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.065 | Acc: 21.898,35.518,90.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.062 | Acc: 21.879,35.580,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.064 | Acc: 21.856,35.643,90.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.063 | Acc: 22.046,35.812,90.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.063 | Acc: 22.008,35.854,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.063 | Acc: 21.966,35.818,90.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.063 | Acc: 22.031,35.884,90.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.062 | Acc: 22.127,35.999,90.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.063 | Acc: 22.072,35.983,90.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.063 | Acc: 22.055,36.077,90.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.647 | Acc: 21.875,36.719,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.802 | Acc: 21.019,35.454,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.805 | Acc: 20.770,34.756,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.805 | Acc: 21.043,34.964,71.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.041 | Acc: 24.219,35.938,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.064 | Acc: 23.177,35.045,89.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.051 | Acc: 22.485,35.232,90.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.050 | Acc: 22.246,35.464,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.051 | Acc: 21.943,35.581,90.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.049 | Acc: 21.976,35.489,90.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.046 | Acc: 22.146,35.640,90.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.046 | Acc: 22.235,35.838,90.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.044 | Acc: 22.394,35.874,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.042 | Acc: 22.393,35.860,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.043 | Acc: 22.415,36.074,90.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.042 | Acc: 22.331,36.139,90.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.042 | Acc: 22.303,36.109,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.044 | Acc: 22.441,36.135,90.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.045 | Acc: 22.420,36.107,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.046 | Acc: 22.254,36.018,90.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.045 | Acc: 22.250,36.057,90.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.044 | Acc: 22.278,36.077,90.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.044 | Acc: 22.336,36.141,90.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.044 | Acc: 22.330,36.153,90.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.697 | Acc: 21.875,37.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 20.759,35.826,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.815 | Acc: 20.484,35.137,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.808 | Acc: 20.953,35.361,72.093,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.098 | Acc: 25.000,39.062,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.032 | Acc: 21.801,36.458,91.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.025 | Acc: 22.332,37.062,91.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.022 | Acc: 22.656,36.680,91.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.029 | Acc: 22.405,35.966,91.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.033 | Acc: 22.525,36.092,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.032 | Acc: 22.501,36.041,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.030 | Acc: 22.595,36.420,91.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.033 | Acc: 22.414,36.238,91.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.033 | Acc: 22.350,36.171,91.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.034 | Acc: 22.299,36.081,91.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.037 | Acc: 22.246,35.913,91.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.035 | Acc: 22.225,36.054,91.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.036 | Acc: 22.228,35.994,91.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.036 | Acc: 22.214,35.921,91.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.037 | Acc: 22.233,36.054,91.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.036 | Acc: 22.245,36.037,91.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.036 | Acc: 22.136,36.006,91.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.035 | Acc: 22.275,36.102,91.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.035 | Acc: 22.295,36.132,91.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.685 | Acc: 23.438,35.938,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.802 | Acc: 21.317,36.124,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.810 | Acc: 20.998,35.728,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.804 | Acc: 21.324,35.643,72.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.101 | Acc: 16.406,28.906,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.015 | Acc: 21.466,35.231,91.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.015 | Acc: 22.066,35.461,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.015 | Acc: 21.734,35.131,91.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.014 | Acc: 21.885,35.426,91.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.015 | Acc: 21.860,35.373,91.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.019 | Acc: 21.940,35.279,91.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.019 | Acc: 22.030,35.472,91.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.021 | Acc: 21.880,35.477,91.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.021 | Acc: 21.953,35.471,91.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.020 | Acc: 21.999,35.541,91.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.018 | Acc: 22.041,35.683,91.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.018 | Acc: 22.193,35.795,91.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.015 | Acc: 22.372,36.099,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.016 | Acc: 22.348,36.038,91.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.017 | Acc: 22.386,36.052,91.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.018 | Acc: 22.427,36.135,91.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.017 | Acc: 22.407,36.139,91.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.019 | Acc: 22.474,36.210,91.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.018 | Acc: 22.431,36.208,91.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.672 | Acc: 25.000,35.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.811 | Acc: 21.317,36.124,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.816 | Acc: 21.265,35.442,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.812 | Acc: 21.465,35.579,72.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 0.964 | Acc: 24.219,37.500,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.982 | Acc: 22.582,36.049,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.990 | Acc: 22.294,36.585,92.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.998 | Acc: 22.118,36.757,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.008 | Acc: 21.759,36.236,92.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.008 | Acc: 21.875,36.324,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.007 | Acc: 21.959,36.318,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.010 | Acc: 21.875,36.104,91.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.010 | Acc: 21.904,36.078,91.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.010 | Acc: 22.026,36.158,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.010 | Acc: 22.100,36.163,92.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.009 | Acc: 22.009,36.259,92.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.009 | Acc: 21.894,36.138,92.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.010 | Acc: 21.959,36.147,91.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.011 | Acc: 21.945,36.160,91.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.011 | Acc: 21.984,36.197,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.010 | Acc: 22.135,36.300,92.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.010 | Acc: 22.193,36.380,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.009 | Acc: 22.280,36.446,92.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.010 | Acc: 22.353,36.464,91.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.687 | Acc: 21.875,39.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.821 | Acc: 21.057,37.016,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.822 | Acc: 20.827,36.052,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.818 | Acc: 21.107,36.091,72.118,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 0.999 | Acc: 21.875,35.156,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.004 | Acc: 22.545,37.016,92.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.997 | Acc: 22.790,37.252,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.003 | Acc: 22.836,37.090,92.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.007 | Acc: 22.319,36.892,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.007 | Acc: 22.200,36.510,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.003 | Acc: 22.049,36.228,92.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.998 | Acc: 22.097,36.431,92.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.999 | Acc: 22.249,36.379,92.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.998 | Acc: 22.337,36.451,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.999 | Acc: 22.501,36.657,92.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.001 | Acc: 22.490,36.570,92.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.003 | Acc: 22.504,36.563,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.004 | Acc: 22.528,36.551,92.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.004 | Acc: 22.551,36.641,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.004 | Acc: 22.545,36.607,92.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.003 | Acc: 22.513,36.670,92.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.003 | Acc: 22.409,36.490,92.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.004 | Acc: 22.375,36.420,92.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.004 | Acc: 22.412,36.542,92.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.740 | Acc: 23.438,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.836 | Acc: 21.317,36.458,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.833 | Acc: 21.151,35.823,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.828 | Acc: 21.401,35.784,71.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 0.909 | Acc: 24.219,44.531,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.984 | Acc: 22.917,37.202,92.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.978 | Acc: 23.380,37.862,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.978 | Acc: 23.630,37.462,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.978 | Acc: 23.245,36.873,93.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.979 | Acc: 22.912,36.989,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.981 | Acc: 22.766,36.925,92.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.982 | Acc: 22.773,36.979,92.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.984 | Acc: 22.884,37.039,92.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.985 | Acc: 22.764,36.969,92.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.984 | Acc: 22.769,36.991,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.984 | Acc: 22.702,36.906,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.985 | Acc: 22.773,37.011,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.986 | Acc: 22.623,36.803,92.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.987 | Acc: 22.659,36.813,92.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.989 | Acc: 22.667,36.768,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.989 | Acc: 22.693,36.819,92.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.991 | Acc: 22.626,36.749,92.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.991 | Acc: 22.563,36.637,92.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.991 | Acc: 22.593,36.670,92.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.693 | Acc: 21.875,38.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.830 | Acc: 21.057,35.789,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.827 | Acc: 20.655,35.175,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.826 | Acc: 20.914,35.361,72.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 1.016 | Acc: 19.531,35.938,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.994 | Acc: 22.173,36.644,92.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.985 | Acc: 22.046,36.681,92.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.979 | Acc: 22.246,36.872,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.979 | Acc: 22.415,36.941,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.981 | Acc: 22.471,36.788,92.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.986 | Acc: 22.579,36.751,92.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.986 | Acc: 22.623,36.663,92.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.989 | Acc: 22.448,36.588,92.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.989 | Acc: 22.522,36.654,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 22.388,36.602,92.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.988 | Acc: 22.370,36.616,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.989 | Acc: 22.394,36.570,92.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.988 | Acc: 22.321,36.590,92.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.988 | Acc: 22.334,36.616,92.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.987 | Acc: 22.482,36.773,92.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.988 | Acc: 22.498,36.784,92.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.988 | Acc: 22.514,36.753,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.988 | Acc: 22.494,36.816,92.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.987 | Acc: 22.502,36.834,92.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.740 | Acc: 22.656,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.843 | Acc: 21.243,36.421,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.841 | Acc: 21.113,35.766,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.836 | Acc: 21.337,35.899,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 0.961 | Acc: 22.656,37.500,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.969 | Acc: 23.289,36.682,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.972 | Acc: 22.618,36.300,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.976 | Acc: 22.362,35.784,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.972 | Acc: 22.473,36.044,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.972 | Acc: 22.494,36.077,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.974 | Acc: 22.760,36.351,93.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.975 | Acc: 22.512,36.292,93.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.974 | Acc: 22.719,36.578,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.975 | Acc: 22.773,36.550,93.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.978 | Acc: 22.575,36.622,93.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.978 | Acc: 22.589,36.825,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.978 | Acc: 22.604,36.998,92.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.978 | Acc: 22.611,36.895,92.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.978 | Acc: 22.665,36.933,92.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.977 | Acc: 22.612,36.836,93.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 22.574,36.826,93.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.977 | Acc: 22.610,36.865,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.977 | Acc: 22.671,36.877,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.978 | Acc: 22.607,36.881,92.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.689 | Acc: 23.438,38.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.841 | Acc: 21.354,36.458,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 21.018,36.052,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 21.311,36.027,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.987 | Acc: 24.219,32.812,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.960 | Acc: 22.433,37.091,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.968 | Acc: 22.237,36.757,93.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.966 | Acc: 22.503,37.090,93.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.963 | Acc: 22.290,37.085,93.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.965 | Acc: 22.146,36.959,93.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.964 | Acc: 21.843,36.932,93.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.966 | Acc: 21.781,36.796,93.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.967 | Acc: 21.919,36.835,93.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.968 | Acc: 22.030,36.758,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.969 | Acc: 22.069,36.738,93.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.969 | Acc: 22.172,36.814,93.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.969 | Acc: 22.125,36.858,93.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.968 | Acc: 22.129,36.868,93.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.968 | Acc: 22.203,36.841,93.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.968 | Acc: 22.270,36.784,93.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.968 | Acc: 22.318,36.782,93.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.968 | Acc: 22.381,36.790,93.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.970 | Acc: 22.381,36.749,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.971 | Acc: 22.369,36.756,93.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.669 | Acc: 24.219,37.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.843 | Acc: 21.429,36.644,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.838 | Acc: 21.113,35.785,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.838 | Acc: 21.311,35.950,71.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 0.873 | Acc: 19.531,39.844,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.952 | Acc: 23.326,36.607,93.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.948 | Acc: 23.133,36.471,93.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.947 | Acc: 23.322,36.270,93.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.949 | Acc: 22.811,36.429,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.958 | Acc: 22.656,36.131,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.955 | Acc: 22.882,36.454,93.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.953 | Acc: 22.828,36.625,93.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.957 | Acc: 22.865,36.680,93.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.959 | Acc: 22.881,36.594,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.960 | Acc: 22.889,36.692,93.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.962 | Acc: 22.766,36.609,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.962 | Acc: 22.783,36.722,93.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.963 | Acc: 22.743,36.830,93.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.963 | Acc: 22.770,36.827,93.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.963 | Acc: 22.794,36.776,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.962 | Acc: 22.851,36.821,93.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.963 | Acc: 22.782,36.749,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.963 | Acc: 22.767,36.697,93.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.964 | Acc: 22.742,36.678,93.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.662 | Acc: 22.656,39.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.848 | Acc: 21.205,37.016,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.844 | Acc: 20.979,35.938,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.840 | Acc: 21.209,36.053,72.054,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 0.883 | Acc: 21.875,36.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.965 | Acc: 22.768,36.458,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.958 | Acc: 22.580,37.043,93.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.956 | Acc: 22.234,36.783,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.957 | Acc: 22.097,37.076,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.957 | Acc: 21.867,36.665,93.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.956 | Acc: 21.991,36.512,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.956 | Acc: 22.047,36.580,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.955 | Acc: 22.040,36.578,93.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.955 | Acc: 21.961,36.516,93.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.954 | Acc: 22.124,36.423,93.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.955 | Acc: 22.140,36.379,93.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.955 | Acc: 22.115,36.356,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.954 | Acc: 22.234,36.446,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.953 | Acc: 22.337,36.535,93.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.953 | Acc: 22.454,36.703,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.952 | Acc: 22.459,36.814,93.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.954 | Acc: 22.484,36.854,93.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.955 | Acc: 22.546,36.918,93.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 22.554,36.959,93.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.712 | Acc: 25.000,37.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.860 | Acc: 21.466,36.868,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.847 | Acc: 21.475,36.128,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.846 | Acc: 21.696,36.232,71.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 0.982 | Acc: 16.406,33.594,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.949 | Acc: 22.024,35.491,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.946 | Acc: 22.313,36.338,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.951 | Acc: 22.374,36.232,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.950 | Acc: 22.396,36.526,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.954 | Acc: 22.502,36.463,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.955 | Acc: 22.521,36.460,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.954 | Acc: 22.468,36.436,93.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.951 | Acc: 22.588,36.685,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.950 | Acc: 22.540,36.732,93.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.951 | Acc: 22.540,36.579,93.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.952 | Acc: 22.504,36.648,93.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.953 | Acc: 22.585,36.839,93.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.954 | Acc: 22.486,36.838,93.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.953 | Acc: 22.495,36.830,93.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.954 | Acc: 22.511,36.825,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.954 | Acc: 22.522,36.819,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.956 | Acc: 22.624,36.875,93.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.957 | Acc: 22.526,36.799,93.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.956 | Acc: 22.507,36.832,93.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.771 | Acc: 23.438,37.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.851 | Acc: 21.540,37.463,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.843 | Acc: 21.418,36.547,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.842 | Acc: 21.734,36.629,71.798,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 0.910 | Acc: 26.562,36.719,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.954 | Acc: 23.289,37.537,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.947 | Acc: 23.514,37.671,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.946 | Acc: 23.373,37.577,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.947 | Acc: 23.100,37.539,94.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.942 | Acc: 23.291,37.732,94.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.941 | Acc: 23.160,37.694,94.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.945 | Acc: 22.878,37.400,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.945 | Acc: 22.647,37.233,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.947 | Acc: 22.665,37.163,94.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.947 | Acc: 22.582,37.185,94.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.949 | Acc: 22.497,37.154,93.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.947 | Acc: 22.659,37.237,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.947 | Acc: 22.728,37.329,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.948 | Acc: 22.751,37.305,93.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.947 | Acc: 22.706,37.324,93.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.947 | Acc: 22.676,37.215,93.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.948 | Acc: 22.739,37.184,93.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.948 | Acc: 22.704,37.119,93.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.947 | Acc: 22.695,37.133,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.794 | Acc: 23.438,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 21.577,37.426,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.855 | Acc: 21.456,36.547,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 21.926,36.668,71.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 0.884 | Acc: 18.750,35.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.932 | Acc: 22.433,36.756,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.943 | Acc: 22.885,37.043,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.940 | Acc: 22.515,36.783,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.939 | Acc: 22.541,36.661,93.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.941 | Acc: 22.687,36.726,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.940 | Acc: 22.940,36.680,93.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.943 | Acc: 22.750,36.702,93.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.944 | Acc: 22.671,36.539,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.944 | Acc: 22.622,36.736,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.945 | Acc: 22.664,36.719,93.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.945 | Acc: 22.738,36.687,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 22.763,36.767,93.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.943 | Acc: 22.887,36.973,94.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.944 | Acc: 22.729,36.966,94.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.945 | Acc: 22.724,37.043,93.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.946 | Acc: 22.698,37.025,93.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.944 | Acc: 22.805,37.083,93.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.945 | Acc: 22.821,37.175,93.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.946 | Acc: 22.812,37.227,93.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.689 | Acc: 24.219,37.500,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.862 | Acc: 22.024,37.426,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.858 | Acc: 21.684,36.986,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.853 | Acc: 21.913,36.898,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 0.944 | Acc: 28.125,36.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.925 | Acc: 23.512,38.207,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.931 | Acc: 22.771,37.710,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.935 | Acc: 22.592,37.410,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.935 | Acc: 22.608,37.365,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.935 | Acc: 22.865,37.353,94.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.936 | Acc: 22.837,37.519,94.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.939 | Acc: 22.800,37.289,94.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.939 | Acc: 22.719,37.068,94.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.939 | Acc: 22.756,37.116,94.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.940 | Acc: 22.785,37.166,93.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.939 | Acc: 22.801,37.104,94.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.940 | Acc: 22.757,37.079,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.938 | Acc: 22.767,37.213,94.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.939 | Acc: 22.734,37.141,94.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.940 | Acc: 22.610,37.054,94.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.939 | Acc: 22.605,37.023,94.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.939 | Acc: 22.645,37.076,94.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 22.656,37.039,94.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.939 | Acc: 22.667,37.035,94.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.768 | Acc: 22.656,37.500,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.870 | Acc: 21.763,37.016,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.865 | Acc: 21.094,36.433,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.861 | Acc: 21.440,36.424,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 0.989 | Acc: 17.188,35.938,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.903 | Acc: 23.624,37.686,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.907 | Acc: 23.761,37.557,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.918 | Acc: 23.258,37.500,94.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.922 | Acc: 22.801,37.317,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.923 | Acc: 22.950,37.330,94.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.928 | Acc: 22.940,37.197,94.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.930 | Acc: 22.822,37.145,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.931 | Acc: 22.875,37.151,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.934 | Acc: 22.850,37.081,94.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.935 | Acc: 22.788,37.135,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.935 | Acc: 22.709,37.083,94.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.935 | Acc: 22.728,37.137,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.936 | Acc: 22.701,37.207,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.935 | Acc: 22.767,37.203,94.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.934 | Acc: 22.885,37.318,94.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.934 | Acc: 22.851,37.320,94.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.936 | Acc: 22.807,37.250,94.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.937 | Acc: 22.860,37.277,94.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.937 | Acc: 22.931,37.311,94.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.770 | Acc: 22.656,36.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 21.466,37.463,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.870 | Acc: 21.208,36.890,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.873 | Acc: 21.644,36.924,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 0.898 | Acc: 28.125,40.625,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.928 | Acc: 21.652,35.863,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.922 | Acc: 21.989,35.461,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.924 | Acc: 22.323,35.745,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.923 | Acc: 22.425,36.015,94.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.925 | Acc: 22.432,36.193,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.927 | Acc: 22.488,36.260,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.927 | Acc: 22.518,36.342,94.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.927 | Acc: 22.540,36.476,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.928 | Acc: 22.725,36.641,94.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.927 | Acc: 22.882,36.688,94.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.926 | Acc: 22.967,36.793,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.927 | Acc: 22.929,36.916,94.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.928 | Acc: 22.944,36.928,94.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.929 | Acc: 22.912,36.908,94.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.931 | Acc: 22.833,36.843,94.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.931 | Acc: 22.797,36.926,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.931 | Acc: 22.860,37.021,94.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.931 | Acc: 22.853,37.007,94.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.930 | Acc: 22.841,37.071,94.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.825 | Acc: 23.438,36.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 21.391,37.463,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.864 | Acc: 20.998,36.757,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.865 | Acc: 21.580,36.821,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 0.876 | Acc: 25.000,39.844,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.914 | Acc: 23.810,38.467,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.916 | Acc: 22.961,37.748,94.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.916 | Acc: 23.079,37.423,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.919 | Acc: 22.618,36.863,94.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.922 | Acc: 22.695,36.928,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.926 | Acc: 22.346,36.441,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.926 | Acc: 22.307,36.652,94.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.930 | Acc: 22.336,36.578,94.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.930 | Acc: 22.397,36.689,94.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.929 | Acc: 22.544,37.006,94.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.929 | Acc: 22.504,37.079,94.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.929 | Acc: 22.624,37.101,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.929 | Acc: 22.677,37.093,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.927 | Acc: 22.734,37.189,94.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.928 | Acc: 22.680,37.009,94.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.928 | Acc: 22.720,37.021,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.929 | Acc: 22.700,36.994,94.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.928 | Acc: 22.713,37.002,94.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.928 | Acc: 22.773,37.030,94.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.753 | Acc: 24.219,39.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.865 | Acc: 21.577,37.537,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.871 | Acc: 21.532,36.528,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 21.837,36.552,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 0.885 | Acc: 26.562,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.905 | Acc: 24.070,39.509,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.906 | Acc: 24.428,39.139,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.901 | Acc: 24.321,39.050,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.905 | Acc: 24.238,38.879,94.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.906 | Acc: 23.987,38.467,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.907 | Acc: 23.864,38.307,94.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.912 | Acc: 23.604,37.977,94.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.912 | Acc: 23.457,37.864,94.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.914 | Acc: 23.355,37.530,94.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.915 | Acc: 23.313,37.477,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.918 | Acc: 23.264,37.359,94.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.919 | Acc: 23.185,37.309,94.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.919 | Acc: 23.222,37.464,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.920 | Acc: 23.062,37.380,94.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.920 | Acc: 23.110,37.534,94.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.921 | Acc: 22.995,37.454,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.922 | Acc: 23.016,37.445,94.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.921 | Acc: 22.946,37.400,94.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.922 | Acc: 22.933,37.408,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.755 | Acc: 23.438,38.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.883 | Acc: 21.503,37.463,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.886 | Acc: 21.399,36.719,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.890 | Acc: 21.773,36.565,71.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 0.941 | Acc: 23.438,38.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.917 | Acc: 21.726,37.240,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.908 | Acc: 21.742,36.890,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.902 | Acc: 22.503,37.846,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.905 | Acc: 22.560,37.596,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.907 | Acc: 22.664,37.446,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.908 | Acc: 22.869,37.636,95.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.908 | Acc: 22.706,37.794,95.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.910 | Acc: 22.739,37.796,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.913 | Acc: 22.712,37.599,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.913 | Acc: 22.664,37.523,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.915 | Acc: 22.723,37.397,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.915 | Acc: 22.711,37.254,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.915 | Acc: 22.848,37.542,94.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.915 | Acc: 22.823,37.497,94.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.916 | Acc: 22.778,37.456,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.917 | Acc: 22.758,37.454,94.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.917 | Acc: 22.663,37.353,94.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.918 | Acc: 22.721,37.448,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.918 | Acc: 22.728,37.412,94.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.834 | Acc: 23.438,39.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.878 | Acc: 21.317,37.240,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.888 | Acc: 21.284,36.623,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.894 | Acc: 21.696,36.591,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 0.931 | Acc: 21.094,37.500,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.921 | Acc: 22.321,37.798,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.919 | Acc: 21.589,36.852,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.916 | Acc: 22.106,36.962,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.910 | Acc: 22.251,37.220,94.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.907 | Acc: 22.424,37.508,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.910 | Acc: 22.443,37.487,94.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.912 | Acc: 22.379,37.434,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.913 | Acc: 22.593,37.563,94.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.913 | Acc: 22.566,37.586,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.914 | Acc: 22.551,37.574,94.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.914 | Acc: 22.522,37.631,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.914 | Acc: 22.744,37.591,94.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.914 | Acc: 22.689,37.584,94.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.915 | Acc: 22.726,37.539,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.915 | Acc: 22.732,37.445,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.916 | Acc: 22.754,37.483,94.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.916 | Acc: 22.794,37.546,94.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.916 | Acc: 22.879,37.472,94.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.916 | Acc: 22.911,37.488,94.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.831 | Acc: 24.219,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.899 | Acc: 21.726,36.942,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.904 | Acc: 21.551,36.338,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.902 | Acc: 21.913,36.552,71.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.876 | Acc: 20.312,43.750,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.913 | Acc: 22.359,37.537,94.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.906 | Acc: 22.790,38.072,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.905 | Acc: 22.695,38.025,95.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.906 | Acc: 22.801,37.886,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.907 | Acc: 22.780,37.562,95.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.911 | Acc: 22.740,37.351,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.912 | Acc: 22.518,37.439,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.913 | Acc: 22.457,37.335,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.914 | Acc: 22.484,37.332,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.913 | Acc: 22.516,37.469,94.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.914 | Acc: 22.614,37.458,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.912 | Acc: 22.747,37.461,94.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.912 | Acc: 22.857,37.512,94.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.914 | Acc: 22.829,37.494,94.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.913 | Acc: 22.757,37.479,94.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.913 | Acc: 22.749,37.408,94.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.913 | Acc: 22.787,37.459,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.912 | Acc: 22.773,37.470,94.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.912 | Acc: 22.796,37.473,94.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.823 | Acc: 25.000,35.938,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.891 | Acc: 21.838,38.504,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.892 | Acc: 21.894,37.252,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.894 | Acc: 22.016,37.295,71.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 0.806 | Acc: 25.000,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.908 | Acc: 22.954,37.723,94.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.905 | Acc: 23.247,38.186,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.905 | Acc: 23.194,38.102,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.905 | Acc: 23.225,38.484,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.910 | Acc: 23.283,38.165,94.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.908 | Acc: 23.192,38.146,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.907 | Acc: 23.476,38.159,95.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.907 | Acc: 23.263,37.951,95.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.909 | Acc: 23.153,37.871,95.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.910 | Acc: 23.107,37.881,95.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.909 | Acc: 23.232,37.945,95.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.909 | Acc: 23.172,38.025,95.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.909 | Acc: 23.123,37.943,95.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.910 | Acc: 22.990,37.784,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.911 | Acc: 22.981,37.752,95.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.910 | Acc: 22.924,37.687,95.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.911 | Acc: 22.814,37.621,95.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.911 | Acc: 22.853,37.677,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.912 | Acc: 22.828,37.605,94.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.768 | Acc: 22.656,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.917 | Acc: 22.098,37.463,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.908 | Acc: 22.066,37.081,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.914 | Acc: 22.362,37.308,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 0.844 | Acc: 23.438,43.750,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.904 | Acc: 22.396,36.979,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.896 | Acc: 22.618,37.290,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.894 | Acc: 23.105,37.615,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.893 | Acc: 22.936,37.568,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.899 | Acc: 23.113,37.778,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.900 | Acc: 23.095,37.565,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.901 | Acc: 22.895,37.517,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.901 | Acc: 22.909,37.451,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.903 | Acc: 22.838,37.573,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.903 | Acc: 22.994,37.562,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.903 | Acc: 22.928,37.631,95.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.905 | Acc: 23.016,37.610,95.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.906 | Acc: 23.099,37.578,95.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.909 | Acc: 22.979,37.367,94.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.908 | Acc: 23.004,37.407,94.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.909 | Acc: 22.929,37.259,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.909 | Acc: 22.906,37.255,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.910 | Acc: 22.957,37.364,94.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.910 | Acc: 22.833,37.283,94.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.812 | Acc: 24.219,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.925 | Acc: 21.838,37.723,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.908 | Acc: 21.761,37.024,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.903 | Acc: 21.926,37.065,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 0.862 | Acc: 23.438,39.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.906 | Acc: 23.438,36.533,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.912 | Acc: 23.323,36.986,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.906 | Acc: 23.489,37.103,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.908 | Acc: 23.293,37.037,94.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.907 | Acc: 23.058,36.989,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.904 | Acc: 22.889,37.016,95.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.905 | Acc: 22.817,37.062,95.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.904 | Acc: 22.787,37.180,95.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.904 | Acc: 22.781,37.289,95.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.906 | Acc: 22.750,37.302,94.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.907 | Acc: 22.854,37.472,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.907 | Acc: 22.812,37.396,94.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.907 | Acc: 22.815,37.410,94.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.907 | Acc: 22.829,37.433,94.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.908 | Acc: 22.841,37.368,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.908 | Acc: 22.841,37.364,94.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.909 | Acc: 22.872,37.312,94.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.909 | Acc: 22.879,37.346,94.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.908 | Acc: 22.937,37.402,94.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.800 | Acc: 24.219,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.915 | Acc: 22.061,38.430,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.900 | Acc: 21.761,37.329,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.903 | Acc: 22.016,37.398,71.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 0.959 | Acc: 23.438,34.375,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.892 | Acc: 24.107,37.984,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.896 | Acc: 23.399,37.824,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.894 | Acc: 23.271,37.884,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.894 | Acc: 23.486,38.146,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.892 | Acc: 23.329,38.142,95.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.894 | Acc: 23.212,38.081,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.896 | Acc: 23.144,38.021,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.897 | Acc: 23.340,38.014,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.900 | Acc: 23.217,37.880,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.901 | Acc: 23.220,37.737,95.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.900 | Acc: 23.278,37.740,95.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.901 | Acc: 23.178,37.737,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.901 | Acc: 23.240,37.698,95.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.901 | Acc: 23.204,37.672,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.900 | Acc: 23.227,37.700,95.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.901 | Acc: 23.216,37.631,95.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.902 | Acc: 23.185,37.509,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.902 | Acc: 23.202,37.528,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.903 | Acc: 23.228,37.521,95.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.862 | Acc: 27.344,39.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.917 | Acc: 21.503,37.760,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 21.437,36.986,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.913 | Acc: 21.849,37.129,71.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.953 | Acc: 18.750,35.938,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.910 | Acc: 21.168,36.756,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.898 | Acc: 21.684,37.348,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.897 | Acc: 22.234,38.025,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.893 | Acc: 22.801,38.320,95.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.893 | Acc: 23.089,38.405,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.890 | Acc: 23.063,38.236,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.891 | Acc: 22.967,38.176,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 22.904,38.102,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.895 | Acc: 22.967,38.178,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.897 | Acc: 22.975,38.099,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.898 | Acc: 22.861,37.917,95.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.900 | Acc: 22.831,37.814,95.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.899 | Acc: 22.854,37.922,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.899 | Acc: 22.884,37.962,95.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.899 | Acc: 22.879,37.959,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.898 | Acc: 22.851,37.979,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.898 | Acc: 22.851,37.961,95.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.899 | Acc: 22.730,37.796,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.899 | Acc: 22.771,37.754,95.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.831 | Acc: 24.219,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 21.391,37.984,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.935 | Acc: 21.037,37.309,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.935 | Acc: 21.555,37.282,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 0.906 | Acc: 28.906,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.886 | Acc: 24.442,37.872,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.891 | Acc: 22.866,37.062,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.889 | Acc: 22.887,37.602,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.887 | Acc: 22.666,37.847,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.889 | Acc: 22.842,37.693,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.891 | Acc: 22.927,37.758,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.892 | Acc: 22.906,37.711,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.891 | Acc: 22.899,37.718,95.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 22.911,37.668,95.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.893 | Acc: 22.979,37.605,95.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.894 | Acc: 22.964,37.723,95.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.893 | Acc: 22.909,37.717,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.894 | Acc: 22.881,37.778,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.894 | Acc: 22.809,37.823,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.894 | Acc: 22.838,37.786,95.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.895 | Acc: 22.870,37.739,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.895 | Acc: 22.860,37.699,95.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.895 | Acc: 22.888,37.732,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.895 | Acc: 22.882,37.721,95.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.801 | Acc: 24.219,35.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.916 | Acc: 22.098,37.723,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.909 | Acc: 21.608,37.157,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.911 | Acc: 21.913,37.167,71.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 0.851 | Acc: 21.094,28.906,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.877 | Acc: 22.507,37.202,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.884 | Acc: 22.142,37.195,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.882 | Acc: 22.541,37.269,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.885 | Acc: 22.589,37.384,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.886 | Acc: 22.532,37.423,95.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.888 | Acc: 22.805,37.532,95.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.888 | Acc: 22.967,37.661,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.888 | Acc: 23.302,37.801,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.888 | Acc: 23.321,37.828,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.888 | Acc: 23.336,37.799,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.888 | Acc: 23.363,37.988,95.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.890 | Acc: 23.285,37.934,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.890 | Acc: 23.201,37.865,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.890 | Acc: 23.207,37.873,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.891 | Acc: 23.181,37.832,95.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.891 | Acc: 23.199,37.914,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.891 | Acc: 23.229,37.922,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.891 | Acc: 23.139,37.970,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.890 | Acc: 23.087,37.951,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.852 | Acc: 25.000,36.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.924 | Acc: 21.801,37.835,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 21.684,37.138,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.918 | Acc: 21.875,37.052,71.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 0.886 | Acc: 21.875,39.844,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.886 | Acc: 22.135,37.760,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.880 | Acc: 23.018,37.652,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 22.861,37.756,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 23.023,37.818,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.885 | Acc: 23.167,37.987,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.889 | Acc: 22.960,37.933,95.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.888 | Acc: 22.811,37.949,95.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.889 | Acc: 22.812,37.743,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.888 | Acc: 22.820,37.772,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.888 | Acc: 22.765,37.889,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.889 | Acc: 22.872,37.984,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.889 | Acc: 22.890,37.837,95.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.890 | Acc: 22.947,37.859,95.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.891 | Acc: 22.923,37.778,95.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.891 | Acc: 22.963,37.765,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.890 | Acc: 22.980,37.756,95.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.891 | Acc: 22.954,37.722,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.892 | Acc: 22.992,37.719,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.894 | Acc: 22.974,37.641,95.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.924 | Acc: 25.781,36.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.930 | Acc: 21.317,37.612,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 21.322,37.005,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.941 | Acc: 21.773,36.936,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 0.831 | Acc: 21.094,36.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.870 | Acc: 22.879,38.690,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.884 | Acc: 23.514,38.472,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.885 | Acc: 23.566,38.397,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.886 | Acc: 23.495,38.850,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.886 | Acc: 23.391,38.931,95.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.884 | Acc: 23.547,38.778,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.885 | Acc: 23.232,38.292,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.887 | Acc: 23.200,38.272,95.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.889 | Acc: 23.166,38.355,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.890 | Acc: 23.243,38.305,95.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.892 | Acc: 23.112,38.119,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.893 | Acc: 23.055,38.025,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.893 | Acc: 23.075,37.997,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.892 | Acc: 23.154,38.067,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.891 | Acc: 23.181,38.094,95.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.891 | Acc: 23.189,38.140,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.891 | Acc: 23.140,38.096,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.891 | Acc: 23.104,38.037,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.891 | Acc: 23.132,38.050,95.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.862 | Acc: 25.000,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.932 | Acc: 21.466,37.091,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.936 | Acc: 21.037,36.623,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.940 | Acc: 21.555,36.796,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.910 | Acc: 22.656,35.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.878 | Acc: 23.438,37.463,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.877 | Acc: 23.323,37.329,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.882 | Acc: 22.707,37.116,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.887 | Acc: 22.309,36.979,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.889 | Acc: 22.757,37.214,95.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.894 | Acc: 22.792,37.113,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.893 | Acc: 22.767,37.317,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.890 | Acc: 22.904,37.539,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.889 | Acc: 22.833,37.474,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.891 | Acc: 22.722,37.310,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.890 | Acc: 22.745,37.397,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.890 | Acc: 22.770,37.613,95.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.889 | Acc: 22.854,37.707,95.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.887 | Acc: 22.918,37.831,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.887 | Acc: 22.999,37.786,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 22.990,37.848,95.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.888 | Acc: 23.023,37.812,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.888 | Acc: 22.979,37.859,95.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.889 | Acc: 22.906,37.799,95.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.848 | Acc: 25.781,37.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.923 | Acc: 21.503,37.984,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.927 | Acc: 21.494,37.386,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.927 | Acc: 21.862,37.398,70.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 0.868 | Acc: 30.469,39.844,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.897 | Acc: 24.665,37.760,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.889 | Acc: 23.342,36.852,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.892 | Acc: 23.002,37.039,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 23.110,37.413,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.882 | Acc: 22.966,37.237,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.881 | Acc: 23.134,37.332,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.882 | Acc: 23.088,37.467,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.882 | Acc: 23.243,37.757,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.881 | Acc: 23.304,37.876,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.881 | Acc: 23.348,37.978,95.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 23.165,37.864,95.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.882 | Acc: 23.159,37.883,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.883 | Acc: 23.189,37.835,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.884 | Acc: 23.171,37.836,95.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.884 | Acc: 23.155,37.845,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.884 | Acc: 23.162,37.941,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.885 | Acc: 23.167,37.977,95.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.886 | Acc: 23.085,37.939,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.887 | Acc: 23.068,37.963,95.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.939 | Acc: 25.000,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 21.912,37.388,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 21.532,37.195,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 22.016,37.282,70.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 0.834 | Acc: 27.344,41.406,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.884 | Acc: 24.256,38.616,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 23.399,38.986,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 23.348,38.371,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 23.438,37.973,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 23.229,38.072,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.876 | Acc: 23.457,37.900,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.876 | Acc: 23.293,37.783,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 23.171,37.684,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.878 | Acc: 23.179,37.772,95.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.879 | Acc: 23.173,37.722,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.879 | Acc: 23.183,37.797,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.878 | Acc: 23.165,37.857,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.878 | Acc: 23.333,38.048,95.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.878 | Acc: 23.282,38.095,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 23.235,38.022,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 23.184,37.979,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.883 | Acc: 23.130,38.061,95.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.884 | Acc: 23.074,38.050,95.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.885 | Acc: 23.064,38.002,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.967 | Acc: 25.781,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 21.987,38.914,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 21.951,37.900,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 22.413,37.679,70.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.765 | Acc: 28.906,42.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.879 | Acc: 22.954,38.504,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.871 | Acc: 23.037,38.491,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 22.541,37.948,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 22.791,37.915,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.880 | Acc: 22.618,37.809,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.881 | Acc: 22.701,37.752,95.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 22.967,37.954,95.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.880 | Acc: 23.108,37.796,95.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.880 | Acc: 23.140,37.888,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.879 | Acc: 23.088,37.854,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.879 | Acc: 23.052,37.684,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.880 | Acc: 23.104,37.753,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.880 | Acc: 23.186,37.820,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.879 | Acc: 23.229,37.864,95.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 23.209,37.869,95.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 23.189,37.877,95.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.882 | Acc: 23.105,37.818,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.882 | Acc: 23.048,37.805,95.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.881 | Acc: 23.085,37.828,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.912 | Acc: 25.000,39.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 22.210,38.207,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 22.066,37.386,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.945 | Acc: 22.477,37.385,70.850,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.869 | Acc: 22.656,36.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.868 | Acc: 22.693,37.537,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 22.580,37.671,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 22.682,37.769,95.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.876 | Acc: 22.666,37.481,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.877 | Acc: 22.881,37.539,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 22.843,37.577,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.878 | Acc: 22.811,37.672,95.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 22.894,37.680,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.876 | Acc: 22.937,37.759,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.876 | Acc: 23.119,37.792,95.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.876 | Acc: 23.169,37.878,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.877 | Acc: 23.340,38.116,95.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.878 | Acc: 23.357,38.105,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.879 | Acc: 23.223,38.048,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.879 | Acc: 23.209,38.113,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.878 | Acc: 23.138,38.116,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.879 | Acc: 23.158,38.089,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.880 | Acc: 23.169,38.050,95.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.881 | Acc: 23.146,37.974,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.027 | Acc: 26.562,36.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.981 | Acc: 22.024,38.393,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 21.665,37.500,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 21.990,37.359,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 0.791 | Acc: 22.656,32.812,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.878 | Acc: 22.693,37.760,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.884 | Acc: 22.199,37.881,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.874 | Acc: 23.002,39.088,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 23.293,38.937,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 23.399,38.931,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 23.509,38.946,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 23.515,38.852,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 23.408,38.597,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 23.381,38.424,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.875 | Acc: 23.383,38.328,95.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.873 | Acc: 23.317,38.352,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.874 | Acc: 23.298,38.362,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.876 | Acc: 23.285,38.233,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.877 | Acc: 23.279,38.262,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 23.271,38.209,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 23.287,38.230,95.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 23.266,38.217,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 23.273,38.199,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 23.302,38.181,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.912 | Acc: 25.781,35.156,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.210,37.686,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.975 | Acc: 21.856,37.100,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 22.093,37.193,70.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.900 | Acc: 14.844,28.125,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 22.024,36.756,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 23.209,37.176,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.868 | Acc: 23.322,37.538,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 23.399,37.799,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 23.422,38.103,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 23.173,38.120,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.869 | Acc: 23.332,38.071,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 23.316,38.204,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 23.256,38.221,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 23.134,38.134,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 23.176,38.147,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 23.220,38.122,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 23.087,38.135,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.873 | Acc: 23.043,38.098,95.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.874 | Acc: 23.030,38.146,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.875 | Acc: 23.024,38.135,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.875 | Acc: 22.961,38.135,95.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.875 | Acc: 22.998,38.190,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.876 | Acc: 23.042,38.091,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.980 | Acc: 25.781,36.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 22.098,38.207,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.894,37.652,69.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 22.131,37.500,70.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.935 | Acc: 18.750,31.250,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.857 | Acc: 23.996,38.170,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.864 | Acc: 23.895,38.034,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 23.745,38.089,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 23.708,38.426,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 23.453,38.057,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 23.270,37.939,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 23.399,37.988,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.875 | Acc: 23.471,37.976,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.876 | Acc: 23.386,37.897,95.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.878 | Acc: 23.313,37.896,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.879 | Acc: 23.285,37.967,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.877 | Acc: 23.412,38.012,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.877 | Acc: 23.363,37.949,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.877 | Acc: 23.235,37.870,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 23.264,37.933,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 23.284,37.979,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 23.236,37.864,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 23.223,37.894,95.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.876 | Acc: 23.239,37.945,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.896 | Acc: 24.219,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 22.470,38.356,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.954 | Acc: 22.409,37.671,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.957 | Acc: 22.426,37.705,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.780 | Acc: 28.906,46.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.879 | Acc: 23.921,38.504,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.881 | Acc: 23.323,38.148,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.880 | Acc: 22.925,38.243,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 23.090,38.407,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 22.997,38.614,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 23.050,38.262,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 23.027,38.342,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 22.947,38.417,96.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 22.980,38.596,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 22.963,38.413,96.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 23.003,38.447,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 23.055,38.391,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 23.129,38.443,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.872 | Acc: 23.076,38.381,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 23.022,38.271,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.872 | Acc: 23.089,38.296,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.873 | Acc: 23.071,38.199,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 23.072,38.236,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.875 | Acc: 23.066,38.164,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.938 | Acc: 23.438,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.972 | Acc: 22.284,38.058,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.977 | Acc: 22.142,37.271,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.976 | Acc: 22.272,37.193,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 0.838 | Acc: 25.781,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 22.619,38.244,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 22.637,38.396,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.862 | Acc: 22.989,38.665,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.866 | Acc: 23.341,38.493,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 23.236,38.243,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.871 | Acc: 23.263,38.281,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 23.365,38.359,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 23.277,38.204,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 23.222,38.113,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 23.084,38.048,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 23.035,38.044,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 23.042,37.938,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.874 | Acc: 23.114,37.997,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.872 | Acc: 23.140,38.056,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 23.235,38.216,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 23.304,38.230,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 23.355,38.208,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.872 | Acc: 23.379,38.229,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 23.491,38.285,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.950 | Acc: 23.438,37.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.952 | Acc: 21.652,38.132,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.837,37.309,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.957 | Acc: 22.298,37.410,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.906 | Acc: 20.312,36.719,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.876 | Acc: 22.247,38.802,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 22.656,39.539,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 23.002,38.819,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.863 | Acc: 23.052,38.686,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 23.321,38.622,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 23.270,38.824,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.866 | Acc: 23.338,38.664,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.867 | Acc: 23.326,38.577,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.867 | Acc: 23.161,38.415,95.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.866 | Acc: 23.243,38.394,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 23.285,38.380,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 23.227,38.430,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 23.312,38.428,96.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 23.401,38.509,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 23.393,38.406,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 23.309,38.488,95.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 23.314,38.467,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 23.368,38.465,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.869 | Acc: 23.349,38.478,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.930 | Acc: 25.781,35.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.961 | Acc: 21.615,38.132,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.973 | Acc: 21.494,37.424,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.975 | Acc: 21.785,37.244,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 0.861 | Acc: 27.344,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.864 | Acc: 24.070,38.393,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.871 | Acc: 23.342,38.415,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 23.322,38.665,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 23.225,38.262,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 23.291,38.475,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 23.244,38.301,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 23.205,38.381,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 23.127,38.451,95.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 23.183,38.277,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 23.204,38.468,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 23.257,38.493,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 23.249,38.563,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 23.405,38.458,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 23.371,38.479,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 23.354,38.429,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.870 | Acc: 23.386,38.427,95.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 23.254,38.387,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 23.243,38.376,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 23.208,38.357,95.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.917 | Acc: 22.656,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 21.875,38.132,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.975 | Acc: 21.818,37.671,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 21.977,37.718,70.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 0.854 | Acc: 28.125,42.188,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.877 | Acc: 23.140,38.207,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.876 | Acc: 23.209,38.167,95.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.871 | Acc: 22.989,38.128,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 22.994,38.194,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.864 | Acc: 23.058,38.204,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.864 | Acc: 23.128,38.540,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.864 | Acc: 22.972,38.276,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 23.035,38.393,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.863 | Acc: 23.049,38.277,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 23.111,38.238,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.864 | Acc: 23.169,38.264,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.864 | Acc: 23.285,38.408,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 23.432,38.437,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 23.337,38.284,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 23.373,38.367,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 23.413,38.306,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 23.396,38.320,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 23.340,38.249,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 23.380,38.242,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.925 | Acc: 24.219,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 22.210,38.653,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.958 | Acc: 21.989,37.633,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.957 | Acc: 22.464,37.756,70.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.847 | Acc: 25.000,39.844,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 23.847,38.356,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 23.761,38.415,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 23.450,38.358,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.860 | Acc: 23.544,38.349,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.861 | Acc: 23.507,38.475,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 23.657,38.714,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 23.637,38.536,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 23.423,38.407,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 23.312,38.225,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 23.488,38.215,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.864 | Acc: 23.508,38.136,96.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.864 | Acc: 23.421,38.045,96.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 23.417,38.024,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.865 | Acc: 23.418,38.064,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 23.425,38.076,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 23.467,38.099,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.866 | Acc: 23.467,38.075,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 23.483,38.128,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 23.485,38.162,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.992 | Acc: 24.219,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.999 | Acc: 22.247,38.170,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 21.742,37.405,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.987 | Acc: 22.118,37.090,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.873 | Acc: 31.250,47.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 23.661,37.872,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.860 | Acc: 23.609,37.062,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.858 | Acc: 24.462,38.115,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 23.746,37.799,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.859 | Acc: 23.909,37.833,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.859 | Acc: 23.786,37.610,96.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.860 | Acc: 23.698,37.877,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 23.520,38.005,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 23.485,38.221,96.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.866 | Acc: 23.399,38.184,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 23.392,38.158,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 23.421,38.249,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.865 | Acc: 23.452,38.323,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.865 | Acc: 23.446,38.342,95.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 23.443,38.434,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 23.445,38.512,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 23.481,38.563,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 23.470,38.597,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.865 | Acc: 23.444,38.511,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.027 | Acc: 27.344,39.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 21.577,38.839,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.989 | Acc: 21.742,37.691,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.989 | Acc: 22.041,37.743,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 0.803 | Acc: 24.219,45.312,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 22.768,37.091,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 22.523,37.748,96.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 22.567,38.166,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 22.386,37.818,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.860 | Acc: 22.757,37.864,96.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 22.637,37.713,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 22.667,37.727,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 22.661,37.660,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 22.833,38.009,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 22.785,37.920,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.862 | Acc: 22.957,37.998,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 23.036,38.074,96.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.861 | Acc: 23.105,38.236,96.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 23.107,38.262,96.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 23.048,38.216,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.863 | Acc: 23.175,38.296,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 23.259,38.334,96.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 23.336,38.385,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 23.259,38.359,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.922 | Acc: 23.438,40.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.007 | Acc: 21.875,38.393,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.989 | Acc: 21.723,37.805,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.993 | Acc: 22.067,37.743,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.848 | Acc: 23.438,32.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.847 | Acc: 23.028,37.426,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 23.018,38.281,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 22.938,38.294,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.857 | Acc: 23.380,38.358,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 23.329,38.374,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.859 | Acc: 23.360,38.275,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.862 | Acc: 23.299,38.154,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 23.156,38.121,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 23.222,38.238,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 23.107,38.122,96.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 23.165,38.059,96.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.862 | Acc: 23.198,38.161,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.863 | Acc: 23.204,38.251,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 23.276,38.362,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.866 | Acc: 23.248,38.284,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 23.289,38.284,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.866 | Acc: 23.355,38.394,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 23.364,38.424,95.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 23.409,38.445,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.996 | Acc: 24.219,37.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.022 | Acc: 22.284,37.612,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.990 | Acc: 22.027,37.081,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.990 | Acc: 22.310,37.308,70.300,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.833 | Acc: 19.531,33.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.866 | Acc: 22.433,38.318,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.861 | Acc: 22.713,38.034,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 22.387,37.436,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 22.242,37.384,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 22.316,37.608,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 22.663,37.997,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 22.662,37.971,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 22.763,37.976,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.860 | Acc: 22.820,37.996,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.859 | Acc: 22.905,38.165,96.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 23.042,38.193,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 23.130,38.262,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 23.216,38.257,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.860 | Acc: 23.293,38.370,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.861 | Acc: 23.279,38.416,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.860 | Acc: 23.318,38.510,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.860 | Acc: 23.295,38.462,96.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 23.264,38.459,96.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.861 | Acc: 23.276,38.488,96.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.074 | Acc: 25.781,39.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 21.912,38.393,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.976 | Acc: 21.951,37.367,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.987 | Acc: 22.285,37.474,70.223,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.995 | Acc: 10.156,34.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.863 | Acc: 22.805,39.472,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.864 | Acc: 22.961,38.377,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.859 | Acc: 22.964,38.614,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 23.081,38.648,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.853 | Acc: 23.012,38.490,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 23.224,38.914,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 23.354,39.068,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 23.306,39.029,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 23.334,39.071,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.855 | Acc: 23.305,39.024,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 23.247,38.974,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.856 | Acc: 23.217,38.826,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 23.189,38.727,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 23.193,38.757,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.860 | Acc: 23.118,38.681,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 23.187,38.736,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.859 | Acc: 23.195,38.705,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.859 | Acc: 23.234,38.716,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.860 | Acc: 23.253,38.712,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.884 | Acc: 24.219,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.997 | Acc: 22.396,38.765,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 22.409,38.148,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.988 | Acc: 22.541,38.115,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.835 | Acc: 20.312,39.844,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 24.144,38.728,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 23.304,38.491,96.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.846 | Acc: 23.335,38.934,96.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 23.081,38.474,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 23.051,38.366,96.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.850 | Acc: 23.289,38.585,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 23.332,38.547,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 23.282,38.602,96.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.854 | Acc: 23.347,38.627,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 23.379,38.437,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 23.307,38.458,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 23.198,38.524,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 23.255,38.536,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 23.226,38.540,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.858 | Acc: 23.290,38.507,96.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 23.313,38.620,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.860 | Acc: 23.282,38.636,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 23.221,38.591,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.861 | Acc: 23.245,38.659,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.923 | Acc: 23.438,35.938,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.002 | Acc: 21.726,38.207,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.997 | Acc: 21.799,37.405,69.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.006 | Acc: 22.310,37.462,69.826,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 0.932 | Acc: 19.531,29.688,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 24.740,38.839,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 23.228,38.777,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 24.001,39.101,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.847 | Acc: 23.592,38.889,96.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.850 | Acc: 23.670,38.838,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.851 | Acc: 23.618,39.121,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 23.332,38.636,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 23.336,38.480,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 23.325,38.579,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 23.317,38.557,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 23.289,38.398,96.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 23.399,38.502,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.856 | Acc: 23.387,38.419,96.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 23.371,38.468,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 23.373,38.504,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 23.377,38.464,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 23.362,38.481,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 23.364,38.411,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 23.380,38.353,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 25.000,38.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 21.949,38.765,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 21.799,38.091,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.004 | Acc: 21.977,38.128,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.900 | Acc: 32.812,50.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.866 | Acc: 23.251,38.951,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.860 | Acc: 23.609,38.072,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.856 | Acc: 23.297,38.422,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.856 | Acc: 23.283,38.223,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 23.291,38.691,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 23.515,38.765,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.854 | Acc: 23.637,38.863,96.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 23.738,39.004,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 23.830,38.985,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 23.799,39.016,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 23.791,38.882,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 23.677,38.813,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 23.587,38.760,96.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 23.560,38.746,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 23.572,38.759,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 23.596,38.868,96.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 23.547,38.785,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.857 | Acc: 23.518,38.679,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.857 | Acc: 23.513,38.648,96.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.876 | Acc: 24.219,38.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 21.838,38.244,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.973 | Acc: 21.170,37.729,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.976 | Acc: 21.452,37.602,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.842 | Acc: 22.656,39.062,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.845 | Acc: 23.326,39.062,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 23.552,39.444,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 23.489,38.909,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 23.206,38.715,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.853 | Acc: 23.260,38.776,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 23.438,38.791,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 23.244,38.830,96.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 23.277,38.878,96.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.852 | Acc: 23.243,38.929,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 23.142,38.790,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.852 | Acc: 23.179,38.783,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.853 | Acc: 23.149,38.722,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 23.240,38.703,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 23.212,38.732,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 23.155,38.728,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 23.253,38.787,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.856 | Acc: 23.266,38.746,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 23.364,38.818,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 23.401,38.800,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.959 | Acc: 25.000,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 22.210,38.132,69.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 21.951,37.786,68.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.003 | Acc: 22.323,37.961,69.262,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.864 | Acc: 27.344,35.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.853 | Acc: 23.661,38.095,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 23.571,38.186,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 23.412,37.987,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.856 | Acc: 23.360,38.252,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.857 | Acc: 23.244,38.304,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 23.463,38.430,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 23.404,38.370,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 23.486,38.524,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 23.602,38.704,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 23.570,38.806,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 23.558,38.688,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 23.609,38.531,96.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 23.617,38.605,96.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 23.599,38.632,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.859 | Acc: 23.591,38.600,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.859 | Acc: 23.574,38.632,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.859 | Acc: 23.586,38.634,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 23.608,38.695,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 23.618,38.648,96.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.932 | Acc: 21.875,39.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 21.763,38.616,68.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 21.665,38.091,69.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.349,38.012,69.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 0.809 | Acc: 27.344,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 22.879,38.653,96.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.846 | Acc: 23.514,39.082,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 23.617,39.216,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.849 | Acc: 23.640,39.342,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.849 | Acc: 23.554,39.093,96.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 23.263,38.804,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.850 | Acc: 23.271,38.841,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 23.340,38.975,96.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 23.304,38.963,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 23.286,39.024,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 23.413,39.098,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 23.295,38.917,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 23.357,38.955,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 23.374,38.843,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 23.380,38.855,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 23.350,38.912,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.850 | Acc: 23.385,38.797,96.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 23.336,38.863,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 23.323,38.845,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.972 | Acc: 26.562,37.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.040 | Acc: 22.396,38.095,68.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.046,37.424,69.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.310,37.666,69.762,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.859 | Acc: 21.094,35.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.852 | Acc: 24.182,38.579,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 23.285,38.205,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 23.604,37.974,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 23.322,38.021,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 23.213,38.258,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.855 | Acc: 23.334,38.456,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 23.305,38.558,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.854 | Acc: 23.350,38.655,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 23.317,38.709,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.854 | Acc: 23.336,38.829,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 23.370,38.776,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 23.369,38.745,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 23.396,38.844,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 23.474,38.890,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 23.471,38.790,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 23.430,38.851,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 23.499,38.831,96.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 23.435,38.725,96.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.857 | Acc: 23.483,38.661,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.007 | Acc: 26.562,38.281,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.023 | Acc: 22.396,38.876,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 22.561,38.167,69.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.006 | Acc: 22.823,38.345,70.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.828 | Acc: 25.000,38.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 23.996,38.467,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.836 | Acc: 23.266,39.024,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 23.181,38.653,96.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.843 | Acc: 22.955,38.349,96.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 22.873,38.204,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.846 | Acc: 22.837,38.268,96.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 22.828,38.054,96.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 23.161,38.301,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 23.196,38.260,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 23.364,38.546,96.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 23.483,38.762,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 23.444,38.693,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 23.482,38.721,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.850 | Acc: 23.546,38.837,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 23.508,38.806,96.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 23.530,38.802,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 23.536,38.781,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 23.608,38.846,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 23.587,38.788,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.831 | Acc: 24.219,38.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.019 | Acc: 22.396,38.914,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.999 | Acc: 22.466,37.938,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.000 | Acc: 22.810,38.166,70.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 0.838 | Acc: 20.312,41.406,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 23.289,39.249,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.841 | Acc: 23.476,38.834,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.849 | Acc: 23.156,37.935,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 22.975,37.973,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 23.012,38.096,96.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.851 | Acc: 22.986,38.404,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.850 | Acc: 22.994,38.586,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 23.122,38.796,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.850 | Acc: 23.135,38.791,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 23.251,38.798,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 23.293,38.758,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 23.343,38.758,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 23.417,38.775,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 23.360,38.729,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 23.352,38.712,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 23.352,38.732,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 23.394,38.714,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 23.435,38.831,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 23.415,38.757,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.095 | Acc: 23.438,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.035 | Acc: 21.987,38.653,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.044 | Acc: 21.723,38.148,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.044 | Acc: 21.990,37.897,69.749,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.843 | Acc: 28.906,31.250,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 24.256,38.542,96.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 24.181,39.196,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.851 | Acc: 23.732,38.665,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 23.409,38.465,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.850 | Acc: 23.229,38.498,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 23.212,38.533,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 23.210,38.630,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 23.321,38.766,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 23.476,38.786,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.851 | Acc: 23.624,38.969,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 23.621,39.112,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 23.551,39.053,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 23.372,39.024,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 23.365,39.029,96.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 23.448,39.034,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 23.430,39.048,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 23.421,39.065,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.852 | Acc: 23.429,39.021,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 23.431,38.991,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.957 | Acc: 24.219,39.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 22.098,38.393,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 21.951,37.881,69.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.011 | Acc: 22.106,37.897,70.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.826 | Acc: 25.781,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.834 | Acc: 23.438,39.993,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 23.933,40.015,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 23.835,39.805,96.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 23.544,39.198,96.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 23.244,38.892,96.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.838 | Acc: 23.270,38.972,96.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.840 | Acc: 23.205,38.880,96.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 23.229,38.781,96.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.841 | Acc: 23.347,38.886,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 23.290,38.872,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 23.254,38.847,96.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 23.331,38.887,96.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.844 | Acc: 23.291,38.868,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 23.251,38.779,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.845 | Acc: 23.344,38.850,96.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 23.382,38.963,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 23.341,38.854,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 23.336,38.872,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 23.302,38.890,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.935 | Acc: 24.219,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 21.652,39.025,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 21.894,38.014,70.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.007 | Acc: 22.477,37.807,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.836 | Acc: 23.438,40.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 24.330,39.249,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.828 | Acc: 23.552,39.272,97.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 23.630,39.370,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 23.524,39.091,96.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 23.770,39.194,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 23.696,39.050,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 23.604,39.129,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.839 | Acc: 23.578,38.980,96.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 23.455,38.920,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 23.426,38.884,96.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 23.331,38.727,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 23.486,38.887,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 23.611,38.898,96.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 23.451,38.926,96.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.843 | Acc: 23.588,38.946,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 23.630,38.963,96.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.845 | Acc: 23.653,38.904,96.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 23.593,38.831,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 23.597,38.841,96.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.944 | Acc: 24.219,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.014 | Acc: 21.987,39.025,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.104,37.900,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.011 | Acc: 22.451,37.910,70.056,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.786 | Acc: 28.906,37.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 23.512,37.835,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.842 | Acc: 22.466,37.710,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.844 | Acc: 23.143,38.486,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 23.630,38.715,96.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 23.507,38.629,96.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 23.276,38.656,96.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 23.160,38.586,96.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 23.384,38.796,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 23.567,38.937,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 23.663,39.020,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 23.554,38.872,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 23.506,38.858,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 23.542,38.877,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.844 | Acc: 23.643,38.962,96.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.845 | Acc: 23.585,38.979,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.845 | Acc: 23.693,39.053,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.846 | Acc: 23.580,38.996,96.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 23.598,39.017,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.847 | Acc: 23.538,39.011,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.956 | Acc: 25.781,38.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.014 | Acc: 21.763,39.286,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 21.627,38.548,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 22.170,38.307,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.905 | Acc: 23.438,35.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.851 | Acc: 23.065,38.430,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 23.228,38.510,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 23.117,38.742,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.846 | Acc: 23.042,39.014,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.846 | Acc: 23.136,38.916,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 22.992,38.811,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 23.221,38.725,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 23.195,38.626,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 23.161,38.747,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 23.197,38.709,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 23.201,38.956,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 23.337,39.095,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 23.414,38.994,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.850 | Acc: 23.374,38.882,96.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 23.399,38.831,96.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 23.547,38.914,96.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 23.612,39.028,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 23.617,39.039,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 23.583,38.995,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.051 | Acc: 25.000,37.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.027 | Acc: 21.949,38.690,69.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 21.742,38.053,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 22.234,38.179,69.915,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.827 | Acc: 23.438,35.938,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.851 | Acc: 25.000,40.365,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.848 | Acc: 23.780,39.901,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 23.220,39.613,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.849 | Acc: 23.129,39.477,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 23.058,39.217,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 23.315,39.295,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.846 | Acc: 23.476,39.423,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 23.433,39.121,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 23.463,38.959,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 23.585,39.043,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.846 | Acc: 23.639,39.116,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.846 | Acc: 23.833,39.312,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 23.713,39.212,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 23.613,39.115,96.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 23.598,39.078,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 23.601,39.121,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 23.591,39.237,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 23.535,39.223,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.849 | Acc: 23.528,39.177,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.060 | Acc: 21.875,39.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.044 | Acc: 21.912,38.914,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.031 | Acc: 21.742,38.053,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.034 | Acc: 22.093,38.012,69.634,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.761 | Acc: 21.094,43.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.847 | Acc: 23.400,39.249,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 23.704,39.615,96.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.836 | Acc: 24.001,39.127,96.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 24.026,39.458,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 23.824,39.271,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 23.728,39.256,96.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.843 | Acc: 23.582,39.306,96.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 23.700,39.426,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 23.843,39.593,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 23.826,39.478,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 23.798,39.434,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 23.720,39.280,96.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 23.809,39.263,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 23.774,39.227,96.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 23.822,39.223,96.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 23.786,39.170,96.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.844 | Acc: 23.751,39.156,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.844 | Acc: 23.712,39.166,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 23.710,39.181,96.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.071 | Acc: 25.000,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.025 | Acc: 22.247,38.951,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.025 | Acc: 21.989,38.224,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 22.310,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.904 | Acc: 23.438,36.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 23.289,39.993,97.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 23.514,39.196,96.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.838 | Acc: 23.092,38.525,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.836 | Acc: 23.196,38.484,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 23.275,38.544,96.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 23.541,38.979,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 23.792,39.068,96.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 23.704,39.130,96.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 23.826,39.235,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.838 | Acc: 23.713,39.307,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 23.819,39.352,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 23.658,39.199,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 23.602,39.299,96.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 23.543,39.254,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.843 | Acc: 23.508,39.247,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.843 | Acc: 23.469,39.267,96.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.843 | Acc: 23.522,39.248,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 23.507,39.255,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 23.440,39.116,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.094 | Acc: 27.344,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.045 | Acc: 22.210,38.765,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.044 | Acc: 22.313,37.919,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.045 | Acc: 22.490,38.102,69.851,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.790 | Acc: 20.312,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 22.954,39.360,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.830 | Acc: 22.847,39.405,96.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.832 | Acc: 22.772,38.768,96.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.839 | Acc: 22.782,38.455,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 22.896,38.521,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 23.102,38.565,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 23.282,38.553,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 23.171,38.708,96.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 23.368,38.886,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 23.453,38.923,96.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 23.420,38.879,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 23.438,38.874,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 23.435,38.892,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.845 | Acc: 23.510,38.935,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.845 | Acc: 23.526,38.902,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.846 | Acc: 23.481,38.892,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 23.447,38.827,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 23.476,38.809,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 23.495,38.927,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 25.000,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.050 | Acc: 21.354,38.542,69.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.034 | Acc: 21.551,38.129,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.040 | Acc: 21.926,38.089,69.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.822 | Acc: 30.469,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 23.996,39.137,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 23.209,39.196,96.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 23.706,39.447,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.838 | Acc: 23.727,39.651,96.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 24.002,39.743,96.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 23.967,39.566,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 23.798,39.340,96.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.839 | Acc: 23.792,39.266,96.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.842 | Acc: 23.532,39.015,96.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 23.581,38.996,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 23.554,39.070,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 23.626,39.098,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 23.686,39.188,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 23.707,39.165,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.846 | Acc: 23.669,39.109,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 23.659,38.955,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 23.632,38.975,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 23.593,38.978,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.849 | Acc: 23.636,38.948,96.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.224 | Acc: 22.656,39.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.047 | Acc: 21.615,38.951,69.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.032 | Acc: 21.856,38.300,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.037 | Acc: 22.285,38.409,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.890 | Acc: 20.312,34.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 24.442,41.109,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.831 | Acc: 24.562,41.178,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.835 | Acc: 23.886,39.895,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.837 | Acc: 23.997,39.680,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 24.049,39.650,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 23.980,39.411,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 23.692,39.240,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 23.714,39.189,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 23.701,39.170,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 23.663,39.055,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 23.625,39.073,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 23.561,39.088,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 23.509,39.125,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 23.563,39.035,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.846 | Acc: 23.461,39.039,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.846 | Acc: 23.523,39.060,96.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.845 | Acc: 23.481,39.035,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.845 | Acc: 23.489,39.117,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.845 | Acc: 23.493,39.116,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 25.000,39.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.000 | Acc: 21.838,39.435,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.020 | Acc: 22.123,38.739,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 22.554,38.691,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.751 | Acc: 22.656,45.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 23.810,40.997,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.830 | Acc: 24.162,40.149,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.838 | Acc: 23.463,39.101,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.836 | Acc: 23.563,39.140,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 23.685,39.186,96.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 23.502,39.321,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 23.498,39.356,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 23.336,39.223,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.839 | Acc: 23.269,39.196,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.840 | Acc: 23.286,38.954,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.839 | Acc: 23.356,39.031,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 23.392,38.981,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 23.435,38.997,96.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 23.554,39.229,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 23.663,39.314,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 23.640,39.308,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 23.614,39.202,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 23.574,39.246,96.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.842 | Acc: 23.614,39.224,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.870 | Acc: 23.438,37.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.072 | Acc: 21.801,38.988,69.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.065 | Acc: 21.818,38.396,69.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.058 | Acc: 22.093,38.409,69.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.819 | Acc: 28.125,42.188,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 23.847,38.021,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 23.571,38.986,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 23.706,39.383,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 23.698,39.622,96.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.827 | Acc: 23.584,39.604,96.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.826 | Acc: 23.528,39.650,96.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.825 | Acc: 23.354,39.838,97.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.823 | Acc: 23.501,40.077,97.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.824 | Acc: 23.614,39.930,97.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.823 | Acc: 23.507,39.817,97.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.824 | Acc: 23.586,39.762,97.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.824 | Acc: 23.596,39.685,97.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.823 | Acc: 23.554,39.745,97.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.824 | Acc: 23.513,39.652,97.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 23.640,39.644,97.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.822 | Acc: 23.654,39.659,97.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.822 | Acc: 23.614,39.647,97.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.822 | Acc: 23.572,39.604,97.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.823 | Acc: 23.452,39.473,97.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.908 | Acc: 23.438,37.500,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 21.875,39.360,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 22.104,38.815,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.993 | Acc: 22.451,38.896,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.831 | Acc: 27.344,39.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.816 | Acc: 24.926,40.960,96.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.812 | Acc: 24.009,39.787,97.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.809 | Acc: 24.014,39.959,97.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.811 | Acc: 23.833,39.757,97.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.809 | Acc: 24.080,40.122,97.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.808 | Acc: 24.096,39.947,97.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.807 | Acc: 23.775,39.816,97.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.807 | Acc: 23.700,39.800,97.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.807 | Acc: 23.727,39.714,97.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.807 | Acc: 23.647,39.739,97.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.807 | Acc: 23.554,39.575,97.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.806 | Acc: 23.616,39.539,97.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.806 | Acc: 23.626,39.571,97.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.805 | Acc: 23.699,39.635,97.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.806 | Acc: 23.720,39.496,97.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.805 | Acc: 23.725,39.522,97.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.806 | Acc: 23.630,39.447,97.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.806 | Acc: 23.582,39.372,97.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.806 | Acc: 23.583,39.440,97.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.905 | Acc: 24.219,36.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.359,39.844,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 22.313,39.177,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.991 | Acc: 22.477,39.114,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.882 | Acc: 22.656,35.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.814 | Acc: 22.545,39.025,97.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.808 | Acc: 22.771,39.501,97.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.804 | Acc: 22.964,40.113,97.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.801 | Acc: 23.167,39.931,97.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.801 | Acc: 23.175,39.697,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.805 | Acc: 23.011,39.392,97.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.803 | Acc: 22.972,39.384,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.803 | Acc: 23.146,39.363,97.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.803 | Acc: 23.122,39.205,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.802 | Acc: 23.208,39.323,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.801 | Acc: 23.321,39.465,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.802 | Acc: 23.334,39.439,97.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.802 | Acc: 23.393,39.401,97.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.803 | Acc: 23.443,39.332,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.802 | Acc: 23.502,39.475,97.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.802 | Acc: 23.581,39.544,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.801 | Acc: 23.598,39.539,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.801 | Acc: 23.621,39.580,97.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.801 | Acc: 23.612,39.606,97.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.918 | Acc: 25.781,39.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 22.135,39.769,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.992 | Acc: 22.313,39.005,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 22.746,39.127,70.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.765 | Acc: 21.094,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.790 | Acc: 23.698,40.625,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.799 | Acc: 23.533,40.377,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.801 | Acc: 22.989,39.844,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.802 | Acc: 23.389,39.873,97.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.804 | Acc: 23.159,39.759,97.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.804 | Acc: 23.115,39.605,97.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.805 | Acc: 23.055,39.406,97.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.804 | Acc: 23.253,39.548,97.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.802 | Acc: 23.226,39.580,97.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.802 | Acc: 23.329,39.541,97.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.802 | Acc: 23.409,39.511,97.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.802 | Acc: 23.382,39.484,97.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.802 | Acc: 23.237,39.443,97.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.802 | Acc: 23.273,39.385,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.803 | Acc: 23.308,39.286,97.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.803 | Acc: 23.357,39.352,97.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.803 | Acc: 23.376,39.395,97.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.803 | Acc: 23.388,39.365,97.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.802 | Acc: 23.491,39.423,97.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.968 | Acc: 25.000,38.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.000 | Acc: 22.061,40.141,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.999 | Acc: 22.085,39.062,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 22.605,38.986,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.816 | Acc: 19.531,35.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.798 | Acc: 23.549,39.360,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.796 | Acc: 24.047,39.844,98.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.793 | Acc: 24.014,39.895,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.793 | Acc: 24.306,39.921,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.793 | Acc: 24.304,40.145,98.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.796 | Acc: 23.877,39.947,98.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.795 | Acc: 24.025,40.071,97.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.795 | Acc: 23.957,39.955,97.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.795 | Acc: 23.912,39.939,97.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.796 | Acc: 23.923,39.859,97.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.796 | Acc: 23.954,39.847,97.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.797 | Acc: 23.908,39.808,97.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.797 | Acc: 23.881,39.805,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.797 | Acc: 23.810,39.866,97.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.798 | Acc: 23.778,39.810,97.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.800 | Acc: 23.622,39.744,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.800 | Acc: 23.676,39.768,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.800 | Acc: 23.704,39.668,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.800 | Acc: 23.706,39.633,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.924 | Acc: 25.781,37.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.981 | Acc: 22.396,39.509,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.982 | Acc: 22.313,39.005,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.986 | Acc: 22.656,39.062,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.807 | Acc: 21.094,38.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.796 | Acc: 23.512,40.290,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.802 | Acc: 23.895,40.339,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.802 | Acc: 23.604,39.703,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.802 | Acc: 23.679,39.497,97.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.800 | Acc: 23.809,39.968,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.797 | Acc: 23.696,39.889,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.798 | Acc: 23.648,39.661,97.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.797 | Acc: 23.763,39.713,97.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.797 | Acc: 23.584,39.580,97.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.797 | Acc: 23.574,39.513,97.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.797 | Acc: 23.703,39.533,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.797 | Acc: 23.726,39.604,97.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.797 | Acc: 23.629,39.556,97.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.797 | Acc: 23.721,39.632,97.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.796 | Acc: 23.752,39.662,97.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.796 | Acc: 23.817,39.715,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.797 | Acc: 23.799,39.674,97.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.797 | Acc: 23.717,39.649,97.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.797 | Acc: 23.704,39.589,97.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.995 | Acc: 24.219,37.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 22.135,39.769,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 22.275,39.062,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.993 | Acc: 22.618,39.152,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.796 | Acc: 24.219,44.531,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.791 | Acc: 24.405,40.402,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.795 | Acc: 23.780,39.596,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.794 | Acc: 23.963,39.472,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.795 | Acc: 23.900,39.583,98.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.795 | Acc: 23.770,39.465,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.797 | Acc: 23.838,39.301,97.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.797 | Acc: 23.759,39.146,98.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.795 | Acc: 23.748,39.203,98.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.795 | Acc: 23.632,39.127,98.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.796 | Acc: 23.535,39.144,98.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.796 | Acc: 23.469,39.112,98.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.796 | Acc: 23.544,39.241,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.797 | Acc: 23.530,39.323,97.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.796 | Acc: 23.538,39.371,97.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.795 | Acc: 23.601,39.522,98.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.794 | Acc: 23.686,39.571,98.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.794 | Acc: 23.612,39.502,98.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.795 | Acc: 23.593,39.528,98.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.795 | Acc: 23.620,39.594,98.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 24.219,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.098,39.583,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.999 | Acc: 22.161,39.024,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 22.528,38.998,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.777 | Acc: 27.344,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.792 | Acc: 23.586,39.360,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.797 | Acc: 24.505,40.225,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.795 | Acc: 24.244,40.164,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.793 | Acc: 24.103,40.201,97.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.798 | Acc: 23.770,39.875,97.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.796 | Acc: 23.760,39.799,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.794 | Acc: 23.775,39.655,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.794 | Acc: 23.763,39.761,97.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.793 | Acc: 23.813,39.693,97.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.793 | Acc: 23.737,39.630,97.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.793 | Acc: 23.639,39.607,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.792 | Acc: 23.674,39.675,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.793 | Acc: 23.680,39.640,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.793 | Acc: 23.538,39.513,98.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.793 | Acc: 23.531,39.600,97.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.792 | Acc: 23.581,39.664,98.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.793 | Acc: 23.584,39.631,97.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.793 | Acc: 23.658,39.731,97.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.793 | Acc: 23.739,39.764,98.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.952 | Acc: 25.000,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 21.801,40.253,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.996 | Acc: 22.161,39.215,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 22.541,39.229,70.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.836 | Acc: 19.531,30.469,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.785 | Acc: 24.107,40.737,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.787 | Acc: 24.771,40.396,98.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.788 | Acc: 24.308,40.266,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.793 | Acc: 23.929,39.699,98.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.793 | Acc: 23.793,39.519,98.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.790 | Acc: 24.193,39.779,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.790 | Acc: 23.942,39.456,98.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.791 | Acc: 24.039,39.378,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.791 | Acc: 24.029,39.524,98.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.791 | Acc: 24.141,39.607,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.791 | Acc: 23.975,39.434,98.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.792 | Acc: 23.911,39.455,98.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.791 | Acc: 23.881,39.431,98.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.792 | Acc: 23.880,39.482,98.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.791 | Acc: 23.892,39.517,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.792 | Acc: 23.783,39.540,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.793 | Acc: 23.804,39.541,98.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.793 | Acc: 23.760,39.485,98.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.793 | Acc: 23.788,39.448,98.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.979 | Acc: 25.000,36.719,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 21.801,39.286,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 22.085,38.662,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 22.515,38.845,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.796 | Acc: 25.781,40.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.790 | Acc: 24.256,40.030,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.789 | Acc: 24.066,40.530,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.788 | Acc: 23.194,39.664,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.790 | Acc: 23.486,39.603,98.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.790 | Acc: 23.631,39.836,98.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.790 | Acc: 23.689,39.779,98.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.792 | Acc: 23.454,39.561,98.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.792 | Acc: 23.423,39.684,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.792 | Acc: 23.446,39.844,98.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.794 | Acc: 23.418,39.704,97.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.793 | Acc: 23.483,39.667,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.792 | Acc: 23.515,39.759,98.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.793 | Acc: 23.533,39.718,98.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.793 | Acc: 23.499,39.607,98.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.794 | Acc: 23.536,39.525,98.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.793 | Acc: 23.608,39.605,98.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.793 | Acc: 23.712,39.736,98.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.793 | Acc: 23.708,39.744,98.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.792 | Acc: 23.770,39.774,98.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.974 | Acc: 25.000,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.173,39.918,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 22.313,39.043,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.000 | Acc: 22.772,39.037,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.820 | Acc: 22.656,37.500,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.787 | Acc: 24.330,40.476,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.789 | Acc: 23.685,40.034,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.790 | Acc: 23.361,40.023,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.790 | Acc: 23.389,39.998,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.787 | Acc: 23.600,40.076,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.790 | Acc: 23.295,39.689,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.792 | Acc: 23.271,39.583,98.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.792 | Acc: 23.287,39.465,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.792 | Acc: 23.412,39.641,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.792 | Acc: 23.344,39.583,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.791 | Acc: 23.434,39.649,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.791 | Acc: 23.532,39.711,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.791 | Acc: 23.509,39.649,98.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.790 | Acc: 23.621,39.830,98.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.790 | Acc: 23.778,39.883,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.790 | Acc: 23.798,39.875,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.790 | Acc: 23.816,39.906,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.790 | Acc: 23.825,39.850,98.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.790 | Acc: 23.874,39.852,98.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.976 | Acc: 25.000,36.719,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 21.912,39.695,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.990 | Acc: 22.027,38.910,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 22.259,38.858,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.792 | Acc: 25.000,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.779 | Acc: 24.554,39.769,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.782 | Acc: 24.123,39.996,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.782 | Acc: 23.963,40.087,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.786 | Acc: 23.910,40.268,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.785 | Acc: 23.963,40.292,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.787 | Acc: 23.993,40.263,98.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.788 | Acc: 23.964,40.110,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.787 | Acc: 23.928,40.159,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.788 | Acc: 23.951,40.120,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.787 | Acc: 23.943,40.096,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.787 | Acc: 23.989,40.233,98.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.787 | Acc: 23.982,40.210,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.788 | Acc: 23.946,40.179,98.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.788 | Acc: 23.921,40.133,98.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.788 | Acc: 23.954,40.168,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.787 | Acc: 23.958,40.073,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.787 | Acc: 23.880,40.004,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 23.892,39.954,98.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 23.807,39.899,98.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.024 | Acc: 25.000,36.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 22.396,39.918,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 22.561,39.177,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.993 | Acc: 22.784,39.178,70.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.717 | Acc: 35.938,50.781,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.786 | Acc: 22.507,39.435,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.795 | Acc: 23.190,39.691,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.796 | Acc: 23.438,39.946,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.794 | Acc: 23.669,39.969,97.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.791 | Acc: 23.577,39.790,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.792 | Acc: 23.567,39.689,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.793 | Acc: 23.604,39.678,97.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.792 | Acc: 23.462,39.431,97.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.792 | Acc: 23.472,39.546,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.792 | Acc: 23.457,39.486,98.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.792 | Acc: 23.402,39.543,98.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.791 | Acc: 23.476,39.594,98.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.792 | Acc: 23.488,39.625,98.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.790 | Acc: 23.454,39.791,98.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.790 | Acc: 23.591,39.948,98.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.789 | Acc: 23.654,40.004,98.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.789 | Acc: 23.724,39.972,98.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.789 | Acc: 23.784,39.928,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.789 | Acc: 23.700,39.959,98.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.986 | Acc: 25.000,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 22.656,40.439,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.990 | Acc: 22.618,39.386,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 22.900,39.383,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.796 | Acc: 14.062,37.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.795 | Acc: 22.879,38.021,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.787 | Acc: 23.990,38.739,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.787 | Acc: 23.719,39.575,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.789 | Acc: 23.351,39.024,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.790 | Acc: 23.422,39.070,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.789 | Acc: 23.521,39.347,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.789 | Acc: 23.465,39.245,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.788 | Acc: 23.510,39.300,98.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.788 | Acc: 23.498,39.378,98.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.788 | Acc: 23.593,39.319,98.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.788 | Acc: 23.597,39.384,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.788 | Acc: 23.577,39.452,98.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.788 | Acc: 23.617,39.494,98.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.789 | Acc: 23.604,39.543,98.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.789 | Acc: 23.624,39.571,98.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.788 | Acc: 23.649,39.603,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.789 | Acc: 23.644,39.569,98.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 23.715,39.595,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 23.692,39.561,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.009 | Acc: 25.781,39.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 22.396,40.327,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 22.542,39.558,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.001 | Acc: 22.772,39.575,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.786 | Acc: 25.781,39.844,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.786 | Acc: 23.214,39.695,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.788 | Acc: 23.342,39.672,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.787 | Acc: 23.258,40.190,98.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 23.592,40.606,98.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 23.747,40.215,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.783 | Acc: 23.844,40.425,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.784 | Acc: 23.969,40.287,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.785 | Acc: 23.986,40.159,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.785 | Acc: 23.990,40.172,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.786 | Acc: 23.970,40.147,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.787 | Acc: 23.971,40.052,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.787 | Acc: 23.930,39.993,98.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.785 | Acc: 23.901,40.113,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.785 | Acc: 23.880,40.152,98.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.785 | Acc: 23.759,40.062,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.785 | Acc: 23.727,40.004,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.786 | Acc: 23.701,39.912,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.787 | Acc: 23.650,39.783,98.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.786 | Acc: 23.694,39.756,98.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.991 | Acc: 24.219,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 22.433,40.179,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.991 | Acc: 22.561,39.272,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.998 | Acc: 22.772,39.293,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.776 | Acc: 20.312,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.792 | Acc: 23.438,39.025,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.795 | Acc: 23.380,38.834,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.789 | Acc: 23.489,39.344,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.790 | Acc: 23.611,39.622,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.789 | Acc: 23.801,39.689,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.788 | Acc: 23.702,39.882,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.787 | Acc: 23.737,40.016,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.789 | Acc: 23.675,39.878,98.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.789 | Acc: 23.830,39.943,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.790 | Acc: 23.624,39.789,98.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.789 | Acc: 23.738,39.830,98.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.788 | Acc: 23.814,39.802,98.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.788 | Acc: 23.881,39.913,98.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.788 | Acc: 23.785,39.788,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.788 | Acc: 23.788,39.833,98.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.788 | Acc: 23.854,39.995,98.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.787 | Acc: 23.880,39.997,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 23.847,39.982,98.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 23.835,39.961,98.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.008 | Acc: 25.781,39.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.507,39.621,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.991 | Acc: 22.523,38.834,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 22.874,39.062,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.792 | Acc: 28.906,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.779 | Acc: 25.186,41.592,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.777 | Acc: 24.428,40.663,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 24.347,40.061,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 24.045,40.278,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.780 | Acc: 23.987,40.099,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.781 | Acc: 24.083,39.786,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 24.108,39.799,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 24.010,39.732,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 23.986,39.736,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.781 | Acc: 24.075,39.797,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.781 | Acc: 23.971,39.713,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.782 | Acc: 23.950,39.633,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.783 | Acc: 23.881,39.739,98.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.783 | Acc: 23.857,39.838,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.784 | Acc: 23.783,39.787,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.784 | Acc: 23.834,39.856,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.784 | Acc: 23.841,39.800,98.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.785 | Acc: 23.860,39.800,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.785 | Acc: 23.872,39.811,98.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.007 | Acc: 25.000,38.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 21.949,39.844,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 22.180,39.043,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.995 | Acc: 22.541,39.178,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.758 | Acc: 24.219,34.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 24.740,39.807,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.779 | Acc: 24.600,39.043,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.781 | Acc: 24.590,39.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.782 | Acc: 24.431,39.313,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 24.381,39.325,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.784 | Acc: 24.257,39.269,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.784 | Acc: 24.119,39.179,98.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.785 | Acc: 23.869,39.082,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.786 | Acc: 23.839,39.265,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.786 | Acc: 23.900,39.350,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.786 | Acc: 23.911,39.321,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.786 | Acc: 23.911,39.351,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.786 | Acc: 23.872,39.341,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.785 | Acc: 23.930,39.457,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.785 | Acc: 24.058,39.550,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.785 | Acc: 24.036,39.564,98.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.785 | Acc: 24.013,39.718,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.785 | Acc: 23.972,39.733,98.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.785 | Acc: 24.040,39.797,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 27.344,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.000 | Acc: 22.731,39.583,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 22.428,38.967,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 22.887,39.139,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.789 | Acc: 22.656,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.789 | Acc: 25.446,40.290,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.792 | Acc: 24.905,40.263,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.789 | Acc: 24.321,40.266,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.789 | Acc: 24.595,40.519,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.790 | Acc: 24.110,40.192,98.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.791 | Acc: 23.799,39.992,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.789 | Acc: 23.986,40.132,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.788 | Acc: 24.088,40.276,98.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.788 | Acc: 24.007,40.288,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.788 | Acc: 24.009,40.217,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.788 | Acc: 24.000,40.197,98.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.788 | Acc: 24.031,40.298,98.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.788 | Acc: 24.072,40.239,98.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.788 | Acc: 24.049,40.197,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.788 | Acc: 23.985,40.179,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.789 | Acc: 23.883,40.036,98.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.788 | Acc: 23.850,40.034,98.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.789 | Acc: 23.847,40.047,98.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.789 | Acc: 23.854,39.983,98.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.007 | Acc: 25.781,39.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 22.433,40.327,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 22.504,39.596,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.001 | Acc: 22.772,39.395,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.757 | Acc: 29.688,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.785 | Acc: 22.731,40.327,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.785 | Acc: 23.114,39.920,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.786 | Acc: 22.900,39.536,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 23.322,39.786,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 23.677,39.550,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.785 | Acc: 23.644,39.230,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.786 | Acc: 23.559,39.306,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.786 | Acc: 23.554,39.407,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.786 | Acc: 23.619,39.460,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.786 | Acc: 23.710,39.642,98.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.786 | Acc: 23.710,39.625,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.786 | Acc: 23.697,39.734,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.786 | Acc: 23.725,39.667,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.786 | Acc: 23.663,39.730,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.786 | Acc: 23.656,39.693,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.786 | Acc: 23.657,39.776,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.786 | Acc: 23.621,39.757,98.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.786 | Acc: 23.643,39.805,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.786 | Acc: 23.671,39.883,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.973 | Acc: 25.000,39.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.017 | Acc: 22.470,40.365,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.012 | Acc: 22.313,39.291,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 22.618,39.460,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.768 | Acc: 20.312,38.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.784 | Acc: 24.219,39.360,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 24.104,39.768,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 23.963,39.985,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.784 | Acc: 23.727,39.786,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.785 | Acc: 23.360,39.735,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.786 | Acc: 23.308,39.786,98.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.787 | Acc: 23.493,39.744,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.787 | Acc: 23.564,39.776,98.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.785 | Acc: 23.722,39.697,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.785 | Acc: 23.811,39.766,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.785 | Acc: 23.925,40.003,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.785 | Acc: 23.933,39.970,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.785 | Acc: 23.967,39.957,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.786 | Acc: 23.949,39.938,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.787 | Acc: 23.931,39.971,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.786 | Acc: 23.915,39.941,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.786 | Acc: 23.841,39.931,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.786 | Acc: 23.786,39.818,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.787 | Acc: 23.733,39.795,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.000 | Acc: 25.781,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.007 | Acc: 22.470,40.104,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 22.485,39.348,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 22.772,39.434,70.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.795 | Acc: 25.781,38.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.787 | Acc: 24.182,39.621,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 24.943,40.987,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 24.475,41.060,98.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 24.334,40.799,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 24.134,40.586,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.786 | Acc: 23.909,40.412,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.787 | Acc: 23.958,40.221,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.786 | Acc: 23.952,40.179,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.786 | Acc: 24.037,40.258,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.786 | Acc: 24.056,40.407,98.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.786 | Acc: 24.028,40.363,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.786 | Acc: 24.037,40.353,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.786 | Acc: 24.108,40.332,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.786 | Acc: 24.119,40.291,98.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.785 | Acc: 24.112,40.321,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.786 | Acc: 24.048,40.216,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.786 | Acc: 24.024,40.139,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.786 | Acc: 23.922,40.054,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.786 | Acc: 23.889,39.989,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.016 | Acc: 25.000,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 22.507,40.290,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 22.485,39.386,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.008 | Acc: 22.810,39.460,70.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.785 | Acc: 21.094,39.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 23.996,39.881,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.787 | Acc: 24.009,39.139,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.785 | Acc: 24.270,39.383,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.786 | Acc: 23.862,39.603,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 23.716,39.581,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.784 | Acc: 23.651,39.682,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.784 | Acc: 23.460,39.711,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.783 | Acc: 23.617,39.664,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.782 | Acc: 23.770,39.788,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.784 | Acc: 23.640,39.517,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.783 | Acc: 23.833,39.762,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.783 | Acc: 23.836,39.821,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 23.779,39.790,98.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.784 | Acc: 23.757,39.788,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.767,39.797,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.783 | Acc: 23.761,39.858,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.783 | Acc: 23.838,39.880,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.783 | Acc: 23.849,39.887,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.783 | Acc: 23.919,39.979,98.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.967 | Acc: 25.000,36.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.433,40.513,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 22.599,39.501,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 22.810,39.511,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.736 | Acc: 25.000,46.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.782 | Acc: 24.144,40.104,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.783 | Acc: 23.914,39.958,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.787 | Acc: 23.386,39.677,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.783 | Acc: 23.669,39.892,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.783 | Acc: 23.561,39.720,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.785 | Acc: 23.715,39.766,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.786 | Acc: 23.648,39.428,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.785 | Acc: 23.767,39.650,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.784 | Acc: 23.912,39.645,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.784 | Acc: 23.908,39.591,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.784 | Acc: 24.084,39.766,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.784 | Acc: 24.157,39.886,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 24.222,39.969,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.785 | Acc: 24.174,40.011,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.786 | Acc: 24.193,39.955,98.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.786 | Acc: 24.134,39.895,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.785 | Acc: 24.166,39.945,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.785 | Acc: 24.134,39.820,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.786 | Acc: 24.030,39.805,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.966 | Acc: 25.781,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 22.135,40.402,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 22.351,39.748,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 22.682,39.793,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.752 | Acc: 26.562,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 24.144,39.955,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 24.123,39.386,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 23.886,39.280,98.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.782 | Acc: 23.785,39.545,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.783 | Acc: 23.956,39.735,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.783 | Acc: 24.109,39.863,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.782 | Acc: 24.269,40.071,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.782 | Acc: 24.059,39.955,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.782 | Acc: 24.016,39.960,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.784 | Acc: 23.954,39.902,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.785 | Acc: 23.855,39.745,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.784 | Acc: 23.956,39.821,98.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 23.931,39.793,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.784 | Acc: 23.916,39.721,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.784 | Acc: 23.902,39.659,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.784 | Acc: 23.924,39.763,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.784 | Acc: 23.960,39.798,98.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.784 | Acc: 23.989,39.807,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.784 | Acc: 23.930,39.784,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.021 | Acc: 25.781,39.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.997 | Acc: 22.545,40.104,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.998 | Acc: 22.694,39.386,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 23.040,39.421,70.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.759 | Acc: 28.125,39.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.784 | Acc: 22.507,39.025,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.787 | Acc: 23.304,39.291,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.785 | Acc: 23.438,39.498,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.788 | Acc: 23.351,39.516,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.788 | Acc: 23.438,39.356,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.788 | Acc: 23.399,39.469,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.788 | Acc: 23.310,39.328,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.787 | Acc: 23.428,39.286,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.786 | Acc: 23.671,39.529,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.786 | Acc: 23.760,39.556,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.785 | Acc: 23.777,39.748,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.785 | Acc: 23.895,39.841,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.783 | Acc: 23.970,39.963,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.783 | Acc: 24.149,40.063,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 24.138,40.150,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.783 | Acc: 24.112,40.082,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.783 | Acc: 24.129,40.103,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.783 | Acc: 24.145,40.002,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.783 | Acc: 24.047,39.948,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 24.219,39.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.007 | Acc: 22.582,40.476,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 22.656,39.482,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.912,39.472,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.826 | Acc: 23.438,34.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.790 | Acc: 22.656,38.951,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.786 | Acc: 22.771,39.768,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.781 | Acc: 23.271,40.023,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.783 | Acc: 23.167,39.921,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 23.128,40.161,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.785 | Acc: 23.147,40.050,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.784 | Acc: 23.360,40.038,98.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.785 | Acc: 23.229,39.970,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.785 | Acc: 23.304,39.978,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.784 | Acc: 23.476,39.972,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.784 | Acc: 23.590,39.914,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.784 | Acc: 23.593,39.922,98.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 23.656,39.901,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.783 | Acc: 23.702,39.999,98.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.741,39.963,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.782 | Acc: 23.781,40.019,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.782 | Acc: 23.884,40.061,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.782 | Acc: 23.948,40.114,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.781 | Acc: 23.926,40.075,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.974 | Acc: 25.781,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.999 | Acc: 22.247,40.699,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 22.466,39.672,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.010 | Acc: 22.900,39.434,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.819 | Acc: 22.656,35.938,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.788 | Acc: 22.842,39.360,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.791 | Acc: 22.942,39.043,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.787 | Acc: 23.476,39.728,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.787 | Acc: 23.466,39.853,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.787 | Acc: 23.461,39.836,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.786 | Acc: 23.631,39.773,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.786 | Acc: 23.426,39.794,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.785 | Acc: 23.277,39.722,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.785 | Acc: 23.338,39.688,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.784 | Acc: 23.383,39.715,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.785 | Acc: 23.572,39.745,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.783 | Acc: 23.674,39.782,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.783 | Acc: 23.749,39.679,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.783 | Acc: 23.874,39.746,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.816,39.789,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.783 | Acc: 23.822,39.795,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.784 | Acc: 23.742,39.780,98.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.784 | Acc: 23.719,39.818,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.783 | Acc: 23.805,39.911,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.010 | Acc: 25.000,37.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 22.768,40.104,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.885,39.310,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 23.028,39.229,70.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.767 | Acc: 28.906,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.784 | Acc: 23.326,39.025,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.783 | Acc: 23.438,39.386,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.782 | Acc: 24.155,39.703,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 24.257,39.815,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.783 | Acc: 23.894,39.728,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.783 | Acc: 23.883,39.882,98.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.783 | Acc: 23.853,39.827,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.783 | Acc: 23.569,39.523,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.782 | Acc: 23.744,39.740,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.803,39.844,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.783 | Acc: 23.791,39.777,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.782 | Acc: 23.801,39.860,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.783 | Acc: 23.716,39.784,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.782 | Acc: 23.779,39.799,98.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.783,39.833,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.783 | Acc: 23.800,39.802,98.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.782 | Acc: 23.772,39.757,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.782 | Acc: 23.855,39.779,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.782 | Acc: 23.778,39.797,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 24.219,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.002 | Acc: 22.433,39.993,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 22.294,39.139,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 22.720,39.101,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.794 | Acc: 15.625,36.719,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.779 | Acc: 23.586,40.737,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.778 | Acc: 24.371,39.958,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 24.039,40.036,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.779 | Acc: 24.074,40.152,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.963,40.254,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 24.032,40.309,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 24.008,40.348,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 24.034,40.193,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 24.007,40.150,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.954,40.069,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.781 | Acc: 23.886,40.013,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.780 | Acc: 23.921,40.054,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 24.033,40.131,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.781 | Acc: 23.932,40.063,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.781 | Acc: 24.011,40.114,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.781 | Acc: 24.041,40.063,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.781 | Acc: 24.118,40.116,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.781 | Acc: 24.128,40.084,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.781 | Acc: 24.131,40.067,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.991 | Acc: 25.000,39.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.008 | Acc: 22.545,40.253,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 22.561,39.558,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.014 | Acc: 22.874,39.600,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.836 | Acc: 22.656,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.793 | Acc: 22.693,38.356,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.787 | Acc: 24.009,39.120,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.787 | Acc: 23.899,39.434,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 23.794,39.497,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.784 | Acc: 23.840,39.496,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.782 | Acc: 23.812,39.573,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 23.820,39.600,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 23.787,39.630,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 23.951,39.680,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 23.931,39.770,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.780 | Acc: 23.922,39.752,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 23.959,39.662,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 23.824,39.604,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.780 | Acc: 23.832,39.716,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.874,39.877,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.944,39.963,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.944,39.951,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.888,39.956,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.889,39.987,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.027 | Acc: 24.219,39.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 22.582,40.179,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.618,39.367,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.887,39.485,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.787 | Acc: 28.125,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 23.661,40.365,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 23.761,40.187,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 23.822,40.061,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.782 | Acc: 24.035,40.133,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 23.987,39.836,98.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.782 | Acc: 23.896,39.902,98.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 23.792,39.993,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 23.860,39.946,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 23.783,39.887,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.780 | Acc: 23.783,39.929,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.780 | Acc: 23.752,39.847,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 23.827,39.918,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 23.842,40.101,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 23.707,39.974,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.687,40.007,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.530,39.902,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.781 | Acc: 23.531,39.876,98.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.539,39.885,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.781 | Acc: 23.628,39.942,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.963 | Acc: 25.781,39.062,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 22.433,40.030,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.007 | Acc: 22.713,39.329,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.951,39.344,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.774 | Acc: 19.531,35.156,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.784 | Acc: 23.624,40.141,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 23.990,40.511,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 23.732,40.625,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.782 | Acc: 23.852,40.500,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 23.847,40.494,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.782 | Acc: 23.760,40.502,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.783 | Acc: 23.631,40.281,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.782 | Acc: 23.593,40.256,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 23.563,40.258,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.539,40.197,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.782 | Acc: 23.614,40.066,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.782 | Acc: 23.684,40.100,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.782 | Acc: 23.725,40.101,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.781 | Acc: 23.949,40.169,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.781 | Acc: 23.931,40.168,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.781 | Acc: 23.949,40.116,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.781 | Acc: 23.923,40.096,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.781 | Acc: 23.927,40.209,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.781 | Acc: 23.915,40.149,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.976 | Acc: 25.000,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.015 | Acc: 22.433,39.807,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.409,39.101,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 22.720,39.101,70.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.747 | Acc: 21.094,41.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.783 | Acc: 23.214,39.323,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.783 | Acc: 22.904,39.482,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 23.425,39.780,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.784 | Acc: 23.312,39.718,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.781 | Acc: 23.731,39.921,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.781 | Acc: 23.521,39.734,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.779 | Acc: 23.548,39.888,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.622,39.907,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.778 | Acc: 23.813,40.012,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.861,40.201,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.993,40.293,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 24.024,40.191,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 24.108,40.155,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 24.088,40.138,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 24.081,40.059,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 24.095,40.124,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 23.990,40.036,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 24.046,39.997,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.940,39.936,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.953 | Acc: 24.219,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.006 | Acc: 22.321,40.104,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.012 | Acc: 22.523,39.405,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.797,39.549,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.838 | Acc: 19.531,35.938,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 23.438,40.141,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 22.961,39.501,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 22.938,39.319,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 23.187,39.361,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.499,39.588,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 23.612,39.663,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 23.504,39.816,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.476,39.868,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 23.425,39.805,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 23.352,39.727,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.779 | Acc: 23.505,39.734,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.551,39.772,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 23.569,39.742,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.588,39.766,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 23.617,39.691,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 23.608,39.693,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.703,39.828,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 23.656,39.785,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 23.682,39.813,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.007 | Acc: 24.219,38.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 22.768,40.402,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.790,39.539,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 22.938,39.395,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.808 | Acc: 19.531,27.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 23.921,39.695,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 24.143,39.882,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.781 | Acc: 23.796,39.600,98.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.779 | Acc: 24.209,40.143,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 23.979,39.766,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.780 | Acc: 23.954,39.811,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.875,39.838,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 23.734,39.693,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 23.684,39.619,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.764,39.684,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.781 | Acc: 23.862,39.695,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.782 | Acc: 23.914,39.717,98.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.782 | Acc: 23.934,39.799,98.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.782 | Acc: 23.857,39.796,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.905,39.955,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.781 | Acc: 23.961,39.973,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.781 | Acc: 23.845,39.896,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.781 | Acc: 23.818,39.850,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.782 | Acc: 23.846,39.911,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.955 | Acc: 25.781,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 23.103,40.365,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 22.866,39.425,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 23.220,39.344,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.738 | Acc: 25.000,39.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 23.772,39.881,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.783 | Acc: 23.228,39.139,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.784 | Acc: 23.694,39.652,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.783 | Acc: 23.225,39.487,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.783 | Acc: 23.592,39.859,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.781 | Acc: 23.941,40.057,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.782 | Acc: 23.992,39.877,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.784 | Acc: 23.932,39.747,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.783 | Acc: 23.986,39.801,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.783 | Acc: 23.904,39.844,98.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.783 | Acc: 23.894,39.826,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.782 | Acc: 23.911,39.863,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.782 | Acc: 23.889,39.922,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.782 | Acc: 24.052,40.049,98.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.970,39.984,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.784 | Acc: 23.980,39.834,98.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.784 | Acc: 23.889,39.867,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.784 | Acc: 23.881,39.833,98.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.784 | Acc: 23.882,39.897,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 21.875,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 22.061,40.104,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.066,39.348,70.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.413,39.293,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.823 | Acc: 15.625,32.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.789 | Acc: 22.247,39.137,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 22.771,39.825,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 22.976,39.408,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.777 | Acc: 23.351,39.651,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.175,39.449,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.780 | Acc: 23.270,39.540,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.393,39.567,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 23.268,39.436,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 23.196,39.490,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.781 | Acc: 23.321,39.498,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.781 | Acc: 23.367,39.533,98.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.781 | Acc: 23.356,39.571,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.782 | Acc: 23.381,39.544,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.782 | Acc: 23.468,39.607,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.781 | Acc: 23.694,39.732,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.781 | Acc: 23.681,39.700,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.781 | Acc: 23.742,39.832,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.795,39.881,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.796,39.868,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.018 | Acc: 23.438,39.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 22.433,40.365,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 22.523,39.386,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 22.733,39.434,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.794 | Acc: 19.531,34.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.781 | Acc: 21.987,37.872,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.771 | Acc: 24.181,39.882,98.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.847,40.228,98.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.779 | Acc: 23.717,40.046,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 23.832,40.122,98.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 23.973,40.257,98.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 23.986,40.265,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 24.083,40.227,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 24.025,40.146,98.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 24.122,39.980,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 24.127,40.038,98.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 24.183,40.158,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 24.093,39.975,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 24.049,39.933,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.779 | Acc: 24.084,40.020,98.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 24.087,40.075,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 24.061,40.036,98.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 24.072,40.017,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 24.059,40.045,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.037 | Acc: 25.000,39.062,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 22.396,39.732,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.370,39.101,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.014 | Acc: 22.746,39.152,70.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.727 | Acc: 29.688,47.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 23.624,39.881,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 24.085,40.130,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.777 | Acc: 23.527,39.818,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.777 | Acc: 23.900,40.008,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 23.801,40.006,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 23.922,40.199,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 24.064,40.132,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.986,40.096,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 23.917,40.202,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.850,40.159,98.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.922,40.052,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 23.972,39.996,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 23.937,39.916,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.985,40.013,98.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 24.019,40.051,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 24.087,40.041,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 24.015,39.970,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 24.015,39.971,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 24.067,39.985,98.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.028 | Acc: 26.562,39.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 22.879,40.365,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.012 | Acc: 22.866,39.386,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.019 | Acc: 23.156,39.626,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.768 | Acc: 22.656,38.281,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 24.516,40.625,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.782 | Acc: 23.704,40.282,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 23.591,39.716,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.782 | Acc: 23.698,39.824,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 23.654,39.674,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.781 | Acc: 23.702,39.818,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 23.659,39.428,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 23.782,39.344,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.778 | Acc: 24.037,39.628,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 24.013,39.599,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 24.155,39.702,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 23.937,39.558,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 23.824,39.559,98.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 23.874,39.657,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.779 | Acc: 23.858,39.745,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 23.880,39.768,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 23.859,39.793,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 23.786,39.710,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 23.831,39.694,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.986 | Acc: 25.000,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 22.210,40.030,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.014 | Acc: 22.370,39.272,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 22.682,39.331,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.778 | Acc: 21.875,38.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 23.549,40.216,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.037,39.672,98.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 23.553,40.318,98.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 23.881,40.451,98.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.569,40.099,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.935,40.360,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 24.058,40.547,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 24.049,40.484,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 24.176,40.556,98.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 24.133,40.473,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 24.106,40.431,98.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 24.053,40.304,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.979,40.188,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.941,40.125,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.779 | Acc: 23.866,40.098,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 23.849,40.097,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.793,39.993,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 23.860,39.961,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 23.889,39.965,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.989 | Acc: 25.781,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 22.359,40.216,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 22.199,39.444,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.554,39.383,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.744 | Acc: 28.906,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 24.293,40.476,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 24.009,40.854,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 23.911,39.959,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 23.881,39.525,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.780 | Acc: 23.840,39.434,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.780 | Acc: 23.948,39.521,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 23.980,39.589,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 23.962,39.596,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.778 | Acc: 24.029,39.826,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.927,39.832,98.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.971,39.812,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.891,39.756,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 23.961,39.889,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.918,39.830,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.779 | Acc: 23.915,39.781,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.888,39.798,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.923,39.844,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 23.950,39.865,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 24.003,39.897,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 25.781,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.017 | Acc: 22.507,40.141,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.014 | Acc: 22.542,39.425,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.797,39.370,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.775 | Acc: 24.219,32.031,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 23.400,40.253,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.778 | Acc: 23.152,39.691,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 23.399,40.138,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.781 | Acc: 23.582,40.230,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.780 | Acc: 23.739,40.184,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 23.857,40.283,98.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.753,40.115,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.850,40.276,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.778 | Acc: 23.856,40.133,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.974,40.310,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.993,40.141,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.872,40.178,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.779,40.074,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.785,40.027,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 23.770,39.966,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 23.778,39.936,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 23.804,39.974,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 23.803,39.976,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 23.817,39.987,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.035 | Acc: 26.562,37.500,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 22.433,39.732,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.017 | Acc: 22.542,39.158,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.023 | Acc: 22.912,39.203,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.791 | Acc: 19.531,42.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.781 | Acc: 24.740,39.583,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.778 | Acc: 24.181,39.748,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.778 | Acc: 23.899,40.164,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.949,40.249,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.886,39.998,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 23.806,40.025,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.886,40.038,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 23.797,39.931,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.986,40.051,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.923,39.918,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.978,39.989,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.921,40.003,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.934,39.922,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.971,39.986,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 23.970,39.968,98.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 23.905,39.978,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 23.825,39.974,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 23.855,39.997,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 23.905,40.041,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.996 | Acc: 24.219,39.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.433,39.732,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 22.504,39.101,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 22.912,39.062,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.768 | Acc: 31.250,40.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 24.442,39.807,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 23.647,39.463,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 23.553,39.985,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.777 | Acc: 23.756,40.345,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.778 | Acc: 23.600,40.207,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.470,40.025,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.609,40.226,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 23.646,40.111,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.731,39.969,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.791,40.061,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.774 | Acc: 23.918,40.218,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 23.891,40.152,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 23.851,40.128,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.846,40.122,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.892,40.098,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.807,40.114,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 23.786,40.114,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.853,40.166,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.850,40.176,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.010 | Acc: 25.000,39.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.002 | Acc: 22.582,40.104,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.000 | Acc: 22.504,39.215,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.007 | Acc: 22.836,39.344,70.620,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.733 | Acc: 26.562,50.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 23.884,38.876,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.777 | Acc: 23.438,39.082,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.777 | Acc: 23.668,39.191,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.929,39.284,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 23.917,39.349,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.818,39.553,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.775 | Acc: 23.814,39.738,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.811,39.795,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.796,39.719,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.853,39.836,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 24.003,39.897,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.924,39.905,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 23.898,39.781,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 23.871,39.691,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.779 | Acc: 23.874,39.688,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 23.924,39.788,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.919,39.855,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 23.881,39.848,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 23.926,39.885,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.026 | Acc: 25.781,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 22.545,40.402,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.003 | Acc: 22.637,39.482,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.014 | Acc: 22.964,39.536,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.761 | Acc: 22.656,37.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.779 | Acc: 24.368,39.583,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 24.238,40.111,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 24.168,40.523,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 24.460,40.422,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 24.366,40.594,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 24.496,40.560,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 24.512,40.392,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 24.398,40.285,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 24.378,40.353,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 24.273,40.271,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 24.198,40.346,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 24.086,40.255,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.018,40.182,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.946,40.147,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.964,40.033,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.961,39.987,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 23.980,39.942,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.981,39.954,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.954,39.901,98.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 25.000,39.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 22.135,40.179,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.999 | Acc: 22.313,39.177,70.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.008 | Acc: 22.567,39.165,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.752 | Acc: 28.125,43.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.779 | Acc: 24.219,40.179,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.777 | Acc: 24.028,39.901,98.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.778 | Acc: 23.835,39.498,98.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.778 | Acc: 23.949,39.728,98.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 24.211,40.099,98.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 24.103,40.037,98.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 24.058,39.938,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 24.015,39.853,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 24.154,40.055,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.777 | Acc: 24.024,39.894,98.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 24.017,40.003,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.982,40.022,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.042,40.155,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 24.049,40.191,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 24.050,40.132,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 24.124,40.121,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 24.113,40.164,98.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 24.067,40.075,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 24.022,40.051,98.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.986 | Acc: 27.344,39.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 22.582,39.658,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 22.656,39.062,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 22.938,39.050,70.594,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.747 | Acc: 24.219,43.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 24.740,40.179,98.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.778 | Acc: 23.761,40.034,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.783,39.895,98.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.775,40.008,98.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.809,40.022,98.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.735,39.760,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.870,39.916,98.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 23.889,40.135,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 24.025,40.172,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 24.056,40.069,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 24.035,40.148,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.921,40.155,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.958,40.146,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.988,40.136,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.964,40.070,98.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 23.997,39.970,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 24.026,40.016,98.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 24.046,40.010,98.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 24.063,39.940,98.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 25.781,38.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.619,40.141,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 22.504,39.253,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.008 | Acc: 22.874,39.152,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.736 | Acc: 26.562,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 24.702,41.146,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.777 | Acc: 24.085,40.739,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 24.424,40.856,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.777 | Acc: 24.248,40.693,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 24.157,40.424,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 24.141,40.393,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 23.875,40.143,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 23.821,40.125,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.882,40.081,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.777 | Acc: 23.966,40.085,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 23.943,40.095,98.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.878,40.051,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 23.848,40.062,98.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.752,40.044,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.806,40.057,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.822,40.090,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.843,40.059,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.829,40.023,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.825,40.057,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.985 | Acc: 25.781,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.006 | Acc: 22.582,40.439,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.007 | Acc: 22.752,39.634,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.014 | Acc: 23.040,39.664,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.843 | Acc: 24.219,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.782 | Acc: 25.260,40.625,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 24.581,40.339,98.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 24.052,39.664,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.784 | Acc: 23.939,39.979,98.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 24.072,40.068,98.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.781 | Acc: 23.806,39.960,98.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 24.180,40.099,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 24.204,40.290,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 24.271,40.452,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 24.203,40.415,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.779 | Acc: 24.141,40.378,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 24.057,40.398,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.779 | Acc: 23.970,40.257,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 23.988,40.202,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.779 | Acc: 23.944,40.134,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 23.900,40.065,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.873,40.107,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 23.879,40.119,98.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 23.995,40.196,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.025 | Acc: 27.344,39.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 22.619,40.513,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.002 | Acc: 22.713,39.653,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.010 | Acc: 23.105,39.639,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.799 | Acc: 17.969,32.812,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 24.591,40.253,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 24.924,40.301,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.773 | Acc: 24.513,40.266,98.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.778 | Acc: 24.035,40.326,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.778 | Acc: 24.010,40.169,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.780 | Acc: 23.986,40.115,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.947,40.209,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 24.044,40.101,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 24.098,40.211,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 24.180,40.287,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 24.385,40.392,98.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 24.316,40.236,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 24.288,40.200,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 24.169,40.155,98.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 24.086,40.108,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 24.005,40.121,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 24.015,40.080,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.979,40.071,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 24.014,40.155,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 25.000,37.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.008 | Acc: 22.545,40.402,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.003 | Acc: 22.561,39.501,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 22.874,39.498,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.813 | Acc: 25.000,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 22.731,40.588,98.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 23.380,39.501,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.777 | Acc: 23.630,39.690,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.553,39.593,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.778 | Acc: 23.662,39.712,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 23.948,39.534,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.779 | Acc: 23.853,39.528,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.966,39.708,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.930,39.693,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.795,39.696,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.939,39.840,98.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 24.105,39.892,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 24.099,39.993,98.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 24.027,39.913,98.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 24.084,39.955,98.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 24.099,40.104,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 24.052,40.089,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 24.046,40.052,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 24.008,40.059,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.043 | Acc: 25.000,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.013 | Acc: 22.470,40.290,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.485,39.444,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.631,39.280,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.742 | Acc: 29.688,38.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 24.070,39.025,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.771 | Acc: 23.857,39.501,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.773 | Acc: 23.809,39.895,98.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 23.833,40.017,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.886,39.998,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.864,39.837,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 23.753,39.716,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.695,39.795,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.774,40.012,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 23.850,40.023,98.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 23.936,39.929,98.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.917,39.990,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.818,39.868,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.907,40.005,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 23.889,39.981,98.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.941,40.114,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.905,40.240,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.879,40.216,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.901,40.219,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.047 | Acc: 26.562,42.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.020 | Acc: 22.842,40.439,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 22.828,39.577,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 23.105,39.613,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.756 | Acc: 25.000,43.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 24.702,41.629,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 24.676,40.606,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 24.872,40.791,98.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 24.769,40.500,98.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.772 | Acc: 24.497,40.408,98.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.773 | Acc: 24.367,40.328,98.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 24.202,40.293,98.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 24.141,40.285,98.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 24.227,40.340,98.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 24.122,40.147,98.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.774 | Acc: 24.166,40.222,98.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 24.183,40.262,98.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 24.198,40.293,98.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.773 | Acc: 24.208,40.322,98.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.773 | Acc: 24.206,40.316,98.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.774 | Acc: 24.170,40.245,98.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 24.205,40.231,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 24.178,40.129,98.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 24.096,40.092,98.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.012 | Acc: 25.781,38.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.805,40.402,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 22.866,39.386,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 23.143,39.370,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.780 | Acc: 21.875,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 24.516,39.174,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 24.143,39.482,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.773 | Acc: 24.385,39.754,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 24.402,39.689,98.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 24.327,39.882,98.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 24.341,39.876,98.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 24.125,39.860,98.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.773 | Acc: 23.996,39.795,98.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 24.016,39.775,98.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 23.935,39.712,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 23.993,39.837,98.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 23.969,39.785,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.006,39.853,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 24.024,39.841,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 24.042,39.932,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 24.024,39.909,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.974,39.844,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.961,39.831,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.960,39.854,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.996 | Acc: 26.562,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 22.768,40.588,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.009 | Acc: 22.866,39.863,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 23.143,39.831,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.760 | Acc: 25.781,37.500,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 24.182,38.579,98.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 24.143,40.377,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 24.308,40.369,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 23.978,40.287,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 23.925,40.339,98.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.941,40.386,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 24.030,40.387,98.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.773 | Acc: 24.073,40.445,98.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 23.960,40.180,98.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 23.951,40.236,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 23.795,40.190,98.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.801,40.116,98.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.845,40.119,98.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.866,40.100,98.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.868,40.153,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.829,40.170,98.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.820,40.203,98.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.805,40.303,98.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.784,40.207,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.991 | Acc: 25.781,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 22.321,40.402,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 22.389,39.444,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.823,39.536,70.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.745 | Acc: 31.250,43.750,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 24.479,39.993,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 24.600,40.072,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 24.001,40.126,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 24.122,40.133,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 24.103,40.029,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 24.070,40.225,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.774 | Acc: 24.075,39.955,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 24.005,40.038,98.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 24.042,40.034,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 24.180,39.991,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 24.127,39.883,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 24.160,39.905,98.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.039,39.972,98.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 24.085,39.933,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 24.011,39.919,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 24.112,39.944,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 24.086,40.020,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 24.041,40.054,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 24.073,40.119,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.981 | Acc: 25.781,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 22.470,40.253,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.637,39.386,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.989,39.331,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.742 | Acc: 29.688,47.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 24.516,41.555,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 24.028,40.835,98.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 24.360,40.791,98.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 24.074,40.297,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 24.010,39.968,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 24.135,39.941,98.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.992,39.982,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 24.097,40.232,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 24.245,40.245,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 24.075,40.019,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 23.915,40.038,98.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.771,39.879,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 23.925,39.990,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.946,40.002,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 23.905,40.025,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.912,40.046,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 24.010,40.181,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 24.005,40.160,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 24.012,40.143,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.017 | Acc: 25.000,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 22.396,40.141,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 22.466,39.215,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 22.797,39.344,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.753 | Acc: 28.125,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 24.665,40.216,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.778 | Acc: 24.162,40.072,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 24.257,40.689,98.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 24.248,40.384,98.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 24.350,40.416,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 24.335,40.096,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 24.208,39.971,98.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 24.093,40.101,98.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 24.003,40.008,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.900,39.937,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.897,39.978,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.891,39.931,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 24.009,40.035,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.991,40.091,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.923,40.041,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.934,40.087,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 23.923,40.089,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.959,40.177,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.913,40.221,98.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.058 | Acc: 25.781,41.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.021 | Acc: 22.284,40.439,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 22.580,39.691,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 22.989,39.575,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.767 | Acc: 22.656,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 22.879,38.951,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.769 | Acc: 24.295,40.492,98.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 24.308,40.266,98.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.771 | Acc: 24.354,40.442,98.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.772 | Acc: 24.041,40.176,98.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.993,40.244,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.775 | Acc: 23.886,40.193,98.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 23.937,40.145,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.917,39.986,98.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 23.908,40.030,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 23.982,40.102,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 24.040,40.119,98.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.048,40.080,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 24.041,40.016,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 24.063,39.906,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 24.041,39.917,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.983,39.926,98.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.901,39.913,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.909,39.907,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.002 | Acc: 26.562,39.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.021 | Acc: 22.879,40.625,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.866,39.653,70.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 23.143,39.588,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.748 | Acc: 30.469,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 24.219,40.141,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.770 | Acc: 24.829,40.816,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 24.475,40.843,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 24.470,41.155,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 24.180,40.648,98.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 24.167,40.599,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 24.075,40.581,98.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 24.078,40.271,98.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 24.098,40.215,98.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.773 | Acc: 24.087,40.190,98.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 24.190,40.360,98.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.773 | Acc: 24.125,40.336,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 23.964,40.170,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.905,40.130,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.897,40.077,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.824,39.975,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.829,39.972,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 23.883,40.047,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.889,39.993,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.025 | Acc: 24.219,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.008 | Acc: 22.507,40.513,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 22.599,39.539,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.010 | Acc: 22.900,39.664,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.719 | Acc: 31.250,49.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 25.670,40.439,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 24.581,39.863,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.780 | Acc: 24.052,39.280,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 24.344,40.066,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.948,39.519,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 23.915,39.482,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 23.958,39.716,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 23.821,39.727,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.882,39.568,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 24.090,39.712,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 24.091,39.755,98.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.995,39.850,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 23.967,39.934,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.971,39.860,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 24.068,39.919,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 24.070,39.892,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 24.031,39.906,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 24.046,40.021,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 24.067,40.071,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.024 | Acc: 25.000,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.014 | Acc: 22.545,40.588,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.675,39.558,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 23.028,39.421,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.776 | Acc: 18.750,40.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 22.768,39.621,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 22.752,40.149,98.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 22.887,40.074,98.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.013,39.670,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.407,39.527,98.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 23.360,39.715,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 23.460,39.772,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.520,39.887,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.502,39.831,98.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.515,39.723,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.590,39.731,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.616,39.850,98.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.656,39.787,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.713,39.891,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.879,40.049,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.897,40.004,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 23.891,40.034,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 23.853,40.008,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 23.878,39.998,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.021 | Acc: 25.781,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.016 | Acc: 22.693,40.476,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.866,39.615,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.023 | Acc: 23.117,39.549,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.753 | Acc: 25.000,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 25.260,42.076,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 24.295,40.549,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.773 | Acc: 23.809,40.651,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 23.833,40.567,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.662,40.292,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.631,40.251,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.620,40.243,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 23.704,40.329,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 23.632,40.275,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.624,40.085,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.774 | Acc: 23.515,39.964,98.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 23.337,39.980,98.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 23.449,40.050,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 23.507,40.063,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.523,39.984,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.774 | Acc: 23.642,40.063,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.706,40.126,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.723,40.212,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.753,40.242,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.004 | Acc: 25.000,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 22.582,39.769,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.447,39.234,70.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.823,39.357,70.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.765 | Acc: 23.438,36.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 24.963,40.365,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 24.409,40.511,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 24.603,40.727,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 24.392,40.500,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 24.397,40.586,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 24.316,40.341,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 24.186,40.243,98.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 24.131,40.271,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.951,40.241,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.777 | Acc: 23.993,40.306,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.862,40.116,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.885,40.161,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 23.866,40.191,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.799,40.094,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.933,40.246,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 23.897,40.216,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.916,40.171,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.946,40.194,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.862,40.131,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.002 | Acc: 26.562,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.013 | Acc: 22.545,40.104,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 22.675,39.444,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.976,39.370,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.757 | Acc: 24.219,36.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 23.810,39.918,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 23.895,39.977,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 24.116,39.741,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 24.113,39.844,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 23.948,39.689,98.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 23.986,39.941,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 24.141,40.104,98.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.773 | Acc: 24.190,40.086,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 24.111,40.159,98.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 24.172,40.100,98.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 24.091,39.960,98.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 23.908,39.892,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.042,39.996,98.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 24.057,39.930,98.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 24.112,39.903,98.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 24.058,39.885,98.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 24.102,39.894,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 24.076,39.852,98.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.774 | Acc: 24.055,39.872,98.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.030 | Acc: 24.219,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.013 | Acc: 22.470,40.365,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.561,39.501,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.951,39.370,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.772 | Acc: 34.375,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 24.182,40.848,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.800,40.530,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 23.591,40.548,98.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.775 | Acc: 23.438,40.557,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 23.693,40.308,98.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.967,40.276,98.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 23.792,40.082,98.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.719,40.018,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.778,40.085,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 23.822,40.221,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 23.784,40.250,98.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.807,40.294,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.836,40.302,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.855,40.227,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.905,40.163,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 23.922,40.150,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 23.925,40.128,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 23.842,40.021,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.868,40.067,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.026 | Acc: 26.562,39.844,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.019 | Acc: 22.805,40.662,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.904,39.577,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 23.169,39.652,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.787 | Acc: 22.656,40.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 24.888,39.918,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 23.990,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 23.591,39.664,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 23.708,39.747,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.780 | Acc: 23.801,39.643,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 23.999,39.902,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.779 | Acc: 23.848,39.888,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.779 | Acc: 23.865,39.887,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.778 | Acc: 23.882,39.943,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 23.881,39.953,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.779 | Acc: 23.791,39.890,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.780 | Acc: 23.658,39.795,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 23.758,39.838,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.781 | Acc: 23.693,39.780,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.741,39.854,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.885,39.948,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 23.848,39.887,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.836,39.863,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 23.839,39.924,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.007 | Acc: 24.219,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 22.805,40.476,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.732,39.329,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.964,39.370,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.781 | Acc: 32.812,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 24.702,40.811,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 24.848,41.425,98.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 24.436,40.868,98.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 24.662,41.078,98.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 24.281,40.687,98.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.728,40.412,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.914,40.453,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 24.044,40.635,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 23.986,40.526,98.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.982,40.497,98.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.773 | Acc: 24.035,40.501,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 24.060,40.437,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 24.072,40.368,98.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.969,40.244,98.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.936,40.275,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.941,40.214,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.912,40.135,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.942,40.114,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.923,40.030,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 26.562,39.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.582,39.993,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 22.580,39.405,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.011 | Acc: 22.964,39.267,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.809 | Acc: 25.781,42.969,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.791 | Acc: 23.028,39.472,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.783 | Acc: 23.514,40.187,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 23.220,40.010,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 23.457,40.239,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.438,40.084,98.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 23.463,40.218,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 23.349,40.049,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.292,40.120,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.183,39.874,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 23.263,39.855,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.367,39.748,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.288,39.711,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.369,39.853,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.526,39.872,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.614,39.979,98.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 23.598,40.034,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.692,40.132,98.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.704,40.134,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.669,40.108,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.050 | Acc: 25.781,37.500,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 22.842,39.918,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.847,39.158,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.019 | Acc: 23.181,39.255,70.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.784 | Acc: 24.219,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 23.810,40.402,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.769 | Acc: 24.276,40.587,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 24.270,40.497,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 24.016,40.268,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 23.894,40.037,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 23.851,40.108,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.775 | Acc: 23.631,40.054,98.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.467,39.931,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.636,40.008,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.777 | Acc: 23.678,40.023,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.671,39.999,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.716,40.045,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.686,39.952,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 23.743,40.013,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 23.736,40.038,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.810,40.070,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 23.829,40.009,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.866,40.056,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.827,39.961,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.016 | Acc: 25.000,39.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.015 | Acc: 22.693,40.439,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 22.713,39.463,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.925,39.460,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.789 | Acc: 28.125,43.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.760 | Acc: 25.670,40.885,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 24.733,40.530,98.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 24.590,40.702,98.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 24.325,40.500,98.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 24.435,40.625,98.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 24.445,40.373,98.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 24.291,40.304,98.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.773 | Acc: 24.355,40.324,98.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 24.063,40.142,98.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 24.056,40.061,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 24.137,40.095,98.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 24.177,40.142,98.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 24.114,40.083,98.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 24.088,40.058,98.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 24.040,40.168,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.980,40.124,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 23.921,40.073,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.942,40.173,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.889,40.129,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.032 | Acc: 26.562,38.281,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.013 | Acc: 22.656,40.439,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.012 | Acc: 22.504,39.596,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.912,39.716,70.543,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.833 | Acc: 17.188,32.812,96.875,% | Adaptive Acc: 95.312% | clf_exit: 0.008 0.062 0.930
Batch: 20 | Loss: 0.772 | Acc: 23.475,39.844,98.624,% | Adaptive Acc: 97.619% | clf_exit: 0.006 0.073 0.921
Batch: 40 | Loss: 0.773 | Acc: 24.200,40.568,98.457,% | Adaptive Acc: 97.580% | clf_exit: 0.006 0.073 0.921
Batch: 60 | Loss: 0.776 | Acc: 23.386,40.394,98.476,% | Adaptive Acc: 97.554% | clf_exit: 0.006 0.072 0.923
Batch: 80 | Loss: 0.776 | Acc: 23.389,40.046,98.457,% | Adaptive Acc: 97.541% | clf_exit: 0.005 0.072 0.923
Batch: 100 | Loss: 0.777 | Acc: 23.561,40.014,98.438,% | Adaptive Acc: 97.401% | clf_exit: 0.005 0.073 0.922
Batch: 120 | Loss: 0.777 | Acc: 23.760,40.025,98.450,% | Adaptive Acc: 97.456% | clf_exit: 0.005 0.074 0.921
Batch: 140 | Loss: 0.778 | Acc: 23.654,39.871,98.482,% | Adaptive Acc: 97.490% | clf_exit: 0.005 0.074 0.922
Batch: 160 | Loss: 0.779 | Acc: 23.704,39.829,98.438,% | Adaptive Acc: 97.428% | clf_exit: 0.005 0.074 0.921
Batch: 180 | Loss: 0.778 | Acc: 23.804,39.857,98.459,% | Adaptive Acc: 97.462% | clf_exit: 0.005 0.074 0.921
Batch: 200 | Loss: 0.778 | Acc: 23.881,39.879,98.461,% | Adaptive Acc: 97.493% | clf_exit: 0.005 0.073 0.922
Batch: 220 | Loss: 0.779 | Acc: 23.763,39.766,98.476,% | Adaptive Acc: 97.501% | clf_exit: 0.005 0.073 0.922
Batch: 240 | Loss: 0.778 | Acc: 23.775,39.805,98.496,% | Adaptive Acc: 97.527% | clf_exit: 0.005 0.073 0.922
Batch: 260 | Loss: 0.779 | Acc: 23.725,39.751,98.497,% | Adaptive Acc: 97.531% | clf_exit: 0.005 0.073 0.922
Batch: 280 | Loss: 0.779 | Acc: 23.779,39.847,98.499,% | Adaptive Acc: 97.548% | clf_exit: 0.005 0.073 0.922
Batch: 300 | Loss: 0.778 | Acc: 23.837,39.937,98.510,% | Adaptive Acc: 97.581% | clf_exit: 0.005 0.073 0.922
Batch: 320 | Loss: 0.779 | Acc: 23.842,39.934,98.484,% | Adaptive Acc: 97.542% | clf_exit: 0.005 0.073 0.922
Batch: 340 | Loss: 0.779 | Acc: 23.827,39.919,98.481,% | Adaptive Acc: 97.528% | clf_exit: 0.005 0.073 0.922
Batch: 360 | Loss: 0.779 | Acc: 23.758,39.930,98.472,% | Adaptive Acc: 97.505% | clf_exit: 0.005 0.073 0.922
Batch: 380 | Loss: 0.779 | Acc: 23.813,39.928,98.481,% | Adaptive Acc: 97.527% | clf_exit: 0.005 0.073 0.922
Batch: 0 | Loss: 2.025 | Acc: 23.438,38.281,71.875,% | Adaptive Acc: 68.750% | clf_exit: 0.023 0.188 0.789
Batch: 20 | Loss: 2.015 | Acc: 22.582,40.067,70.610,% | Adaptive Acc: 69.680% | clf_exit: 0.025 0.127 0.849
Batch: 40 | Loss: 2.013 | Acc: 22.542,39.672,70.293,% | Adaptive Acc: 69.550% | clf_exit: 0.021 0.127 0.852
Batch: 60 | Loss: 2.021 | Acc: 22.900,39.652,70.377,% | Adaptive Acc: 69.454% | clf_exit: 0.021 0.123 0.856
model is save as models/resnet56_cifar100_adaptive0_circles2_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 4.249 | Acc: 2.344,0.000,35.156,% | Adaptive Acc: 34.375% | clf_exit: 0.008 0.000 0.992
Batch: 20 | Loss: 4.520 | Acc: 1.935,2.530,26.451,% | Adaptive Acc: 26.302% | clf_exit: 0.019 0.000 0.981
Batch: 40 | Loss: 4.503 | Acc: 1.867,2.591,26.810,% | Adaptive Acc: 26.601% | clf_exit: 0.018 0.000 0.982
Batch: 60 | Loss: 4.490 | Acc: 1.665,2.536,26.972,% | Adaptive Acc: 26.793% | clf_exit: 0.018 0.000 0.982
Batch: 0 | Loss: 2.423 | Acc: 6.250,15.625,66.406,% | Adaptive Acc: 66.406% | clf_exit: 0.000 0.016 0.984
Batch: 20 | Loss: 2.455 | Acc: 6.882,14.211,64.472,% | Adaptive Acc: 64.435% | clf_exit: 0.003 0.006 0.991
Batch: 40 | Loss: 2.467 | Acc: 6.574,14.310,64.425,% | Adaptive Acc: 64.367% | clf_exit: 0.003 0.006 0.991
Batch: 60 | Loss: 2.465 | Acc: 6.519,14.319,64.767,% | Adaptive Acc: 64.716% | clf_exit: 0.003 0.006 0.991
Batch: 0 | Loss: 2.025 | Acc: 23.438,38.281,71.875,% | Adaptive Acc: 68.750% | clf_exit: 0.023 0.188 0.789
Batch: 20 | Loss: 2.015 | Acc: 22.582,40.067,70.610,% | Adaptive Acc: 69.680% | clf_exit: 0.025 0.127 0.849
Batch: 40 | Loss: 2.013 | Acc: 22.542,39.672,70.293,% | Adaptive Acc: 69.550% | clf_exit: 0.021 0.127 0.852
Batch: 60 | Loss: 2.021 | Acc: 22.900,39.652,70.377,% | Adaptive Acc: 69.454% | clf_exit: 0.021 0.123 0.856







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 5.111 |  Acc: 2.002,2.370,7.568,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 4.802 |  Acc: 3.160,4.530,10.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 4.592 |  Acc: 3.936,6.374,14.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 4.462 |  Acc: 4.700,7.810,15.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 4.323 |  Acc: 4.980,8.860,18.592,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 4.276 |  Acc: 5.250,9.570,18.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 4.108 |  Acc: 5.776,10.198,22.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 3.954 |  Acc: 5.480,11.110,24.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 3.909 |  Acc: 6.586,11.308,25.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 3.880 |  Acc: 6.100,9.960,26.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 3.744 |  Acc: 7.004,12.396,28.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 3.712 |  Acc: 7.160,12.440,29.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 3.592 |  Acc: 7.584,13.576,30.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 3.479 |  Acc: 7.990,14.080,31.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 3.443 |  Acc: 8.270,14.486,33.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 3.399 |  Acc: 8.620,14.630,33.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 3.306 |  Acc: 8.812,15.332,36.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 3.471 |  Acc: 9.080,14.230,33.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 3.177 |  Acc: 9.454,16.274,38.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 3.196 |  Acc: 9.630,15.360,38.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 3.073 |  Acc: 9.772,16.676,41.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 3.282 |  Acc: 9.200,15.860,36.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 2.973 |  Acc: 10.234,17.308,43.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 3.091 |  Acc: 10.010,16.910,40.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 2.880 |  Acc: 10.534,18.106,45.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 3.263 |  Acc: 10.110,15.190,37.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 2.804 |  Acc: 10.872,18.520,46.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 3.162 |  Acc: 10.130,17.630,40.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 2.734 |  Acc: 11.224,19.132,48.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 3.130 |  Acc: 11.010,17.280,40.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 2.671 |  Acc: 11.424,19.622,49.686,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 2.893 |  Acc: 11.160,18.280,45.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 2.614 |  Acc: 11.620,20.178,50.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 2.997 |  Acc: 11.480,18.110,43.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 2.554 |  Acc: 11.950,20.522,52.176,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 2.942 |  Acc: 9.820,17.600,45.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 2.500 |  Acc: 12.068,20.754,53.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 2.717 |  Acc: 11.990,19.550,49.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 2.459 |  Acc: 12.394,21.300,54.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 2.704 |  Acc: 11.640,20.320,49.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 2.416 |  Acc: 12.560,21.584,55.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 2.742 |  Acc: 11.850,20.560,48.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 2.365 |  Acc: 12.872,22.004,56.660,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 3.004 |  Acc: 10.600,18.230,44.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 2.345 |  Acc: 13.032,22.402,56.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 2.604 |  Acc: 13.030,20.000,52.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 2.306 |  Acc: 13.192,22.626,57.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 2.556 |  Acc: 11.680,20.560,52.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 2.272 |  Acc: 13.020,22.704,58.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 2.598 |  Acc: 10.750,20.200,51.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 2.230 |  Acc: 13.454,23.036,59.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 2.532 |  Acc: 12.930,21.830,53.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 2.216 |  Acc: 13.540,23.298,60.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 2.583 |  Acc: 12.760,20.840,52.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 2.181 |  Acc: 13.814,23.520,61.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 2.611 |  Acc: 11.980,20.080,53.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.157 |  Acc: 14.004,23.990,61.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 2.584 |  Acc: 12.200,22.780,53.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.125 |  Acc: 13.950,24.024,62.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 2.488 |  Acc: 12.730,21.920,55.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.114 |  Acc: 14.172,24.300,62.506,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 2.439 |  Acc: 11.590,22.110,56.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.080 |  Acc: 14.210,24.596,63.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 2.410 |  Acc: 13.370,21.660,55.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.069 |  Acc: 14.316,24.414,63.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 2.483 |  Acc: 12.900,21.640,54.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.043 |  Acc: 14.498,24.496,64.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 2.452 |  Acc: 12.840,22.960,55.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.021 |  Acc: 14.852,24.926,64.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 2.411 |  Acc: 12.550,22.820,56.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.000 |  Acc: 14.750,24.960,65.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 2.376 |  Acc: 13.080,22.570,57.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 1.989 |  Acc: 14.916,25.328,65.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 2.431 |  Acc: 13.140,23.120,55.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 1.974 |  Acc: 15.084,25.156,65.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 2.451 |  Acc: 13.900,24.140,55.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 1.959 |  Acc: 15.298,25.372,66.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 2.460 |  Acc: 12.870,21.280,56.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 1.952 |  Acc: 15.318,25.608,66.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 2.368 |  Acc: 14.570,24.540,57.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 1.933 |  Acc: 15.376,25.566,67.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 2.392 |  Acc: 13.200,22.870,57.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 1.918 |  Acc: 15.562,25.888,67.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 2.517 |  Acc: 12.970,22.130,54.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 1.907 |  Acc: 15.594,25.746,67.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 2.430 |  Acc: 13.930,24.010,56.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 1.893 |  Acc: 15.682,25.686,68.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 2.447 |  Acc: 13.060,23.160,56.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 1.884 |  Acc: 16.130,26.220,68.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 2.617 |  Acc: 12.900,22.990,53.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 1.867 |  Acc: 16.194,26.406,68.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 2.567 |  Acc: 14.420,23.210,53.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 1.876 |  Acc: 16.188,26.186,68.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 2.380 |  Acc: 14.570,25.280,57.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 1.846 |  Acc: 16.222,26.490,69.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 2.343 |  Acc: 13.800,24.250,58.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 1.841 |  Acc: 16.260,26.422,69.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 2.378 |  Acc: 14.030,22.350,58.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 1.832 |  Acc: 16.398,26.472,69.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 2.418 |  Acc: 13.930,21.860,56.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 1.820 |  Acc: 16.812,26.968,69.830,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 2.488 |  Acc: 14.420,23.410,55.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 1.820 |  Acc: 16.920,26.868,69.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 2.360 |  Acc: 15.270,24.510,58.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 1.801 |  Acc: 17.110,26.898,70.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 2.298 |  Acc: 15.030,23.490,59.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 1.796 |  Acc: 16.890,27.048,70.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 2.414 |  Acc: 12.590,23.200,57.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 1.787 |  Acc: 17.050,27.294,70.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 2.334 |  Acc: 15.520,25.540,58.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 1.775 |  Acc: 17.370,27.158,70.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 2.604 |  Acc: 15.740,23.830,54.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 1.766 |  Acc: 17.320,27.418,70.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 2.357 |  Acc: 14.920,26.360,58.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 1.765 |  Acc: 17.464,27.512,71.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 2.312 |  Acc: 15.240,25.920,59.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 1.749 |  Acc: 17.666,27.586,71.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 2.332 |  Acc: 15.020,24.870,59.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 1.751 |  Acc: 17.432,27.434,71.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 2.336 |  Acc: 15.470,25.270,58.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 1.743 |  Acc: 17.692,27.678,71.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 2.318 |  Acc: 14.600,25.370,59.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 1.730 |  Acc: 17.700,27.634,72.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 2.383 |  Acc: 14.480,24.140,57.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 1.729 |  Acc: 17.900,27.938,72.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 2.396 |  Acc: 14.540,24.820,57.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 1.724 |  Acc: 17.898,27.890,72.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 2.343 |  Acc: 17.040,24.450,58.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 1.710 |  Acc: 18.084,28.180,72.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 2.486 |  Acc: 12.570,22.870,56.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 1.705 |  Acc: 18.288,27.944,72.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 2.376 |  Acc: 16.330,25.510,58.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 1.699 |  Acc: 18.294,28.252,72.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 2.344 |  Acc: 16.650,23.660,59.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 1.704 |  Acc: 18.468,28.100,72.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 2.328 |  Acc: 15.860,24.890,59.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 1.678 |  Acc: 18.462,28.336,73.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 2.280 |  Acc: 14.820,23.510,60.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 1.680 |  Acc: 18.542,28.424,73.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 2.406 |  Acc: 16.310,24.130,57.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 1.688 |  Acc: 18.322,28.380,72.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 2.280 |  Acc: 15.500,24.960,60.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 1.672 |  Acc: 18.538,28.544,73.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 2.284 |  Acc: 15.670,24.210,60.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 1.664 |  Acc: 18.774,28.694,73.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 2.339 |  Acc: 15.260,26.260,59.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 1.654 |  Acc: 18.748,28.750,73.826,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 2.313 |  Acc: 15.670,25.110,59.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 1.657 |  Acc: 19.132,29.122,73.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 2.306 |  Acc: 16.180,25.870,60.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 1.652 |  Acc: 18.896,28.924,73.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 2.321 |  Acc: 18.520,25.450,59.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 1.655 |  Acc: 18.870,28.954,73.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 2.286 |  Acc: 16.550,27.090,60.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 1.644 |  Acc: 18.854,29.100,73.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 2.391 |  Acc: 16.790,26.010,58.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 1.633 |  Acc: 18.990,29.114,74.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 2.377 |  Acc: 16.440,26.070,57.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 1.627 |  Acc: 19.266,29.322,74.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 2.325 |  Acc: 15.710,26.370,59.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 1.631 |  Acc: 19.210,29.448,74.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 2.337 |  Acc: 15.650,24.490,59.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 1.628 |  Acc: 19.102,29.502,74.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 2.424 |  Acc: 14.980,24.890,57.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 1.619 |  Acc: 19.384,29.520,74.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 2.297 |  Acc: 16.840,26.850,60.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 1.616 |  Acc: 19.414,29.768,74.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 2.365 |  Acc: 15.920,25.170,58.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 1.614 |  Acc: 19.730,29.532,74.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 2.371 |  Acc: 15.360,24.040,58.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 1.607 |  Acc: 19.702,29.702,74.808,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 2.417 |  Acc: 16.010,24.690,57.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 1.611 |  Acc: 19.736,29.894,74.740,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 2.451 |  Acc: 15.530,24.240,57.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 1.601 |  Acc: 19.704,29.740,74.992,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 2.494 |  Acc: 15.690,25.130,56.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 1.598 |  Acc: 19.818,30.032,74.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 2.265 |  Acc: 17.440,27.260,60.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 1.589 |  Acc: 19.714,30.046,75.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 2.421 |  Acc: 15.370,23.990,57.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 1.595 |  Acc: 19.436,29.766,75.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 2.195 |  Acc: 17.390,28.240,61.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 1.589 |  Acc: 19.596,30.034,75.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 2.383 |  Acc: 16.680,26.320,58.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 1.579 |  Acc: 20.044,30.482,75.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 2.301 |  Acc: 16.070,25.960,59.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 1.587 |  Acc: 19.746,30.344,75.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 2.316 |  Acc: 15.990,25.800,59.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 1.570 |  Acc: 20.068,30.482,75.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 2.269 |  Acc: 18.490,27.500,60.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 1.572 |  Acc: 19.964,30.530,75.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 2.171 |  Acc: 18.110,27.950,62.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 1.572 |  Acc: 19.766,30.590,75.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 2.378 |  Acc: 18.260,27.600,58.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 1.565 |  Acc: 19.876,30.588,75.776,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 2.285 |  Acc: 16.990,26.860,60.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 1.564 |  Acc: 20.066,30.498,75.864,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 2.212 |  Acc: 16.550,26.230,62.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 1.563 |  Acc: 20.002,30.734,75.780,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 2.348 |  Acc: 17.410,27.300,59.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 1.559 |  Acc: 19.938,31.150,75.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 2.249 |  Acc: 16.790,27.760,61.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 1.542 |  Acc: 20.122,30.928,76.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 2.394 |  Acc: 17.830,27.320,58.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 1.558 |  Acc: 20.266,30.906,75.922,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 2.288 |  Acc: 17.810,26.890,60.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 1.549 |  Acc: 20.382,30.994,76.100,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 2.218 |  Acc: 17.920,27.940,61.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 1.546 |  Acc: 20.066,31.062,76.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 2.308 |  Acc: 17.010,26.880,60.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 1.546 |  Acc: 20.336,30.942,76.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 2.269 |  Acc: 18.910,27.990,60.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 1.540 |  Acc: 20.474,31.268,76.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 2.316 |  Acc: 17.730,28.570,59.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 1.546 |  Acc: 20.260,30.842,76.278,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 2.387 |  Acc: 16.500,26.260,58.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 1.537 |  Acc: 20.476,31.232,76.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 2.340 |  Acc: 19.350,27.370,59.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 1.535 |  Acc: 20.270,31.556,76.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 2.340 |  Acc: 16.950,26.770,58.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 1.535 |  Acc: 20.404,31.554,76.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 2.265 |  Acc: 17.750,28.860,60.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.530 |  Acc: 20.792,31.424,76.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 2.328 |  Acc: 17.250,26.050,60.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 1.523 |  Acc: 20.560,31.488,76.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 2.213 |  Acc: 18.640,27.180,61.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 1.538 |  Acc: 20.298,31.612,76.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 2.132 |  Acc: 18.560,29.460,63.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 1.529 |  Acc: 20.502,31.566,76.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 2.315 |  Acc: 16.480,26.470,60.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 1.521 |  Acc: 20.592,31.616,76.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 2.238 |  Acc: 16.290,27.410,61.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.527 |  Acc: 20.590,31.928,76.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 2.367 |  Acc: 18.240,26.390,60.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.520 |  Acc: 20.528,31.746,76.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 2.191 |  Acc: 18.630,29.010,62.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.513 |  Acc: 20.530,31.740,76.984,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 2.503 |  Acc: 16.300,24.440,56.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.511 |  Acc: 20.630,31.884,77.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 2.286 |  Acc: 16.030,27.440,60.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.505 |  Acc: 20.398,31.948,77.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 2.186 |  Acc: 19.120,29.780,62.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.515 |  Acc: 20.442,31.972,76.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 2.209 |  Acc: 16.420,27.340,62.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.504 |  Acc: 20.842,32.068,77.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 2.148 |  Acc: 17.370,27.640,62.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.506 |  Acc: 20.742,32.014,77.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 2.201 |  Acc: 16.520,27.460,61.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.507 |  Acc: 20.688,32.010,77.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 2.336 |  Acc: 16.760,25.710,60.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.508 |  Acc: 20.766,32.222,77.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 2.266 |  Acc: 18.470,27.920,60.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.498 |  Acc: 20.908,32.518,77.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 2.124 |  Acc: 18.380,29.170,63.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.497 |  Acc: 20.832,32.380,77.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 2.264 |  Acc: 16.670,27.700,61.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.489 |  Acc: 20.664,32.128,77.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 2.313 |  Acc: 18.670,29.260,60.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.502 |  Acc: 20.954,32.334,77.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 2.309 |  Acc: 17.380,27.850,60.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.493 |  Acc: 20.644,32.456,77.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 2.270 |  Acc: 15.780,26.850,61.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.496 |  Acc: 20.844,32.388,77.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 2.410 |  Acc: 16.030,24.760,58.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.492 |  Acc: 20.838,32.688,77.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 2.289 |  Acc: 19.310,30.230,60.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.488 |  Acc: 20.960,32.422,77.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 2.301 |  Acc: 17.990,29.640,59.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.488 |  Acc: 21.072,32.876,77.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 2.284 |  Acc: 17.570,27.100,60.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.487 |  Acc: 20.764,32.694,77.666,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 2.272 |  Acc: 16.560,29.020,61.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.487 |  Acc: 20.814,32.774,77.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 2.170 |  Acc: 18.810,29.350,62.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.480 |  Acc: 20.932,33.052,77.678,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 2.209 |  Acc: 18.110,30.190,61.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.476 |  Acc: 20.956,33.090,77.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 2.303 |  Acc: 17.690,29.000,59.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.475 |  Acc: 20.824,32.958,77.798,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 2.211 |  Acc: 17.270,28.170,61.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.484 |  Acc: 21.002,33.000,77.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 2.190 |  Acc: 17.870,29.830,62.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.478 |  Acc: 20.726,32.980,77.698,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 2.277 |  Acc: 16.510,28.440,60.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.483 |  Acc: 20.848,32.714,77.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 2.304 |  Acc: 18.480,30.530,60.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.474 |  Acc: 20.872,33.096,77.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 2.229 |  Acc: 17.280,28.960,61.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.475 |  Acc: 21.076,33.248,77.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 2.452 |  Acc: 17.150,26.090,57.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.474 |  Acc: 20.972,33.024,77.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 2.241 |  Acc: 16.400,28.370,61.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.473 |  Acc: 21.218,33.428,77.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 2.303 |  Acc: 17.280,28.600,60.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.477 |  Acc: 21.120,33.228,77.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 2.206 |  Acc: 18.950,30.780,62.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.466 |  Acc: 20.918,33.378,78.106,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 2.335 |  Acc: 17.840,26.720,59.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.460 |  Acc: 21.192,33.540,78.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 2.404 |  Acc: 16.640,27.680,59.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.220 |  Acc: 21.728,34.502,85.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 1.776 |  Acc: 20.590,34.800,72.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.116 |  Acc: 22.136,35.662,88.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 1.768 |  Acc: 20.370,34.470,72.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.084 |  Acc: 22.130,35.810,89.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 1.780 |  Acc: 20.600,34.650,72.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.064 |  Acc: 22.040,35.996,90.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 1.784 |  Acc: 20.860,34.890,72.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.045 |  Acc: 22.300,36.106,90.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 1.791 |  Acc: 20.830,35.200,72.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.035 |  Acc: 22.332,36.190,91.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 1.790 |  Acc: 21.220,35.690,72.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.018 |  Acc: 22.430,36.264,91.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 1.798 |  Acc: 21.330,35.540,72.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.012 |  Acc: 22.364,36.460,91.946,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 1.802 |  Acc: 21.010,35.950,72.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.004 |  Acc: 22.396,36.510,92.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 1.810 |  Acc: 21.260,35.630,72.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 0.991 |  Acc: 22.564,36.674,92.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 1.807 |  Acc: 20.690,35.320,72.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 0.987 |  Acc: 22.518,36.800,92.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 1.821 |  Acc: 21.210,35.700,72.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 0.979 |  Acc: 22.654,36.908,92.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 1.818 |  Acc: 21.120,35.870,72.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 0.972 |  Acc: 22.412,36.728,93.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 1.822 |  Acc: 21.110,35.770,72.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 0.964 |  Acc: 22.716,36.740,93.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 1.822 |  Acc: 21.020,35.980,72.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 0.957 |  Acc: 22.554,36.944,93.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 1.827 |  Acc: 21.440,36.120,72.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 0.956 |  Acc: 22.538,36.864,93.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 1.828 |  Acc: 21.550,36.620,72.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 0.948 |  Acc: 22.740,37.164,93.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 1.843 |  Acc: 21.600,36.550,72.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 0.945 |  Acc: 22.810,37.264,93.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 1.843 |  Acc: 21.770,36.840,71.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 0.939 |  Acc: 22.652,37.006,94.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 1.851 |  Acc: 21.230,36.510,72.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 0.937 |  Acc: 22.900,37.272,94.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 1.864 |  Acc: 21.420,36.840,72.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 0.930 |  Acc: 22.864,37.092,94.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 1.852 |  Acc: 21.290,36.530,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 0.929 |  Acc: 22.728,36.992,94.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 1.857 |  Acc: 21.670,36.500,72.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 0.923 |  Acc: 22.932,37.382,94.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 1.873 |  Acc: 21.630,36.540,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 0.919 |  Acc: 22.738,37.386,94.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 1.880 |  Acc: 21.450,36.570,71.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 0.916 |  Acc: 22.942,37.508,94.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 1.896 |  Acc: 21.700,36.490,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 0.912 |  Acc: 22.774,37.446,94.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 1.883 |  Acc: 21.860,37.130,71.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 0.913 |  Acc: 22.844,37.570,94.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 1.898 |  Acc: 22.140,37.170,71.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 0.911 |  Acc: 22.866,37.328,94.884,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 1.892 |  Acc: 21.770,36.900,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 0.908 |  Acc: 22.936,37.388,94.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 1.888 |  Acc: 21.810,37.400,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 0.903 |  Acc: 23.210,37.508,95.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 1.897 |  Acc: 21.730,37.100,71.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 0.900 |  Acc: 22.784,37.740,95.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 1.923 |  Acc: 21.220,37.190,71.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 0.895 |  Acc: 22.910,37.764,95.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 1.900 |  Acc: 21.640,37.290,72.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 0.890 |  Acc: 23.066,37.984,95.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 1.896 |  Acc: 21.700,37.040,71.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 0.894 |  Acc: 22.928,37.626,95.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 1.923 |  Acc: 21.660,36.820,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 0.891 |  Acc: 23.120,38.050,95.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 1.921 |  Acc: 21.320,36.750,71.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 0.889 |  Acc: 22.908,37.806,95.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 1.914 |  Acc: 21.750,37.360,71.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 0.887 |  Acc: 23.094,38.022,95.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 1.926 |  Acc: 21.820,37.040,71.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 0.885 |  Acc: 23.042,37.958,95.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 1.917 |  Acc: 22.140,37.480,71.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 0.882 |  Acc: 23.088,37.794,95.590,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 1.933 |  Acc: 22.210,37.130,71.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.881 |  Acc: 23.138,38.010,95.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 1.953 |  Acc: 21.810,37.250,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.878 |  Acc: 23.286,38.180,95.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 1.950 |  Acc: 21.840,37.000,71.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.877 |  Acc: 23.008,38.026,95.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 1.944 |  Acc: 21.950,37.450,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.876 |  Acc: 23.230,37.964,95.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 1.934 |  Acc: 22.220,37.620,71.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.875 |  Acc: 23.036,38.120,95.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 1.964 |  Acc: 22.050,37.270,70.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.872 |  Acc: 23.442,38.262,95.840,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 1.945 |  Acc: 22.050,37.300,71.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.870 |  Acc: 23.312,38.432,95.968,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 1.961 |  Acc: 21.660,37.090,70.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.870 |  Acc: 23.208,38.390,95.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 1.961 |  Acc: 21.780,37.670,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.868 |  Acc: 23.396,38.228,95.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 1.940 |  Acc: 22.190,37.550,71.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.867 |  Acc: 23.454,38.138,96.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 1.966 |  Acc: 21.860,36.960,70.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.866 |  Acc: 23.450,38.478,95.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 1.974 |  Acc: 21.950,37.690,70.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.864 |  Acc: 23.246,38.352,96.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 1.972 |  Acc: 21.920,37.670,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.867 |  Acc: 23.412,38.400,95.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 1.967 |  Acc: 22.040,37.220,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.862 |  Acc: 23.272,38.462,96.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 1.968 |  Acc: 22.010,37.380,70.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.860 |  Acc: 23.188,38.670,96.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 1.972 |  Acc: 22.250,38.080,71.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.861 |  Acc: 23.186,38.610,96.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 1.986 |  Acc: 22.080,37.350,70.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.859 |  Acc: 23.354,38.340,96.242,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 1.984 |  Acc: 21.780,38.070,70.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.858 |  Acc: 23.470,38.614,96.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 1.958 |  Acc: 21.270,37.530,70.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.857 |  Acc: 23.380,38.776,96.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 1.983 |  Acc: 22.180,37.970,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.858 |  Acc: 23.600,38.666,96.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 1.990 |  Acc: 22.060,38.020,69.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.850 |  Acc: 23.344,38.866,96.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 2.000 |  Acc: 22.080,37.630,70.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.858 |  Acc: 23.412,38.602,96.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 1.984 |  Acc: 22.570,38.250,70.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.852 |  Acc: 23.574,38.766,96.264,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 1.982 |  Acc: 22.620,38.110,70.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.852 |  Acc: 23.452,38.824,96.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 2.021 |  Acc: 21.860,38.020,70.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.852 |  Acc: 23.456,39.010,96.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 1.993 |  Acc: 21.920,37.740,70.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.848 |  Acc: 23.340,38.956,96.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 1.990 |  Acc: 22.210,37.850,70.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.847 |  Acc: 23.556,38.822,96.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 1.990 |  Acc: 22.260,37.820,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.847 |  Acc: 23.494,38.998,96.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 1.980 |  Acc: 22.010,38.270,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.854 |  Acc: 23.580,38.984,96.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 2.009 |  Acc: 22.040,38.100,70.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.848 |  Acc: 23.498,39.146,96.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 2.009 |  Acc: 21.890,38.030,70.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.847 |  Acc: 23.698,39.170,96.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 2.006 |  Acc: 22.170,38.050,69.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.844 |  Acc: 23.436,39.098,96.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 2.020 |  Acc: 22.220,37.880,70.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.849 |  Acc: 23.478,38.906,96.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 2.016 |  Acc: 21.770,37.990,69.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.850 |  Acc: 23.650,38.960,96.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 2.022 |  Acc: 22.120,38.180,70.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.845 |  Acc: 23.480,39.082,96.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 2.003 |  Acc: 22.320,38.440,70.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.843 |  Acc: 23.546,39.206,96.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 2.036 |  Acc: 21.940,38.270,69.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.822 |  Acc: 23.436,39.424,97.166,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 1.972 |  Acc: 22.290,38.770,70.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.806 |  Acc: 23.564,39.450,97.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 1.970 |  Acc: 22.350,39.000,71.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.802 |  Acc: 23.596,39.584,97.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 1.979 |  Acc: 22.490,38.970,71.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.802 |  Acc: 23.512,39.432,97.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 1.976 |  Acc: 22.420,38.910,71.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.800 |  Acc: 23.738,39.670,97.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 1.966 |  Acc: 22.470,38.980,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.797 |  Acc: 23.734,39.636,97.878,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 1.971 |  Acc: 22.440,38.980,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.795 |  Acc: 23.652,39.582,98.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 1.981 |  Acc: 22.360,38.990,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.793 |  Acc: 23.724,39.752,97.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 1.981 |  Acc: 22.380,39.170,71.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.793 |  Acc: 23.788,39.458,98.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 1.977 |  Acc: 22.390,38.670,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.793 |  Acc: 23.768,39.772,98.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 1.979 |  Acc: 22.580,39.020,71.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.791 |  Acc: 23.842,39.876,98.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 1.979 |  Acc: 22.100,38.750,71.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.788 |  Acc: 23.818,39.836,98.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 1.975 |  Acc: 22.590,39.180,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.789 |  Acc: 23.712,39.948,98.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 1.978 |  Acc: 22.670,39.190,71.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.789 |  Acc: 23.686,39.544,98.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 1.981 |  Acc: 22.610,39.480,71.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.786 |  Acc: 23.716,39.748,98.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 1.979 |  Acc: 22.580,39.180,71.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.788 |  Acc: 23.812,39.898,98.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 1.976 |  Acc: 22.630,39.000,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.785 |  Acc: 23.854,39.790,98.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 1.978 |  Acc: 22.300,39.080,71.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.785 |  Acc: 24.014,39.790,98.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 1.977 |  Acc: 22.660,39.060,71.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.789 |  Acc: 23.888,39.956,98.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 1.982 |  Acc: 22.650,39.260,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.786 |  Acc: 23.664,39.870,98.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 1.995 |  Acc: 22.420,39.230,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.787 |  Acc: 23.724,39.796,98.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 1.990 |  Acc: 22.670,39.490,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.786 |  Acc: 23.880,39.958,98.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 1.988 |  Acc: 22.620,39.340,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.783 |  Acc: 23.908,39.936,98.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 1.992 |  Acc: 22.660,39.320,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.786 |  Acc: 24.020,39.830,98.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 1.993 |  Acc: 22.460,39.650,71.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.784 |  Acc: 23.928,39.794,98.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 1.991 |  Acc: 22.880,39.320,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.783 |  Acc: 24.090,40.008,98.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 1.995 |  Acc: 22.810,39.360,71.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.782 |  Acc: 23.940,40.072,98.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 1.992 |  Acc: 22.720,39.320,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.783 |  Acc: 23.838,39.974,98.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 1.998 |  Acc: 22.820,39.130,71.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.782 |  Acc: 23.774,39.780,98.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 1.987 |  Acc: 22.520,39.000,71.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.781 |  Acc: 24.120,40.056,98.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 1.996 |  Acc: 22.710,39.440,70.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.780 |  Acc: 23.912,39.922,98.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 1.999 |  Acc: 22.730,39.400,71.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.781 |  Acc: 23.640,39.988,98.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 1.994 |  Acc: 22.770,39.170,70.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.781 |  Acc: 23.942,40.132,98.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 1.992 |  Acc: 22.490,39.140,71.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.780 |  Acc: 23.972,40.000,98.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 1.998 |  Acc: 22.640,39.410,70.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.779 |  Acc: 23.722,39.804,98.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 1.996 |  Acc: 22.710,39.480,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.782 |  Acc: 23.860,39.984,98.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 1.999 |  Acc: 23.060,39.270,71.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.784 |  Acc: 23.874,39.902,98.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 1.997 |  Acc: 22.250,39.300,70.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.781 |  Acc: 23.782,39.892,98.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 1.993 |  Acc: 22.570,39.430,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.778 |  Acc: 23.976,39.986,98.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 1.995 |  Acc: 22.500,39.070,71.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.777 |  Acc: 24.080,39.990,98.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 1.999 |  Acc: 22.950,39.580,71.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.778 |  Acc: 23.858,39.732,98.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 2.004 |  Acc: 22.540,39.140,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.779 |  Acc: 23.898,39.990,98.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 1.992 |  Acc: 22.400,39.300,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.778 |  Acc: 23.968,39.900,98.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 2.002 |  Acc: 22.640,39.180,70.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.778 |  Acc: 23.850,39.984,98.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 2.003 |  Acc: 22.730,39.060,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.778 |  Acc: 23.910,40.036,98.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 1.992 |  Acc: 22.750,38.990,71.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.776 |  Acc: 23.830,40.134,98.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 1.987 |  Acc: 22.700,39.280,71.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.779 |  Acc: 23.916,39.934,98.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 1.995 |  Acc: 22.780,39.460,71.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.777 |  Acc: 23.930,39.922,98.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 1.990 |  Acc: 22.410,39.100,71.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.776 |  Acc: 24.004,40.046,98.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 1.993 |  Acc: 22.690,38.960,71.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.777 |  Acc: 24.028,39.940,98.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 1.990 |  Acc: 22.770,39.060,71.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.776 |  Acc: 23.842,40.108,98.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 1.996 |  Acc: 22.890,39.640,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.779 |  Acc: 24.016,40.182,98.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 1.992 |  Acc: 22.910,39.540,71.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.776 |  Acc: 24.026,40.100,98.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 1.993 |  Acc: 22.770,39.360,71.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.777 |  Acc: 24.028,40.048,98.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 1.996 |  Acc: 22.440,39.240,70.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.777 |  Acc: 23.856,40.204,98.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 2.005 |  Acc: 22.860,39.390,71.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.775 |  Acc: 24.072,40.042,98.602,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 1.992 |  Acc: 22.900,39.260,70.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.776 |  Acc: 23.992,39.792,98.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 1.993 |  Acc: 22.990,39.770,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.776 |  Acc: 23.796,40.180,98.578,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 2.002 |  Acc: 22.640,39.490,70.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.776 |  Acc: 24.004,40.060,98.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 1.996 |  Acc: 22.830,39.270,71.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.778 |  Acc: 23.980,40.132,98.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 1.994 |  Acc: 22.560,39.170,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.777 |  Acc: 23.880,40.192,98.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 2.004 |  Acc: 22.810,39.510,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.775 |  Acc: 23.896,39.944,98.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 1.998 |  Acc: 22.970,39.450,70.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.775 |  Acc: 23.920,39.988,98.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 1.989 |  Acc: 22.760,39.530,71.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.776 |  Acc: 24.070,40.100,98.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 1.995 |  Acc: 22.850,39.350,70.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.779 |  Acc: 23.886,39.974,98.428,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 2.001 |  Acc: 22.890,39.370,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.775 |  Acc: 23.790,40.210,98.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 2.000 |  Acc: 22.620,39.330,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.777 |  Acc: 23.812,40.122,98.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 1.999 |  Acc: 22.790,39.380,70.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.774 |  Acc: 24.028,39.910,98.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 1.997 |  Acc: 22.740,39.240,71.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.778 |  Acc: 23.864,40.014,98.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 2.003 |  Acc: 23.040,39.600,70.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.780 |  Acc: 23.850,39.916,98.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 1.998 |  Acc: 22.720,39.310,71.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.776 |  Acc: 23.858,39.986,98.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 1.991 |  Acc: 22.720,39.270,71.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.775 |  Acc: 23.766,40.122,98.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 1.996 |  Acc: 22.900,39.290,71.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.777 |  Acc: 23.852,40.034,98.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 1.999 |  Acc: 22.700,39.330,71.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.776 |  Acc: 23.886,40.160,98.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 1.999 |  Acc: 22.790,39.560,71.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=2, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.778 |  Acc: 23.860,39.938,98.490,% | Adaptive Acc:97.534% | clf_exit: 0.005 0.073 0.922
Testing: Epoch=299 | Loss: 2.000 |  Acc: 22.750,39.590,70.890,% | Adaptive Acc:69.960% | clf_exit: 0.022 0.122 0.856

circles: 0
Testing: Epoch=299 | Loss: 4.470 |  Acc: 1.580,2.390,27.220,% | Adaptive Acc:27.080% | clf_exit: 0.018 0.000 0.982
circles: 1
Testing: Epoch=299 | Loss: 2.458 |  Acc: 6.660,14.490,65.080,% | Adaptive Acc:65.030% | clf_exit: 0.003 0.006 0.991
circles: 2
Testing: Epoch=299 | Loss: 2.000 |  Acc: 22.750,39.590,70.890,% | Adaptive Acc:69.960% | clf_exit: 0.022 0.122 0.856
