==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=16, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=132, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=132, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=164, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=164, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 5.974 | Acc: 0.781,0.781,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.792 | Acc: 1.042,0.856,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.698 | Acc: 0.915,0.819,2.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.643 | Acc: 0.999,0.961,2.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.599 | Acc: 0.993,0.955,2.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.556 | Acc: 0.959,1.052,2.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.517 | Acc: 1.046,1.162,3.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.476 | Acc: 1.197,1.280,3.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.434 | Acc: 1.271,1.383,3.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.397 | Acc: 1.321,1.515,4.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.366 | Acc: 1.388,1.594,4.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.340 | Acc: 1.442,1.683,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.312 | Acc: 1.543,1.783,4.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.287 | Acc: 1.625,1.898,5.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.262 | Acc: 1.649,1.968,5.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.238 | Acc: 1.716,2.022,5.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.218 | Acc: 1.794,2.074,5.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.200 | Acc: 1.821,2.133,6.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.180 | Acc: 1.887,2.199,6.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.163 | Acc: 1.934,2.262,6.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.706 | Acc: 4.688,5.469,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.834 | Acc: 2.753,3.497,10.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.819 | Acc: 3.068,3.792,10.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.831 | Acc: 3.010,4.086,10.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 4.801 | Acc: 2.344,4.688,14.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.833 | Acc: 2.865,3.943,10.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.793 | Acc: 3.258,4.402,11.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.789 | Acc: 3.163,4.470,11.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.775 | Acc: 3.183,4.581,11.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.773 | Acc: 3.110,4.486,11.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.761 | Acc: 3.183,4.558,11.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.754 | Acc: 3.252,4.643,11.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.746 | Acc: 3.227,4.692,11.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.738 | Acc: 3.216,4.774,12.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.729 | Acc: 3.191,4.839,12.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.720 | Acc: 3.224,4.931,12.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.711 | Acc: 3.216,5.122,12.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.702 | Acc: 3.197,5.175,12.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.696 | Acc: 3.222,5.230,12.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.690 | Acc: 3.234,5.264,12.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.682 | Acc: 3.220,5.323,12.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.674 | Acc: 3.201,5.382,12.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.667 | Acc: 3.238,5.428,13.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.661 | Acc: 3.264,5.520,13.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.432 | Acc: 2.344,3.906,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.506 | Acc: 2.865,5.618,15.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.508 | Acc: 3.106,5.755,15.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.523 | Acc: 2.805,5.725,15.087,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 4.437 | Acc: 2.344,6.250,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.491 | Acc: 2.827,6.845,16.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.470 | Acc: 3.030,6.860,16.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.473 | Acc: 3.138,6.621,16.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.478 | Acc: 3.231,6.752,15.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.471 | Acc: 3.349,6.931,16.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.462 | Acc: 3.409,7.115,16.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.461 | Acc: 3.480,7.164,16.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.458 | Acc: 3.518,7.206,16.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.454 | Acc: 3.548,7.269,16.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.448 | Acc: 3.584,7.296,16.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.442 | Acc: 3.616,7.356,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.438 | Acc: 3.614,7.417,16.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.436 | Acc: 3.601,7.399,16.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.430 | Acc: 3.614,7.434,16.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.425 | Acc: 3.631,7.488,16.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.420 | Acc: 3.636,7.569,16.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.413 | Acc: 3.638,7.666,16.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.408 | Acc: 3.640,7.685,16.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.406 | Acc: 3.650,7.712,16.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.356 | Acc: 7.031,7.031,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.370 | Acc: 3.943,7.366,17.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.369 | Acc: 3.544,7.450,17.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.373 | Acc: 3.663,7.403,16.765,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 4.318 | Acc: 3.906,5.469,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.231 | Acc: 3.981,8.222,20.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.254 | Acc: 4.249,8.498,19.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.244 | Acc: 4.098,8.491,19.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.254 | Acc: 4.012,8.410,19.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.260 | Acc: 3.922,8.478,19.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.254 | Acc: 3.997,8.645,19.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.247 | Acc: 4.012,8.660,19.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.240 | Acc: 4.100,8.841,19.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.239 | Acc: 4.070,8.771,19.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.236 | Acc: 4.112,8.885,19.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.230 | Acc: 4.136,8.908,19.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.228 | Acc: 4.146,8.941,19.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.228 | Acc: 4.161,9.016,19.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.227 | Acc: 4.184,9.041,19.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.222 | Acc: 4.179,9.064,19.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.223 | Acc: 4.157,9.085,19.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.219 | Acc: 4.202,9.052,20.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.216 | Acc: 4.214,9.081,20.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.213 | Acc: 4.236,9.108,20.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.141 | Acc: 6.250,11.719,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.149 | Acc: 3.906,9.747,20.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.161 | Acc: 3.811,9.623,20.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.170 | Acc: 3.842,9.349,20.415,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 4.155 | Acc: 4.688,6.250,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.059 | Acc: 5.469,10.528,23.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.104 | Acc: 5.221,10.194,22.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.092 | Acc: 4.969,10.118,22.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.099 | Acc: 4.697,9.790,22.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.095 | Acc: 4.834,10.002,22.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.092 | Acc: 4.649,10.053,22.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.092 | Acc: 4.593,9.946,22.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.085 | Acc: 4.692,10.016,22.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.082 | Acc: 4.653,9.975,22.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.081 | Acc: 4.606,10.016,22.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.081 | Acc: 4.634,9.979,22.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.078 | Acc: 4.665,9.968,22.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.074 | Acc: 4.622,9.983,22.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.072 | Acc: 4.607,10.056,22.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.068 | Acc: 4.610,10.102,22.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.065 | Acc: 4.590,10.098,22.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.061 | Acc: 4.633,10.165,22.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.057 | Acc: 4.599,10.238,22.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.054 | Acc: 4.587,10.267,22.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.883 | Acc: 9.375,11.719,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.966 | Acc: 5.841,11.458,23.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.968 | Acc: 5.145,11.166,23.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.974 | Acc: 4.905,10.733,23.284,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 3.949 | Acc: 7.031,10.156,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.918 | Acc: 4.874,11.012,24.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.943 | Acc: 4.726,10.537,24.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.954 | Acc: 4.790,10.861,23.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.953 | Acc: 5.035,11.015,24.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.945 | Acc: 5.128,11.309,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.934 | Acc: 5.049,11.247,24.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.927 | Acc: 5.081,11.281,24.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.922 | Acc: 5.129,11.326,24.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.922 | Acc: 5.098,11.291,24.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.926 | Acc: 5.065,11.342,24.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.919 | Acc: 5.073,11.355,24.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.918 | Acc: 5.102,11.245,25.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.914 | Acc: 5.077,11.201,25.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.912 | Acc: 5.060,11.135,25.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.908 | Acc: 5.064,11.200,25.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.904 | Acc: 5.062,11.220,25.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.898 | Acc: 5.075,11.267,25.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.895 | Acc: 5.086,11.334,25.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.892 | Acc: 5.046,11.329,25.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.679 | Acc: 9.375,7.812,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.846 | Acc: 4.836,9.896,26.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.840 | Acc: 4.630,9.966,25.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.851 | Acc: 4.700,9.849,25.768,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 3.855 | Acc: 3.125,14.062,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.832 | Acc: 4.539,10.826,27.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.791 | Acc: 4.707,11.395,27.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.794 | Acc: 5.289,11.872,27.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.784 | Acc: 5.392,11.728,27.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.790 | Acc: 5.314,11.897,27.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.789 | Acc: 5.288,11.848,27.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.777 | Acc: 5.280,11.852,27.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.770 | Acc: 5.236,11.889,27.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.765 | Acc: 5.287,11.878,27.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.761 | Acc: 5.271,11.933,27.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.756 | Acc: 5.303,12.016,27.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.754 | Acc: 5.248,12.023,27.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.747 | Acc: 5.271,11.967,27.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.745 | Acc: 5.274,11.933,27.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.743 | Acc: 5.271,11.947,28.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.740 | Acc: 5.289,11.974,28.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.739 | Acc: 5.249,11.962,28.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.740 | Acc: 5.274,11.935,28.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.736 | Acc: 5.288,11.969,28.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.646 | Acc: 6.250,14.062,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.752 | Acc: 5.915,11.607,26.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.733 | Acc: 5.621,11.376,28.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.737 | Acc: 5.302,11.283,28.061,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 3.745 | Acc: 1.562,7.031,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.607 | Acc: 5.320,12.984,30.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.611 | Acc: 5.526,12.824,30.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.604 | Acc: 5.443,12.961,30.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.601 | Acc: 5.565,12.799,30.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.610 | Acc: 5.662,12.871,30.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.611 | Acc: 5.527,13.036,30.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.614 | Acc: 5.591,12.965,30.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.617 | Acc: 5.576,12.791,30.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.618 | Acc: 5.628,12.850,30.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.619 | Acc: 5.601,12.745,30.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.616 | Acc: 5.585,12.804,30.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.613 | Acc: 5.692,12.675,30.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.604 | Acc: 5.720,12.689,30.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.603 | Acc: 5.775,12.703,30.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.598 | Acc: 5.811,12.796,30.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.594 | Acc: 5.773,12.858,30.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.593 | Acc: 5.755,12.816,30.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.589 | Acc: 5.778,12.872,30.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.589 | Acc: 5.795,12.890,30.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.507 | Acc: 6.250,14.844,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.604 | Acc: 5.246,11.124,30.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.582 | Acc: 5.107,11.166,30.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.590 | Acc: 4.995,11.194,30.866,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 3.628 | Acc: 4.688,13.281,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.500 | Acc: 6.436,14.211,33.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.490 | Acc: 6.498,13.567,33.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.497 | Acc: 6.519,13.819,33.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.476 | Acc: 6.780,14.246,33.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.476 | Acc: 6.737,14.171,32.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.475 | Acc: 6.592,13.946,33.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.470 | Acc: 6.560,13.835,33.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.475 | Acc: 6.454,13.679,33.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.474 | Acc: 6.405,13.532,33.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.470 | Acc: 6.382,13.538,33.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.470 | Acc: 6.459,13.493,33.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.468 | Acc: 6.415,13.469,33.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.468 | Acc: 6.409,13.467,33.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.465 | Acc: 6.383,13.487,33.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.460 | Acc: 6.414,13.491,33.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.455 | Acc: 6.437,13.508,33.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.456 | Acc: 6.465,13.492,33.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.456 | Acc: 6.464,13.526,33.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.453 | Acc: 6.465,13.577,33.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.447 | Acc: 7.031,12.500,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.574 | Acc: 5.952,12.128,31.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.564 | Acc: 5.774,11.852,30.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.566 | Acc: 5.520,12.167,31.224,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 3.277 | Acc: 9.375,16.406,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.344 | Acc: 6.510,13.616,36.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.324 | Acc: 6.764,13.929,36.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.328 | Acc: 6.852,14.191,36.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.332 | Acc: 6.742,14.323,36.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.331 | Acc: 6.776,14.426,36.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.331 | Acc: 6.941,14.437,36.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.330 | Acc: 7.015,14.445,36.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.334 | Acc: 7.007,14.465,36.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.336 | Acc: 6.971,14.347,35.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.338 | Acc: 6.950,14.292,35.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.340 | Acc: 6.936,14.303,35.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.340 | Acc: 6.898,14.293,35.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.338 | Acc: 6.938,14.323,35.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.336 | Acc: 6.906,14.304,35.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.336 | Acc: 6.946,14.304,35.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.335 | Acc: 6.944,14.364,35.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.332 | Acc: 6.985,14.360,35.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.329 | Acc: 7.018,14.396,35.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.323 | Acc: 6.996,14.432,36.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.521 | Acc: 9.375,17.969,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.710 | Acc: 5.283,13.579,28.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.734 | Acc: 4.897,13.338,28.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.765 | Acc: 4.931,13.192,28.522,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 3.319 | Acc: 2.344,11.719,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.238 | Acc: 7.031,14.286,37.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.223 | Acc: 7.165,14.577,38.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.214 | Acc: 7.223,14.959,38.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.210 | Acc: 7.475,15.287,38.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.217 | Acc: 7.503,15.323,38.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.213 | Acc: 7.567,15.380,38.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.210 | Acc: 7.596,15.570,38.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.209 | Acc: 7.521,15.504,38.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.211 | Acc: 7.450,15.444,38.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.211 | Acc: 7.482,15.396,38.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.211 | Acc: 7.410,15.374,38.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.210 | Acc: 7.466,15.320,38.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.208 | Acc: 7.468,15.302,38.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.201 | Acc: 7.462,15.325,38.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.199 | Acc: 7.519,15.404,38.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.200 | Acc: 7.511,15.501,38.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.200 | Acc: 7.572,15.561,38.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.202 | Acc: 7.538,15.601,38.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.203 | Acc: 7.534,15.635,38.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.544 | Acc: 9.375,17.969,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.588 | Acc: 6.510,15.402,31.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.606 | Acc: 6.593,15.168,31.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.616 | Acc: 6.570,14.780,31.570,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 3.148 | Acc: 11.719,17.188,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.126 | Acc: 7.738,16.295,39.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.115 | Acc: 7.908,16.502,39.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.120 | Acc: 7.915,16.112,40.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.102 | Acc: 7.697,16.281,40.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.089 | Acc: 7.743,16.460,40.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.086 | Acc: 7.858,16.497,40.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.091 | Acc: 7.718,16.379,40.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.091 | Acc: 7.808,16.503,40.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.090 | Acc: 7.774,16.471,40.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.093 | Acc: 7.828,16.484,40.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.096 | Acc: 7.798,16.495,40.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.098 | Acc: 7.838,16.516,40.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.097 | Acc: 7.848,16.571,40.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.101 | Acc: 7.876,16.593,40.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.101 | Acc: 7.893,16.513,40.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.102 | Acc: 7.864,16.504,40.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.103 | Acc: 7.911,16.484,40.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.099 | Acc: 7.932,16.523,40.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.100 | Acc: 7.942,16.544,40.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.163 | Acc: 10.156,17.188,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.368 | Acc: 7.478,14.695,35.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.357 | Acc: 7.203,15.015,35.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.377 | Acc: 7.095,14.959,35.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 3.171 | Acc: 9.375,17.969,39.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.999 | Acc: 9.003,17.522,41.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.022 | Acc: 9.204,17.664,41.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.017 | Acc: 8.914,17.597,42.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.006 | Acc: 8.709,17.467,42.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.008 | Acc: 8.524,17.350,42.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.013 | Acc: 8.445,17.336,42.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.011 | Acc: 8.416,17.138,42.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.008 | Acc: 8.419,17.149,42.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.009 | Acc: 8.378,17.179,42.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.003 | Acc: 8.427,17.254,42.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.003 | Acc: 8.368,17.195,42.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.005 | Acc: 8.409,17.139,42.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.006 | Acc: 8.420,17.161,42.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.007 | Acc: 8.452,17.107,42.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.007 | Acc: 8.422,17.099,42.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.003 | Acc: 8.416,17.044,42.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.003 | Acc: 8.353,17.064,42.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.005 | Acc: 8.334,17.017,42.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.003 | Acc: 8.352,17.015,42.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.975 | Acc: 9.375,17.969,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.298 | Acc: 6.920,14.881,37.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.289 | Acc: 6.764,14.463,37.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.302 | Acc: 6.878,14.408,36.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 2.881 | Acc: 6.250,19.531,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.901 | Acc: 9.003,17.448,43.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.903 | Acc: 9.394,17.854,44.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.906 | Acc: 9.196,17.853,44.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.909 | Acc: 8.748,17.728,44.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.922 | Acc: 8.648,17.768,44.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.918 | Acc: 8.574,17.698,44.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.917 | Acc: 8.577,17.780,44.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.917 | Acc: 8.545,17.847,44.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.915 | Acc: 8.572,17.848,44.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.912 | Acc: 8.629,17.969,44.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.910 | Acc: 8.576,17.856,44.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.914 | Acc: 8.545,17.862,44.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.916 | Acc: 8.549,17.885,44.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.916 | Acc: 8.627,17.902,44.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.920 | Acc: 8.630,17.878,44.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.920 | Acc: 8.586,17.823,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.922 | Acc: 8.637,17.813,44.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.924 | Acc: 8.685,17.783,44.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.923 | Acc: 8.684,17.819,44.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.905 | Acc: 10.938,18.750,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.164 | Acc: 7.850,16.815,40.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.146 | Acc: 7.412,16.711,40.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.153 | Acc: 7.403,16.445,40.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 2.894 | Acc: 7.812,12.500,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 8.929,18.192,46.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.851 | Acc: 8.670,17.569,45.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.844 | Acc: 8.658,17.354,45.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.841 | Acc: 8.546,17.515,45.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.821 | Acc: 8.571,17.752,46.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.832 | Acc: 8.549,17.833,45.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.830 | Acc: 8.693,17.886,45.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.827 | Acc: 8.749,17.925,46.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.826 | Acc: 8.741,17.822,45.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.827 | Acc: 8.745,17.875,46.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.827 | Acc: 8.732,17.905,46.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.828 | Acc: 8.685,17.930,45.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.829 | Acc: 8.687,17.930,46.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.828 | Acc: 8.766,17.974,46.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.829 | Acc: 8.794,18.000,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.832 | Acc: 8.808,17.998,45.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.831 | Acc: 8.800,17.973,45.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.833 | Acc: 8.804,18.012,45.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.832 | Acc: 8.811,18.059,45.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.988 | Acc: 14.062,17.969,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.139 | Acc: 8.929,17.522,40.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.153 | Acc: 8.689,17.111,40.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.176 | Acc: 8.696,17.149,40.010,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 2.733 | Acc: 6.250,13.281,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.751 | Acc: 9.375,18.080,48.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.753 | Acc: 9.242,18.426,48.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.761 | Acc: 9.170,18.417,47.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.775 | Acc: 8.980,18.171,47.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.767 | Acc: 9.174,18.441,47.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.752 | Acc: 9.130,18.737,47.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.759 | Acc: 9.187,18.833,47.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.756 | Acc: 9.220,18.862,47.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.746 | Acc: 9.319,19.091,47.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.744 | Acc: 9.297,19.108,47.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.743 | Acc: 9.350,19.043,47.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.749 | Acc: 9.291,18.922,47.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.752 | Acc: 9.255,18.771,47.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.757 | Acc: 9.242,18.714,47.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.759 | Acc: 9.263,18.662,47.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.758 | Acc: 9.224,18.772,47.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.757 | Acc: 9.242,18.794,47.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.755 | Acc: 9.247,18.756,47.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.756 | Acc: 9.246,18.783,47.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.993 | Acc: 8.594,22.656,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.966 | Acc: 7.478,17.039,44.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.958 | Acc: 7.622,16.787,44.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.964 | Acc: 7.390,16.598,44.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 2.854 | Acc: 11.719,17.969,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.740 | Acc: 9.226,17.932,46.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.716 | Acc: 9.299,18.464,46.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.695 | Acc: 9.516,18.814,47.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.694 | Acc: 9.857,18.856,47.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.684 | Acc: 9.623,19.052,48.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.690 | Acc: 9.724,19.305,48.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.693 | Acc: 9.630,19.099,48.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.701 | Acc: 9.686,19.250,48.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.705 | Acc: 9.660,19.052,48.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.703 | Acc: 9.670,18.979,48.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.709 | Acc: 9.753,19.072,48.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.706 | Acc: 9.783,19.142,48.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.703 | Acc: 9.857,19.217,48.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.706 | Acc: 9.784,19.212,48.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.707 | Acc: 9.736,19.248,48.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.707 | Acc: 9.706,19.249,48.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.704 | Acc: 9.732,19.320,48.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.701 | Acc: 9.765,19.298,48.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.703 | Acc: 9.820,19.324,48.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.874 | Acc: 7.812,17.969,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.876 | Acc: 9.189,17.894,46.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.877 | Acc: 9.127,17.740,46.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.887 | Acc: 9.016,17.495,45.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 2.527 | Acc: 9.375,28.906,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.589 | Acc: 10.454,20.573,52.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.583 | Acc: 10.633,20.598,51.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.594 | Acc: 10.540,20.530,51.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.607 | Acc: 10.204,20.071,50.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.608 | Acc: 10.172,20.135,50.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.610 | Acc: 10.182,20.125,50.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.625 | Acc: 10.012,19.930,50.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.632 | Acc: 9.952,19.929,50.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.636 | Acc: 9.902,19.807,50.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.641 | Acc: 9.970,19.877,50.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.645 | Acc: 10.008,19.775,49.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.647 | Acc: 9.952,19.842,49.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.643 | Acc: 9.947,19.855,50.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.645 | Acc: 9.920,19.770,49.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.647 | Acc: 9.897,19.799,50.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.645 | Acc: 9.918,19.777,50.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.644 | Acc: 9.962,19.795,50.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.641 | Acc: 9.994,19.782,50.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.643 | Acc: 9.972,19.736,50.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.722 | Acc: 6.250,17.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.878 | Acc: 6.473,13.988,47.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.884 | Acc: 6.784,14.024,46.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.908 | Acc: 6.673,14.165,45.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 2.447 | Acc: 8.594,18.750,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.471 | Acc: 10.082,20.238,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 9.909,20.408,53.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.505 | Acc: 10.003,20.428,53.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.536 | Acc: 9.954,20.390,52.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.538 | Acc: 9.901,20.173,52.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.542 | Acc: 9.866,20.048,52.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.557 | Acc: 9.940,19.936,52.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.568 | Acc: 9.865,19.779,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.574 | Acc: 9.850,19.782,52.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.576 | Acc: 9.830,19.834,52.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.573 | Acc: 9.958,20.019,52.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.573 | Acc: 10.017,19.898,52.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.573 | Acc: 10.072,19.956,52.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.577 | Acc: 10.090,20.001,51.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.581 | Acc: 10.107,19.954,51.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.579 | Acc: 10.125,19.901,51.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.582 | Acc: 10.101,19.873,51.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.583 | Acc: 10.104,19.888,51.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.585 | Acc: 10.093,19.839,51.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.711 | Acc: 7.812,20.312,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.924 | Acc: 8.519,16.629,46.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.906 | Acc: 8.365,17.054,46.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.921 | Acc: 8.210,16.778,45.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 2.428 | Acc: 12.500,21.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.533 | Acc: 10.603,19.717,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.520 | Acc: 10.861,20.179,53.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.497 | Acc: 10.643,20.645,53.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.504 | Acc: 10.725,20.486,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.513 | Acc: 10.458,20.312,52.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.516 | Acc: 10.440,20.403,52.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.517 | Acc: 10.611,20.512,53.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.526 | Acc: 10.525,20.220,52.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.529 | Acc: 10.428,20.192,52.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.528 | Acc: 10.467,20.390,52.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.535 | Acc: 10.340,20.281,52.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.537 | Acc: 10.254,20.270,52.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.538 | Acc: 10.297,20.241,52.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.539 | Acc: 10.301,20.285,52.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.540 | Acc: 10.328,20.300,52.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.540 | Acc: 10.380,20.320,52.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.542 | Acc: 10.404,20.342,52.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.542 | Acc: 10.420,20.401,52.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.544 | Acc: 10.435,20.407,52.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.575 | Acc: 7.031,17.969,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 8.185,17.374,47.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.848 | Acc: 8.213,17.435,47.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.854 | Acc: 7.992,17.392,46.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 2.557 | Acc: 6.250,17.969,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.488 | Acc: 10.714,20.982,54.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.486 | Acc: 10.804,21.075,54.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 10.950,21.401,54.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.484 | Acc: 10.986,21.277,53.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.488 | Acc: 10.845,21.225,53.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.487 | Acc: 10.537,21.100,53.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.484 | Acc: 10.444,20.789,53.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.486 | Acc: 10.515,20.895,53.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.480 | Acc: 10.627,21.007,53.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.481 | Acc: 10.607,20.958,53.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 10.619,20.991,53.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 10.711,21.058,53.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.475 | Acc: 10.704,21.067,53.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.482 | Acc: 10.696,21.033,53.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.483 | Acc: 10.673,20.995,53.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.482 | Acc: 10.753,21.099,53.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.483 | Acc: 10.711,21.080,53.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.484 | Acc: 10.764,21.031,53.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.484 | Acc: 10.763,21.061,53.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.704 | Acc: 8.594,22.656,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.812 | Acc: 9.784,18.192,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.802 | Acc: 9.794,18.026,47.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.813 | Acc: 9.670,18.276,46.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 2.587 | Acc: 12.500,24.219,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.483 | Acc: 10.454,20.015,54.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.419 | Acc: 11.223,21.437,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.417 | Acc: 11.258,21.913,55.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.411 | Acc: 11.063,21.865,55.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.407 | Acc: 10.876,21.860,55.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.419 | Acc: 10.770,21.914,55.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.423 | Acc: 10.777,21.919,55.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.423 | Acc: 10.729,21.967,55.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.422 | Acc: 10.761,22.000,55.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.426 | Acc: 10.766,21.863,55.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.422 | Acc: 10.842,21.960,55.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.424 | Acc: 10.879,21.917,55.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.432 | Acc: 10.866,21.812,55.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.435 | Acc: 10.904,21.730,55.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.438 | Acc: 10.984,21.802,54.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.440 | Acc: 10.989,21.773,54.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.441 | Acc: 11.011,21.733,54.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.444 | Acc: 10.987,21.680,54.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.444 | Acc: 10.970,21.623,54.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.839 | Acc: 6.250,19.531,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.963 | Acc: 7.924,17.374,44.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.954 | Acc: 7.965,17.264,45.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.954 | Acc: 7.851,16.995,45.389,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 2.301 | Acc: 12.500,17.969,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.349 | Acc: 11.682,21.689,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.350 | Acc: 11.986,22.313,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.369 | Acc: 11.616,21.683,56.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.377 | Acc: 11.622,21.865,56.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.384 | Acc: 11.502,21.759,55.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.389 | Acc: 11.409,21.688,55.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.391 | Acc: 11.492,21.714,55.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.390 | Acc: 11.452,21.657,55.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.391 | Acc: 11.425,21.625,55.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.395 | Acc: 11.369,21.498,55.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.394 | Acc: 11.372,21.592,55.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.396 | Acc: 11.369,21.677,55.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.397 | Acc: 11.324,21.627,55.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.400 | Acc: 11.227,21.552,55.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.401 | Acc: 11.226,21.584,55.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.401 | Acc: 11.161,21.532,55.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.402 | Acc: 11.178,21.621,55.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.403 | Acc: 11.195,21.633,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.404 | Acc: 11.202,21.631,55.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.596 | Acc: 10.156,20.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.631 | Acc: 9.263,18.490,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.643 | Acc: 8.746,17.873,51.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.656 | Acc: 9.004,17.943,50.922,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.363 | Acc: 8.594,19.531,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.318 | Acc: 11.830,22.433,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.318 | Acc: 11.452,23.037,57.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.308 | Acc: 11.322,22.887,58.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.307 | Acc: 11.352,22.425,58.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.324 | Acc: 11.324,22.177,57.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.328 | Acc: 11.448,21.894,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.328 | Acc: 11.420,21.958,57.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.338 | Acc: 11.496,21.948,57.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.341 | Acc: 11.525,22.078,57.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.338 | Acc: 11.521,22.201,57.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.341 | Acc: 11.563,22.229,57.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.339 | Acc: 11.560,22.215,57.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.339 | Acc: 11.467,22.150,57.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.340 | Acc: 11.441,22.153,57.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.343 | Acc: 11.431,22.116,57.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.345 | Acc: 11.439,22.101,57.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.348 | Acc: 11.460,22.136,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.351 | Acc: 11.450,22.139,57.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.349 | Acc: 11.454,22.101,57.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.603 | Acc: 7.812,21.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.698 | Acc: 9.524,19.196,50.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.689 | Acc: 9.851,19.607,50.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.706 | Acc: 9.708,19.570,49.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 2.316 | Acc: 13.281,17.969,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.264 | Acc: 11.905,22.135,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.299 | Acc: 11.947,22.656,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.320 | Acc: 11.821,22.182,57.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.312 | Acc: 11.574,21.943,57.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.307 | Acc: 11.634,21.875,57.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.307 | Acc: 11.796,22.191,57.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.308 | Acc: 11.896,22.108,57.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.310 | Acc: 12.024,22.215,57.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.313 | Acc: 11.952,22.099,57.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.320 | Acc: 11.831,22.069,57.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.320 | Acc: 11.878,22.172,57.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.318 | Acc: 11.839,22.287,57.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.318 | Acc: 11.892,22.450,57.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.317 | Acc: 11.847,22.356,57.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.317 | Acc: 11.869,22.334,57.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.317 | Acc: 11.896,22.337,57.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.319 | Acc: 11.916,22.370,57.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.317 | Acc: 11.918,22.338,57.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.316 | Acc: 11.858,22.363,57.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.522 | Acc: 8.594,21.094,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.662 | Acc: 9.859,18.452,50.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.674 | Acc: 9.661,18.598,49.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.679 | Acc: 10.003,18.481,50.090,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 2.252 | Acc: 11.719,20.312,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.193 | Acc: 12.314,25.037,61.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.245 | Acc: 12.062,23.571,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.255 | Acc: 11.655,23.002,59.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.247 | Acc: 11.786,23.100,60.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.251 | Acc: 11.765,22.981,59.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.262 | Acc: 11.622,22.747,59.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.271 | Acc: 11.719,22.629,59.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.272 | Acc: 11.772,22.525,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.280 | Acc: 11.771,22.617,58.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.282 | Acc: 11.828,22.718,58.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.289 | Acc: 11.779,22.578,58.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.289 | Acc: 11.868,22.689,58.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.288 | Acc: 11.883,22.740,58.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.285 | Acc: 11.874,22.692,58.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.286 | Acc: 11.929,22.755,58.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.289 | Acc: 11.884,22.685,58.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.291 | Acc: 11.943,22.734,58.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.290 | Acc: 11.963,22.684,58.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.290 | Acc: 11.965,22.640,58.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.411 | Acc: 9.375,24.219,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.592 | Acc: 9.263,20.164,52.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.599 | Acc: 9.585,20.522,52.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.616 | Acc: 9.413,20.453,51.601,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.268 | Acc: 16.406,29.688,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.200 | Acc: 11.868,23.958,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.194 | Acc: 11.662,22.771,61.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.197 | Acc: 11.603,22.746,61.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.207 | Acc: 11.642,22.627,60.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.229 | Acc: 11.688,22.741,60.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.226 | Acc: 11.706,22.818,60.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.234 | Acc: 11.924,23.033,59.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.244 | Acc: 11.971,23.015,59.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.250 | Acc: 11.982,22.816,59.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.252 | Acc: 12.053,22.948,59.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.248 | Acc: 12.072,23.038,59.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.245 | Acc: 12.020,22.896,59.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.243 | Acc: 11.955,22.851,59.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.245 | Acc: 11.991,22.923,59.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.243 | Acc: 11.952,22.848,59.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.246 | Acc: 11.901,22.849,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.250 | Acc: 11.879,22.922,59.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.251 | Acc: 11.883,22.916,59.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.255 | Acc: 11.860,22.888,59.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.562 | Acc: 10.938,24.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.573 | Acc: 11.272,20.126,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.599 | Acc: 11.033,19.703,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.597 | Acc: 10.963,19.736,52.626,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.097 | Acc: 7.031,24.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.193 | Acc: 12.054,22.619,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.207 | Acc: 12.157,23.018,60.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.211 | Acc: 12.513,22.836,60.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.196 | Acc: 12.211,22.743,60.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.198 | Acc: 12.198,23.020,60.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.199 | Acc: 12.035,23.037,60.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.197 | Acc: 12.079,23.249,60.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.201 | Acc: 12.146,23.161,60.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.203 | Acc: 12.129,23.153,60.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.210 | Acc: 12.131,23.185,60.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.209 | Acc: 12.185,23.300,60.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.212 | Acc: 12.276,23.331,60.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.217 | Acc: 12.392,23.390,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.221 | Acc: 12.442,23.415,59.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.224 | Acc: 12.503,23.344,59.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.229 | Acc: 12.510,23.318,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.229 | Acc: 12.452,23.348,59.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.226 | Acc: 12.476,23.383,59.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.225 | Acc: 12.477,23.374,59.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.491 | Acc: 7.812,22.656,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.504 | Acc: 8.854,19.866,55.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.539 | Acc: 8.956,19.741,53.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.543 | Acc: 9.080,19.723,53.381,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 2.221 | Acc: 11.719,19.531,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.143 | Acc: 13.244,24.665,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.166 | Acc: 13.224,24.486,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.166 | Acc: 12.897,23.937,61.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.166 | Acc: 12.857,23.756,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.171 | Acc: 12.833,23.546,60.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.175 | Acc: 12.810,23.689,60.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.175 | Acc: 12.916,23.703,60.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.183 | Acc: 12.874,23.651,60.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.182 | Acc: 12.927,23.778,60.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.189 | Acc: 12.834,23.671,60.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.191 | Acc: 12.871,23.706,60.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.196 | Acc: 12.821,23.580,60.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.196 | Acc: 12.853,23.554,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.195 | Acc: 12.878,23.599,60.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.196 | Acc: 12.806,23.552,60.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.200 | Acc: 12.741,23.501,60.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.196 | Acc: 12.734,23.550,60.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.198 | Acc: 12.697,23.578,60.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.200 | Acc: 12.676,23.561,60.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.495 | Acc: 10.938,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.526 | Acc: 11.421,20.350,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.575 | Acc: 11.338,20.922,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.577 | Acc: 11.463,21.030,52.818,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.139 | Acc: 17.188,25.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.079 | Acc: 12.723,24.516,63.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.094 | Acc: 13.472,24.409,63.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.104 | Acc: 13.461,24.193,62.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.117 | Acc: 13.252,24.334,62.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.127 | Acc: 13.328,24.528,62.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.135 | Acc: 13.268,24.419,62.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.140 | Acc: 13.220,24.324,62.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.150 | Acc: 13.199,24.199,61.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.149 | Acc: 13.109,24.219,61.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.144 | Acc: 13.188,24.227,61.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.150 | Acc: 13.087,24.190,61.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.153 | Acc: 13.015,24.121,61.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.154 | Acc: 12.880,24.114,61.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.156 | Acc: 12.831,23.963,61.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.159 | Acc: 12.884,23.928,61.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.163 | Acc: 12.928,23.849,61.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.166 | Acc: 12.919,23.790,61.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.167 | Acc: 12.868,23.721,61.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.168 | Acc: 12.863,23.815,61.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.407 | Acc: 14.844,23.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.567 | Acc: 11.421,20.350,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.582 | Acc: 11.128,20.541,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.582 | Acc: 11.002,20.415,52.651,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.085 | Acc: 13.281,25.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.094 | Acc: 12.314,24.256,63.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.105 | Acc: 12.024,23.647,63.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.112 | Acc: 12.167,23.502,62.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.111 | Acc: 12.481,23.785,62.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.105 | Acc: 12.454,23.817,63.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.103 | Acc: 12.584,23.941,63.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.099 | Acc: 12.677,24.058,63.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.106 | Acc: 12.563,24.049,63.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.112 | Acc: 12.535,24.098,63.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.117 | Acc: 12.465,24.083,63.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.123 | Acc: 12.539,23.964,62.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.120 | Acc: 12.678,24.044,62.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.119 | Acc: 12.730,24.054,62.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.124 | Acc: 12.714,23.980,62.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.125 | Acc: 12.710,23.990,62.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.127 | Acc: 12.729,23.985,62.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.132 | Acc: 12.750,23.944,62.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.134 | Acc: 12.762,23.924,62.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.138 | Acc: 12.740,23.841,62.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.670 | Acc: 11.719,22.656,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.820 | Acc: 11.049,18.824,48.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.851 | Acc: 11.071,18.750,47.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.849 | Acc: 11.027,18.904,48.002,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 1.994 | Acc: 10.156,18.750,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.021 | Acc: 12.574,23.438,65.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.056 | Acc: 12.691,22.771,63.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.061 | Acc: 13.153,23.847,63.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.056 | Acc: 13.040,24.055,63.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.065 | Acc: 12.941,24.064,63.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.065 | Acc: 13.152,24.167,63.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.071 | Acc: 13.226,24.097,63.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.078 | Acc: 13.310,24.345,63.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.087 | Acc: 13.204,24.223,63.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.089 | Acc: 13.200,24.114,63.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.091 | Acc: 13.186,24.162,62.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.097 | Acc: 13.129,24.297,62.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.104 | Acc: 13.126,24.288,62.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.108 | Acc: 13.023,24.208,62.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.111 | Acc: 12.985,24.198,62.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.114 | Acc: 12.999,24.192,62.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.120 | Acc: 13.002,24.090,62.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.121 | Acc: 13.032,24.132,62.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.120 | Acc: 13.089,24.225,62.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.461 | Acc: 11.719,23.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.584 | Acc: 9.189,17.634,54.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.586 | Acc: 8.994,17.264,53.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.604 | Acc: 9.106,17.277,53.317,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.137 | Acc: 12.500,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.038 | Acc: 13.504,25.818,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.063 | Acc: 14.005,25.514,64.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.067 | Acc: 13.397,25.026,63.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.062 | Acc: 13.628,24.971,63.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.071 | Acc: 13.274,24.783,63.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.075 | Acc: 13.191,24.735,63.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.080 | Acc: 13.126,24.501,63.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.077 | Acc: 13.097,24.558,63.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.077 | Acc: 13.113,24.525,63.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.074 | Acc: 13.270,24.518,63.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.077 | Acc: 13.235,24.558,63.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.079 | Acc: 13.310,24.605,63.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.082 | Acc: 13.314,24.518,63.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.087 | Acc: 13.231,24.413,63.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.085 | Acc: 13.268,24.471,63.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.088 | Acc: 13.225,24.499,63.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.090 | Acc: 13.210,24.551,63.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.095 | Acc: 13.199,24.565,62.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.099 | Acc: 13.156,24.551,62.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.609 | Acc: 14.062,23.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.588 | Acc: 11.793,20.424,53.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.622 | Acc: 11.966,20.198,52.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.622 | Acc: 11.872,20.044,52.267,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 1.971 | Acc: 10.156,23.438,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 13.021,23.661,65.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.009 | Acc: 13.472,24.009,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 13.294,23.873,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.034 | Acc: 13.011,23.669,64.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.043 | Acc: 13.072,23.770,64.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.047 | Acc: 13.326,23.767,64.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.046 | Acc: 13.265,23.764,64.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.045 | Acc: 13.432,24.073,64.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.055 | Acc: 13.428,24.081,64.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.057 | Acc: 13.538,24.304,64.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.057 | Acc: 13.504,24.328,64.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.061 | Acc: 13.443,24.248,64.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.060 | Acc: 13.413,24.261,63.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.060 | Acc: 13.443,24.347,63.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.061 | Acc: 13.460,24.447,63.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.062 | Acc: 13.454,24.479,63.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.069 | Acc: 13.391,24.432,63.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.074 | Acc: 13.394,24.403,63.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.076 | Acc: 13.435,24.510,63.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.579 | Acc: 12.500,25.000,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.640 | Acc: 11.198,21.280,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.646 | Acc: 11.719,21.570,52.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.658 | Acc: 11.603,21.568,51.627,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.061 | Acc: 9.375,26.562,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 14.211,24.740,65.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.020 | Acc: 13.662,24.638,64.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.998 | Acc: 14.139,25.051,65.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.005 | Acc: 14.159,24.691,65.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.008 | Acc: 14.032,24.845,65.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.009 | Acc: 13.946,24.826,65.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.016 | Acc: 13.813,24.789,65.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.016 | Acc: 13.999,24.971,65.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.019 | Acc: 13.937,24.914,65.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.024 | Acc: 13.919,24.938,64.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.027 | Acc: 13.900,24.880,64.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.028 | Acc: 13.878,25.078,64.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.031 | Acc: 13.886,25.108,64.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.035 | Acc: 13.893,25.064,64.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.037 | Acc: 13.754,25.018,64.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.037 | Acc: 13.756,25.083,64.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.040 | Acc: 13.726,25.016,64.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.042 | Acc: 13.703,25.013,64.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.046 | Acc: 13.724,24.961,64.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.589 | Acc: 12.500,25.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.512 | Acc: 11.049,22.247,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.518 | Acc: 11.395,22.313,54.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.527 | Acc: 11.232,21.901,54.495,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 1.891 | Acc: 13.281,22.656,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 13.132,26.339,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 13.186,24.905,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 13.435,25.179,65.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.003 | Acc: 13.522,24.778,65.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.003 | Acc: 13.544,24.830,65.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.015 | Acc: 13.339,24.613,65.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.019 | Acc: 13.287,24.712,65.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.022 | Acc: 13.451,24.563,65.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.023 | Acc: 13.640,24.750,65.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.024 | Acc: 13.713,24.802,64.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.028 | Acc: 13.790,24.859,64.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.034 | Acc: 13.742,24.841,64.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.039 | Acc: 13.676,24.847,64.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.036 | Acc: 13.704,24.928,64.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.036 | Acc: 13.694,24.992,64.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.038 | Acc: 13.654,24.898,64.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.040 | Acc: 13.600,24.931,64.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.042 | Acc: 13.586,24.961,64.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.046 | Acc: 13.628,24.990,64.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.322 | Acc: 11.719,24.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.478 | Acc: 10.268,21.577,55.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.533 | Acc: 10.137,22.085,54.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.542 | Acc: 10.169,22.041,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 1.721 | Acc: 10.156,28.125,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 14.583,26.339,65.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.970 | Acc: 14.710,26.143,66.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.983 | Acc: 14.255,25.679,65.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.982 | Acc: 13.802,25.174,65.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.979 | Acc: 13.761,25.503,65.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.988 | Acc: 13.817,25.491,65.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.997 | Acc: 13.752,25.283,65.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.998 | Acc: 13.699,25.146,65.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.004 | Acc: 13.773,25.220,65.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.003 | Acc: 13.806,25.272,65.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.006 | Acc: 13.748,25.191,65.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.005 | Acc: 13.787,25.246,65.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.009 | Acc: 13.790,25.224,64.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.009 | Acc: 13.776,25.131,64.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.009 | Acc: 13.793,25.158,65.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.010 | Acc: 13.839,25.136,65.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.013 | Acc: 13.895,25.076,64.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.014 | Acc: 13.896,25.063,64.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.016 | Acc: 13.919,25.127,64.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.307 | Acc: 10.938,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.604 | Acc: 10.900,21.949,54.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.621 | Acc: 10.995,22.180,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 10.989,22.208,53.240,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 2.144 | Acc: 12.500,20.312,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.964 | Acc: 13.281,25.670,66.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.926 | Acc: 13.948,25.667,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.947 | Acc: 13.909,25.435,66.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.963 | Acc: 13.812,25.145,65.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.970 | Acc: 13.846,25.340,65.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.980 | Acc: 13.804,25.394,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.988 | Acc: 13.935,25.227,65.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.993 | Acc: 14.009,25.325,65.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.998 | Acc: 14.062,25.203,65.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.999 | Acc: 14.187,25.268,65.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.002 | Acc: 14.236,25.283,65.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.001 | Acc: 14.221,25.347,65.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.002 | Acc: 14.155,25.317,65.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.005 | Acc: 14.135,25.314,65.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.007 | Acc: 14.120,25.273,65.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.006 | Acc: 14.109,25.307,65.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.008 | Acc: 14.042,25.211,65.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.006 | Acc: 14.037,25.238,65.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.008 | Acc: 14.015,25.213,65.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.774 | Acc: 13.281,19.531,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.616 | Acc: 11.458,20.350,53.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.658 | Acc: 11.909,20.293,52.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.677 | Acc: 11.936,20.056,51.895,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 1.801 | Acc: 18.750,34.375,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.926 | Acc: 15.402,26.488,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.959 | Acc: 14.710,25.877,66.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 14.127,25.704,66.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.966 | Acc: 14.342,25.858,65.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.960 | Acc: 14.279,25.750,66.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.967 | Acc: 14.172,25.788,66.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.965 | Acc: 14.184,25.787,66.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.958 | Acc: 14.247,25.878,66.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.962 | Acc: 14.317,25.816,66.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.966 | Acc: 14.354,25.711,66.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.971 | Acc: 14.282,25.696,65.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.978 | Acc: 14.202,25.600,65.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.980 | Acc: 14.206,25.608,65.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.983 | Acc: 14.238,25.609,65.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.985 | Acc: 14.231,25.571,65.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.985 | Acc: 14.167,25.467,65.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.988 | Acc: 14.179,25.454,65.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.987 | Acc: 14.214,25.526,65.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.989 | Acc: 14.188,25.488,65.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.235 | Acc: 15.625,25.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.431 | Acc: 11.235,22.173,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.445 | Acc: 11.395,22.275,55.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.448 | Acc: 11.514,22.310,55.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 1.956 | Acc: 15.625,26.562,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.887 | Acc: 14.435,26.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.891 | Acc: 13.929,26.315,67.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.885 | Acc: 14.062,26.204,67.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.890 | Acc: 14.304,26.350,67.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.906 | Acc: 14.086,26.191,67.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.913 | Acc: 14.230,26.201,67.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.925 | Acc: 14.273,26.058,67.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.933 | Acc: 14.276,25.956,67.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.937 | Acc: 14.252,25.639,66.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.943 | Acc: 14.202,25.571,66.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.949 | Acc: 14.243,25.576,66.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.955 | Acc: 14.195,25.551,66.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.958 | Acc: 14.197,25.545,66.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.959 | Acc: 14.188,25.559,66.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.966 | Acc: 14.091,25.446,66.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.969 | Acc: 14.206,25.565,65.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.970 | Acc: 14.216,25.587,65.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.974 | Acc: 14.171,25.573,65.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.974 | Acc: 14.286,25.660,65.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.465 | Acc: 12.500,25.000,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 11.124,20.499,53.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.606 | Acc: 11.204,20.465,52.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.622 | Acc: 11.411,20.274,52.728,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 1.777 | Acc: 16.406,24.219,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.902 | Acc: 14.546,26.674,67.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.874 | Acc: 14.310,26.143,68.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.889 | Acc: 14.165,25.897,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.899 | Acc: 14.371,25.858,68.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.911 | Acc: 14.418,25.913,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.923 | Acc: 14.398,25.897,67.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.930 | Acc: 14.484,26.008,67.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.928 | Acc: 14.494,26.135,67.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.930 | Acc: 14.503,26.105,67.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.942 | Acc: 14.544,26.100,66.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.946 | Acc: 14.465,25.933,66.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.953 | Acc: 14.464,25.908,66.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.950 | Acc: 14.503,25.928,66.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.951 | Acc: 14.435,25.892,66.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.950 | Acc: 14.506,25.867,66.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.951 | Acc: 14.510,25.789,66.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.953 | Acc: 14.482,25.795,66.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.955 | Acc: 14.478,25.755,66.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.960 | Acc: 14.475,25.707,66.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.390 | Acc: 10.938,25.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.438 | Acc: 11.793,20.796,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 11.890,21.437,55.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 11.924,21.081,55.507,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 2.029 | Acc: 16.406,23.438,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 14.583,24.405,66.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.930 | Acc: 14.444,25.724,67.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.906 | Acc: 14.562,25.807,67.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.920 | Acc: 14.361,25.685,67.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.922 | Acc: 14.325,25.750,67.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.924 | Acc: 14.379,25.730,67.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.932 | Acc: 14.284,25.676,67.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.932 | Acc: 14.315,25.806,67.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.930 | Acc: 14.429,25.850,67.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 14.486,25.894,67.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.936 | Acc: 14.480,25.873,66.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.933 | Acc: 14.610,26.008,67.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.934 | Acc: 14.553,26.018,66.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.939 | Acc: 14.507,25.995,66.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.942 | Acc: 14.483,25.963,66.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.942 | Acc: 14.571,26.056,66.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.941 | Acc: 14.601,26.129,66.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.941 | Acc: 14.640,26.162,66.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.941 | Acc: 14.653,26.169,66.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.412 | Acc: 18.750,22.656,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.648 | Acc: 12.165,20.982,51.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.641 | Acc: 12.424,21.246,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.646 | Acc: 12.346,21.132,51.883,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 1.842 | Acc: 15.625,20.312,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.916 | Acc: 15.067,27.232,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.887 | Acc: 15.072,27.020,67.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.899 | Acc: 14.728,26.550,67.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.884 | Acc: 14.525,26.476,68.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.887 | Acc: 14.341,26.617,68.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.892 | Acc: 14.560,26.408,67.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.896 | Acc: 14.445,26.197,67.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.899 | Acc: 14.431,26.024,67.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.902 | Acc: 14.425,26.075,67.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.907 | Acc: 14.544,26.263,67.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.913 | Acc: 14.653,26.223,67.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.914 | Acc: 14.575,26.238,67.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.920 | Acc: 14.473,26.060,67.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.923 | Acc: 14.418,26.023,67.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.929 | Acc: 14.478,26.059,66.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.929 | Acc: 14.496,26.047,67.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.931 | Acc: 14.647,26.155,66.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.934 | Acc: 14.647,26.156,66.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.935 | Acc: 14.653,26.146,66.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.354 | Acc: 12.500,29.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.564 | Acc: 11.830,23.996,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.573 | Acc: 11.662,23.552,53.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.576 | Acc: 11.911,23.271,53.842,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 2.018 | Acc: 14.062,30.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.889 | Acc: 16.481,27.195,68.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.873 | Acc: 15.720,26.677,68.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.875 | Acc: 15.715,26.716,68.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.881 | Acc: 15.172,26.630,68.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.885 | Acc: 15.084,26.578,68.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.884 | Acc: 14.915,26.343,68.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.886 | Acc: 14.899,26.241,68.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.890 | Acc: 14.970,26.344,68.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.896 | Acc: 14.926,26.403,68.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.899 | Acc: 14.984,26.469,68.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.903 | Acc: 15.091,26.566,67.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.905 | Acc: 14.970,26.426,67.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.911 | Acc: 14.949,26.350,67.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.915 | Acc: 15.011,26.387,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.918 | Acc: 15.088,26.487,67.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.918 | Acc: 15.068,26.416,67.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.918 | Acc: 15.048,26.459,67.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.920 | Acc: 15.039,26.476,67.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.919 | Acc: 15.032,26.468,67.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.470 | Acc: 17.188,23.438,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.615 | Acc: 11.868,20.201,53.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.627 | Acc: 11.757,20.312,53.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.618 | Acc: 11.706,20.748,52.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 1.681 | Acc: 16.406,32.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 13.914,26.153,69.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.837 | Acc: 14.120,25.934,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.865 | Acc: 14.255,25.564,69.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.872 | Acc: 14.439,25.540,68.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.864 | Acc: 14.813,26.037,68.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.867 | Acc: 14.837,26.330,68.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.878 | Acc: 14.910,26.430,68.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.876 | Acc: 15.009,26.553,68.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.874 | Acc: 14.986,26.666,68.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.877 | Acc: 15.003,26.590,68.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.880 | Acc: 14.992,26.626,68.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.882 | Acc: 14.977,26.640,68.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.887 | Acc: 14.934,26.607,68.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.889 | Acc: 15.041,26.671,67.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.891 | Acc: 15.070,26.814,67.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.894 | Acc: 15.116,26.825,67.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.896 | Acc: 15.048,26.787,67.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.898 | Acc: 15.043,26.840,67.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.899 | Acc: 15.010,26.780,67.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.531 | Acc: 10.156,19.531,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.664 | Acc: 10.156,19.048,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.701 | Acc: 10.404,18.579,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.708 | Acc: 10.489,18.712,51.998,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 2.007 | Acc: 10.156,19.531,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.826 | Acc: 15.476,26.711,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.816 | Acc: 14.882,26.639,69.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.827 | Acc: 14.921,26.101,69.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.830 | Acc: 15.220,26.456,69.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.850 | Acc: 15.323,26.454,68.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.855 | Acc: 15.328,26.427,68.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.857 | Acc: 15.370,26.640,68.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.862 | Acc: 15.436,26.660,68.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.863 | Acc: 15.232,26.645,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.867 | Acc: 15.248,26.671,68.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.870 | Acc: 15.141,26.527,68.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.869 | Acc: 15.191,26.585,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.873 | Acc: 15.032,26.434,68.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.876 | Acc: 15.041,26.526,67.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.881 | Acc: 15.057,26.562,67.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.886 | Acc: 15.058,26.572,67.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.888 | Acc: 15.071,26.549,67.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.890 | Acc: 15.064,26.569,67.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.894 | Acc: 15.116,26.597,67.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.361 | Acc: 14.844,25.781,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 12.165,21.763,57.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.462 | Acc: 11.738,21.780,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.472 | Acc: 12.321,21.773,56.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 1.884 | Acc: 16.406,26.562,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.845 | Acc: 15.625,27.083,69.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.853 | Acc: 15.358,26.715,69.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.858 | Acc: 15.292,26.678,69.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.854 | Acc: 15.046,26.427,68.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.863 | Acc: 14.898,26.160,68.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.865 | Acc: 14.992,26.201,68.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.867 | Acc: 15.021,26.186,68.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.865 | Acc: 15.101,26.368,68.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.871 | Acc: 15.142,26.239,68.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.868 | Acc: 15.089,26.220,68.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.871 | Acc: 15.127,26.241,68.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.874 | Acc: 15.184,26.404,68.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.875 | Acc: 15.167,26.488,68.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.878 | Acc: 15.141,26.562,67.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.880 | Acc: 15.205,26.643,67.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.882 | Acc: 15.092,26.633,67.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.884 | Acc: 15.098,26.590,67.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.886 | Acc: 15.086,26.608,67.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.890 | Acc: 15.073,26.616,67.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.758 | Acc: 16.406,19.531,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.612 | Acc: 12.463,19.792,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.653 | Acc: 12.024,19.817,52.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 12.065,20.044,52.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 1.912 | Acc: 10.938,28.125,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.857 | Acc: 16.406,26.562,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.824 | Acc: 15.930,27.191,70.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.814 | Acc: 15.868,27.011,70.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.822 | Acc: 15.808,27.180,70.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.826 | Acc: 15.648,27.413,69.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.826 | Acc: 15.683,27.512,69.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.825 | Acc: 15.575,27.438,69.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.824 | Acc: 15.538,27.252,69.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.832 | Acc: 15.560,27.223,69.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.838 | Acc: 15.458,27.165,69.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.839 | Acc: 15.424,26.987,69.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.842 | Acc: 15.418,26.913,69.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.845 | Acc: 15.401,26.877,69.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.846 | Acc: 15.439,26.877,69.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.850 | Acc: 15.472,26.908,69.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.855 | Acc: 15.435,26.879,68.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.858 | Acc: 15.417,26.835,68.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.863 | Acc: 15.370,26.744,68.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.869 | Acc: 15.348,26.716,68.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.460 | Acc: 21.875,29.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.501 | Acc: 14.211,23.847,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.537 | Acc: 14.062,23.609,53.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.526 | Acc: 14.460,23.438,54.022,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 1.837 | Acc: 10.156,28.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.825 | Acc: 15.848,27.046,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.838 | Acc: 15.320,26.258,69.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.835 | Acc: 15.318,26.998,69.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.837 | Acc: 15.471,27.122,69.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.826 | Acc: 15.501,27.514,69.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.836 | Acc: 15.373,27.079,69.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.838 | Acc: 15.631,27.277,69.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.840 | Acc: 15.659,27.368,69.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.842 | Acc: 15.547,27.227,69.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.842 | Acc: 15.477,27.317,69.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.842 | Acc: 15.480,27.305,69.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 15.479,27.279,68.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.848 | Acc: 15.436,27.200,68.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.848 | Acc: 15.475,27.185,68.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.851 | Acc: 15.355,27.139,68.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.852 | Acc: 15.374,27.098,68.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.855 | Acc: 15.389,27.128,68.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.861 | Acc: 15.383,27.041,68.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.862 | Acc: 15.371,27.003,68.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.364 | Acc: 14.844,22.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.413 | Acc: 11.830,23.177,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.434 | Acc: 11.719,23.209,57.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.429 | Acc: 12.013,23.105,57.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 1.546 | Acc: 16.406,29.688,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.763 | Acc: 15.811,27.827,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 15.930,27.611,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.812 | Acc: 15.612,27.267,69.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 15.519,26.707,69.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.839 | Acc: 15.579,26.617,69.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.842 | Acc: 15.657,26.743,68.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.845 | Acc: 15.836,26.878,68.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.844 | Acc: 15.722,26.970,68.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.844 | Acc: 15.759,26.929,68.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.847 | Acc: 15.742,26.943,68.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.844 | Acc: 15.830,27.132,68.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.846 | Acc: 15.687,26.981,68.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.845 | Acc: 15.661,27.006,68.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.846 | Acc: 15.667,26.977,68.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.844 | Acc: 15.641,27.037,68.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.845 | Acc: 15.613,27.022,68.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.847 | Acc: 15.538,26.979,68.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.848 | Acc: 15.603,27.017,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.849 | Acc: 15.615,27.085,68.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.387 | Acc: 17.188,25.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 13.132,21.689,54.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.517 | Acc: 13.434,21.837,54.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.518 | Acc: 13.371,22.144,54.559,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 1.575 | Acc: 10.156,24.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.813 | Acc: 14.472,27.121,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.805 | Acc: 14.539,26.734,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.810 | Acc: 15.266,27.113,70.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.808 | Acc: 15.374,27.257,70.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.808 | Acc: 15.370,27.096,70.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.809 | Acc: 15.134,26.905,70.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.815 | Acc: 15.204,27.039,69.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.821 | Acc: 15.183,27.174,69.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.827 | Acc: 15.249,27.175,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.829 | Acc: 15.333,27.177,69.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.828 | Acc: 15.409,27.245,69.701,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.828 | Acc: 15.492,27.331,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.832 | Acc: 15.562,27.302,69.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.836 | Acc: 15.664,27.383,69.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.839 | Acc: 15.654,27.357,69.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.842 | Acc: 15.688,27.305,69.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.842 | Acc: 15.659,27.335,69.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.846 | Acc: 15.668,27.357,69.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.849 | Acc: 15.617,27.393,69.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.444 | Acc: 16.406,22.656,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.567 | Acc: 13.058,18.824,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.572 | Acc: 13.072,19.379,54.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.575 | Acc: 12.782,19.301,54.380,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 1.742 | Acc: 16.406,26.562,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.748 | Acc: 16.629,27.158,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.767 | Acc: 16.044,27.153,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.778 | Acc: 16.227,27.241,70.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.783 | Acc: 16.155,27.575,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.792 | Acc: 16.027,27.290,70.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.797 | Acc: 15.741,27.253,70.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.801 | Acc: 15.797,27.344,70.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 15.785,27.203,70.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.808 | Acc: 15.746,27.124,70.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.810 | Acc: 15.668,27.157,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.811 | Acc: 15.795,27.160,70.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.814 | Acc: 15.784,27.195,70.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.814 | Acc: 15.766,27.230,70.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.818 | Acc: 15.792,27.157,69.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.823 | Acc: 15.703,27.157,69.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.826 | Acc: 15.649,27.161,69.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.828 | Acc: 15.652,27.202,69.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.830 | Acc: 15.621,27.168,69.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.832 | Acc: 15.652,27.172,69.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.653 | Acc: 17.969,22.656,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.669 | Acc: 13.207,22.061,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.689 | Acc: 13.281,22.218,52.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.702 | Acc: 13.345,22.400,52.523,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 1.840 | Acc: 14.844,25.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.790 | Acc: 15.997,28.274,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.789 | Acc: 15.320,27.191,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.770 | Acc: 15.279,26.985,70.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.775 | Acc: 15.538,26.833,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.779 | Acc: 15.439,26.895,70.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.785 | Acc: 15.483,26.969,70.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.783 | Acc: 15.714,27.133,70.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.790 | Acc: 15.872,27.324,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.796 | Acc: 15.906,27.244,70.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.798 | Acc: 15.975,27.332,70.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.803 | Acc: 15.880,27.266,70.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.804 | Acc: 15.790,27.201,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.810 | Acc: 15.814,27.068,69.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.815 | Acc: 15.867,27.052,69.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.818 | Acc: 15.877,27.071,69.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.817 | Acc: 15.915,27.120,69.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.822 | Acc: 15.895,27.112,69.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.825 | Acc: 15.945,27.125,69.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.826 | Acc: 16.056,27.210,69.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.430 | Acc: 14.844,28.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.381 | Acc: 13.728,23.996,57.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.392 | Acc: 13.834,23.895,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.399 | Acc: 14.024,23.783,57.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 1.895 | Acc: 20.312,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.813 | Acc: 15.848,26.749,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.790 | Acc: 16.120,27.401,70.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.775 | Acc: 15.599,27.331,70.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.773 | Acc: 15.403,27.180,70.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.769 | Acc: 15.803,27.599,70.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.770 | Acc: 15.883,27.628,70.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.770 | Acc: 15.869,27.588,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.778 | Acc: 15.839,27.518,70.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.787 | Acc: 15.953,27.400,70.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.789 | Acc: 15.928,27.441,70.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.794 | Acc: 16.063,27.400,70.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.796 | Acc: 16.140,27.473,70.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.796 | Acc: 16.164,27.410,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.800 | Acc: 16.087,27.313,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.803 | Acc: 16.113,27.372,69.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.807 | Acc: 16.058,27.373,69.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.809 | Acc: 16.053,27.341,69.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.807 | Acc: 16.125,27.365,69.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.808 | Acc: 16.168,27.387,69.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.509 | Acc: 20.312,21.875,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.380 | Acc: 13.653,22.656,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.399 | Acc: 13.643,22.180,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.391 | Acc: 13.755,22.131,57.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 1.812 | Acc: 21.875,32.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.738 | Acc: 15.848,27.195,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.745 | Acc: 15.377,26.848,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 16.189,27.561,71.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.759 | Acc: 16.541,27.469,71.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.764 | Acc: 16.329,27.336,71.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.769 | Acc: 16.135,27.208,70.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.774 | Acc: 15.996,27.322,70.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.781 | Acc: 16.173,27.417,70.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.786 | Acc: 16.156,27.413,70.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.788 | Acc: 16.262,27.484,70.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.797 | Acc: 16.106,27.330,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.803 | Acc: 16.030,27.256,69.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.803 | Acc: 16.062,27.242,70.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.804 | Acc: 16.084,27.374,69.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.804 | Acc: 16.110,27.515,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.804 | Acc: 16.141,27.551,70.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.804 | Acc: 16.129,27.522,70.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.806 | Acc: 16.114,27.580,70.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.808 | Acc: 16.166,27.614,70.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.494 | Acc: 18.750,27.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.507 | Acc: 14.249,23.772,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.508 | Acc: 14.825,24.390,54.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.517 | Acc: 14.959,24.424,54.547,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 1.640 | Acc: 19.531,25.781,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.756 | Acc: 16.109,27.976,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 15.244,27.172,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.761 | Acc: 16.112,27.357,71.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.761 | Acc: 16.175,27.238,71.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.774 | Acc: 16.252,27.328,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.772 | Acc: 16.296,27.563,71.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.782 | Acc: 16.345,27.554,70.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.785 | Acc: 16.309,27.611,70.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.793 | Acc: 16.277,27.577,70.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.794 | Acc: 16.220,27.682,70.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.792 | Acc: 16.208,27.768,70.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.794 | Acc: 16.209,27.736,70.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.794 | Acc: 16.152,27.778,70.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.797 | Acc: 16.145,27.844,70.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.799 | Acc: 16.199,27.832,69.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.799 | Acc: 16.260,27.906,69.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.799 | Acc: 16.244,27.884,69.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.801 | Acc: 16.255,27.785,69.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.801 | Acc: 16.238,27.781,69.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.210 | Acc: 17.188,27.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.395 | Acc: 14.062,24.144,57.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.425 | Acc: 14.386,24.371,57.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.447 | Acc: 14.549,24.257,57.070,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 1.706 | Acc: 12.500,28.125,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.716 | Acc: 16.332,28.051,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.724 | Acc: 15.987,27.382,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.739 | Acc: 16.278,27.497,71.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.731 | Acc: 16.348,28.000,71.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.741 | Acc: 16.445,27.939,71.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.746 | Acc: 16.290,27.583,71.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.756 | Acc: 16.246,27.399,71.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.762 | Acc: 16.333,27.591,71.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.767 | Acc: 16.100,27.598,70.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.764 | Acc: 16.259,27.849,71.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.769 | Acc: 16.336,27.913,70.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.770 | Acc: 16.345,28.044,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.772 | Acc: 16.343,27.978,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.777 | Acc: 16.320,27.875,70.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.780 | Acc: 16.367,27.899,70.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.782 | Acc: 16.423,27.940,70.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.783 | Acc: 16.340,27.841,70.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.784 | Acc: 16.287,27.768,70.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 16.324,27.879,70.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.245 | Acc: 15.625,23.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.301 | Acc: 11.310,23.140,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.306 | Acc: 11.814,23.399,58.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.319 | Acc: 11.680,23.399,58.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 1.594 | Acc: 20.312,26.562,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.776 | Acc: 16.481,28.162,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.763 | Acc: 16.902,27.782,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 16.778,27.882,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.753 | Acc: 16.541,27.894,71.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.751 | Acc: 16.445,27.831,71.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.746 | Acc: 16.490,27.757,71.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.751 | Acc: 16.401,27.721,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.749 | Acc: 16.363,27.742,71.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.751 | Acc: 16.467,27.849,71.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.755 | Acc: 16.519,27.880,71.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.758 | Acc: 16.572,27.984,70.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.757 | Acc: 16.594,28.161,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.757 | Acc: 16.487,28.209,71.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.762 | Acc: 16.559,28.253,70.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.764 | Acc: 16.596,28.366,70.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.771 | Acc: 16.521,28.295,70.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.773 | Acc: 16.493,28.340,70.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.775 | Acc: 16.424,28.296,70.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.780 | Acc: 16.361,28.266,70.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.368 | Acc: 20.312,30.469,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.344 | Acc: 14.100,25.298,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.324 | Acc: 14.539,25.648,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.336 | Acc: 14.985,25.820,58.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 1.953 | Acc: 12.500,24.219,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 17.374,28.423,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.726 | Acc: 16.654,28.277,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.722 | Acc: 16.265,27.920,72.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.736 | Acc: 16.252,27.932,71.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.734 | Acc: 16.282,28.125,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 16.413,28.196,71.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.734 | Acc: 16.650,28.457,72.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.734 | Acc: 16.654,28.489,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.735 | Acc: 16.704,28.544,71.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.734 | Acc: 16.585,28.549,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.736 | Acc: 16.615,28.627,71.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.738 | Acc: 16.656,28.744,71.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.737 | Acc: 16.676,28.697,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.743 | Acc: 16.648,28.625,71.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.747 | Acc: 16.629,28.631,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.751 | Acc: 16.567,28.566,71.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.757 | Acc: 16.590,28.496,71.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.759 | Acc: 16.646,28.502,71.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.761 | Acc: 16.706,28.539,71.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.457 | Acc: 11.719,26.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.684 | Acc: 12.909,23.065,52.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.660 | Acc: 13.110,23.361,52.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.649 | Acc: 13.204,23.181,52.971,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 1.710 | Acc: 18.750,29.688,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 16.741,27.753,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.748 | Acc: 17.321,28.792,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 17.380,28.727,71.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 17.004,28.482,71.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.751 | Acc: 16.839,28.388,71.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.760 | Acc: 16.723,28.312,71.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.752 | Acc: 16.717,28.480,71.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.752 | Acc: 16.838,28.450,71.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.754 | Acc: 16.847,28.440,71.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.754 | Acc: 16.877,28.475,71.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 16.862,28.528,71.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.759 | Acc: 16.727,28.349,71.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.761 | Acc: 16.804,28.436,71.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.764 | Acc: 16.779,28.372,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.765 | Acc: 16.783,28.348,71.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.767 | Acc: 16.783,28.371,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.768 | Acc: 16.796,28.391,70.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.771 | Acc: 16.876,28.411,70.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 16.812,28.357,70.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.312 | Acc: 14.844,23.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.396 | Acc: 13.430,23.438,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.397 | Acc: 13.091,23.609,57.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.380 | Acc: 13.064,23.412,57.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 1.795 | Acc: 11.719,19.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.732 | Acc: 16.295,27.121,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 17.035,28.468,72.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.709 | Acc: 17.111,28.855,72.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.707 | Acc: 17.091,28.636,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.711 | Acc: 16.716,28.365,72.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.716 | Acc: 16.839,28.370,72.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.720 | Acc: 16.899,28.391,72.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.727 | Acc: 16.848,28.470,72.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.737 | Acc: 16.747,28.224,71.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.739 | Acc: 16.791,28.230,71.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.743 | Acc: 16.717,28.220,71.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.745 | Acc: 16.627,28.200,71.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.747 | Acc: 16.709,28.230,71.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.748 | Acc: 16.734,28.250,71.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.753 | Acc: 16.692,28.185,71.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.755 | Acc: 16.723,28.217,71.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.757 | Acc: 16.704,28.178,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.758 | Acc: 16.690,28.188,70.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.763 | Acc: 16.636,28.098,70.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.055 | Acc: 15.625,29.688,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.291 | Acc: 12.909,24.479,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.310 | Acc: 13.014,24.676,59.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.313 | Acc: 12.923,24.244,59.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.666 | Acc: 19.531,32.812,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 16.295,28.385,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.673 | Acc: 17.226,28.563,73.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.692 | Acc: 17.239,28.599,72.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.693 | Acc: 17.216,28.762,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.695 | Acc: 17.218,28.829,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.704 | Acc: 17.020,28.519,72.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.708 | Acc: 17.093,28.723,72.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 16.964,28.654,72.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.721 | Acc: 16.894,28.583,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.725 | Acc: 16.807,28.623,71.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.731 | Acc: 16.799,28.592,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.736 | Acc: 16.899,28.702,71.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.738 | Acc: 16.870,28.694,71.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.737 | Acc: 16.901,28.678,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.739 | Acc: 17.008,28.761,71.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.744 | Acc: 16.988,28.702,71.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.748 | Acc: 16.949,28.718,71.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.749 | Acc: 16.910,28.681,71.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.751 | Acc: 16.915,28.625,71.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.574 | Acc: 15.625,26.562,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.465 | Acc: 14.211,23.363,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.484 | Acc: 14.120,24.219,55.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 14.524,24.321,55.661,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 1.710 | Acc: 17.188,32.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.730 | Acc: 17.522,28.795,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.723 | Acc: 17.321,28.639,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.713 | Acc: 17.687,28.957,72.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.714 | Acc: 17.477,28.877,72.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.713 | Acc: 17.164,29.092,72.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.710 | Acc: 17.472,29.055,72.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.714 | Acc: 17.121,28.834,72.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.720 | Acc: 16.916,28.736,71.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.722 | Acc: 16.842,28.751,71.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.722 | Acc: 16.853,28.844,71.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.725 | Acc: 16.947,28.839,71.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.728 | Acc: 16.922,28.809,71.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.729 | Acc: 16.918,28.825,71.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.731 | Acc: 17.015,28.781,71.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.733 | Acc: 17.016,28.730,71.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.736 | Acc: 16.971,28.724,71.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.739 | Acc: 16.942,28.757,71.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.742 | Acc: 16.962,28.807,71.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.743 | Acc: 16.939,28.804,71.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.090 | Acc: 16.406,25.000,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.385 | Acc: 12.128,23.251,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.398 | Acc: 11.852,23.095,57.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.409 | Acc: 12.129,22.887,57.172,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 1.706 | Acc: 15.625,25.781,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.643 | Acc: 16.964,27.269,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.673 | Acc: 16.444,27.153,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.673 | Acc: 16.560,27.946,73.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 16.879,28.578,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 16.925,28.937,73.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.677 | Acc: 16.871,28.822,73.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 16.866,28.928,73.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 16.984,28.785,73.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.687 | Acc: 17.080,28.885,73.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.693 | Acc: 16.997,28.906,73.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.696 | Acc: 17.018,28.917,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.700 | Acc: 17.019,28.981,72.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.707 | Acc: 17.002,28.936,72.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.711 | Acc: 16.957,28.954,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.717 | Acc: 16.941,28.914,72.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.723 | Acc: 17.000,28.843,72.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 17.087,28.920,72.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.725 | Acc: 17.110,28.947,72.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 17.077,28.904,71.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.193 | Acc: 17.188,27.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.232 | Acc: 13.988,25.521,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.231 | Acc: 14.444,26.029,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.250 | Acc: 14.549,25.589,60.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 1.567 | Acc: 21.875,27.344,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.665 | Acc: 17.374,28.869,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.661 | Acc: 17.588,28.982,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.675 | Acc: 17.866,29.470,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.673 | Acc: 17.814,29.562,73.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.672 | Acc: 17.907,29.657,73.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.674 | Acc: 17.878,29.442,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.677 | Acc: 18.019,29.566,73.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 17.610,29.333,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 17.589,29.182,72.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.700 | Acc: 17.666,29.264,72.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.705 | Acc: 17.651,29.178,72.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.712 | Acc: 17.499,29.055,72.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.714 | Acc: 17.460,29.068,72.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.720 | Acc: 17.407,29.015,71.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.726 | Acc: 17.426,28.893,71.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 17.438,28.875,71.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.727 | Acc: 17.437,28.876,71.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.728 | Acc: 17.499,29.021,71.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.730 | Acc: 17.421,28.958,71.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.470 | Acc: 16.406,23.438,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.421 | Acc: 12.798,25.000,57.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 12.862,24.867,56.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.477 | Acc: 12.999,24.513,56.263,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 1.657 | Acc: 16.406,25.781,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.705 | Acc: 17.485,27.976,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.696 | Acc: 17.473,28.982,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.686 | Acc: 17.597,29.124,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.682 | Acc: 17.583,28.897,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.682 | Acc: 17.311,29.061,73.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.684 | Acc: 17.155,28.913,73.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.685 | Acc: 17.104,28.962,73.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.694 | Acc: 17.066,28.892,72.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.699 | Acc: 17.170,28.919,72.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.701 | Acc: 17.289,28.914,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.706 | Acc: 17.272,28.874,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.707 | Acc: 17.249,29.016,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.712 | Acc: 17.256,28.978,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.717 | Acc: 17.299,29.062,72.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.722 | Acc: 17.219,28.935,72.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.723 | Acc: 17.268,28.884,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.724 | Acc: 17.236,28.826,72.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.724 | Acc: 17.235,28.848,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.725 | Acc: 17.315,28.955,72.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.218 | Acc: 21.875,29.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.322 | Acc: 15.662,24.702,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.330 | Acc: 15.701,25.133,59.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.340 | Acc: 15.920,25.307,59.567,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 1.791 | Acc: 14.844,27.344,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.622 | Acc: 18.043,30.394,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.628 | Acc: 17.683,29.859,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.643 | Acc: 17.764,29.636,73.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.641 | Acc: 17.631,29.321,73.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.650 | Acc: 17.621,29.455,73.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 17.730,29.307,73.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.666 | Acc: 17.509,29.244,73.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 17.474,29.246,73.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 17.498,29.390,72.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.685 | Acc: 17.549,29.431,72.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.691 | Acc: 17.375,29.097,72.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 17.317,29.081,72.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.696 | Acc: 17.337,29.002,72.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.699 | Acc: 17.388,29.118,72.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.704 | Acc: 17.398,29.119,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.706 | Acc: 17.441,29.116,72.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.707 | Acc: 17.378,29.124,72.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 17.460,29.116,72.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 17.516,29.120,72.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.339 | Acc: 20.312,33.594,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.430 | Acc: 14.286,23.921,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.417 | Acc: 14.463,24.257,57.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.415 | Acc: 14.703,24.155,57.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 1.526 | Acc: 16.406,27.344,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.655 | Acc: 17.597,29.353,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.664 | Acc: 16.864,28.582,73.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.662 | Acc: 16.983,28.842,73.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.668 | Acc: 16.879,28.549,73.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.679 | Acc: 17.010,28.690,73.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.679 | Acc: 17.265,28.732,73.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 17.337,28.751,73.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.678 | Acc: 17.493,28.911,73.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 17.373,28.803,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 17.588,28.953,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.687 | Acc: 17.605,28.945,72.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.690 | Acc: 17.508,28.828,72.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.694 | Acc: 17.562,28.903,72.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.693 | Acc: 17.602,28.962,72.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.697 | Acc: 17.592,28.979,72.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.701 | Acc: 17.699,29.101,72.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.706 | Acc: 17.675,29.083,72.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.708 | Acc: 17.622,29.146,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.710 | Acc: 17.610,29.132,72.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.451 | Acc: 19.531,23.438,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.383 | Acc: 15.030,25.930,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.377 | Acc: 14.329,25.762,58.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.381 | Acc: 14.383,25.768,58.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 1.512 | Acc: 18.750,31.250,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.626 | Acc: 17.113,29.427,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 17.321,29.592,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.646 | Acc: 17.841,30.046,73.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.661 | Acc: 17.785,30.006,73.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.663 | Acc: 17.845,30.059,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.669 | Acc: 17.788,29.959,73.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.670 | Acc: 17.786,30.131,73.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 17.872,29.974,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.682 | Acc: 17.861,29.817,73.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.684 | Acc: 17.837,29.602,73.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 17.824,29.603,72.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.694 | Acc: 17.768,29.522,72.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.704 | Acc: 17.756,29.499,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 17.755,29.496,72.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.709 | Acc: 17.660,29.410,72.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.710 | Acc: 17.630,29.374,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.713 | Acc: 17.614,29.406,72.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.715 | Acc: 17.644,29.434,72.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.720 | Acc: 17.577,29.386,72.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.306 | Acc: 21.875,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.383 | Acc: 16.481,26.153,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 16.425,26.524,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.373 | Acc: 16.624,26.498,58.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 1.565 | Acc: 22.656,38.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 17.522,29.241,74.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.623 | Acc: 17.778,29.116,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.626 | Acc: 17.905,29.009,74.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.638 | Acc: 18.046,29.263,73.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.643 | Acc: 17.984,29.339,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 17.794,29.242,73.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.660 | Acc: 17.769,29.117,73.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.667 | Acc: 17.648,29.144,73.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 17.619,29.122,73.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.682 | Acc: 17.739,29.435,72.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 17.746,29.316,72.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 17.771,29.305,72.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.687 | Acc: 17.690,29.170,72.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 17.582,29.148,72.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.691 | Acc: 17.585,29.163,72.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.693 | Acc: 17.518,29.159,72.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.693 | Acc: 17.623,29.271,72.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.696 | Acc: 17.610,29.311,72.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.696 | Acc: 17.632,29.310,72.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.158 | Acc: 13.281,26.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.365 | Acc: 14.472,24.740,58.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.361 | Acc: 14.425,24.905,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.366 | Acc: 14.460,24.488,58.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 1.685 | Acc: 15.625,24.219,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.671 | Acc: 16.964,28.571,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.637 | Acc: 17.969,29.287,74.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.634 | Acc: 17.828,29.316,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.631 | Acc: 17.978,29.678,74.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.633 | Acc: 17.961,29.904,74.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.642 | Acc: 17.995,30.101,73.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.652 | Acc: 17.786,30.031,73.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.654 | Acc: 17.697,29.896,73.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.657 | Acc: 17.731,29.895,73.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.661 | Acc: 17.634,29.960,73.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.668 | Acc: 17.605,29.938,73.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.670 | Acc: 17.687,30.015,73.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.673 | Acc: 17.669,29.921,72.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.675 | Acc: 17.602,29.879,72.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.680 | Acc: 17.611,29.861,72.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.683 | Acc: 17.604,29.795,72.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.687 | Acc: 17.586,29.768,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.692 | Acc: 17.529,29.755,72.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.693 | Acc: 17.557,29.804,72.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.486 | Acc: 16.406,25.000,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.639 | Acc: 14.137,22.917,53.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.643 | Acc: 14.082,23.399,53.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.646 | Acc: 14.357,22.836,53.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 1.556 | Acc: 18.750,31.250,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.608 | Acc: 18.490,29.539,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 17.950,29.325,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.616 | Acc: 17.866,29.393,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.627 | Acc: 17.564,29.225,74.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.630 | Acc: 17.644,29.440,74.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.634 | Acc: 17.820,29.875,74.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.638 | Acc: 17.830,30.014,74.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.644 | Acc: 17.799,29.974,73.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.648 | Acc: 17.831,29.782,73.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 17.833,29.800,73.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 17.760,29.786,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.668 | Acc: 17.667,29.801,73.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.668 | Acc: 17.687,29.873,73.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.672 | Acc: 17.716,29.915,73.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.675 | Acc: 17.761,29.828,73.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.680 | Acc: 17.750,29.692,73.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.683 | Acc: 17.779,29.653,72.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.685 | Acc: 17.770,29.612,72.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.686 | Acc: 17.805,29.702,72.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.284 | Acc: 19.531,28.906,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.378 | Acc: 14.397,25.372,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.373 | Acc: 14.139,24.886,57.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.356 | Acc: 14.306,25.026,58.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.731 | Acc: 15.625,27.344,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.650 | Acc: 18.006,29.018,73.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.618 | Acc: 17.931,29.764,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.614 | Acc: 17.994,29.880,74.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.609 | Acc: 18.065,29.562,75.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.616 | Acc: 18.108,29.672,75.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.631 | Acc: 18.033,29.533,74.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.631 | Acc: 17.974,29.560,74.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.635 | Acc: 18.017,29.634,74.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.640 | Acc: 18.003,29.679,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.646 | Acc: 17.953,29.559,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.652 | Acc: 17.884,29.599,73.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.656 | Acc: 17.816,29.577,73.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.657 | Acc: 17.834,29.595,73.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 17.813,29.482,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.664 | Acc: 17.823,29.516,73.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.667 | Acc: 17.869,29.612,73.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.673 | Acc: 17.831,29.529,73.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 17.798,29.486,73.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 17.766,29.548,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.102 | Acc: 19.531,25.000,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.244 | Acc: 16.629,26.451,60.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.247 | Acc: 16.406,26.810,60.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.252 | Acc: 16.470,26.691,60.886,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 1.840 | Acc: 20.312,27.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.618 | Acc: 18.415,30.580,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.615 | Acc: 18.178,30.259,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.623 | Acc: 18.148,30.507,74.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.629 | Acc: 17.959,30.449,74.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.634 | Acc: 17.845,30.260,74.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.628 | Acc: 17.904,30.185,74.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.631 | Acc: 17.930,30.286,74.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 18.071,30.338,73.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.635 | Acc: 18.008,30.318,74.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.635 | Acc: 17.907,30.286,74.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.641 | Acc: 17.905,30.334,73.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.650 | Acc: 17.820,30.209,73.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 17.777,30.193,73.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 17.821,30.046,73.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 17.917,30.111,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.669 | Acc: 17.908,30.060,73.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.670 | Acc: 17.973,30.111,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.671 | Acc: 18.027,30.116,73.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.676 | Acc: 17.961,30.007,72.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.435 | Acc: 17.188,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.431 | Acc: 13.467,24.330,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.446 | Acc: 13.205,24.219,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 13.358,24.308,57.006,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 1.644 | Acc: 20.312,34.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 18.304,30.469,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.617 | Acc: 18.407,30.316,74.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.616 | Acc: 18.251,30.264,74.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.621 | Acc: 17.776,30.334,74.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.625 | Acc: 17.590,30.105,74.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.624 | Acc: 17.820,30.107,74.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.623 | Acc: 17.836,29.953,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.628 | Acc: 17.770,30.037,74.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.631 | Acc: 17.796,29.890,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.631 | Acc: 17.755,30.022,74.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.636 | Acc: 17.788,30.098,74.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.644 | Acc: 17.696,30.015,74.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.649 | Acc: 17.663,29.951,73.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.656 | Acc: 17.713,29.949,73.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 17.743,29.942,73.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.666 | Acc: 17.701,29.887,73.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 17.728,29.882,73.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.670 | Acc: 17.791,29.884,73.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.674 | Acc: 17.842,29.932,72.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.162 | Acc: 16.406,26.562,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.339 | Acc: 13.318,23.400,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.325 | Acc: 13.567,23.800,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.322 | Acc: 13.665,23.758,59.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.693 | Acc: 11.719,19.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.603 | Acc: 17.597,30.692,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.607 | Acc: 18.121,31.136,75.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.618 | Acc: 18.020,30.815,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.622 | Acc: 18.210,30.797,74.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.627 | Acc: 18.363,30.848,74.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.636 | Acc: 17.988,30.501,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.633 | Acc: 18.218,30.657,74.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.636 | Acc: 18.129,30.585,74.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 18.236,30.663,73.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.645 | Acc: 18.221,30.554,73.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.643 | Acc: 18.191,30.674,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 18.192,30.582,73.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.649 | Acc: 18.175,30.594,73.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.653 | Acc: 18.052,30.488,73.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 17.982,30.396,73.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 17.942,30.379,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 17.879,30.285,73.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 17.889,30.302,73.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 17.899,30.344,73.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.514 | Acc: 17.969,29.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.363 | Acc: 15.476,25.818,57.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.403 | Acc: 15.377,26.124,56.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.416 | Acc: 15.190,25.909,57.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.630 | Acc: 16.406,24.219,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.637 | Acc: 17.225,28.869,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.630 | Acc: 17.530,28.620,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.624 | Acc: 17.879,28.970,74.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.629 | Acc: 17.872,28.964,74.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.627 | Acc: 17.961,29.254,74.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.636 | Acc: 17.898,29.210,74.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.639 | Acc: 18.035,29.228,74.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.645 | Acc: 18.109,29.353,74.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.645 | Acc: 18.033,29.273,74.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.645 | Acc: 18.105,29.450,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.642 | Acc: 18.234,29.719,74.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.647 | Acc: 18.241,29.671,74.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.652 | Acc: 18.208,29.786,73.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.650 | Acc: 18.219,29.896,73.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.653 | Acc: 18.233,29.973,73.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 18.251,30.072,73.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.657 | Acc: 18.278,30.155,73.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.656 | Acc: 18.328,30.125,73.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.657 | Acc: 18.356,30.122,73.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.499 | Acc: 17.188,29.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.420 | Acc: 14.509,24.144,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.419 | Acc: 14.291,24.428,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.413 | Acc: 14.460,24.488,57.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 1.878 | Acc: 14.844,29.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.598 | Acc: 17.746,29.278,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.609 | Acc: 17.721,29.859,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.612 | Acc: 17.982,29.777,74.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.614 | Acc: 18.113,29.803,74.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.614 | Acc: 18.278,30.229,74.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.624 | Acc: 18.214,30.307,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.622 | Acc: 18.135,30.485,74.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.625 | Acc: 18.105,30.503,74.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.625 | Acc: 18.206,30.456,74.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.623 | Acc: 18.249,30.438,74.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.624 | Acc: 18.308,30.575,74.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.631 | Acc: 18.257,30.598,74.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.633 | Acc: 18.262,30.469,74.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.634 | Acc: 18.250,30.494,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.637 | Acc: 18.244,30.497,73.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.641 | Acc: 18.159,30.384,73.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.647 | Acc: 18.136,30.377,73.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 18.159,30.367,73.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.650 | Acc: 18.235,30.475,73.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.292 | Acc: 18.750,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.349 | Acc: 15.625,25.595,58.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 15.282,25.419,58.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.369 | Acc: 15.087,25.666,58.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 1.599 | Acc: 18.750,29.688,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.636 | Acc: 17.299,28.981,73.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.625 | Acc: 17.740,30.145,73.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.602 | Acc: 18.225,30.443,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.605 | Acc: 18.490,30.768,74.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.606 | Acc: 18.410,30.593,74.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.606 | Acc: 18.550,30.662,74.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.613 | Acc: 18.606,30.530,74.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.620 | Acc: 18.532,30.464,74.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.620 | Acc: 18.608,30.650,74.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.623 | Acc: 18.544,30.578,74.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.629 | Acc: 18.563,30.476,74.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.633 | Acc: 18.536,30.611,73.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.636 | Acc: 18.511,30.633,73.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.636 | Acc: 18.458,30.588,73.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.637 | Acc: 18.441,30.557,73.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.641 | Acc: 18.453,30.505,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.643 | Acc: 18.452,30.521,73.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.645 | Acc: 18.492,30.553,73.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.649 | Acc: 18.502,30.510,73.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.229 | Acc: 14.062,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 12.054,21.280,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 11.719,21.322,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.483 | Acc: 11.744,21.401,58.069,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 1.561 | Acc: 16.406,26.562,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.609 | Acc: 18.080,31.027,75.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.569 | Acc: 18.655,31.536,76.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.573 | Acc: 18.532,31.186,75.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.580 | Acc: 18.490,31.057,75.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.585 | Acc: 18.255,30.848,75.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.585 | Acc: 18.246,30.695,75.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.589 | Acc: 18.551,30.895,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.602 | Acc: 18.401,30.609,75.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.612 | Acc: 18.439,30.680,74.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.618 | Acc: 18.420,30.605,74.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.622 | Acc: 18.351,30.554,74.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.628 | Acc: 18.306,30.427,74.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.630 | Acc: 18.382,30.508,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.629 | Acc: 18.339,30.572,74.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.632 | Acc: 18.309,30.534,74.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.633 | Acc: 18.339,30.590,74.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.636 | Acc: 18.349,30.659,74.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.637 | Acc: 18.397,30.609,74.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.640 | Acc: 18.367,30.545,73.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.187 | Acc: 12.500,25.781,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.352 | Acc: 13.207,23.996,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.363 | Acc: 13.034,24.104,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.376 | Acc: 12.897,23.835,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 1.567 | Acc: 16.406,26.562,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.596 | Acc: 18.638,30.804,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.582 | Acc: 18.598,31.364,76.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.579 | Acc: 19.070,31.749,76.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.586 | Acc: 18.962,31.588,75.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 19.044,31.513,75.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.598 | Acc: 19.066,31.560,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.606 | Acc: 18.983,31.560,74.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.616 | Acc: 18.876,31.187,74.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.619 | Acc: 18.659,30.961,74.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.618 | Acc: 18.696,31.036,74.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.619 | Acc: 18.612,30.967,74.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.620 | Acc: 18.533,30.916,74.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.623 | Acc: 18.621,30.957,74.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.626 | Acc: 18.683,31.019,74.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.630 | Acc: 18.597,30.920,74.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.635 | Acc: 18.524,30.848,73.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.636 | Acc: 18.631,30.920,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.638 | Acc: 18.590,30.854,73.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.641 | Acc: 18.572,30.848,73.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.275 | Acc: 22.656,30.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.374 | Acc: 16.109,25.335,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.349 | Acc: 15.930,25.991,59.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.341 | Acc: 16.073,25.986,59.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.854 | Acc: 19.531,32.031,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.592 | Acc: 17.671,29.948,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.568 | Acc: 17.569,31.021,76.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.567 | Acc: 18.007,31.084,76.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.585 | Acc: 18.248,30.980,75.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.590 | Acc: 18.317,31.049,75.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.595 | Acc: 18.285,31.244,75.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 18.334,31.311,75.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.604 | Acc: 18.367,31.318,74.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.607 | Acc: 18.456,31.198,74.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.612 | Acc: 18.532,31.161,74.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.612 | Acc: 18.580,31.176,74.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 18.601,31.269,74.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.618 | Acc: 18.624,31.151,74.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.623 | Acc: 18.511,31.086,74.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.624 | Acc: 18.524,31.102,74.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.629 | Acc: 18.477,31.102,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.632 | Acc: 18.452,30.984,74.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.634 | Acc: 18.423,31.016,74.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.637 | Acc: 18.438,30.977,73.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.399 | Acc: 18.750,27.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.427 | Acc: 15.327,27.641,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.432 | Acc: 15.663,28.087,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.428 | Acc: 15.894,28.317,57.159,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 1.748 | Acc: 16.406,28.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.593 | Acc: 18.638,30.655,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.578 | Acc: 18.559,31.231,75.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.592 | Acc: 18.648,31.199,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.600 | Acc: 18.625,31.433,74.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.589 | Acc: 18.866,31.706,75.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.597 | Acc: 18.556,31.566,75.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.605 | Acc: 18.484,31.344,74.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.608 | Acc: 18.347,31.153,74.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 18.396,31.246,74.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.614 | Acc: 18.342,31.238,74.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.619 | Acc: 18.276,31.147,74.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.620 | Acc: 18.393,31.198,74.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.626 | Acc: 18.385,31.169,74.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.628 | Acc: 18.336,31.069,74.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.628 | Acc: 18.387,31.001,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.630 | Acc: 18.436,30.987,73.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.631 | Acc: 18.432,30.975,73.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.632 | Acc: 18.408,30.932,73.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.635 | Acc: 18.395,30.906,73.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.659 | Acc: 14.844,21.875,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 13.616,22.805,55.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.606 | Acc: 12.957,22.218,54.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.623 | Acc: 12.692,21.965,54.226,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.523 | Acc: 16.406,28.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 18.862,32.664,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.554 | Acc: 18.921,31.631,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.566 | Acc: 19.275,32.287,75.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.583 | Acc: 18.567,31.896,75.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.595 | Acc: 18.557,31.614,74.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.597 | Acc: 18.511,31.528,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.601 | Acc: 18.600,31.527,74.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.598 | Acc: 18.745,31.502,74.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.600 | Acc: 18.767,31.466,74.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.598 | Acc: 18.750,31.242,74.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.602 | Acc: 18.845,31.370,74.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.607 | Acc: 18.805,31.295,74.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.608 | Acc: 18.864,31.319,74.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.611 | Acc: 18.889,31.297,74.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.614 | Acc: 18.893,31.320,74.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.620 | Acc: 18.738,31.235,74.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.624 | Acc: 18.720,31.186,74.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.625 | Acc: 18.711,31.105,74.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.628 | Acc: 18.652,31.090,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.112 | Acc: 19.531,30.469,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.281 | Acc: 16.629,27.195,61.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.280 | Acc: 16.502,27.477,60.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.268 | Acc: 16.483,27.536,60.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 1.639 | Acc: 17.188,28.125,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.551 | Acc: 18.638,32.217,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.535 | Acc: 18.255,31.536,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.543 | Acc: 18.225,31.263,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.553 | Acc: 17.998,30.999,76.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.562 | Acc: 18.154,31.273,76.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.571 | Acc: 18.208,31.347,75.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.576 | Acc: 18.179,31.278,75.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.584 | Acc: 18.260,31.332,75.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.589 | Acc: 18.236,31.172,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.593 | Acc: 18.439,31.262,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.598 | Acc: 18.573,31.303,75.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.604 | Acc: 18.530,31.247,74.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.606 | Acc: 18.600,31.439,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.609 | Acc: 18.530,31.292,74.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 18.644,31.369,74.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.614 | Acc: 18.623,31.335,74.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.614 | Acc: 18.656,31.367,74.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.617 | Acc: 18.642,31.360,74.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.620 | Acc: 18.627,31.291,74.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.126 | Acc: 19.531,28.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.248 | Acc: 16.667,25.818,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.246 | Acc: 16.482,25.838,60.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.251 | Acc: 16.329,25.756,60.656,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 1.513 | Acc: 14.844,25.781,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.542 | Acc: 18.415,30.618,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.543 | Acc: 18.636,30.926,76.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.556 | Acc: 19.301,31.250,76.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.562 | Acc: 19.165,31.337,75.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.563 | Acc: 19.206,31.219,75.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.567 | Acc: 19.170,31.431,75.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.575 | Acc: 19.099,31.167,75.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.579 | Acc: 19.002,31.274,75.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.586 | Acc: 19.009,31.405,75.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.594 | Acc: 18.948,31.234,74.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.594 | Acc: 19.036,31.345,74.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.599 | Acc: 19.022,31.276,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.600 | Acc: 19.112,31.271,74.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.606 | Acc: 19.134,31.261,74.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.608 | Acc: 19.080,31.364,74.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.610 | Acc: 19.023,31.311,74.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.611 | Acc: 19.030,31.289,74.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.613 | Acc: 18.969,31.302,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.616 | Acc: 18.953,31.215,74.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.158 | Acc: 19.531,28.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.359 | Acc: 14.881,25.298,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.369 | Acc: 15.015,24.886,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.367 | Acc: 14.869,24.769,59.772,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.555 | Acc: 22.656,35.156,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.598 | Acc: 18.750,30.432,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.584 | Acc: 19.398,31.726,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.576 | Acc: 18.916,31.468,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.577 | Acc: 19.001,31.645,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.578 | Acc: 18.943,31.691,75.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.581 | Acc: 18.692,31.495,75.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.587 | Acc: 18.600,31.732,75.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.592 | Acc: 18.663,31.711,75.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.599 | Acc: 18.573,31.539,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.604 | Acc: 18.754,31.720,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.604 | Acc: 18.662,31.674,75.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.604 | Acc: 18.568,31.555,75.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.606 | Acc: 18.567,31.513,74.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.608 | Acc: 18.628,31.464,74.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.610 | Acc: 18.599,31.411,74.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.612 | Acc: 18.614,31.440,74.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.613 | Acc: 18.585,31.312,74.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.617 | Acc: 18.590,31.313,74.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 18.568,31.262,74.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.087 | Acc: 17.188,27.344,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.353 | Acc: 15.439,24.442,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.341 | Acc: 15.111,24.771,59.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.344 | Acc: 15.151,25.231,59.311,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 1.501 | Acc: 21.875,38.281,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.579 | Acc: 19.308,32.329,75.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.591 | Acc: 19.588,31.936,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.593 | Acc: 18.865,31.570,75.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.606 | Acc: 18.933,31.752,74.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.591 | Acc: 19.028,31.954,75.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.595 | Acc: 18.995,31.960,74.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.597 | Acc: 19.038,31.915,74.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.603 | Acc: 19.007,31.803,74.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.602 | Acc: 19.018,31.876,74.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.603 | Acc: 19.150,31.829,74.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.607 | Acc: 19.202,31.847,74.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.612 | Acc: 19.081,31.736,74.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.613 | Acc: 19.091,31.783,74.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.613 | Acc: 19.114,31.706,74.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.616 | Acc: 19.077,31.580,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.619 | Acc: 19.015,31.476,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.620 | Acc: 19.025,31.502,74.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.620 | Acc: 19.062,31.536,74.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.620 | Acc: 19.078,31.502,74.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.221 | Acc: 17.969,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.514 | Acc: 15.774,24.702,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.527 | Acc: 15.492,25.019,56.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.513 | Acc: 15.446,25.141,57.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 1.646 | Acc: 13.281,33.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.569 | Acc: 17.969,30.246,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.578 | Acc: 17.359,29.802,75.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.564 | Acc: 18.084,30.955,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.559 | Acc: 18.297,31.260,75.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.566 | Acc: 18.278,30.987,75.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.577 | Acc: 18.272,30.727,75.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.575 | Acc: 18.246,30.823,75.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.575 | Acc: 18.391,31.075,75.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.576 | Acc: 18.590,31.246,75.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.583 | Acc: 18.711,31.250,75.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.588 | Acc: 18.821,31.292,74.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.588 | Acc: 18.782,31.360,74.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.590 | Acc: 18.831,31.433,74.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.594 | Acc: 18.767,31.353,74.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.595 | Acc: 18.784,31.445,74.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.599 | Acc: 18.787,31.425,74.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.602 | Acc: 18.748,31.442,74.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.603 | Acc: 18.754,31.477,74.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.604 | Acc: 18.748,31.408,74.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.487 | Acc: 14.844,21.094,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.570 | Acc: 14.174,20.908,55.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.553 | Acc: 14.082,21.151,55.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.563 | Acc: 14.280,21.081,55.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 1.644 | Acc: 16.406,32.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 18.341,30.878,73.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.585 | Acc: 18.788,31.212,75.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.583 | Acc: 18.981,31.621,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.579 | Acc: 19.358,31.993,75.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.577 | Acc: 19.083,31.791,75.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.582 | Acc: 19.170,31.760,75.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.580 | Acc: 19.066,31.649,75.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.584 | Acc: 19.124,31.716,75.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.585 | Acc: 19.031,31.621,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.587 | Acc: 19.174,31.627,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.589 | Acc: 19.206,31.596,74.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.589 | Acc: 19.204,31.658,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 19.235,31.708,74.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.594 | Acc: 19.231,31.692,74.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.597 | Acc: 19.139,31.652,74.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.597 | Acc: 19.076,31.681,74.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.600 | Acc: 19.020,31.578,74.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.605 | Acc: 18.947,31.501,74.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.609 | Acc: 18.930,31.500,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.255 | Acc: 17.188,28.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.293 | Acc: 15.179,26.414,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.289 | Acc: 15.206,27.191,60.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.289 | Acc: 15.535,27.574,60.182,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.729 | Acc: 12.500,29.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.531 | Acc: 20.089,34.263,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 19.531,32.736,76.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.541 | Acc: 19.608,32.223,76.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.547 | Acc: 19.252,31.964,76.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.552 | Acc: 19.214,31.938,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.552 | Acc: 19.299,32.115,76.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.562 | Acc: 19.105,31.965,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.566 | Acc: 19.153,31.988,75.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.572 | Acc: 19.026,32.044,75.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.574 | Acc: 18.964,31.946,75.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.580 | Acc: 18.937,31.837,75.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.582 | Acc: 18.919,31.824,75.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.588 | Acc: 18.873,31.753,75.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.591 | Acc: 18.972,31.809,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.594 | Acc: 18.919,31.715,75.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.596 | Acc: 18.964,31.778,75.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.601 | Acc: 18.938,31.715,74.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.607 | Acc: 18.869,31.611,74.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.609 | Acc: 18.918,31.617,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.044 | Acc: 18.750,30.469,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.333 | Acc: 16.704,29.204,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.305 | Acc: 16.159,29.040,60.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.317 | Acc: 16.112,29.303,60.361,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 1.581 | Acc: 14.062,25.000,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.535 | Acc: 18.601,31.845,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.547 | Acc: 19.074,32.031,76.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.551 | Acc: 19.198,31.852,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.552 | Acc: 19.059,32.022,76.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.557 | Acc: 19.114,32.178,76.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.553 | Acc: 19.286,32.348,76.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.559 | Acc: 19.082,32.231,76.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.562 | Acc: 18.934,32.094,76.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.568 | Acc: 18.754,32.023,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.576 | Acc: 18.828,32.078,75.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.580 | Acc: 18.860,32.042,75.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.579 | Acc: 18.925,32.041,75.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.582 | Acc: 18.998,31.935,75.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.585 | Acc: 19.089,31.962,75.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 19.157,32.047,75.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.591 | Acc: 19.137,32.009,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.593 | Acc: 19.091,31.942,75.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.599 | Acc: 19.053,31.782,75.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.604 | Acc: 19.002,31.742,74.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.473 | Acc: 10.938,26.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 12.500,22.693,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.475 | Acc: 11.871,21.818,57.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 11.680,21.273,57.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.336 | Acc: 21.875,33.594,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.528 | Acc: 18.601,32.031,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.538 | Acc: 17.988,32.107,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.540 | Acc: 18.033,31.878,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.547 | Acc: 18.316,31.925,76.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.548 | Acc: 18.557,31.938,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.552 | Acc: 18.395,31.689,75.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.552 | Acc: 18.307,31.727,76.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.551 | Acc: 18.464,31.866,75.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.557 | Acc: 18.452,31.893,75.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.559 | Acc: 18.637,31.988,75.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 18.718,31.915,75.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.566 | Acc: 18.789,31.996,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 18.765,31.971,75.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.574 | Acc: 18.781,31.967,75.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.577 | Acc: 18.771,31.990,75.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.582 | Acc: 18.796,31.985,75.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.588 | Acc: 18.805,31.946,74.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.590 | Acc: 18.860,31.921,74.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.593 | Acc: 18.844,31.939,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.333 | Acc: 17.188,24.219,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.314 | Acc: 14.509,24.442,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.350 | Acc: 14.863,24.657,59.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.355 | Acc: 14.690,24.219,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.516 | Acc: 14.844,28.125,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.533 | Acc: 18.527,30.990,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.551 | Acc: 19.036,31.059,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.529 | Acc: 18.942,31.711,76.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.537 | Acc: 18.885,31.944,76.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.535 | Acc: 18.820,31.915,76.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.538 | Acc: 18.950,32.277,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.548 | Acc: 18.988,32.103,76.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.553 | Acc: 18.939,31.949,76.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.557 | Acc: 18.979,32.049,75.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.559 | Acc: 18.874,31.833,75.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.562 | Acc: 18.891,31.816,75.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 18.873,31.785,75.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 18.816,31.609,75.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.574 | Acc: 18.917,31.659,75.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.578 | Acc: 18.958,31.683,75.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.583 | Acc: 18.925,31.673,75.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.587 | Acc: 19.009,31.756,75.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.591 | Acc: 18.973,31.713,74.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.594 | Acc: 19.000,31.722,74.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.240 | Acc: 14.844,27.344,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.241 | Acc: 15.551,28.906,62.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.249 | Acc: 15.492,28.506,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.254 | Acc: 15.702,28.356,61.258,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 1.627 | Acc: 15.625,22.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.533 | Acc: 19.345,31.585,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 19.665,32.127,76.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.539 | Acc: 19.570,31.878,75.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.548 | Acc: 19.502,31.819,75.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.557 | Acc: 19.485,31.877,75.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.559 | Acc: 19.480,31.909,75.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.556 | Acc: 19.537,32.026,75.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.555 | Acc: 19.420,31.920,76.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 19.501,32.070,75.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.563 | Acc: 19.442,31.911,75.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.570 | Acc: 19.461,31.904,75.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.570 | Acc: 19.337,31.921,75.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.572 | Acc: 19.238,31.756,75.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.578 | Acc: 19.245,31.723,75.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.581 | Acc: 19.189,31.720,75.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.586 | Acc: 19.139,31.666,75.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.588 | Acc: 19.151,31.674,74.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.589 | Acc: 19.166,31.687,74.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.591 | Acc: 19.152,31.695,74.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.208 | Acc: 21.094,29.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.434 | Acc: 14.993,25.074,57.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 14.482,24.790,57.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.474 | Acc: 14.588,24.616,57.275,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 1.597 | Acc: 17.188,32.031,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.567 | Acc: 20.610,31.845,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.537 | Acc: 20.332,32.851,76.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.530 | Acc: 20.018,32.953,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 19.734,32.899,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.536 | Acc: 19.694,32.782,76.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.539 | Acc: 19.499,32.612,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.541 | Acc: 19.670,32.702,76.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.548 | Acc: 19.556,32.516,76.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.558 | Acc: 19.631,32.545,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.560 | Acc: 19.535,32.350,75.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.566 | Acc: 19.496,32.339,75.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.571 | Acc: 19.428,32.187,75.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.572 | Acc: 19.507,32.244,75.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.573 | Acc: 19.487,32.156,75.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.576 | Acc: 19.446,32.153,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.581 | Acc: 19.402,32.043,74.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 19.378,32.013,74.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.588 | Acc: 19.406,32.105,74.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.590 | Acc: 19.382,32.035,74.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.296 | Acc: 18.750,30.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.282 | Acc: 15.030,28.311,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.294 | Acc: 14.996,28.487,60.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.298 | Acc: 15.190,28.586,59.939,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 1.534 | Acc: 24.219,32.812,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 20.424,32.515,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 20.103,31.822,77.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 19.582,31.378,77.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.515 | Acc: 19.579,31.559,77.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.519 | Acc: 19.578,31.699,77.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.520 | Acc: 19.751,31.941,76.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 19.642,32.064,76.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.528 | Acc: 19.546,32.099,76.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.538 | Acc: 19.445,31.902,76.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.547 | Acc: 19.473,32.000,76.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.551 | Acc: 19.461,31.763,76.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.556 | Acc: 19.606,31.879,75.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.562 | Acc: 19.474,31.711,75.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.564 | Acc: 19.445,31.700,75.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.567 | Acc: 19.510,31.779,75.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.572 | Acc: 19.424,31.693,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.575 | Acc: 19.472,31.729,75.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.576 | Acc: 19.408,31.748,75.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.577 | Acc: 19.441,31.882,75.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.131 | Acc: 17.969,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.378 | Acc: 16.815,26.674,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.389 | Acc: 16.711,27.077,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.386 | Acc: 16.919,27.267,58.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 1.528 | Acc: 26.562,32.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.486 | Acc: 21.057,34.338,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 20.312,33.651,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.523 | Acc: 19.800,32.992,76.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 19.666,32.948,76.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 19.531,32.758,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.525 | Acc: 19.467,32.535,76.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.533 | Acc: 19.382,32.497,76.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.548 | Acc: 19.449,32.565,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.551 | Acc: 19.397,32.528,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.555 | Acc: 19.399,32.455,75.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.559 | Acc: 19.383,32.455,75.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.560 | Acc: 19.363,32.391,75.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.563 | Acc: 19.558,32.501,75.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.568 | Acc: 19.465,32.446,75.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.573 | Acc: 19.433,32.449,75.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.575 | Acc: 19.422,32.430,75.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.578 | Acc: 19.463,32.418,75.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.579 | Acc: 19.451,32.406,75.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.580 | Acc: 19.451,32.409,75.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.182 | Acc: 17.188,30.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.232 | Acc: 15.625,28.348,61.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.242 | Acc: 15.873,28.582,61.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.256 | Acc: 16.278,28.330,61.296,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.533 | Acc: 19.531,28.125,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.501 | Acc: 18.229,30.506,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.505 | Acc: 18.921,31.460,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 19.378,31.698,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.504 | Acc: 19.406,32.272,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.508 | Acc: 19.570,32.635,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.519 | Acc: 19.544,32.535,77.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 19.614,32.691,76.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.529 | Acc: 19.541,32.478,76.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.529 | Acc: 19.687,32.718,76.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.536 | Acc: 19.652,32.723,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.543 | Acc: 19.510,32.625,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.545 | Acc: 19.606,32.735,76.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.550 | Acc: 19.498,32.585,75.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.554 | Acc: 19.470,32.515,75.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.559 | Acc: 19.435,32.400,75.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.562 | Acc: 19.390,32.309,75.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.566 | Acc: 19.469,32.338,75.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.567 | Acc: 19.460,32.321,75.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.571 | Acc: 19.492,32.388,75.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.418 | Acc: 16.406,24.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.482 | Acc: 12.314,26.042,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 12.614,25.915,56.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.492 | Acc: 12.538,25.999,56.084,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.553 | Acc: 18.750,25.000,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.537 | Acc: 19.606,30.729,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.520 | Acc: 19.607,31.555,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.522 | Acc: 19.467,31.698,77.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 19.338,31.964,77.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.532 | Acc: 19.276,32.217,76.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.537 | Acc: 19.544,32.348,76.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 19.398,32.247,76.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.545 | Acc: 19.556,32.308,76.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.550 | Acc: 19.570,32.342,76.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.556 | Acc: 19.473,32.226,75.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.559 | Acc: 19.443,32.052,75.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.562 | Acc: 19.444,32.132,75.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.564 | Acc: 19.400,32.097,75.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.565 | Acc: 19.459,32.179,75.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.564 | Acc: 19.503,32.275,75.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.566 | Acc: 19.487,32.197,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.568 | Acc: 19.458,32.107,75.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.570 | Acc: 19.449,32.135,75.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.573 | Acc: 19.474,32.179,75.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.151 | Acc: 17.969,26.562,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.338 | Acc: 14.509,23.772,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.380 | Acc: 14.367,23.114,58.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.395 | Acc: 13.998,22.631,58.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 1.723 | Acc: 22.656,27.344,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.533 | Acc: 19.568,32.403,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.506 | Acc: 19.245,32.260,77.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.514 | Acc: 19.903,33.158,76.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 19.821,33.198,76.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.528 | Acc: 19.794,33.045,76.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.533 | Acc: 19.609,32.974,76.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.532 | Acc: 19.603,32.724,76.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 19.565,32.730,76.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.542 | Acc: 19.549,32.735,76.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 19.488,32.673,76.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.548 | Acc: 19.439,32.636,76.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.549 | Acc: 19.288,32.530,76.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.555 | Acc: 19.289,32.525,75.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.557 | Acc: 19.184,32.429,75.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.558 | Acc: 19.303,32.537,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.558 | Acc: 19.332,32.589,75.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.558 | Acc: 19.359,32.540,75.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.557 | Acc: 19.326,32.574,75.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.560 | Acc: 19.322,32.556,75.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.491 | Acc: 20.312,26.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 15.104,25.893,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 15.072,25.362,56.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.550 | Acc: 15.074,24.808,56.148,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 1.437 | Acc: 19.531,35.938,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.516 | Acc: 19.829,33.259,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.512 | Acc: 19.264,32.165,77.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 19.109,32.236,77.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 19.242,32.350,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.533 | Acc: 19.021,32.256,76.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.532 | Acc: 19.066,32.367,76.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.539 | Acc: 18.739,31.943,76.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 18.862,32.022,76.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.536 | Acc: 18.987,32.126,76.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.541 | Acc: 19.111,32.206,76.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.542 | Acc: 19.231,32.314,76.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.551 | Acc: 19.298,32.154,75.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.550 | Acc: 19.364,32.310,75.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.550 | Acc: 19.409,32.329,75.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.551 | Acc: 19.498,32.426,75.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.555 | Acc: 19.551,32.362,75.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.556 | Acc: 19.524,32.416,75.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.560 | Acc: 19.518,32.390,75.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.562 | Acc: 19.484,32.396,75.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.208 | Acc: 20.312,25.000,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.365 | Acc: 16.704,24.182,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.358 | Acc: 16.864,24.695,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.361 | Acc: 17.303,24.641,58.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.455 | Acc: 17.969,34.375,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.471 | Acc: 20.796,33.185,78.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.513 | Acc: 20.312,32.698,76.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.509 | Acc: 20.005,32.697,76.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.506 | Acc: 20.187,33.092,77.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 20.096,33.106,76.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.522 | Acc: 19.996,33.019,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.526 | Acc: 19.936,33.051,76.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.532 | Acc: 19.992,33.176,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.530 | Acc: 19.894,33.218,76.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.534 | Acc: 19.920,33.127,76.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.539 | Acc: 19.878,32.873,75.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.545 | Acc: 19.914,32.864,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.550 | Acc: 19.768,32.780,75.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.554 | Acc: 19.832,32.785,75.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.557 | Acc: 19.804,32.802,75.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.562 | Acc: 19.853,32.810,75.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.566 | Acc: 19.811,32.778,75.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.568 | Acc: 19.745,32.678,75.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.570 | Acc: 19.691,32.644,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.191 | Acc: 16.406,27.344,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.364 | Acc: 16.555,28.571,59.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.401 | Acc: 16.235,28.487,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.406 | Acc: 16.522,28.509,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.533 | Acc: 25.781,34.375,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.518 | Acc: 20.312,33.854,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.534 | Acc: 19.074,32.717,76.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 19.506,32.915,76.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.532 | Acc: 19.686,32.639,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.528 | Acc: 19.926,32.843,76.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.528 | Acc: 19.938,32.735,76.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.526 | Acc: 19.775,32.696,76.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.533 | Acc: 19.856,32.788,76.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.537 | Acc: 19.769,32.666,76.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 19.815,32.731,76.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.539 | Acc: 19.917,32.820,76.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.546 | Acc: 19.911,32.835,75.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.549 | Acc: 19.858,32.801,75.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.552 | Acc: 19.848,32.774,75.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.557 | Acc: 19.765,32.722,75.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.560 | Acc: 19.697,32.632,75.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.562 | Acc: 19.577,32.563,75.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.565 | Acc: 19.583,32.546,75.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.568 | Acc: 19.517,32.443,75.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.257 | Acc: 12.500,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.295 | Acc: 12.946,25.074,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.341 | Acc: 13.053,25.381,59.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.346 | Acc: 13.256,25.179,59.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.593 | Acc: 21.875,31.250,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 19.792,31.362,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.518 | Acc: 19.436,31.745,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.519 | Acc: 19.454,32.070,76.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 19.435,32.485,76.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 19.423,32.658,76.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 19.499,32.651,76.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.531 | Acc: 19.437,32.535,76.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.530 | Acc: 19.371,32.415,76.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.533 | Acc: 19.505,32.424,76.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.536 | Acc: 19.531,32.249,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.543 | Acc: 19.492,32.332,76.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 19.486,32.505,76.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.546 | Acc: 19.549,32.555,76.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.550 | Acc: 19.515,32.585,76.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.554 | Acc: 19.466,32.491,75.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.554 | Acc: 19.419,32.447,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.560 | Acc: 19.426,32.425,75.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.564 | Acc: 19.460,32.403,75.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 19.568,32.443,75.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.057 | Acc: 16.406,27.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.169 | Acc: 16.704,27.046,63.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.186 | Acc: 16.768,27.172,62.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.192 | Acc: 16.765,27.024,62.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.415 | Acc: 22.656,35.938,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.522 | Acc: 20.833,33.631,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 20.884,32.546,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.505 | Acc: 20.351,33.017,77.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.500 | Acc: 20.351,33.073,77.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.501 | Acc: 20.506,33.099,77.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.507 | Acc: 20.377,33.051,76.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.513 | Acc: 20.185,32.818,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.515 | Acc: 20.114,32.783,76.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.519 | Acc: 20.140,32.735,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 20.060,32.700,76.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.528 | Acc: 20.058,32.572,76.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.529 | Acc: 19.982,32.582,76.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.531 | Acc: 20.052,32.624,76.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.536 | Acc: 20.057,32.604,76.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.540 | Acc: 20.048,32.670,76.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 20.008,32.654,75.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.549 | Acc: 19.978,32.611,75.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.551 | Acc: 19.968,32.670,75.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.556 | Acc: 19.974,32.681,75.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.297 | Acc: 19.531,20.312,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.448 | Acc: 16.332,23.251,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 15.758,23.323,58.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.442 | Acc: 16.048,23.642,58.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.524 | Acc: 19.531,35.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.547 | Acc: 20.015,31.734,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 20.065,32.546,77.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.511 | Acc: 19.749,32.915,77.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.507 | Acc: 19.869,33.179,77.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 19.678,33.207,77.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.511 | Acc: 19.647,33.239,76.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.523 | Acc: 19.614,33.211,76.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 19.696,33.138,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.521 | Acc: 19.713,33.192,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.526 | Acc: 19.753,33.364,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.526 | Acc: 19.772,33.537,76.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.529 | Acc: 19.807,33.474,76.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.533 | Acc: 19.807,33.498,76.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.536 | Acc: 19.756,33.474,76.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.542 | Acc: 19.674,33.285,75.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.541 | Acc: 19.633,33.229,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.542 | Acc: 19.692,33.236,76.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.545 | Acc: 19.626,33.128,75.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.546 | Acc: 19.630,33.048,75.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.184 | Acc: 19.531,30.469,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.369 | Acc: 18.341,26.674,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.398 | Acc: 18.197,26.505,57.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.399 | Acc: 18.020,26.178,57.812,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.370 | Acc: 18.750,37.500,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.474 | Acc: 19.159,32.106,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 19.684,32.393,78.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 19.544,33.094,77.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 19.647,32.629,77.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.494 | Acc: 19.663,32.929,77.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 19.602,32.993,77.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 19.509,33.106,77.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.505 | Acc: 19.546,33.230,77.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 19.579,33.153,77.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 19.566,33.236,77.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.510 | Acc: 19.623,33.159,77.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.514 | Acc: 19.778,33.205,76.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.520 | Acc: 19.660,33.133,76.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.525 | Acc: 19.776,33.207,76.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 19.721,33.075,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.534 | Acc: 19.704,32.971,76.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.537 | Acc: 19.662,32.913,76.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 19.670,32.921,76.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.541 | Acc: 19.708,32.954,76.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.185 | Acc: 18.750,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.322 | Acc: 18.341,30.283,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.354 | Acc: 18.064,30.107,59.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 18.315,30.225,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 1.360 | Acc: 19.531,39.844,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.492 | Acc: 21.094,34.933,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.494 | Acc: 20.122,33.232,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.494 | Acc: 19.992,33.133,77.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.494 | Acc: 19.715,33.092,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 19.694,32.859,77.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.507 | Acc: 19.770,32.838,76.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.513 | Acc: 19.764,32.873,76.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.520 | Acc: 19.924,32.745,76.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.522 | Acc: 19.959,32.860,76.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.524 | Acc: 19.885,32.886,76.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.525 | Acc: 19.828,32.911,76.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.526 | Acc: 19.855,33.001,76.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.530 | Acc: 19.801,32.842,76.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.530 | Acc: 19.870,32.935,76.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.533 | Acc: 19.806,32.888,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.540 | Acc: 19.777,32.822,75.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 19.804,32.769,75.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.545 | Acc: 19.726,32.680,75.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.546 | Acc: 19.841,32.753,75.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.145 | Acc: 14.062,28.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 13.281,26.004,61.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.247 | Acc: 13.624,25.781,61.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.262 | Acc: 13.896,25.794,61.885,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.501 | Acc: 25.000,39.062,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.523 | Acc: 19.085,31.882,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.509 | Acc: 18.312,32.165,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 19.160,33.312,77.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 19.078,33.295,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.502 | Acc: 19.137,33.547,77.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 19.105,33.419,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 19.182,33.339,77.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.515 | Acc: 19.303,33.235,76.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.518 | Acc: 19.281,33.235,76.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.525 | Acc: 19.364,33.166,76.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 19.393,33.109,76.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 19.616,33.263,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.534 | Acc: 19.597,33.312,76.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.539 | Acc: 19.651,33.299,76.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.543 | Acc: 19.622,33.207,75.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 19.665,33.195,75.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 19.621,33.177,75.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.548 | Acc: 19.696,33.222,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.548 | Acc: 19.829,33.358,75.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.117 | Acc: 14.062,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.226 | Acc: 15.997,29.167,61.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.228 | Acc: 15.854,28.925,61.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.224 | Acc: 15.984,29.124,61.808,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 1.431 | Acc: 27.344,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.522 | Acc: 19.903,32.180,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.501 | Acc: 20.065,33.346,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.497 | Acc: 19.775,33.402,77.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 19.994,33.362,77.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.495 | Acc: 20.235,33.656,77.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.502 | Acc: 20.300,33.775,77.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.504 | Acc: 20.185,33.660,77.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 20.206,33.463,77.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.508 | Acc: 20.036,33.335,77.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.508 | Acc: 20.285,33.504,77.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.509 | Acc: 20.281,33.576,77.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.513 | Acc: 20.212,33.552,77.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.517 | Acc: 20.076,33.462,76.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.522 | Acc: 20.001,33.277,76.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 19.944,33.275,76.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.528 | Acc: 19.887,33.187,76.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.530 | Acc: 19.902,33.152,76.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.534 | Acc: 19.873,33.083,76.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.538 | Acc: 19.822,33.050,76.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.097 | Acc: 14.844,29.688,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.251 | Acc: 14.993,28.013,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.262 | Acc: 15.415,27.744,60.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.277 | Acc: 15.676,27.369,60.361,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.399 | Acc: 25.000,45.312,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 20.164,33.110,78.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 19.950,32.908,78.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.479 | Acc: 19.826,33.517,78.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 20.052,33.758,78.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 19.926,33.671,77.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 19.822,33.723,77.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 19.720,33.616,77.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 19.687,33.385,77.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.505 | Acc: 19.756,33.387,77.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.507 | Acc: 19.850,33.551,77.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.513 | Acc: 19.856,33.541,76.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.516 | Acc: 19.855,33.542,76.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.517 | Acc: 19.825,33.588,76.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.521 | Acc: 19.795,33.524,76.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.524 | Acc: 19.843,33.384,76.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.525 | Acc: 19.833,33.341,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.528 | Acc: 19.806,33.381,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 19.880,33.436,76.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.537 | Acc: 19.890,33.419,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.304 | Acc: 20.312,28.906,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.240 | Acc: 19.568,30.915,60.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.243 | Acc: 19.131,31.231,60.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.248 | Acc: 19.057,30.981,60.387,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.393 | Acc: 17.188,27.344,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.421 | Acc: 19.643,35.305,80.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 20.389,35.175,79.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 20.146,34.721,78.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 19.907,34.693,78.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.478 | Acc: 20.026,34.653,78.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 20.106,34.536,77.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 19.897,34.297,77.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.502 | Acc: 20.089,34.094,77.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 20.092,34.038,77.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 20.130,33.897,77.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.506 | Acc: 20.012,33.742,77.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.513 | Acc: 19.936,33.571,77.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 19.935,33.510,76.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.523 | Acc: 19.787,33.319,76.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.529 | Acc: 19.757,33.293,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.533 | Acc: 19.750,33.304,76.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.536 | Acc: 19.788,33.317,76.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.537 | Acc: 19.791,33.271,76.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 19.808,33.354,76.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.314 | Acc: 17.969,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.393 | Acc: 16.406,27.046,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.402 | Acc: 16.597,27.268,58.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.407 | Acc: 16.547,27.344,58.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.470 | Acc: 22.656,32.812,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.465 | Acc: 19.308,31.957,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.455 | Acc: 18.960,31.993,78.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.463 | Acc: 19.019,32.134,78.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.474 | Acc: 18.981,32.215,77.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.474 | Acc: 19.137,32.464,78.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 19.402,32.593,77.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 19.443,32.829,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 19.667,33.002,77.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 19.704,33.136,77.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 19.722,33.193,77.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.501 | Acc: 19.782,33.343,77.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 19.813,33.308,77.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.511 | Acc: 19.792,33.297,76.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.514 | Acc: 19.806,33.385,76.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.518 | Acc: 19.801,33.360,76.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.522 | Acc: 19.850,33.363,76.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 19.838,33.367,76.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 19.890,33.442,76.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.531 | Acc: 19.935,33.497,76.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.241 | Acc: 17.969,31.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.284 | Acc: 17.113,29.315,61.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.283 | Acc: 17.188,29.192,61.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.285 | Acc: 17.239,29.611,61.245,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.388 | Acc: 22.656,36.719,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 20.201,33.743,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.446 | Acc: 20.655,34.470,78.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.452 | Acc: 20.633,33.760,78.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 20.177,33.748,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.475 | Acc: 20.119,33.950,77.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.479 | Acc: 19.912,33.523,77.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 19.941,33.483,77.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 20.060,33.623,77.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 20.006,33.585,77.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.502 | Acc: 20.075,33.547,77.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 20.115,33.477,77.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.509 | Acc: 20.112,33.390,77.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.513 | Acc: 20.196,33.345,76.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.517 | Acc: 20.199,33.349,76.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 20.011,33.256,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.525 | Acc: 20.008,33.231,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.526 | Acc: 20.015,33.246,76.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 20.027,33.289,76.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.531 | Acc: 19.972,33.290,76.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.214 | Acc: 16.406,25.781,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.362 | Acc: 17.746,29.055,59.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.373 | Acc: 17.454,28.887,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.375 | Acc: 17.520,28.676,59.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.378 | Acc: 16.406,35.156,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.487 | Acc: 19.010,33.036,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 18.731,32.165,76.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.482 | Acc: 19.711,32.723,77.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.487 | Acc: 19.715,32.870,77.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.492 | Acc: 19.609,33.354,77.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 19.680,33.426,77.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.495 | Acc: 19.559,33.178,77.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.497 | Acc: 19.575,33.235,77.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.504 | Acc: 19.648,33.205,76.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.509 | Acc: 19.621,33.096,76.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.513 | Acc: 19.528,33.078,76.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.514 | Acc: 19.567,33.130,76.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.519 | Acc: 19.558,33.124,76.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.524 | Acc: 19.656,33.149,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.525 | Acc: 19.671,33.103,76.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.524 | Acc: 19.711,33.168,76.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.525 | Acc: 19.758,33.197,76.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.527 | Acc: 19.919,33.315,76.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.531 | Acc: 19.880,33.278,76.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.058 | Acc: 13.281,28.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.313 | Acc: 16.592,28.571,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.311 | Acc: 16.673,27.896,60.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.312 | Acc: 16.778,28.035,60.566,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.501 | Acc: 14.062,35.156,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.472 | Acc: 19.717,32.850,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.472 | Acc: 19.455,32.889,78.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 19.839,33.094,77.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 19.724,33.054,77.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.484 | Acc: 19.825,33.153,77.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 19.893,33.335,77.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 19.969,33.527,77.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 19.934,33.603,77.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.493 | Acc: 19.833,33.646,77.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.499 | Acc: 19.768,33.640,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 19.701,33.689,77.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 19.664,33.697,77.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 19.687,33.675,77.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 19.676,33.619,76.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 19.619,33.544,76.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 19.668,33.589,76.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.519 | Acc: 19.621,33.575,76.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.521 | Acc: 19.724,33.587,76.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.522 | Acc: 19.765,33.639,76.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.934 | Acc: 20.312,33.594,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.228 | Acc: 19.159,30.134,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.252 | Acc: 19.017,29.783,61.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.249 | Acc: 18.737,29.777,61.373,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.619 | Acc: 17.188,30.469,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 19.159,33.743,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 19.398,33.784,77.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.483 | Acc: 20.044,34.029,78.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 20.139,33.825,77.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.492 | Acc: 20.212,33.648,77.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 20.493,33.975,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 20.362,33.904,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 20.414,33.977,77.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.487 | Acc: 20.420,34.025,77.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 20.425,33.839,77.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.499 | Acc: 20.376,33.813,77.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.500 | Acc: 20.442,33.873,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 20.310,33.705,77.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 20.226,33.694,77.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.513 | Acc: 20.209,33.640,76.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 20.266,33.638,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.521 | Acc: 20.235,33.564,76.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.522 | Acc: 20.161,33.566,76.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.523 | Acc: 20.105,33.561,76.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.222 | Acc: 18.750,29.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.300 | Acc: 15.960,29.018,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.306 | Acc: 15.625,28.639,59.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.327 | Acc: 15.638,28.407,59.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 1.387 | Acc: 17.969,33.594,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.470 | Acc: 19.271,34.003,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.448 | Acc: 19.550,34.470,78.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.452 | Acc: 19.954,34.068,78.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 20.245,33.873,78.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.460 | Acc: 20.266,33.663,78.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.459 | Acc: 20.312,33.620,78.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.471 | Acc: 20.235,33.444,77.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.481 | Acc: 20.215,33.443,77.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.486 | Acc: 20.079,33.425,77.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.488 | Acc: 20.114,33.617,77.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 20.023,33.675,77.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 20.001,33.607,76.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.503 | Acc: 20.121,33.678,76.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 20.171,33.702,76.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.511 | Acc: 20.180,33.687,76.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 20.137,33.630,76.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 20.099,33.578,76.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.521 | Acc: 20.137,33.566,76.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.522 | Acc: 20.157,33.639,76.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.507 | Acc: 14.844,21.094,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.527 | Acc: 14.509,22.507,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.534 | Acc: 14.539,22.218,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.534 | Acc: 14.588,22.951,56.519,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.426 | Acc: 19.531,31.250,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 20.685,33.036,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.486 | Acc: 19.912,32.660,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.487 | Acc: 20.172,33.222,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.488 | Acc: 20.023,33.343,77.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.488 | Acc: 19.949,33.679,77.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 19.990,33.587,77.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 19.980,33.483,77.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.489 | Acc: 19.910,33.492,77.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.494 | Acc: 19.937,33.624,77.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 20.021,33.769,77.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 19.977,33.622,77.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 20.056,33.766,76.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.506 | Acc: 20.076,33.722,76.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 20.137,33.847,76.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.511 | Acc: 20.178,33.775,76.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.516 | Acc: 20.213,33.752,76.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 20.166,33.717,76.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.519 | Acc: 20.157,33.700,76.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.521 | Acc: 20.085,33.651,76.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.081 | Acc: 17.188,31.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.222 | Acc: 15.365,28.348,62.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.237 | Acc: 15.111,27.153,62.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.241 | Acc: 15.010,27.446,62.564,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.410 | Acc: 18.750,32.812,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.478 | Acc: 20.759,34.561,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.470 | Acc: 20.636,33.994,77.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.487 | Acc: 20.415,33.824,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.489 | Acc: 20.322,33.729,77.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.488 | Acc: 20.243,33.950,77.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.486 | Acc: 20.293,34.013,77.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.490 | Acc: 20.307,33.932,77.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 20.303,33.899,77.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.489 | Acc: 20.123,33.892,77.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.487 | Acc: 20.110,33.819,77.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 20.033,33.721,77.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 20.056,33.707,77.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 20.046,33.705,77.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 20.026,33.744,77.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 20.004,33.747,76.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 20.035,33.740,76.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.515 | Acc: 20.012,33.679,76.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.517 | Acc: 20.042,33.739,76.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.518 | Acc: 20.075,33.743,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.162 | Acc: 17.969,28.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.279 | Acc: 16.034,27.567,60.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.282 | Acc: 15.682,26.524,60.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.305 | Acc: 15.971,26.370,59.900,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 1.503 | Acc: 18.750,29.688,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.459 | Acc: 19.457,32.552,78.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.435 | Acc: 20.236,33.727,79.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.456 | Acc: 19.762,33.504,78.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 19.888,33.275,78.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.465 | Acc: 20.080,33.416,78.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.472 | Acc: 20.261,33.555,78.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.475 | Acc: 20.224,33.505,77.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.472 | Acc: 20.264,33.599,77.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.476 | Acc: 20.312,33.615,77.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.481 | Acc: 20.184,33.699,77.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.487 | Acc: 20.206,33.594,77.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.488 | Acc: 20.325,33.779,77.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 20.286,33.660,77.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 20.285,33.647,77.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 20.357,33.685,76.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 20.354,33.616,76.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 20.315,33.667,76.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 20.274,33.626,76.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 20.335,33.649,76.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.014 | Acc: 21.094,31.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.198 | Acc: 18.378,28.125,62.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.217 | Acc: 18.731,28.239,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.237 | Acc: 18.622,27.754,61.475,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.428 | Acc: 22.656,28.125,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.457 | Acc: 21.801,34.301,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.455 | Acc: 21.818,34.223,78.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 21.247,33.837,77.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.465 | Acc: 20.621,33.497,77.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.465 | Acc: 20.529,33.687,77.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.465 | Acc: 20.384,33.794,77.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 20.290,33.666,77.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 20.424,33.798,77.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.475 | Acc: 20.291,33.710,77.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.485 | Acc: 20.390,33.629,77.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 20.373,33.611,77.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 20.397,33.681,77.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.497 | Acc: 20.429,33.779,77.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.500 | Acc: 20.438,33.697,76.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.503 | Acc: 20.388,33.729,76.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 20.339,33.681,76.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.510 | Acc: 20.404,33.674,76.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.514 | Acc: 20.496,33.672,76.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 20.499,33.721,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.158 | Acc: 14.844,28.906,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.370 | Acc: 12.537,25.781,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.391 | Acc: 13.129,26.105,57.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.411 | Acc: 13.025,25.704,57.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.280 | Acc: 22.656,37.500,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.470 | Acc: 19.940,33.371,78.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.454 | Acc: 19.779,33.498,78.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.458 | Acc: 19.839,33.735,78.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 20.042,33.912,78.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 20.436,34.166,77.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.475 | Acc: 20.384,33.988,77.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.481 | Acc: 20.329,33.882,77.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.486 | Acc: 20.502,34.050,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 20.455,34.047,77.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.492 | Acc: 20.347,33.881,77.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 20.298,33.802,76.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 20.290,33.873,77.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 20.241,33.950,76.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 20.268,33.939,76.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.510 | Acc: 20.323,33.923,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 20.305,33.973,76.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.512 | Acc: 20.342,34.031,76.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.512 | Acc: 20.406,34.044,76.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.513 | Acc: 20.446,34.039,76.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.247 | Acc: 14.062,22.656,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.322 | Acc: 16.815,25.781,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.339 | Acc: 16.940,26.620,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.342 | Acc: 17.200,26.806,59.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.213 | Acc: 20.312,37.500,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 19.606,32.961,79.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.424 | Acc: 20.751,34.585,79.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.441 | Acc: 20.364,34.016,79.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.455 | Acc: 20.496,34.057,78.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.472 | Acc: 20.467,33.857,77.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.471 | Acc: 20.351,33.891,77.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.476 | Acc: 20.385,33.948,77.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.482 | Acc: 20.405,33.919,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 20.377,33.952,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 20.336,33.773,77.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 20.235,33.862,77.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 20.432,34.083,76.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.496 | Acc: 20.444,34.133,76.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 20.524,34.239,76.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 20.422,34.123,76.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.511 | Acc: 20.327,34.051,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.514 | Acc: 20.308,33.949,76.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 20.382,33.988,76.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.516 | Acc: 20.438,34.028,76.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.884 | Acc: 15.625,24.219,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.612 | Acc: 13.690,22.842,55.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.648 | Acc: 13.453,22.732,54.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.638 | Acc: 13.320,22.874,54.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 1.430 | Acc: 18.750,33.594,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.475 | Acc: 18.936,32.068,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.466 | Acc: 19.836,33.422,78.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.468 | Acc: 19.864,33.927,78.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.461 | Acc: 19.850,34.008,78.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.463 | Acc: 20.026,34.073,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.470 | Acc: 19.990,34.188,77.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 19.997,34.076,77.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.480 | Acc: 20.036,34.181,77.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.483 | Acc: 19.967,34.133,77.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 20.075,34.118,77.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 20.245,34.219,77.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 20.228,34.057,77.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.494 | Acc: 20.211,33.950,77.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.499 | Acc: 20.193,33.983,76.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 20.232,33.944,76.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 20.166,33.961,76.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.507 | Acc: 20.115,34.027,76.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 20.105,33.886,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.513 | Acc: 20.124,33.918,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.960 | Acc: 19.531,32.031,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.195 | Acc: 17.001,29.576,61.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.240 | Acc: 17.035,28.963,61.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.243 | Acc: 17.098,28.817,61.335,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 1.412 | Acc: 18.750,35.156,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.473 | Acc: 19.866,35.193,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.469 | Acc: 19.989,34.718,78.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.468 | Acc: 20.428,34.221,77.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.476 | Acc: 20.245,33.787,77.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.485 | Acc: 20.127,33.702,77.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 19.957,33.787,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.492 | Acc: 20.141,33.860,77.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 20.046,33.948,77.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 20.140,34.081,77.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.493 | Acc: 20.192,34.185,77.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.493 | Acc: 20.231,34.230,77.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.495 | Acc: 20.231,34.161,77.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 20.253,34.151,77.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.498 | Acc: 20.229,34.030,77.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 20.242,34.004,76.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.505 | Acc: 20.235,34.027,76.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 20.345,34.112,76.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 20.325,34.200,76.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.509 | Acc: 20.298,34.149,76.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.105 | Acc: 19.531,28.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.343 | Acc: 16.109,25.484,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.340 | Acc: 16.425,26.315,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.352 | Acc: 15.996,25.986,59.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.450 | Acc: 11.719,35.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.425 | Acc: 18.899,33.631,79.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 19.874,34.070,78.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.449 | Acc: 20.261,33.888,78.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.461 | Acc: 20.235,33.989,78.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.461 | Acc: 20.645,34.197,78.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.459 | Acc: 20.835,34.317,78.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.463 | Acc: 20.723,34.331,78.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.460 | Acc: 20.701,34.278,78.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.463 | Acc: 20.641,34.328,78.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 20.651,34.340,78.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 20.645,34.326,77.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.484 | Acc: 20.501,34.177,77.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 20.564,34.216,77.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.485 | Acc: 20.507,34.214,77.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 20.497,34.206,77.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.489 | Acc: 20.517,34.210,77.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.495 | Acc: 20.471,34.212,77.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 20.425,34.165,77.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 20.417,34.172,76.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.999 | Acc: 17.188,25.781,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.224 | Acc: 15.699,27.567,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.254 | Acc: 15.777,27.973,60.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.266 | Acc: 15.779,28.112,60.694,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.432 | Acc: 22.656,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 20.052,33.036,77.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.469 | Acc: 20.122,33.498,77.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.467 | Acc: 20.082,33.274,77.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 19.878,33.343,77.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.473 | Acc: 19.957,33.609,77.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.476 | Acc: 19.938,33.749,77.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.480 | Acc: 19.952,33.538,77.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.480 | Acc: 19.895,33.667,77.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.481 | Acc: 19.915,33.831,77.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.484 | Acc: 19.978,33.738,77.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 20.189,33.795,77.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.492 | Acc: 20.296,33.853,77.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.495 | Acc: 20.262,33.872,77.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.497 | Acc: 20.224,33.852,76.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.501 | Acc: 20.136,33.796,76.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.504 | Acc: 20.142,33.854,76.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 20.180,33.926,76.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 20.196,33.914,76.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.514 | Acc: 20.153,33.844,76.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.080 | Acc: 15.625,28.906,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.242 | Acc: 14.323,26.079,62.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.299 | Acc: 14.405,26.239,61.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.299 | Acc: 14.664,26.306,61.565,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.496 | Acc: 21.094,32.031,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.448 | Acc: 20.387,34.896,78.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.425 | Acc: 20.675,34.299,79.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.416 | Acc: 20.735,35.400,79.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.426 | Acc: 20.785,35.137,79.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.432 | Acc: 20.622,34.514,78.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.434 | Acc: 20.467,34.530,78.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 20.617,34.541,78.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.439 | Acc: 20.570,34.525,78.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.448 | Acc: 20.541,34.599,78.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 20.542,34.589,78.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.458 | Acc: 20.415,34.478,78.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.464 | Acc: 20.312,34.268,77.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.471 | Acc: 20.268,34.103,77.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.477 | Acc: 20.246,34.075,77.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 20.229,33.970,77.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.486 | Acc: 20.254,34.068,77.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 20.260,34.004,77.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.494 | Acc: 20.293,34.031,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.496 | Acc: 20.325,34.078,77.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.099 | Acc: 17.969,29.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.208 | Acc: 18.490,29.315,63.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.241 | Acc: 18.293,29.630,62.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.246 | Acc: 18.276,29.905,62.308,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.428 | Acc: 17.969,30.469,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.435 | Acc: 21.205,35.379,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 21.056,34.947,78.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.435 | Acc: 20.684,34.362,78.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.435 | Acc: 20.428,34.037,78.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.438 | Acc: 20.668,33.965,78.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.451 | Acc: 20.616,34.091,78.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.456 | Acc: 20.617,33.793,78.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.462 | Acc: 20.497,33.793,78.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 20.718,33.969,78.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.468 | Acc: 20.627,33.932,78.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.471 | Acc: 20.617,33.933,78.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 20.416,33.788,77.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.484 | Acc: 20.318,33.884,77.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 20.421,34.094,77.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.489 | Acc: 20.346,34.092,77.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 20.407,34.102,77.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 20.397,34.070,77.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.494 | Acc: 20.390,34.120,77.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.494 | Acc: 20.399,34.195,77.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.163 | Acc: 18.750,32.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 16.592,29.799,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.272 | Acc: 16.159,28.773,61.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.272 | Acc: 16.176,28.868,61.002,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.389 | Acc: 24.219,40.625,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.433 | Acc: 21.168,37.426,79.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.449 | Acc: 20.617,35.766,78.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.455 | Acc: 20.056,35.143,78.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.450 | Acc: 20.014,35.204,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.456 | Acc: 19.941,34.994,78.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 19.938,34.950,78.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.457 | Acc: 19.980,34.674,78.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 20.046,34.564,78.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.470 | Acc: 20.062,34.526,77.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.471 | Acc: 20.161,34.667,77.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.472 | Acc: 20.125,34.704,77.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.476 | Acc: 20.196,34.618,77.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.477 | Acc: 20.211,34.689,77.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.480 | Acc: 20.240,34.720,77.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.483 | Acc: 20.255,34.577,77.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.487 | Acc: 20.305,34.579,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.491 | Acc: 20.294,34.526,77.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.495 | Acc: 20.172,34.349,77.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.497 | Acc: 20.167,34.393,77.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.065 | Acc: 17.188,37.500,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.186 | Acc: 16.964,30.655,62.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.198 | Acc: 16.482,30.716,61.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.183 | Acc: 16.624,30.725,61.975,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.486 | Acc: 18.750,37.500,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.452 | Acc: 19.010,33.222,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 20.008,33.899,78.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.446 | Acc: 19.237,33.466,78.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.445 | Acc: 19.753,33.893,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 19.787,33.795,78.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.465 | Acc: 19.802,33.968,78.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.468 | Acc: 20.024,34.015,77.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 20.143,34.094,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.479 | Acc: 20.226,34.142,77.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.482 | Acc: 20.235,34.138,77.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 20.231,34.177,77.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 20.115,34.210,77.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.486 | Acc: 20.271,34.336,77.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.487 | Acc: 20.204,34.253,77.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.492 | Acc: 20.214,34.136,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.496 | Acc: 20.227,34.248,77.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.496 | Acc: 20.246,34.315,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.500 | Acc: 20.161,34.269,77.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.504 | Acc: 20.146,34.238,76.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.138 | Acc: 19.531,28.125,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.282 | Acc: 18.080,29.390,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.289 | Acc: 17.950,29.821,60.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.290 | Acc: 18.186,29.956,60.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.440 | Acc: 19.531,32.031,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.452 | Acc: 20.201,33.668,78.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.427 | Acc: 20.084,34.184,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.432 | Acc: 19.980,34.273,79.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.443 | Acc: 20.206,34.327,78.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.448 | Acc: 19.995,34.035,78.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 20.093,34.330,78.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.453 | Acc: 20.252,34.480,78.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.467 | Acc: 20.279,34.370,77.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.473 | Acc: 20.230,34.276,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.476 | Acc: 20.382,34.499,77.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 20.447,34.527,77.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.476 | Acc: 20.374,34.469,77.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.478 | Acc: 20.459,34.438,77.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.479 | Acc: 20.426,34.436,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.479 | Acc: 20.453,34.549,77.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.482 | Acc: 20.393,34.504,77.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 20.384,34.462,77.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.489 | Acc: 20.250,34.351,77.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.490 | Acc: 20.317,34.381,77.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.066 | Acc: 17.188,29.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.294 | Acc: 16.481,28.237,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.277 | Acc: 16.216,28.296,60.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.277 | Acc: 16.201,28.112,60.950,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.275 | Acc: 14.844,31.250,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 18.973,34.189,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.423 | Acc: 20.198,35.061,78.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.436 | Acc: 20.159,34.516,78.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.440 | Acc: 20.322,34.375,78.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.439 | Acc: 20.436,34.545,78.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.444 | Acc: 20.435,34.259,78.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.449 | Acc: 20.274,34.331,78.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.455 | Acc: 20.143,34.220,78.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.457 | Acc: 20.187,34.250,78.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.457 | Acc: 20.138,34.274,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.462 | Acc: 20.252,34.407,77.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.465 | Acc: 20.218,34.378,77.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 20.226,34.291,77.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.475 | Acc: 20.251,34.105,77.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.481 | Acc: 20.227,34.144,77.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.485 | Acc: 20.179,34.214,77.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.485 | Acc: 20.145,34.233,77.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.491 | Acc: 20.157,34.148,76.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.494 | Acc: 20.196,34.221,76.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.428 | Acc: 17.188,27.344,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.474 | Acc: 16.629,25.856,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.495 | Acc: 16.444,25.762,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.482 | Acc: 16.304,25.423,56.903,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.527 | Acc: 22.656,33.594,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.473 | Acc: 20.573,34.970,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.445 | Acc: 20.198,35.575,78.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.440 | Acc: 20.274,35.028,78.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.436 | Acc: 20.332,35.069,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.435 | Acc: 20.661,35.234,78.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.432 | Acc: 20.538,35.118,78.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.438 | Acc: 20.601,35.262,78.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.446 | Acc: 20.579,35.006,78.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.452 | Acc: 20.619,34.763,78.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.456 | Acc: 20.635,34.690,78.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 20.627,34.690,77.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.463 | Acc: 20.569,34.745,77.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.465 | Acc: 20.693,34.737,77.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.471 | Acc: 20.629,34.742,77.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 20.624,34.715,77.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 20.583,34.638,77.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.482 | Acc: 20.560,34.583,77.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.486 | Acc: 20.540,34.559,77.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.491 | Acc: 20.534,34.611,77.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.331 | Acc: 15.625,32.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.284 | Acc: 15.811,28.125,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.298 | Acc: 15.339,28.296,59.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.302 | Acc: 15.382,28.176,59.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.399 | Acc: 25.000,35.938,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.449 | Acc: 20.275,35.305,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.438 | Acc: 20.560,35.061,78.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.450 | Acc: 20.389,34.874,77.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 20.293,34.635,77.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.455 | Acc: 20.529,34.692,78.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.459 | Acc: 20.629,34.698,77.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.461 | Acc: 20.678,34.752,77.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.470 | Acc: 20.560,34.724,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.472 | Acc: 20.477,34.565,77.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 20.623,34.620,77.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.481 | Acc: 20.648,34.605,77.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.481 | Acc: 20.569,34.615,77.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.484 | Acc: 20.423,34.507,77.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.489 | Acc: 20.465,34.497,77.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.492 | Acc: 20.437,34.437,77.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.498 | Acc: 20.371,34.365,76.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.501 | Acc: 20.306,34.380,76.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 20.165,34.356,76.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.503 | Acc: 20.189,34.365,76.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.077 | Acc: 17.188,33.594,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.275 | Acc: 16.555,29.353,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.333 | Acc: 15.987,28.430,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.340 | Acc: 16.227,28.227,59.874,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.292 | Acc: 21.875,35.938,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.422 | Acc: 19.829,33.631,78.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.419 | Acc: 20.065,34.127,79.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.429 | Acc: 20.287,34.349,79.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.440 | Acc: 20.438,33.970,78.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.446 | Acc: 20.552,34.360,78.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.452 | Acc: 20.293,34.207,78.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.457 | Acc: 20.224,34.331,78.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.460 | Acc: 20.148,34.438,78.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.457 | Acc: 20.265,34.578,78.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.458 | Acc: 20.363,34.632,78.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.464 | Acc: 20.366,34.527,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.468 | Acc: 20.381,34.527,77.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 20.426,34.599,77.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.473 | Acc: 20.468,34.617,77.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.475 | Acc: 20.518,34.637,77.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.477 | Acc: 20.485,34.548,77.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.483 | Acc: 20.500,34.490,77.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 20.594,34.531,77.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.487 | Acc: 20.573,34.541,77.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.071 | Acc: 25.000,33.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.206 | Acc: 17.374,32.217,62.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.245 | Acc: 17.359,31.421,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.250 | Acc: 17.252,30.853,61.142,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.380 | Acc: 21.094,38.281,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.413 | Acc: 20.722,34.635,79.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.402 | Acc: 20.732,34.356,79.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.400 | Acc: 20.902,34.401,79.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.417 | Acc: 20.930,34.751,79.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 20.846,34.630,78.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 20.681,34.504,78.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.451 | Acc: 20.601,34.331,78.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.457 | Acc: 20.332,34.268,78.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.463 | Acc: 20.524,34.535,77.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.466 | Acc: 20.445,34.530,77.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.470 | Acc: 20.376,34.478,77.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.472 | Acc: 20.394,34.544,77.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 20.447,34.650,77.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.471 | Acc: 20.507,34.659,77.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 20.437,34.539,77.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.478 | Acc: 20.441,34.497,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 20.503,34.652,77.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 20.460,34.659,77.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.483 | Acc: 20.442,34.592,77.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.564 | Acc: 15.625,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.515 | Acc: 14.807,24.107,55.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.501 | Acc: 14.691,23.742,56.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 14.754,23.911,56.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.402 | Acc: 17.188,32.031,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.367 | Acc: 21.094,36.347,80.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.387 | Acc: 21.380,36.071,80.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.403 | Acc: 21.452,35.464,79.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.418 | Acc: 20.997,35.041,79.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.429 | Acc: 20.838,34.839,79.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 21.003,34.846,78.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.434 | Acc: 21.116,34.990,78.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.441 | Acc: 21.040,34.909,78.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.450 | Acc: 20.960,34.686,78.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.456 | Acc: 20.833,34.713,78.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.462 | Acc: 20.825,34.637,78.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.466 | Acc: 20.708,34.563,77.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.469 | Acc: 20.726,34.614,77.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.471 | Acc: 20.649,34.533,77.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.477 | Acc: 20.668,34.500,77.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.479 | Acc: 20.736,34.611,77.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.479 | Acc: 20.755,34.675,77.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.482 | Acc: 20.735,34.615,77.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.485 | Acc: 20.610,34.482,77.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.124 | Acc: 17.188,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.292 | Acc: 17.150,28.646,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.290 | Acc: 17.149,28.316,60.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.292 | Acc: 17.200,28.663,60.412,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.477 | Acc: 20.312,28.125,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.404 | Acc: 19.978,34.263,79.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.438 | Acc: 20.179,34.489,78.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.439 | Acc: 19.851,34.388,78.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.432 | Acc: 19.994,34.645,78.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.437 | Acc: 19.879,34.924,78.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.442 | Acc: 20.209,35.182,78.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.450 | Acc: 20.346,35.178,78.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 20.269,35.083,77.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.466 | Acc: 20.477,35.212,77.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.470 | Acc: 20.452,35.110,77.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.468 | Acc: 20.404,34.983,77.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.473 | Acc: 20.293,34.926,77.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.477 | Acc: 20.310,34.842,77.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.482 | Acc: 20.249,34.750,77.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.482 | Acc: 20.344,34.772,77.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.483 | Acc: 20.351,34.879,77.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 20.331,34.797,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.488 | Acc: 20.390,34.853,77.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.491 | Acc: 20.368,34.810,77.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.439 | Acc: 19.531,24.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 17.522,26.228,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.447 | Acc: 17.035,25.343,57.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.477 | Acc: 17.316,25.589,57.480,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.312 | Acc: 25.781,41.406,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.417 | Acc: 20.945,35.454,79.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.420 | Acc: 20.655,35.252,79.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.427 | Acc: 20.799,35.092,78.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.426 | Acc: 20.949,35.503,78.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 20.823,35.241,78.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.436 | Acc: 20.900,35.001,78.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.438 | Acc: 20.894,34.984,78.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.446 | Acc: 20.817,34.870,78.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.450 | Acc: 20.792,34.897,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.449 | Acc: 20.833,35.005,78.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.455 | Acc: 20.857,35.022,77.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.457 | Acc: 20.906,35.004,77.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.462 | Acc: 20.854,34.986,77.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.468 | Acc: 20.738,34.970,77.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.470 | Acc: 20.689,34.936,77.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.474 | Acc: 20.668,34.932,77.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.478 | Acc: 20.679,34.881,77.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.481 | Acc: 20.674,34.825,77.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 20.673,34.863,77.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.063 | Acc: 20.312,29.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.271 | Acc: 17.076,28.943,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.290 | Acc: 16.787,27.611,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.321 | Acc: 16.534,28.189,60.015,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.374 | Acc: 20.312,33.594,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.378 | Acc: 21.689,35.938,79.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.398 | Acc: 21.018,35.595,79.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.406 | Acc: 20.594,35.246,79.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.420 | Acc: 20.120,34.867,79.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.433 | Acc: 20.212,35.032,78.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.441 | Acc: 20.222,34.756,78.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.443 | Acc: 20.274,34.674,78.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.446 | Acc: 20.356,34.787,78.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.447 | Acc: 20.295,34.958,78.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.453 | Acc: 20.417,35.129,78.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.458 | Acc: 20.411,35.078,78.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.458 | Acc: 20.426,35.062,78.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.459 | Acc: 20.459,35.135,78.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.467 | Acc: 20.490,35.092,77.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.472 | Acc: 20.432,35.034,77.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.473 | Acc: 20.468,34.925,77.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 20.439,34.971,77.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.476 | Acc: 20.505,34.992,77.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.477 | Acc: 20.530,34.988,77.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.327 | Acc: 19.531,28.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.347 | Acc: 19.122,31.213,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.338 | Acc: 18.331,31.269,60.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.354 | Acc: 18.443,31.173,59.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.345 | Acc: 21.094,34.375,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.455 | Acc: 21.057,35.975,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 21.284,35.747,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.437 | Acc: 20.492,34.823,78.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.432 | Acc: 20.669,34.722,78.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.439 | Acc: 20.692,34.646,78.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.451 | Acc: 20.642,34.433,78.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.457 | Acc: 20.518,34.408,77.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.461 | Acc: 20.604,34.448,77.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.462 | Acc: 20.653,34.474,77.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.462 | Acc: 20.728,34.612,77.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.464 | Acc: 20.871,34.721,77.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.466 | Acc: 20.802,34.709,77.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.471 | Acc: 20.756,34.617,77.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.472 | Acc: 20.727,34.698,77.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.473 | Acc: 20.671,34.588,77.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.472 | Acc: 20.734,34.650,77.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.476 | Acc: 20.743,34.673,77.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 20.730,34.680,77.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 20.665,34.689,77.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.128 | Acc: 15.625,36.719,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.285 | Acc: 16.406,31.287,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.306 | Acc: 16.521,30.373,59.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.285 | Acc: 16.829,30.277,60.220,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.538 | Acc: 19.531,30.469,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.396 | Acc: 19.829,34.487,80.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.403 | Acc: 19.417,34.661,79.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.406 | Acc: 20.223,34.465,79.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.407 | Acc: 20.554,34.857,79.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.415 | Acc: 20.374,34.994,79.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.422 | Acc: 20.377,34.930,79.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.422 | Acc: 20.462,35.123,79.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.433 | Acc: 20.293,34.933,78.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.439 | Acc: 20.420,34.936,78.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.442 | Acc: 20.651,35.086,78.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.448 | Acc: 20.641,35.078,78.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.451 | Acc: 20.620,35.020,78.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.456 | Acc: 20.708,35.010,78.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.461 | Acc: 20.688,34.962,78.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.466 | Acc: 20.668,34.946,77.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 20.717,34.881,77.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 20.638,34.904,77.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.475 | Acc: 20.670,34.951,77.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.477 | Acc: 20.618,34.834,77.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.348 | Acc: 19.531,28.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.249 | Acc: 17.820,29.725,61.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.289 | Acc: 17.664,29.040,60.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.287 | Acc: 17.482,28.714,60.361,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.536 | Acc: 28.125,37.500,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.420 | Acc: 21.354,35.826,79.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.416 | Acc: 21.341,35.404,79.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.414 | Acc: 20.991,35.553,79.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.413 | Acc: 21.171,35.503,79.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.422 | Acc: 20.846,35.179,79.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.433 | Acc: 20.693,35.195,78.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.439 | Acc: 20.551,35.239,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.444 | Acc: 20.575,35.248,78.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.452 | Acc: 20.632,35.312,78.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.454 | Acc: 20.674,35.269,78.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.460 | Acc: 20.634,35.262,77.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.465 | Acc: 20.572,35.198,77.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.467 | Acc: 20.588,35.138,77.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.470 | Acc: 20.591,35.215,77.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.470 | Acc: 20.567,35.252,77.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.471 | Acc: 20.495,35.217,77.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.472 | Acc: 20.480,35.227,77.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.473 | Acc: 20.535,35.251,77.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.472 | Acc: 20.513,35.259,77.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.385 | Acc: 16.406,31.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.320 | Acc: 15.141,29.948,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.321 | Acc: 15.396,29.459,60.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.324 | Acc: 15.587,29.162,60.553,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.278 | Acc: 22.656,37.500,85.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 19.308,34.003,78.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.440 | Acc: 19.779,34.184,79.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.425 | Acc: 19.890,34.798,79.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.428 | Acc: 20.091,34.877,78.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.437 | Acc: 20.251,34.491,78.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.440 | Acc: 20.442,34.633,78.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.443 | Acc: 20.573,35.001,78.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.450 | Acc: 20.545,34.928,78.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.451 | Acc: 20.597,34.966,78.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.456 | Acc: 20.678,34.911,77.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.458 | Acc: 20.535,34.902,77.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.461 | Acc: 20.582,34.997,77.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.464 | Acc: 20.594,34.950,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.466 | Acc: 20.632,34.945,77.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 20.551,34.873,77.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.471 | Acc: 20.549,34.854,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.474 | Acc: 20.434,34.792,77.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.478 | Acc: 20.377,34.801,77.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.481 | Acc: 20.372,34.754,77.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.268 | Acc: 15.625,32.812,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 17.597,31.213,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.398 | Acc: 17.092,30.545,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.403 | Acc: 17.277,30.597,58.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.320 | Acc: 22.656,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.425 | Acc: 20.387,34.784,79.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.418 | Acc: 20.198,35.252,79.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.417 | Acc: 20.543,36.091,79.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.433 | Acc: 20.660,35.716,78.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.445 | Acc: 20.645,35.404,78.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.447 | Acc: 20.551,35.505,78.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.450 | Acc: 20.484,35.228,78.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.459 | Acc: 20.536,35.054,78.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.460 | Acc: 20.580,35.169,78.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.464 | Acc: 20.592,35.168,77.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.465 | Acc: 20.645,35.199,77.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.468 | Acc: 20.659,35.228,77.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.472 | Acc: 20.672,35.225,77.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.477 | Acc: 20.624,35.151,77.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.480 | Acc: 20.678,35.187,77.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.484 | Acc: 20.673,35.032,77.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.486 | Acc: 20.617,35.074,77.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.487 | Acc: 20.613,35.013,77.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.488 | Acc: 20.598,35.021,77.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.285 | Acc: 15.625,29.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.277 | Acc: 16.741,29.613,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.298 | Acc: 16.845,29.287,60.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.315 | Acc: 17.290,29.086,60.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.577 | Acc: 20.312,28.906,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.438 | Acc: 21.243,35.305,77.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.453 | Acc: 20.008,33.727,77.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.437 | Acc: 20.479,34.413,78.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.425 | Acc: 20.390,34.510,78.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.430 | Acc: 20.243,34.708,78.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.437 | Acc: 20.345,34.782,78.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.438 | Acc: 20.401,34.835,78.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.445 | Acc: 20.424,34.846,77.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.445 | Acc: 20.399,34.789,77.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.447 | Acc: 20.437,34.822,77.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.453 | Acc: 20.472,34.912,77.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.458 | Acc: 20.468,34.809,77.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.464 | Acc: 20.492,34.884,77.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.467 | Acc: 20.618,35.020,77.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.468 | Acc: 20.694,34.967,77.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.470 | Acc: 20.707,35.054,77.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.471 | Acc: 20.725,35.143,77.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.472 | Acc: 20.693,35.050,77.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.473 | Acc: 20.632,35.031,77.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.235 | Acc: 18.750,35.938,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.220 | Acc: 18.080,30.580,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.254 | Acc: 17.950,30.431,61.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.246 | Acc: 17.905,30.584,61.603,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.528 | Acc: 17.188,31.250,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.443 | Acc: 21.838,35.826,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.444 | Acc: 21.532,35.252,78.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.436 | Acc: 21.017,34.926,78.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.425 | Acc: 20.718,35.079,79.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.426 | Acc: 20.707,34.994,79.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.424 | Acc: 20.584,35.111,79.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.426 | Acc: 20.628,35.151,79.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.433 | Acc: 20.822,35.205,78.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.438 | Acc: 20.843,35.286,78.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.443 | Acc: 20.752,35.292,78.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.449 | Acc: 20.655,35.124,78.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.452 | Acc: 20.578,35.143,78.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.453 | Acc: 20.582,35.105,78.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.456 | Acc: 20.599,35.170,78.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.459 | Acc: 20.606,35.076,78.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.463 | Acc: 20.656,35.091,77.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.470 | Acc: 20.645,34.994,77.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.472 | Acc: 20.672,34.977,77.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.476 | Acc: 20.688,35.009,77.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.270 | Acc: 14.844,25.781,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.337 | Acc: 14.249,26.897,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.349 | Acc: 14.120,26.562,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.345 | Acc: 14.600,26.447,59.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.458 | Acc: 17.188,28.906,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.358 | Acc: 20.982,35.528,81.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.329 | Acc: 20.713,35.880,82.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.308 | Acc: 20.902,35.784,82.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.305 | Acc: 20.968,35.687,82.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.296 | Acc: 20.978,35.582,83.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.281 | Acc: 21.204,35.905,83.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.271 | Acc: 21.232,36.004,83.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.265 | Acc: 21.380,36.073,83.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.256 | Acc: 21.547,36.063,83.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.248 | Acc: 21.486,36.287,84.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.241 | Acc: 21.437,36.340,84.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.235 | Acc: 21.528,36.421,84.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.229 | Acc: 21.534,36.575,84.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.226 | Acc: 21.611,36.749,84.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.223 | Acc: 21.470,36.688,84.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.221 | Acc: 21.546,36.826,84.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.218 | Acc: 21.511,36.845,85.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.214 | Acc: 21.509,36.946,85.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.210 | Acc: 21.471,36.973,85.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.768 | Acc: 21.875,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.780 | Acc: 20.759,36.868,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.773 | Acc: 20.846,36.204,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.780 | Acc: 21.107,36.450,71.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.172 | Acc: 17.969,34.375,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.075 | Acc: 22.396,39.397,88.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.098 | Acc: 22.008,38.834,88.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.107 | Acc: 21.709,38.281,88.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.105 | Acc: 21.856,38.146,88.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.112 | Acc: 21.620,38.142,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.117 | Acc: 21.694,37.849,88.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.117 | Acc: 21.648,37.805,87.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.116 | Acc: 21.860,37.922,88.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.117 | Acc: 21.879,37.720,88.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.116 | Acc: 21.972,37.826,88.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.117 | Acc: 21.910,37.825,88.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.118 | Acc: 21.940,37.814,88.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.117 | Acc: 22.055,37.958,88.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.119 | Acc: 22.011,37.861,88.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.118 | Acc: 22.020,37.998,88.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.118 | Acc: 21.977,37.936,88.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.115 | Acc: 21.896,37.885,88.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.115 | Acc: 21.845,37.848,88.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.115 | Acc: 21.887,37.851,88.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.732 | Acc: 23.438,37.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.775 | Acc: 20.871,37.277,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.766 | Acc: 21.132,36.681,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 21.286,36.808,72.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.082 | Acc: 25.000,46.875,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.089 | Acc: 20.908,38.802,89.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.092 | Acc: 21.380,38.434,88.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.084 | Acc: 21.606,38.794,88.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.082 | Acc: 21.711,38.850,88.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.080 | Acc: 21.890,38.699,89.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.088 | Acc: 21.985,38.339,88.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.091 | Acc: 21.941,38.242,88.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.092 | Acc: 21.875,37.980,88.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.088 | Acc: 21.879,38.001,89.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.086 | Acc: 21.914,38.165,89.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.085 | Acc: 21.960,38.154,89.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.085 | Acc: 22.027,38.181,89.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.086 | Acc: 21.944,38.147,89.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.087 | Acc: 21.894,38.050,88.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.087 | Acc: 21.836,38.027,88.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.088 | Acc: 21.851,38.026,88.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.087 | Acc: 21.779,38.050,89.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.087 | Acc: 21.765,38.002,89.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.085 | Acc: 21.713,38.009,89.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.736 | Acc: 22.656,38.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.778 | Acc: 21.280,37.872,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 21.132,36.966,72.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.776 | Acc: 21.324,37.231,72.631,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.145 | Acc: 17.969,36.719,87.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.077 | Acc: 21.615,36.793,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.059 | Acc: 21.532,37.462,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.051 | Acc: 21.363,37.410,90.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.051 | Acc: 21.701,37.876,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.056 | Acc: 21.790,38.157,89.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.054 | Acc: 21.869,38.023,90.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.055 | Acc: 21.881,38.037,90.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.053 | Acc: 22.069,38.208,90.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.053 | Acc: 21.957,38.065,90.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.054 | Acc: 21.739,37.955,90.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.054 | Acc: 21.868,37.931,90.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.054 | Acc: 21.852,37.957,90.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.053 | Acc: 21.983,37.952,90.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.051 | Acc: 21.995,38.067,90.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.053 | Acc: 21.989,38.058,90.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.053 | Acc: 22.021,38.138,90.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.053 | Acc: 22.008,38.158,90.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.054 | Acc: 22.057,38.288,90.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.055 | Acc: 22.090,38.339,90.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.737 | Acc: 21.094,38.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.785 | Acc: 21.131,37.537,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.770 | Acc: 21.361,37.043,72.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.780 | Acc: 21.542,37.205,72.618,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.019 | Acc: 21.094,38.281,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.039 | Acc: 21.503,37.909,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.029 | Acc: 21.818,38.281,90.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.042 | Acc: 21.491,38.384,90.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.042 | Acc: 21.431,38.339,90.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.035 | Acc: 21.566,38.645,90.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.037 | Acc: 21.643,38.565,90.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.036 | Acc: 21.687,38.641,90.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.037 | Acc: 21.681,38.534,90.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.040 | Acc: 21.702,38.501,90.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.041 | Acc: 21.813,38.553,90.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.042 | Acc: 21.854,38.557,90.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.044 | Acc: 21.891,38.651,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.043 | Acc: 21.926,38.736,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.042 | Acc: 21.942,38.684,90.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.041 | Acc: 21.971,38.632,90.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.041 | Acc: 22.002,38.639,90.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.042 | Acc: 21.976,38.604,90.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.044 | Acc: 21.933,38.608,90.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.043 | Acc: 21.943,38.659,90.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.756 | Acc: 21.875,38.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.802 | Acc: 21.577,38.095,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.782 | Acc: 21.532,37.271,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.792 | Acc: 21.632,37.308,71.888,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.005 | Acc: 28.906,44.531,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.015 | Acc: 22.247,39.844,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.020 | Acc: 22.085,38.834,91.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.025 | Acc: 21.977,38.973,90.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.022 | Acc: 22.087,39.082,91.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.023 | Acc: 22.014,38.900,91.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.026 | Acc: 22.191,38.830,90.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.023 | Acc: 21.975,38.697,91.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.023 | Acc: 22.108,38.742,91.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.024 | Acc: 22.065,38.627,91.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.026 | Acc: 22.081,38.608,91.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.024 | Acc: 22.052,38.755,91.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.025 | Acc: 22.037,38.670,91.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.026 | Acc: 21.980,38.745,91.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.026 | Acc: 22.031,38.807,91.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.026 | Acc: 22.033,38.769,91.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.026 | Acc: 21.999,38.719,91.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.026 | Acc: 22.017,38.721,91.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.025 | Acc: 22.033,38.688,91.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.027 | Acc: 22.000,38.695,91.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.741 | Acc: 22.656,38.281,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.792 | Acc: 21.354,38.021,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.780 | Acc: 21.380,37.195,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.789 | Acc: 21.465,37.269,72.259,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.037 | Acc: 23.438,43.750,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.022 | Acc: 22.135,39.025,91.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.015 | Acc: 22.275,38.853,91.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.011 | Acc: 22.208,38.717,91.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.008 | Acc: 22.184,38.513,91.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.007 | Acc: 22.053,38.382,91.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.008 | Acc: 22.075,38.397,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.008 | Acc: 22.030,38.503,91.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.011 | Acc: 21.793,38.500,91.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.011 | Acc: 21.897,38.540,91.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.013 | Acc: 21.859,38.522,91.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.014 | Acc: 21.896,38.599,91.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.016 | Acc: 21.881,38.644,91.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.016 | Acc: 21.860,38.512,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.017 | Acc: 21.856,38.526,91.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.016 | Acc: 21.917,38.554,91.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.017 | Acc: 21.887,38.578,91.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.017 | Acc: 21.905,38.600,91.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.016 | Acc: 21.875,38.615,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.017 | Acc: 21.875,38.585,91.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.762 | Acc: 22.656,39.062,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.800 | Acc: 21.503,37.798,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.786 | Acc: 21.513,36.947,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.799 | Acc: 21.696,37.231,72.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 0.972 | Acc: 17.188,34.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.982 | Acc: 22.731,38.356,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.981 | Acc: 22.027,38.910,92.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.995 | Acc: 22.195,38.691,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.991 | Acc: 21.962,39.188,92.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.994 | Acc: 22.130,39.217,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.995 | Acc: 22.056,39.069,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.996 | Acc: 21.964,39.029,92.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.994 | Acc: 22.069,39.179,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.993 | Acc: 22.056,39.019,92.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.993 | Acc: 22.151,39.016,92.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.992 | Acc: 22.130,38.932,92.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.992 | Acc: 22.108,38.900,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.990 | Acc: 22.126,39.015,92.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.993 | Acc: 22.122,39.021,92.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.993 | Acc: 22.124,39.179,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.995 | Acc: 22.131,39.084,92.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.996 | Acc: 22.155,38.980,92.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.995 | Acc: 22.163,38.985,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.998 | Acc: 22.162,38.993,91.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.754 | Acc: 21.875,38.281,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.819 | Acc: 21.801,37.798,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.792 | Acc: 21.646,37.595,72.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 21.683,37.807,72.195,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.005 | Acc: 22.656,39.062,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.993 | Acc: 20.685,37.574,91.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.995 | Acc: 21.513,38.129,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.989 | Acc: 22.067,38.589,92.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.992 | Acc: 21.807,38.735,92.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.995 | Acc: 21.906,38.869,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.992 | Acc: 21.965,38.966,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.995 | Acc: 21.847,38.830,92.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.991 | Acc: 21.967,38.961,92.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.991 | Acc: 21.957,38.842,92.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.990 | Acc: 22.042,39.012,92.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.992 | Acc: 22.052,38.949,92.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.992 | Acc: 22.115,38.900,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.993 | Acc: 22.019,38.898,92.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.993 | Acc: 22.161,38.896,92.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.992 | Acc: 22.163,38.969,92.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.992 | Acc: 22.172,38.992,92.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.992 | Acc: 22.152,39.090,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.993 | Acc: 22.109,39.032,92.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.995 | Acc: 22.090,38.964,92.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.800 | Acc: 22.656,38.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.801 | Acc: 21.391,37.946,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.785 | Acc: 21.551,37.348,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.802 | Acc: 21.773,37.602,71.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 0.925 | Acc: 25.781,50.781,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.972 | Acc: 22.284,38.728,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.979 | Acc: 22.256,39.672,92.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.988 | Acc: 22.259,38.934,92.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.986 | Acc: 22.290,39.188,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.985 | Acc: 22.215,39.171,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.988 | Acc: 22.327,39.127,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.985 | Acc: 22.346,39.129,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 22.428,39.218,92.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.985 | Acc: 22.488,39.321,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.985 | Acc: 22.392,39.311,92.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.988 | Acc: 22.260,39.306,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.990 | Acc: 22.112,39.092,92.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.989 | Acc: 22.091,38.979,92.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.988 | Acc: 22.106,38.985,92.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.989 | Acc: 22.122,39.013,92.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.989 | Acc: 22.092,38.965,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.989 | Acc: 22.125,38.893,92.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.989 | Acc: 22.128,38.870,92.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.989 | Acc: 22.088,38.878,92.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.807 | Acc: 21.875,39.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.822 | Acc: 21.466,38.021,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.789 | Acc: 21.437,37.481,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.806 | Acc: 21.593,37.602,71.926,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 0.982 | Acc: 23.438,38.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.975 | Acc: 23.921,40.179,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.982 | Acc: 22.752,40.415,92.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.979 | Acc: 22.515,40.100,92.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.974 | Acc: 22.801,39.670,92.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.975 | Acc: 22.432,39.240,92.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.976 | Acc: 22.269,38.979,92.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.977 | Acc: 22.191,39.184,92.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.975 | Acc: 22.195,39.266,92.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.976 | Acc: 22.285,39.395,92.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.976 | Acc: 22.314,39.315,92.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.977 | Acc: 22.338,39.183,92.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.979 | Acc: 22.254,39.040,92.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.979 | Acc: 22.228,39.054,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.978 | Acc: 22.175,39.026,92.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.978 | Acc: 22.137,39.000,92.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.980 | Acc: 22.148,39.038,92.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.980 | Acc: 22.187,39.065,92.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.980 | Acc: 22.146,39.032,92.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.980 | Acc: 22.197,39.052,92.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.790 | Acc: 20.312,39.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.802 | Acc: 21.466,38.839,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.786 | Acc: 21.322,38.110,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.801 | Acc: 21.670,38.217,72.246,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 0.943 | Acc: 28.125,41.406,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.971 | Acc: 22.582,38.467,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.967 | Acc: 22.370,38.472,93.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.969 | Acc: 22.426,38.870,93.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.972 | Acc: 22.502,38.812,93.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.980 | Acc: 22.347,38.653,92.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 22.217,38.682,92.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.977 | Acc: 22.340,39.013,92.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.977 | Acc: 22.268,38.873,92.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.976 | Acc: 22.220,38.855,92.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.975 | Acc: 22.178,38.880,92.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.974 | Acc: 22.119,39.055,92.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.975 | Acc: 22.160,38.939,92.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.975 | Acc: 22.231,39.095,92.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.975 | Acc: 22.250,39.188,92.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.977 | Acc: 22.223,39.169,92.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 22.174,39.145,92.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.977 | Acc: 22.177,39.117,92.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.978 | Acc: 22.180,39.151,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.978 | Acc: 22.213,39.190,92.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.798 | Acc: 21.875,39.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.828 | Acc: 21.838,38.616,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.805 | Acc: 21.799,37.748,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 21.901,38.051,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.916 | Acc: 19.531,40.625,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.961 | Acc: 21.801,39.918,93.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.962 | Acc: 21.856,39.539,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.965 | Acc: 22.310,39.408,92.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.963 | Acc: 22.203,39.043,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.960 | Acc: 22.262,39.179,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.967 | Acc: 22.120,39.088,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.965 | Acc: 22.224,39.046,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.965 | Acc: 22.161,39.062,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.965 | Acc: 22.099,38.998,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.964 | Acc: 22.167,39.121,92.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.966 | Acc: 22.253,39.144,92.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.967 | Acc: 22.102,39.166,92.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.967 | Acc: 22.168,39.281,92.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.968 | Acc: 22.167,39.207,92.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.967 | Acc: 22.119,39.125,92.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.968 | Acc: 22.165,39.170,92.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.967 | Acc: 22.214,39.150,92.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.968 | Acc: 22.226,39.199,92.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.968 | Acc: 22.273,39.280,92.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.851 | Acc: 20.312,39.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.827 | Acc: 21.763,38.579,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.803 | Acc: 21.627,38.224,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.816 | Acc: 21.811,38.397,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 0.945 | Acc: 22.656,38.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.943 | Acc: 22.470,38.430,93.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 22.370,38.834,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.957 | Acc: 21.849,38.448,93.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.953 | Acc: 22.319,39.034,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.953 | Acc: 22.277,39.001,93.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.957 | Acc: 22.030,38.824,93.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.955 | Acc: 22.108,38.813,93.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.957 | Acc: 22.137,38.922,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.958 | Acc: 22.091,38.903,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.957 | Acc: 22.034,38.845,93.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.955 | Acc: 22.278,39.073,93.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.957 | Acc: 22.332,39.137,93.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.957 | Acc: 22.297,39.233,93.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.958 | Acc: 22.231,39.168,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.958 | Acc: 22.249,39.278,93.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.957 | Acc: 22.323,39.284,93.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.959 | Acc: 22.253,39.266,93.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.958 | Acc: 22.249,39.264,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 22.295,39.280,93.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.819 | Acc: 21.094,40.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.843 | Acc: 22.061,39.249,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.816 | Acc: 21.913,38.357,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.825 | Acc: 21.990,38.563,71.939,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 0.997 | Acc: 21.094,40.625,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.956 | Acc: 21.987,38.170,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.954 | Acc: 22.066,38.357,93.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.950 | Acc: 21.939,38.614,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.952 | Acc: 22.155,38.522,93.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.954 | Acc: 21.875,38.420,93.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.953 | Acc: 21.940,38.501,93.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.956 | Acc: 21.980,38.880,93.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.956 | Acc: 21.957,39.029,93.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.959 | Acc: 21.987,38.959,93.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.958 | Acc: 22.151,38.993,93.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.959 | Acc: 22.133,39.084,93.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.958 | Acc: 22.147,39.166,93.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.959 | Acc: 22.219,39.188,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.958 | Acc: 22.278,39.288,93.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.958 | Acc: 22.293,39.364,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.958 | Acc: 22.301,39.406,93.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.957 | Acc: 22.299,39.395,93.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.958 | Acc: 22.280,39.400,93.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 22.402,39.495,93.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.814 | Acc: 21.875,39.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.846 | Acc: 21.801,38.356,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.824 | Acc: 21.837,38.034,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.834 | Acc: 21.977,38.422,72.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 0.847 | Acc: 25.781,47.656,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.917 | Acc: 23.438,40.662,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.937 | Acc: 23.285,39.939,93.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.940 | Acc: 22.912,39.741,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.938 | Acc: 22.859,39.410,93.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.939 | Acc: 22.811,39.712,93.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.939 | Acc: 22.766,39.721,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.942 | Acc: 22.551,39.417,93.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.943 | Acc: 22.613,39.368,93.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.943 | Acc: 22.592,39.468,93.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.942 | Acc: 22.427,39.362,93.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.944 | Acc: 22.359,39.190,93.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 22.335,39.276,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.947 | Acc: 22.399,39.242,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.947 | Acc: 22.311,39.163,93.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.948 | Acc: 22.358,39.226,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.948 | Acc: 22.325,39.243,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.948 | Acc: 22.306,39.269,93.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.950 | Acc: 22.301,39.223,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.950 | Acc: 22.427,39.253,93.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.854 | Acc: 23.438,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.855 | Acc: 21.689,39.025,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 21.818,38.643,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.831 | Acc: 22.080,38.717,72.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 0.918 | Acc: 21.094,40.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.947 | Acc: 22.731,40.476,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.942 | Acc: 22.523,40.072,93.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.942 | Acc: 22.579,39.985,93.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.941 | Acc: 22.589,39.902,93.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.935 | Acc: 22.370,39.952,93.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.936 | Acc: 22.456,39.837,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.935 | Acc: 22.557,39.727,93.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 22.482,39.509,93.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.937 | Acc: 22.566,39.559,93.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.939 | Acc: 22.532,39.533,93.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.942 | Acc: 22.458,39.579,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.942 | Acc: 22.358,39.494,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.940 | Acc: 22.369,39.470,93.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.941 | Acc: 22.323,39.457,93.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.942 | Acc: 22.298,39.390,93.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.944 | Acc: 22.284,39.423,93.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.944 | Acc: 22.276,39.507,93.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.944 | Acc: 22.342,39.549,93.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.944 | Acc: 22.349,39.571,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.843 | Acc: 22.656,39.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 21.949,39.100,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.831 | Acc: 22.046,38.338,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 22.041,38.512,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 1.012 | Acc: 14.844,42.969,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.922 | Acc: 22.396,41.406,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.923 | Acc: 22.313,40.873,94.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.929 | Acc: 22.131,40.407,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.930 | Acc: 21.817,39.969,93.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.929 | Acc: 22.068,39.913,94.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.931 | Acc: 21.978,39.863,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.930 | Acc: 21.980,39.866,94.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.929 | Acc: 22.059,39.829,94.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.932 | Acc: 22.048,39.749,94.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.932 | Acc: 22.124,39.735,94.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.934 | Acc: 22.172,39.603,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.935 | Acc: 22.258,39.536,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.935 | Acc: 22.300,39.559,93.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.936 | Acc: 22.311,39.516,93.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.937 | Acc: 22.301,39.499,93.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.937 | Acc: 22.257,39.432,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.937 | Acc: 22.374,39.617,93.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 22.358,39.586,93.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.939 | Acc: 22.361,39.651,93.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.873 | Acc: 21.094,41.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.853 | Acc: 21.652,39.062,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.827 | Acc: 21.932,38.014,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.833 | Acc: 21.952,38.256,72.093,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 0.973 | Acc: 19.531,29.688,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.928 | Acc: 22.098,39.286,93.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.941 | Acc: 22.409,39.310,93.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.943 | Acc: 22.221,39.062,93.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.939 | Acc: 22.454,39.641,93.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.937 | Acc: 22.532,39.782,93.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.937 | Acc: 22.508,39.857,93.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.935 | Acc: 22.629,40.038,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.935 | Acc: 22.613,39.912,93.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.935 | Acc: 22.691,39.826,93.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.935 | Acc: 22.656,39.762,93.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.934 | Acc: 22.738,39.663,93.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.932 | Acc: 22.608,39.643,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.933 | Acc: 22.540,39.455,93.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.932 | Acc: 22.592,39.532,93.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.930 | Acc: 22.672,39.654,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.931 | Acc: 22.610,39.566,93.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.931 | Acc: 22.526,39.553,93.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.931 | Acc: 22.496,39.504,93.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.931 | Acc: 22.601,39.553,93.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.867 | Acc: 21.875,41.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.853 | Acc: 21.466,38.914,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.830 | Acc: 21.475,38.338,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 21.824,38.563,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 0.851 | Acc: 30.469,42.969,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.914 | Acc: 23.289,40.476,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.916 | Acc: 22.561,41.025,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.921 | Acc: 22.298,40.779,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.918 | Acc: 22.483,40.548,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.918 | Acc: 22.184,39.991,94.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.921 | Acc: 22.385,40.076,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.920 | Acc: 22.440,39.855,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.920 | Acc: 22.642,40.048,94.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.920 | Acc: 22.635,39.865,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.920 | Acc: 22.567,39.774,94.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.920 | Acc: 22.610,39.893,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.922 | Acc: 22.702,39.938,94.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.922 | Acc: 22.671,39.892,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.923 | Acc: 22.751,39.988,94.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.923 | Acc: 22.700,39.966,94.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.923 | Acc: 22.758,39.956,94.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.925 | Acc: 22.679,39.851,94.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.924 | Acc: 22.687,39.952,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.926 | Acc: 22.548,39.866,94.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.806 | Acc: 21.094,41.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 21.391,39.025,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.835 | Acc: 21.456,38.434,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.851 | Acc: 21.555,38.525,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 0.882 | Acc: 21.875,35.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.919 | Acc: 21.503,38.504,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.918 | Acc: 22.218,39.253,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.917 | Acc: 22.349,39.011,94.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.919 | Acc: 22.512,39.140,94.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.920 | Acc: 22.633,39.364,94.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.920 | Acc: 22.708,39.740,94.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 22.595,39.783,94.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.918 | Acc: 22.389,39.587,94.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.918 | Acc: 22.423,39.559,94.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.920 | Acc: 22.349,39.447,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.922 | Acc: 22.381,39.455,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.921 | Acc: 22.364,39.636,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.922 | Acc: 22.432,39.670,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.923 | Acc: 22.381,39.621,94.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.923 | Acc: 22.404,39.706,94.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.922 | Acc: 22.374,39.742,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.923 | Acc: 22.347,39.654,94.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.924 | Acc: 22.351,39.565,94.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.925 | Acc: 22.425,39.614,94.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.834 | Acc: 21.875,37.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.877 | Acc: 21.466,38.765,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.841 | Acc: 21.780,38.396,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.851 | Acc: 21.977,38.576,71.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 0.914 | Acc: 20.312,35.938,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.918 | Acc: 23.772,39.583,94.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.912 | Acc: 23.476,40.854,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.912 | Acc: 22.887,40.202,94.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.909 | Acc: 22.859,39.950,94.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.910 | Acc: 22.935,40.084,94.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.914 | Acc: 22.934,40.018,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.914 | Acc: 23.050,40.054,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.914 | Acc: 23.059,40.023,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.912 | Acc: 23.097,39.982,94.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.914 | Acc: 23.025,39.859,94.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.915 | Acc: 23.003,39.713,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.916 | Acc: 23.013,39.837,94.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.917 | Acc: 22.890,39.823,94.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.917 | Acc: 22.934,39.744,94.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.917 | Acc: 22.851,39.719,94.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.919 | Acc: 22.758,39.788,94.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.919 | Acc: 22.684,39.816,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.919 | Acc: 22.706,39.798,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.920 | Acc: 22.623,39.745,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.814 | Acc: 21.094,41.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.880 | Acc: 22.173,39.695,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.850 | Acc: 22.218,38.567,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.856 | Acc: 22.310,38.665,71.977,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 0.900 | Acc: 21.875,40.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.901 | Acc: 24.182,40.551,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.902 | Acc: 23.819,40.587,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.907 | Acc: 23.079,39.921,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.911 | Acc: 23.177,40.104,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.912 | Acc: 23.012,40.161,94.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.909 | Acc: 23.089,40.380,94.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.911 | Acc: 23.005,40.176,94.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.912 | Acc: 22.991,40.018,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.916 | Acc: 22.941,39.947,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.916 | Acc: 22.847,39.859,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.916 | Acc: 22.748,39.716,94.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.915 | Acc: 22.698,39.798,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.915 | Acc: 22.791,39.946,94.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.914 | Acc: 22.781,39.986,94.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.915 | Acc: 22.677,39.953,94.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.914 | Acc: 22.732,39.982,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.914 | Acc: 22.709,40.004,94.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.914 | Acc: 22.678,39.965,94.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.915 | Acc: 22.667,39.893,94.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.901 | Acc: 21.094,39.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.890 | Acc: 21.317,39.397,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.859 | Acc: 21.627,38.815,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.872 | Acc: 21.773,38.819,71.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 0.875 | Acc: 24.219,42.969,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.903 | Acc: 21.949,38.876,94.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.907 | Acc: 22.237,39.272,94.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.908 | Acc: 22.592,39.498,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.909 | Acc: 22.627,39.564,94.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.910 | Acc: 22.532,39.805,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.911 | Acc: 22.630,39.902,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.912 | Acc: 22.590,39.949,94.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.910 | Acc: 22.778,40.130,94.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.910 | Acc: 22.885,40.193,94.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.912 | Acc: 22.858,40.139,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.911 | Acc: 22.784,40.038,94.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.911 | Acc: 22.737,40.029,94.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.911 | Acc: 22.680,39.960,94.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.912 | Acc: 22.653,39.994,94.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.913 | Acc: 22.708,40.044,94.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.913 | Acc: 22.688,39.985,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.914 | Acc: 22.709,39.853,94.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.914 | Acc: 22.749,39.909,94.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.914 | Acc: 22.765,40.020,94.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.797 | Acc: 22.656,41.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 21.726,39.062,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.852 | Acc: 21.989,38.548,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.868 | Acc: 22.221,38.819,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 0.996 | Acc: 19.531,36.719,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.902 | Acc: 22.470,40.104,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.896 | Acc: 23.171,40.911,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.898 | Acc: 23.181,40.727,94.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.903 | Acc: 22.897,40.152,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.901 | Acc: 22.718,40.060,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.903 | Acc: 22.927,40.134,94.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.902 | Acc: 22.933,39.971,94.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.902 | Acc: 22.899,39.994,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.904 | Acc: 22.820,39.831,94.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.903 | Acc: 22.843,40.015,94.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.903 | Acc: 22.801,40.063,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.902 | Acc: 22.763,40.045,94.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.903 | Acc: 22.869,40.035,94.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.904 | Acc: 22.762,39.949,94.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.905 | Acc: 22.809,39.989,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.905 | Acc: 22.741,39.939,94.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.905 | Acc: 22.720,40.013,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.906 | Acc: 22.702,40.041,94.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.906 | Acc: 22.662,40.080,94.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.925 | Acc: 21.875,41.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 22.135,39.621,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.844 | Acc: 22.256,39.005,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.850 | Acc: 22.323,39.152,72.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.888 | Acc: 23.438,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.927 | Acc: 21.949,39.807,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.912 | Acc: 21.970,39.653,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.905 | Acc: 22.310,40.356,94.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.908 | Acc: 22.647,40.519,94.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.906 | Acc: 22.517,40.354,94.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.909 | Acc: 22.191,40.212,94.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.906 | Acc: 22.340,40.281,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.906 | Acc: 22.215,40.266,94.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.908 | Acc: 22.216,40.262,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.909 | Acc: 22.221,40.112,94.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.908 | Acc: 22.250,40.095,94.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.908 | Acc: 22.339,40.113,94.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.908 | Acc: 22.387,40.170,94.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.908 | Acc: 22.414,40.141,94.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.907 | Acc: 22.394,40.064,94.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.908 | Acc: 22.401,40.017,94.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.908 | Acc: 22.475,40.025,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.908 | Acc: 22.448,39.991,94.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.909 | Acc: 22.420,39.961,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.845 | Acc: 22.656,39.844,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.914 | Acc: 22.024,39.695,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.871 | Acc: 22.142,39.082,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.885 | Acc: 22.131,39.178,71.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 0.959 | Acc: 27.344,40.625,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.893 | Acc: 22.619,40.104,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.892 | Acc: 22.485,40.187,95.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.902 | Acc: 22.669,40.292,94.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.899 | Acc: 22.695,40.326,95.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.898 | Acc: 22.765,40.261,94.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.897 | Acc: 22.701,40.238,94.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.896 | Acc: 22.745,40.348,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.897 | Acc: 22.778,40.339,94.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.897 | Acc: 22.764,40.314,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.896 | Acc: 22.672,40.252,94.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.896 | Acc: 22.748,40.342,94.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.897 | Acc: 22.640,40.236,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.898 | Acc: 22.614,40.209,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.899 | Acc: 22.567,40.230,94.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.899 | Acc: 22.607,40.189,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.900 | Acc: 22.654,40.240,94.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.899 | Acc: 22.599,40.268,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.899 | Acc: 22.667,40.274,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.900 | Acc: 22.613,40.143,94.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.904 | Acc: 21.875,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.880 | Acc: 21.615,39.174,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.848 | Acc: 21.761,38.567,72.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.863 | Acc: 21.965,38.691,72.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 0.902 | Acc: 21.875,42.969,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.891 | Acc: 23.103,41.183,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.893 | Acc: 22.790,40.987,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.889 | Acc: 22.439,41.022,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.889 | Acc: 22.415,40.741,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.891 | Acc: 22.339,40.455,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.896 | Acc: 22.514,40.476,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.894 | Acc: 22.490,40.470,94.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.894 | Acc: 22.467,40.411,94.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.894 | Acc: 22.419,40.392,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.894 | Acc: 22.396,40.306,95.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.895 | Acc: 22.423,40.261,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.897 | Acc: 22.394,40.197,94.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.898 | Acc: 22.408,40.110,94.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.898 | Acc: 22.434,40.066,94.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.897 | Acc: 22.423,40.059,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.897 | Acc: 22.491,40.146,94.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.898 | Acc: 22.370,39.990,94.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.899 | Acc: 22.392,40.026,94.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.899 | Acc: 22.482,40.078,94.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.883 | Acc: 21.875,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.896 | Acc: 22.061,39.286,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.866 | Acc: 22.142,38.796,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.881 | Acc: 22.285,39.050,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 0.881 | Acc: 21.094,41.406,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 21.615,39.732,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.892 | Acc: 21.989,39.710,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 22.298,40.241,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.887 | Acc: 22.637,40.721,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.889 | Acc: 22.741,40.756,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.888 | Acc: 22.598,40.838,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.888 | Acc: 22.606,40.653,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.888 | Acc: 22.428,40.479,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.888 | Acc: 22.497,40.474,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.889 | Acc: 22.419,40.314,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.890 | Acc: 22.437,40.349,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.892 | Acc: 22.530,40.278,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.892 | Acc: 22.495,40.191,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.892 | Acc: 22.431,40.161,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.892 | Acc: 22.485,40.114,95.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.892 | Acc: 22.525,40.182,95.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.892 | Acc: 22.551,40.236,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.891 | Acc: 22.572,40.318,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.891 | Acc: 22.615,40.344,95.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.861 | Acc: 22.656,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.898 | Acc: 21.689,39.695,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.868 | Acc: 21.932,39.139,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.882 | Acc: 22.080,39.242,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 0.920 | Acc: 19.531,40.625,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 23.140,41.667,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.883 | Acc: 22.885,40.396,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.879 | Acc: 22.784,40.241,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 22.936,40.152,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.886 | Acc: 22.942,40.169,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.886 | Acc: 22.998,40.128,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.887 | Acc: 22.889,40.060,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.889 | Acc: 22.773,40.285,95.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 22.712,40.431,95.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.890 | Acc: 22.761,40.431,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.891 | Acc: 22.844,40.392,95.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.891 | Acc: 22.773,40.324,95.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.892 | Acc: 22.716,40.311,95.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.894 | Acc: 22.634,40.189,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.893 | Acc: 22.532,40.158,95.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.894 | Acc: 22.479,40.053,95.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.894 | Acc: 22.494,39.990,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.894 | Acc: 22.448,39.900,95.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.894 | Acc: 22.478,39.989,95.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.001 | Acc: 22.656,41.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.914 | Acc: 22.173,39.509,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.876 | Acc: 22.332,38.700,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.885 | Acc: 22.528,38.998,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.847 | Acc: 25.000,45.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.899 | Acc: 23.810,41.332,94.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.888 | Acc: 23.457,41.063,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.892 | Acc: 23.578,41.060,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.891 | Acc: 23.360,40.664,94.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.894 | Acc: 23.097,40.207,94.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.892 | Acc: 22.798,40.160,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.893 | Acc: 22.706,40.076,94.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 22.588,40.033,94.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 22.721,40.111,95.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.891 | Acc: 22.687,40.229,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.890 | Acc: 22.759,40.307,95.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.890 | Acc: 22.689,40.291,95.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.891 | Acc: 22.701,40.284,95.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.891 | Acc: 22.673,40.222,95.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.890 | Acc: 22.770,40.342,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.891 | Acc: 22.790,40.382,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.891 | Acc: 22.796,40.325,95.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.892 | Acc: 22.775,40.432,95.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.893 | Acc: 22.701,40.344,95.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.932 | Acc: 21.875,42.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.895 | Acc: 21.801,39.955,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.865 | Acc: 21.723,39.101,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.875 | Acc: 21.824,39.037,71.363,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 0.852 | Acc: 22.656,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.893 | Acc: 21.429,39.062,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.889 | Acc: 22.123,39.710,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 21.977,39.639,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.883 | Acc: 22.106,39.747,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.880 | Acc: 22.355,39.790,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.882 | Acc: 22.463,39.915,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.883 | Acc: 22.462,39.783,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.883 | Acc: 22.588,39.834,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.883 | Acc: 22.656,39.926,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.885 | Acc: 22.722,39.937,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.885 | Acc: 22.851,39.964,95.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.885 | Acc: 22.812,39.977,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.886 | Acc: 22.890,40.110,95.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.886 | Acc: 22.915,40.177,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.887 | Acc: 22.890,40.111,95.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.888 | Acc: 22.880,40.109,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.888 | Acc: 22.952,40.155,95.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.887 | Acc: 22.903,40.101,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.888 | Acc: 22.882,40.129,95.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.893 | Acc: 21.875,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 21.763,39.062,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.863 | Acc: 22.199,38.739,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.882 | Acc: 22.400,38.998,71.785,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 0.812 | Acc: 21.875,39.062,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 22.991,41.183,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.879 | Acc: 22.313,40.377,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 22.298,39.600,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.881 | Acc: 22.290,39.940,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.882 | Acc: 22.239,39.534,95.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.880 | Acc: 22.282,39.624,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.879 | Acc: 22.523,39.833,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.881 | Acc: 22.370,39.659,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.881 | Acc: 22.397,39.822,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.881 | Acc: 22.454,39.991,95.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.882 | Acc: 22.487,40.074,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.883 | Acc: 22.497,39.999,95.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.884 | Acc: 22.581,40.011,95.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.884 | Acc: 22.603,40.019,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.885 | Acc: 22.693,40.140,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.885 | Acc: 22.651,40.107,95.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.884 | Acc: 22.775,40.199,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.883 | Acc: 22.782,40.318,95.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.884 | Acc: 22.808,40.307,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.009 | Acc: 22.656,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.908 | Acc: 22.098,39.621,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.876 | Acc: 22.142,38.910,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.891 | Acc: 22.298,38.934,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 0.898 | Acc: 24.219,38.281,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.887 | Acc: 22.582,38.728,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.880 | Acc: 22.542,39.634,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.884 | Acc: 22.567,39.946,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.879 | Acc: 22.569,40.181,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 22.525,40.145,95.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.880 | Acc: 22.676,40.121,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.879 | Acc: 22.822,40.038,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.879 | Acc: 22.753,40.106,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.882 | Acc: 22.730,40.167,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.881 | Acc: 22.699,40.217,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.880 | Acc: 22.670,40.243,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.881 | Acc: 22.624,40.327,95.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.882 | Acc: 22.635,40.308,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.881 | Acc: 22.715,40.336,95.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.881 | Acc: 22.786,40.329,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.882 | Acc: 22.722,40.257,95.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.881 | Acc: 22.807,40.391,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.881 | Acc: 22.896,40.510,95.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.883 | Acc: 22.812,40.471,95.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.977 | Acc: 22.656,39.062,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.921 | Acc: 21.689,40.253,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.878 | Acc: 22.027,39.291,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.892 | Acc: 22.144,39.319,71.875,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 0.868 | Acc: 21.094,41.406,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 23.028,41.109,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 23.876,40.225,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 23.937,40.920,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.880 | Acc: 23.592,40.567,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.880 | Acc: 23.523,40.416,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.877 | Acc: 23.431,40.528,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.876 | Acc: 23.305,40.658,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.878 | Acc: 23.059,40.630,95.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.879 | Acc: 22.984,40.483,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.879 | Acc: 23.014,40.477,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.878 | Acc: 23.088,40.484,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.878 | Acc: 23.071,40.696,95.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.879 | Acc: 23.021,40.622,95.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.879 | Acc: 22.995,40.614,95.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 22.975,40.690,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.880 | Acc: 23.012,40.659,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.881 | Acc: 22.956,40.630,95.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.881 | Acc: 23.031,40.657,95.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.882 | Acc: 22.997,40.627,95.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 22.656,41.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.918 | Acc: 21.466,39.918,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.884 | Acc: 21.704,39.596,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.896 | Acc: 21.939,39.600,71.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.817 | Acc: 28.906,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.861 | Acc: 22.879,41.034,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.889 | Acc: 22.161,40.339,95.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.882 | Acc: 22.298,40.126,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 22.328,39.660,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.888 | Acc: 22.633,39.759,95.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.884 | Acc: 22.760,40.063,95.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.880 | Acc: 22.828,40.043,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.878 | Acc: 22.879,40.203,95.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.878 | Acc: 22.799,40.349,95.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 22.645,40.229,95.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 22.667,40.187,95.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.877 | Acc: 22.715,40.366,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.877 | Acc: 22.692,40.338,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.877 | Acc: 22.742,40.272,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 22.879,40.456,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 22.997,40.489,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 22.982,40.446,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.878 | Acc: 22.933,40.404,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.878 | Acc: 22.945,40.457,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.911 | Acc: 22.656,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.929 | Acc: 21.987,39.509,70.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.893 | Acc: 22.142,38.662,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.911 | Acc: 22.349,38.947,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 0.870 | Acc: 20.312,44.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 22.582,39.695,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.876 | Acc: 23.476,40.777,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.873 | Acc: 23.540,40.984,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.872 | Acc: 23.013,40.750,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.869 | Acc: 22.927,40.733,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 23.044,40.825,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 22.861,40.542,95.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 22.981,40.664,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.871 | Acc: 22.984,40.638,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 22.897,40.594,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 22.978,40.639,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.873 | Acc: 22.812,40.586,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 22.686,40.559,95.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.873 | Acc: 22.751,40.461,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.873 | Acc: 22.789,40.539,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.874 | Acc: 22.727,40.513,95.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.874 | Acc: 22.732,40.570,95.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 22.719,40.593,95.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.875 | Acc: 22.728,40.465,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.932 | Acc: 22.656,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.924 | Acc: 21.615,39.769,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.887 | Acc: 21.894,39.158,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.909 | Acc: 22.106,39.460,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 0.810 | Acc: 24.219,39.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.867 | Acc: 23.772,39.807,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.867 | Acc: 23.380,39.615,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 23.207,40.010,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 23.100,40.258,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 23.175,40.377,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 23.140,40.192,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 22.961,40.342,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 22.933,40.213,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.871 | Acc: 23.040,40.176,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.872 | Acc: 22.967,40.248,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.871 | Acc: 22.981,40.247,95.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 22.967,40.265,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 23.009,40.311,95.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.872 | Acc: 23.001,40.311,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.873 | Acc: 22.965,40.332,95.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 22.904,40.284,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.873 | Acc: 22.840,40.309,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.873 | Acc: 22.931,40.389,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.874 | Acc: 22.900,40.354,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.947 | Acc: 21.875,41.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.933 | Acc: 21.801,39.881,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.897 | Acc: 21.913,39.215,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.912 | Acc: 22.003,39.229,71.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.887 | Acc: 25.000,32.812,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.865 | Acc: 23.065,41.778,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 22.999,40.987,96.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.860 | Acc: 22.964,40.753,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 23.110,40.664,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.863 | Acc: 23.368,41.159,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.864 | Acc: 23.418,41.129,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.867 | Acc: 23.310,40.852,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 23.239,40.790,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.871 | Acc: 23.273,40.763,95.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.871 | Acc: 23.251,40.734,95.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.871 | Acc: 23.183,40.685,95.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.871 | Acc: 23.220,40.807,95.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 23.189,40.769,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 23.129,40.631,95.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 23.009,40.464,95.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 23.009,40.457,95.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.874 | Acc: 22.963,40.476,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 22.901,40.443,95.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.875 | Acc: 22.911,40.484,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.041 | Acc: 22.656,39.844,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 21.949,39.881,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.907 | Acc: 22.447,39.177,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.916 | Acc: 22.464,39.447,71.004,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.913 | Acc: 21.094,35.938,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.856 | Acc: 23.251,40.476,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.865 | Acc: 23.438,40.320,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 23.361,40.113,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 23.601,40.866,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 23.283,40.834,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.862 | Acc: 23.237,40.883,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 23.232,40.780,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 23.263,40.601,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 23.278,40.539,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 23.266,40.606,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 23.240,40.593,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.865 | Acc: 23.243,40.586,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.867 | Acc: 23.150,40.568,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 23.210,40.594,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 23.139,40.472,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.868 | Acc: 23.153,40.440,95.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 23.181,40.536,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 23.059,40.482,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 22.986,40.500,95.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 21.875,41.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 21.652,39.621,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.908 | Acc: 21.913,39.310,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.921 | Acc: 22.157,39.331,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 0.884 | Acc: 28.125,46.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 21.726,40.439,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.870 | Acc: 21.989,40.149,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 22.067,40.177,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 22.270,40.403,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 22.401,40.695,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 22.469,40.651,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.866 | Acc: 22.878,40.891,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 22.812,40.974,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 22.781,40.845,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.866 | Acc: 22.672,40.703,95.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 22.713,40.710,95.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.868 | Acc: 22.679,40.631,95.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 22.656,40.724,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.869 | Acc: 22.653,40.625,95.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.869 | Acc: 22.838,40.643,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 22.948,40.744,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 22.938,40.790,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.871 | Acc: 22.909,40.766,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.872 | Acc: 22.894,40.779,95.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.012 | Acc: 21.875,42.188,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 22.135,40.141,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 22.104,39.596,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.918 | Acc: 22.323,39.626,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.859 | Acc: 21.094,37.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.855 | Acc: 22.507,39.211,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 22.599,39.634,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.853 | Acc: 22.541,39.754,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.860 | Acc: 22.425,39.583,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.861 | Acc: 22.679,39.983,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 22.689,40.063,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.864 | Acc: 22.579,40.060,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 22.729,40.329,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.864 | Acc: 22.738,40.379,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 22.722,40.345,95.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 22.741,40.388,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.863 | Acc: 22.770,40.427,95.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 22.827,40.568,95.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 22.865,40.486,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.864 | Acc: 22.846,40.545,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.864 | Acc: 22.953,40.603,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 22.975,40.607,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 23.033,40.584,95.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 23.036,40.584,95.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.957 | Acc: 23.438,39.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.947 | Acc: 21.540,39.360,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.905 | Acc: 21.780,39.272,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.918 | Acc: 22.080,39.408,71.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.809 | Acc: 30.469,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 24.293,42.262,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.860 | Acc: 23.857,40.911,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.865 | Acc: 23.361,40.420,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 23.148,40.123,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 22.950,39.991,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.873 | Acc: 22.953,40.115,95.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.873 | Acc: 23.077,40.232,95.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.872 | Acc: 22.831,40.154,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 22.842,40.344,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 23.006,40.668,95.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 22.914,40.491,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 22.860,40.395,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 22.791,40.395,95.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.871 | Acc: 22.876,40.308,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 22.963,40.373,95.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.871 | Acc: 22.880,40.318,95.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 22.908,40.407,95.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.872 | Acc: 22.901,40.489,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 22.952,40.561,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.960 | Acc: 21.875,39.062,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.941 | Acc: 22.396,40.030,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.910 | Acc: 22.828,39.367,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.921 | Acc: 22.976,39.472,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.823 | Acc: 28.906,39.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 23.140,41.257,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 23.457,41.349,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.865 | Acc: 23.092,40.753,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 23.254,40.992,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 23.043,41.112,95.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 23.179,40.877,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 23.205,40.896,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 23.137,40.945,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.862 | Acc: 23.187,41.005,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 23.200,40.971,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.863 | Acc: 23.250,40.887,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.863 | Acc: 23.227,40.742,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.862 | Acc: 23.204,40.799,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.862 | Acc: 23.146,40.800,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.861 | Acc: 23.116,40.773,95.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 23.038,40.722,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 22.975,40.685,95.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 22.933,40.616,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 22.902,40.617,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.980 | Acc: 22.656,41.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.934 | Acc: 22.173,39.732,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.900 | Acc: 22.123,39.253,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.919 | Acc: 22.439,39.370,71.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 0.768 | Acc: 31.250,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 24.702,41.369,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 23.209,41.178,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.861 | Acc: 22.989,40.702,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.864 | Acc: 22.782,40.056,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.863 | Acc: 22.958,40.362,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.863 | Acc: 23.069,40.580,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.863 | Acc: 23.072,40.575,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.863 | Acc: 23.078,40.504,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.860 | Acc: 22.997,40.526,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 22.998,40.489,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 22.985,40.505,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 23.055,40.651,96.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 23.081,40.697,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.860 | Acc: 23.048,40.617,96.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.863 | Acc: 22.986,40.550,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.862 | Acc: 23.094,40.676,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 23.048,40.696,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 23.050,40.764,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.863 | Acc: 23.056,40.760,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.086 | Acc: 23.438,41.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.939 | Acc: 21.949,40.290,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.896 | Acc: 22.389,39.672,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.906 | Acc: 22.592,39.767,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.875 | Acc: 17.188,33.594,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.849 | Acc: 23.475,40.588,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.847 | Acc: 23.533,40.835,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.853 | Acc: 23.668,40.817,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.852 | Acc: 23.389,40.789,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 23.321,40.648,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 23.418,40.870,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 23.493,40.869,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 23.501,40.960,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.856 | Acc: 23.373,40.750,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.857 | Acc: 23.317,40.800,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 23.321,40.731,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.857 | Acc: 23.191,40.654,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 23.081,40.598,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 23.059,40.617,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.858 | Acc: 23.160,40.705,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 23.158,40.720,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.857 | Acc: 23.240,40.843,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.857 | Acc: 23.148,40.768,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.857 | Acc: 23.183,40.857,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.990 | Acc: 23.438,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 22.135,40.662,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 22.447,40.187,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.932 | Acc: 22.592,40.305,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 0.797 | Acc: 28.125,42.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 23.475,42.411,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 22.618,41.616,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 22.656,41.253,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.856 | Acc: 22.203,40.963,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 22.463,41.151,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 22.618,41.264,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 22.712,41.395,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 22.836,41.309,96.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.853 | Acc: 22.920,41.307,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 23.022,41.340,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.853 | Acc: 22.989,41.155,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.852 | Acc: 22.993,41.202,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 23.036,41.110,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 23.082,41.181,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 23.087,41.165,96.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.855 | Acc: 22.985,41.029,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 22.972,41.053,96.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 22.946,41.038,96.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 22.933,40.972,96.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.029 | Acc: 25.000,40.625,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.977 | Acc: 22.396,40.141,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.931 | Acc: 22.580,39.596,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.945 | Acc: 22.669,39.818,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 0.849 | Acc: 22.656,36.719,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 22.731,41.481,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 22.332,40.396,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 22.874,40.471,96.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.849 | Acc: 22.888,40.461,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 23.028,40.780,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 23.128,41.012,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 22.961,41.113,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 22.981,41.086,96.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 22.928,41.104,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 22.963,41.088,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 22.925,41.102,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 22.919,41.098,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.850 | Acc: 22.872,41.011,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 22.929,40.895,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 22.859,40.846,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 22.819,40.761,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.855 | Acc: 22.849,40.756,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 22.892,40.753,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 22.962,40.896,96.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.108 | Acc: 24.219,42.188,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 22.247,40.030,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 22.332,39.653,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.939 | Acc: 22.387,39.639,70.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.759 | Acc: 32.812,46.875,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.842 | Acc: 22.879,41.890,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 23.037,41.635,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 23.079,41.650,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 22.868,41.319,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 22.842,41.298,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 22.624,40.974,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 22.629,40.919,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 22.753,40.916,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 23.019,40.875,96.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 23.127,40.839,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 23.204,40.869,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 23.104,40.871,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.853 | Acc: 23.066,40.751,96.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 23.029,40.717,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 22.999,40.643,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 23.055,40.715,96.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 23.066,40.627,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.855 | Acc: 23.070,40.703,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 23.155,40.785,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.913 | Acc: 23.438,42.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.961 | Acc: 22.359,40.439,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 22.599,39.748,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.939 | Acc: 22.874,39.857,71.081,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.922 | Acc: 21.094,41.406,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 23.512,42.783,96.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 23.761,41.978,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 23.719,41.483,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.846 | Acc: 23.582,41.165,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.846 | Acc: 23.584,41.174,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.848 | Acc: 23.405,41.284,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 23.310,41.295,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.847 | Acc: 23.209,41.168,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 23.114,41.130,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 23.092,41.037,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 23.225,40.947,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 23.126,40.949,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 23.042,40.918,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 22.995,40.767,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.854 | Acc: 23.022,40.866,96.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.854 | Acc: 22.982,40.934,96.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.854 | Acc: 22.929,40.856,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 22.974,40.911,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.854 | Acc: 22.980,40.955,96.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.927 | Acc: 23.438,37.500,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.984 | Acc: 22.024,39.695,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 22.104,39.463,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 22.310,39.524,70.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 0.846 | Acc: 24.219,37.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 22.805,41.704,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 23.647,42.550,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 23.117,42.123,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.851 | Acc: 22.907,41.454,95.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.849 | Acc: 23.020,41.399,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 22.940,41.187,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 22.712,40.869,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 22.836,41.033,96.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 22.829,41.005,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.850 | Acc: 22.831,41.021,96.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 23.052,41.109,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 23.146,41.157,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 23.069,41.026,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.851 | Acc: 23.071,41.009,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.851 | Acc: 23.004,41.027,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 22.978,41.002,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 22.968,40.976,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 23.003,41.071,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 23.017,41.088,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.012 | Acc: 21.875,39.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 22.210,40.253,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.953 | Acc: 22.389,39.539,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 22.464,39.613,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.775 | Acc: 20.312,45.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 22.954,40.885,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.836 | Acc: 23.228,41.273,96.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 23.297,41.342,96.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 22.936,40.789,96.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.841 | Acc: 23.128,40.756,96.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 22.889,40.864,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.843 | Acc: 22.911,40.719,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 22.889,40.751,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 22.846,40.858,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 23.010,40.745,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 22.985,40.788,96.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 23.026,40.823,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 23.108,40.817,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 23.168,40.836,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 23.194,40.895,96.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.850 | Acc: 23.189,40.932,96.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.850 | Acc: 23.188,40.946,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.851 | Acc: 23.139,40.932,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 23.097,40.974,96.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.079 | Acc: 23.438,43.750,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.978 | Acc: 21.838,40.476,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.931 | Acc: 22.313,40.015,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.936 | Acc: 22.298,39.946,70.761,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.873 | Acc: 23.438,40.625,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.846 | Acc: 22.247,40.067,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.838 | Acc: 22.637,40.835,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 23.335,41.201,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 23.360,41.445,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 23.438,41.507,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 23.438,41.471,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 23.305,41.268,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.846 | Acc: 23.151,41.076,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.846 | Acc: 23.062,41.031,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 23.018,41.119,96.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 23.183,41.275,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 23.262,41.286,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 23.279,41.301,96.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 23.204,41.231,96.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 23.212,41.217,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 23.223,41.207,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 23.199,41.198,96.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.849 | Acc: 23.160,41.203,96.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 23.159,41.218,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.963 | Acc: 25.000,41.406,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 22.582,40.774,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 22.923,39.691,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 23.105,39.767,70.697,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.796 | Acc: 22.656,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.852 | Acc: 22.507,40.402,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 22.675,39.748,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.847 | Acc: 22.874,40.177,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.849 | Acc: 22.849,40.027,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 22.695,40.223,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 22.953,40.522,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.852 | Acc: 23.111,40.725,96.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.849 | Acc: 23.200,40.979,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 23.118,41.048,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.850 | Acc: 23.200,41.227,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 23.197,41.247,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 23.136,41.183,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 23.162,41.251,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 23.115,41.234,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 23.121,41.334,96.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 23.192,41.404,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 23.041,41.262,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.847 | Acc: 23.078,41.309,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 23.093,41.308,96.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.912 | Acc: 22.656,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 21.912,40.104,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 22.332,39.806,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 22.579,40.010,70.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.758 | Acc: 26.562,46.875,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 23.214,41.183,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.849 | Acc: 22.942,41.101,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.845 | Acc: 22.938,41.201,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.847 | Acc: 23.032,41.069,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 23.291,40.989,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.842 | Acc: 23.212,41.012,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 23.310,41.362,96.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 23.253,41.154,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.844 | Acc: 23.174,41.070,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 23.224,41.138,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.845 | Acc: 23.176,41.021,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 23.152,40.891,96.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 23.174,40.981,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.848 | Acc: 23.282,41.075,96.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 23.295,41.030,96.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 23.306,41.092,96.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 23.229,41.076,96.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 23.225,41.069,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.849 | Acc: 23.216,41.088,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.887 | Acc: 25.000,39.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.949,40.253,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.934 | Acc: 22.313,39.768,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.948 | Acc: 22.528,40.074,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 0.847 | Acc: 21.094,42.969,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 22.098,40.997,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.847 | Acc: 22.447,40.892,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 22.643,40.945,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.837 | Acc: 23.225,41.329,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.839 | Acc: 23.314,41.399,96.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 23.386,41.180,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 23.194,41.018,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 23.040,41.052,96.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 23.027,40.988,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 23.084,41.165,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 23.070,41.074,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 23.279,41.254,96.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.844 | Acc: 23.336,41.376,96.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 23.285,41.351,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 23.147,41.183,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 23.279,41.258,96.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 23.245,41.250,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 23.208,41.186,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 23.259,41.300,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.979 | Acc: 25.781,42.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 21.726,40.513,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.942 | Acc: 22.275,40.034,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 22.426,40.023,70.825,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.847 | Acc: 25.000,39.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 23.140,41.629,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.846 | Acc: 23.190,41.044,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.844 | Acc: 23.514,41.457,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 23.515,41.744,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 23.453,41.329,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 23.476,41.154,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.848 | Acc: 23.410,41.307,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.848 | Acc: 23.496,41.251,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 23.416,41.225,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 23.387,41.220,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 23.339,41.109,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 23.441,41.234,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 23.357,41.182,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.848 | Acc: 23.385,41.292,95.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 23.318,41.245,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 23.369,41.409,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.848 | Acc: 23.321,41.347,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.849 | Acc: 23.293,41.207,96.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 23.343,41.283,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.994 | Acc: 25.781,41.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 22.135,40.216,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.925 | Acc: 22.485,39.806,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 22.643,39.933,70.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.841 | Acc: 19.531,39.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.835 | Acc: 23.586,41.481,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.831 | Acc: 24.733,42.340,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 24.155,42.034,96.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 24.103,42.052,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 23.894,42.149,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.834 | Acc: 23.818,41.645,96.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 23.654,41.705,96.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.833 | Acc: 23.573,41.625,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 23.528,41.406,96.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.836 | Acc: 23.383,41.278,96.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 23.353,41.233,96.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.838 | Acc: 23.343,41.212,96.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 23.249,41.134,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.840 | Acc: 23.301,41.173,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 23.256,41.116,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.842 | Acc: 23.167,41.068,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 23.234,41.111,96.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.842 | Acc: 23.264,41.123,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.843 | Acc: 23.265,41.127,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.046 | Acc: 25.781,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.997 | Acc: 22.470,40.551,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.954 | Acc: 22.713,39.920,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 22.848,40.074,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.836 | Acc: 25.781,43.750,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 23.140,41.667,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 23.647,41.159,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 23.540,41.073,96.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 23.833,41.358,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.839 | Acc: 23.577,40.896,96.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 23.450,40.793,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 23.454,40.896,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 23.505,40.877,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.841 | Acc: 23.524,40.923,96.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 23.422,40.967,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 23.462,41.085,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 23.386,41.118,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.842 | Acc: 23.270,40.954,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 23.346,40.992,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.843 | Acc: 23.362,41.077,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.843 | Acc: 23.274,41.019,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.843 | Acc: 23.305,41.113,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 23.390,41.173,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.843 | Acc: 23.362,41.117,96.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.894 | Acc: 24.219,44.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.433,41.034,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 22.847,40.549,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.951 | Acc: 22.797,40.535,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 0.874 | Acc: 24.219,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 22.098,40.885,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.839 | Acc: 22.637,40.739,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.840 | Acc: 22.464,40.612,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 22.733,40.992,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 22.741,41.136,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 22.708,41.154,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 22.750,41.257,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 22.860,41.261,96.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 23.002,41.406,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 23.064,41.468,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.840 | Acc: 22.886,41.314,96.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 23.010,41.377,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 23.051,41.334,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 23.051,41.256,96.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 23.085,41.222,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 23.187,41.306,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 23.254,41.399,96.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 23.297,41.417,96.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 23.247,41.386,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.057 | Acc: 21.094,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.173,40.253,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 22.104,40.034,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 22.285,39.818,70.940,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.858 | Acc: 17.188,35.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.828 | Acc: 23.065,41.778,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.827 | Acc: 23.666,42.035,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 23.655,42.034,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.829 | Acc: 23.621,41.676,96.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 23.499,41.878,96.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.832 | Acc: 23.554,41.929,96.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.833 | Acc: 23.471,41.994,96.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.833 | Acc: 23.476,41.843,96.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.833 | Acc: 23.299,41.622,96.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.833 | Acc: 23.344,41.694,96.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.834 | Acc: 23.307,41.682,96.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 23.172,41.523,96.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.835 | Acc: 23.129,41.514,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 23.235,41.556,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 23.194,41.570,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 23.099,41.428,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 23.082,41.386,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.840 | Acc: 23.070,41.333,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.840 | Acc: 23.058,41.296,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.895 | Acc: 23.438,41.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 21.875,40.662,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 22.389,40.377,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 22.631,40.228,70.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.821 | Acc: 25.000,44.531,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 23.735,42.113,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 23.114,41.139,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 23.258,41.611,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.837 | Acc: 23.360,41.667,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 23.291,41.576,96.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 23.373,41.736,96.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 23.487,41.589,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.841 | Acc: 23.209,41.246,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 23.286,41.324,96.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 23.336,41.387,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 23.303,41.357,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 23.159,41.293,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 23.156,41.319,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.840 | Acc: 23.257,41.398,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 23.287,41.510,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 23.184,41.338,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 23.234,41.404,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 23.206,41.350,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 23.148,41.298,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.958 | Acc: 23.438,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.015 | Acc: 22.321,40.551,69.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.958 | Acc: 22.694,40.339,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 22.861,40.369,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 0.813 | Acc: 20.312,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 22.582,41.890,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 22.866,42.473,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.835 | Acc: 22.746,42.405,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 22.897,42.081,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 22.857,41.754,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.834 | Acc: 22.753,41.593,96.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 22.712,41.329,96.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 22.787,41.431,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.837 | Acc: 22.855,41.467,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 22.792,41.305,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.838 | Acc: 22.893,41.360,96.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 22.896,41.341,96.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 22.997,41.394,96.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 22.968,41.387,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 22.903,41.362,96.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 22.909,41.253,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 22.950,41.319,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.840 | Acc: 22.961,41.324,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.840 | Acc: 23.056,41.451,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.047 | Acc: 23.438,42.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.040 | Acc: 22.321,40.885,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.983 | Acc: 22.370,40.225,70.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.985 | Acc: 22.707,40.113,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.774 | Acc: 23.438,40.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 24.219,40.327,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.833 | Acc: 23.838,41.101,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.835 | Acc: 23.873,41.470,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 23.804,41.416,96.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.830 | Acc: 23.584,41.375,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.832 | Acc: 23.521,41.342,96.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 23.460,41.373,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.834 | Acc: 23.258,41.319,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.835 | Acc: 23.230,41.402,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 23.200,41.224,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 23.409,41.569,96.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 23.366,41.516,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.837 | Acc: 23.390,41.517,96.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 23.482,41.606,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 23.435,41.469,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.838 | Acc: 23.452,41.501,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.838 | Acc: 23.376,41.379,96.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.838 | Acc: 23.314,41.335,96.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 23.339,41.419,96.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.074 | Acc: 21.875,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.036 | Acc: 21.987,40.774,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.988 | Acc: 22.542,40.377,70.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.995 | Acc: 22.772,40.369,70.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.796 | Acc: 19.531,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.825 | Acc: 23.698,41.220,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.822 | Acc: 23.418,41.940,96.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.820 | Acc: 23.617,41.803,96.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.824 | Acc: 23.428,41.937,96.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.828 | Acc: 23.329,41.863,96.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.832 | Acc: 23.199,41.548,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.833 | Acc: 23.155,41.379,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.835 | Acc: 23.054,41.358,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.837 | Acc: 23.127,41.406,96.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 23.033,41.161,96.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 23.010,41.141,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 23.000,41.127,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 23.162,41.275,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.837 | Acc: 23.207,41.245,96.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.838 | Acc: 23.194,41.136,96.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 23.189,41.180,96.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 23.254,41.278,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 23.318,41.369,96.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.839 | Acc: 23.278,41.285,96.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.048 | Acc: 22.656,40.625,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.359,40.923,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 22.809,40.511,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.954 | Acc: 22.964,40.587,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.820 | Acc: 24.219,48.438,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.833 | Acc: 24.107,41.964,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.832 | Acc: 24.276,41.635,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 24.155,41.842,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 23.920,41.686,96.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.832 | Acc: 24.087,41.986,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 24.057,42.013,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.830 | Acc: 23.958,41.883,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.830 | Acc: 23.918,41.877,96.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 23.947,41.834,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 23.982,41.709,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.830 | Acc: 23.911,41.710,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.831 | Acc: 23.901,41.798,96.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.830 | Acc: 23.916,41.870,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.831 | Acc: 23.779,41.595,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.832 | Acc: 23.617,41.432,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.833 | Acc: 23.540,41.479,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.833 | Acc: 23.577,41.452,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 23.567,41.352,96.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 23.497,41.365,96.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.995 | Acc: 24.219,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 22.582,41.071,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.966 | Acc: 22.752,40.339,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.981 | Acc: 22.900,40.407,71.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.885 | Acc: 22.656,39.062,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 23.735,42.188,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 23.438,41.711,96.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 23.604,41.752,96.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 23.823,42.014,96.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 23.832,41.948,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 23.728,41.781,96.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.831 | Acc: 23.764,41.645,96.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.831 | Acc: 23.564,41.547,96.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 23.416,41.436,96.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 23.519,41.550,96.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.831 | Acc: 23.491,41.562,96.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.832 | Acc: 23.366,41.426,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.831 | Acc: 23.381,41.526,96.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.832 | Acc: 23.463,41.651,96.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.833 | Acc: 23.500,41.591,96.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.833 | Acc: 23.484,41.599,96.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 23.499,41.601,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.836 | Acc: 23.392,41.514,96.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.836 | Acc: 23.355,41.429,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.954 | Acc: 23.438,44.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.014 | Acc: 22.656,40.774,70.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 22.942,40.377,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.992 | Acc: 23.233,40.625,70.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.913 | Acc: 24.219,39.844,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 24.107,42.001,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 23.228,41.254,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 23.860,41.662,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 23.736,41.541,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 23.824,41.708,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.831 | Acc: 23.851,41.652,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 23.836,41.628,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.835 | Acc: 23.598,41.304,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.836 | Acc: 23.537,41.290,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.836 | Acc: 23.515,41.185,96.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.836 | Acc: 23.533,41.328,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.835 | Acc: 23.548,41.384,96.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.835 | Acc: 23.414,41.355,96.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 23.399,41.276,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 23.352,41.243,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 23.386,41.280,96.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 23.357,41.232,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 23.327,41.237,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.837 | Acc: 23.310,41.273,96.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.053 | Acc: 23.438,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 21.615,40.253,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.958 | Acc: 21.704,39.710,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.977 | Acc: 21.939,39.985,70.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.826 | Acc: 19.531,37.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.823 | Acc: 23.549,41.927,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 23.171,41.578,96.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.825 | Acc: 23.143,41.547,96.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.824 | Acc: 23.341,41.426,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.822 | Acc: 23.221,41.329,96.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.821 | Acc: 23.295,41.484,96.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.824 | Acc: 23.138,41.151,96.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.824 | Acc: 23.195,41.227,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.826 | Acc: 23.191,41.212,96.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.827 | Acc: 23.165,41.189,96.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.828 | Acc: 23.169,41.205,96.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.828 | Acc: 23.052,41.244,96.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.829 | Acc: 23.150,41.328,96.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.829 | Acc: 23.162,41.398,96.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.828 | Acc: 23.199,41.422,96.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.830 | Acc: 23.192,41.404,96.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.830 | Acc: 23.282,41.500,96.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.830 | Acc: 23.280,41.458,96.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.831 | Acc: 23.269,41.507,96.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.020 | Acc: 25.000,44.531,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.059 | Acc: 22.210,40.551,68.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.294,40.091,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.030 | Acc: 22.503,39.882,69.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.800 | Acc: 25.781,43.750,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 23.586,40.885,96.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 23.152,40.968,96.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 23.297,40.894,96.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 23.139,41.310,96.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.830 | Acc: 23.151,41.391,96.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 23.153,41.426,96.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.831 | Acc: 23.066,41.384,96.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.830 | Acc: 23.161,41.421,96.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.829 | Acc: 23.343,41.570,96.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.830 | Acc: 23.255,41.441,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 23.218,41.417,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 23.285,41.461,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.836 | Acc: 23.192,41.304,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.836 | Acc: 23.218,41.284,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 23.240,41.271,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 23.214,41.268,96.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 23.277,41.328,96.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 23.293,41.343,96.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 23.286,41.373,96.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.973 | Acc: 22.656,43.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 22.582,40.365,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.981 | Acc: 23.037,39.806,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.994 | Acc: 23.117,40.113,70.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.941 | Acc: 27.344,41.406,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.842 | Acc: 22.731,41.853,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 22.904,41.216,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 23.066,41.176,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 23.293,41.397,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.829 | Acc: 23.615,41.592,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.828 | Acc: 23.586,41.729,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.829 | Acc: 23.465,41.811,96.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 23.501,41.586,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.829 | Acc: 23.412,41.536,96.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.829 | Acc: 23.298,41.461,96.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.829 | Acc: 23.314,41.427,96.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.829 | Acc: 23.399,41.504,96.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.829 | Acc: 23.470,41.595,96.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.829 | Acc: 23.557,41.751,96.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.831 | Acc: 23.531,41.759,96.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.830 | Acc: 23.666,41.927,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.831 | Acc: 23.550,41.860,96.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.832 | Acc: 23.572,41.820,96.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 23.474,41.753,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.042 | Acc: 25.781,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 22.210,41.704,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.972 | Acc: 22.656,40.892,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.992 | Acc: 22.772,40.932,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.732 | Acc: 25.781,43.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 22.731,40.885,96.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 23.133,41.139,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 23.373,41.790,96.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.828 | Acc: 23.698,41.686,96.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.828 | Acc: 24.041,42.041,96.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 23.954,42.052,96.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.829 | Acc: 23.759,41.971,96.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.831 | Acc: 23.758,42.008,96.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 23.662,41.950,96.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 23.612,41.900,96.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.831 | Acc: 23.512,41.806,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.832 | Acc: 23.412,41.714,96.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.832 | Acc: 23.420,41.736,96.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 23.401,41.556,96.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.834 | Acc: 23.419,41.578,96.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 23.367,41.518,96.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 23.380,41.441,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 23.334,41.428,96.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 23.384,41.499,96.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.041 | Acc: 23.438,41.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.013 | Acc: 21.875,40.848,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.976 | Acc: 22.180,40.320,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.996 | Acc: 22.323,40.561,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.898 | Acc: 21.875,35.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.825 | Acc: 23.400,42.597,96.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 22.904,42.149,96.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.821 | Acc: 22.900,42.098,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.821 | Acc: 23.177,42.014,97.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.826 | Acc: 23.267,41.963,96.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 23.186,41.813,96.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 23.354,41.827,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.829 | Acc: 23.360,41.707,96.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.829 | Acc: 23.299,41.730,96.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.829 | Acc: 23.422,41.791,96.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.829 | Acc: 23.423,41.774,96.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.829 | Acc: 23.434,41.727,96.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.831 | Acc: 23.405,41.655,96.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.831 | Acc: 23.351,41.559,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.830 | Acc: 23.380,41.645,96.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.831 | Acc: 23.433,41.620,96.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.831 | Acc: 23.444,41.686,96.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.832 | Acc: 23.392,41.646,96.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.833 | Acc: 23.407,41.626,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.014 | Acc: 24.219,42.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.021 | Acc: 22.359,41.481,70.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.975 | Acc: 22.466,40.796,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.990 | Acc: 22.784,40.561,70.517,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.793 | Acc: 23.438,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.812 | Acc: 23.586,42.374,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.817 | Acc: 24.257,42.626,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.822 | Acc: 24.078,42.200,97.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.820 | Acc: 23.794,42.091,97.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.822 | Acc: 23.631,41.870,97.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 23.308,41.626,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.824 | Acc: 23.454,41.567,96.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.825 | Acc: 23.471,41.523,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.826 | Acc: 23.420,41.458,96.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.825 | Acc: 23.496,41.500,96.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.826 | Acc: 23.635,41.625,96.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.828 | Acc: 23.551,41.523,96.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.829 | Acc: 23.533,41.472,96.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.831 | Acc: 23.471,41.334,96.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.831 | Acc: 23.409,41.339,96.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.831 | Acc: 23.328,41.321,96.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.833 | Acc: 23.353,41.360,96.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 23.386,41.382,96.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.833 | Acc: 23.351,41.375,96.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.834 | Acc: 22.656,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 22.321,41.778,69.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 22.428,40.682,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.992 | Acc: 22.707,40.612,69.954,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.879 | Acc: 18.750,37.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 23.103,40.923,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.833 | Acc: 23.571,41.044,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.828 | Acc: 23.450,41.176,96.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 23.505,41.503,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 23.615,41.414,96.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.831 | Acc: 23.567,41.555,96.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 23.454,41.445,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.833 | Acc: 23.520,41.532,96.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.834 | Acc: 23.554,41.596,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 23.496,41.542,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 23.515,41.583,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 23.509,41.620,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 23.372,41.505,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.834 | Acc: 23.368,41.554,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.833 | Acc: 23.399,41.611,96.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.832 | Acc: 23.452,41.664,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.832 | Acc: 23.408,41.624,96.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 23.433,41.595,96.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.833 | Acc: 23.466,41.581,96.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.016 | Acc: 25.000,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.060 | Acc: 22.396,41.071,69.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 22.771,40.682,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.034 | Acc: 22.900,40.932,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.833 | Acc: 25.781,37.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.825 | Acc: 23.772,42.262,97.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.831 | Acc: 23.514,41.997,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.825 | Acc: 23.745,42.354,96.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.825 | Acc: 23.457,41.725,96.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.821 | Acc: 23.453,41.955,96.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.821 | Acc: 23.457,41.839,96.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.817 | Acc: 23.676,41.960,97.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.816 | Acc: 23.704,41.896,97.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.815 | Acc: 23.796,42.011,97.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.815 | Acc: 23.795,41.950,97.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.815 | Acc: 23.671,41.869,97.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.815 | Acc: 23.713,41.909,97.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.814 | Acc: 23.752,41.903,97.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.813 | Acc: 23.727,41.823,97.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.813 | Acc: 23.645,41.806,97.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.811 | Acc: 23.632,41.891,97.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.811 | Acc: 23.580,41.832,97.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.810 | Acc: 23.498,41.735,97.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.810 | Acc: 23.470,41.679,97.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.907 | Acc: 23.438,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 22.210,41.369,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 22.694,40.720,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 22.925,40.856,70.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.787 | Acc: 23.438,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.799 | Acc: 22.396,41.555,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.786 | Acc: 22.961,41.845,97.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.795 | Acc: 22.848,41.445,97.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.793 | Acc: 22.907,41.310,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.793 | Acc: 23.260,41.600,97.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.794 | Acc: 23.173,41.542,97.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.794 | Acc: 23.194,41.628,97.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.793 | Acc: 23.340,41.702,97.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.794 | Acc: 23.446,41.553,97.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.794 | Acc: 23.414,41.729,97.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.795 | Acc: 23.448,41.615,97.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.796 | Acc: 23.564,41.747,97.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.795 | Acc: 23.593,41.777,97.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.794 | Acc: 23.563,41.857,97.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.793 | Acc: 23.635,41.886,97.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.794 | Acc: 23.669,41.966,97.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.794 | Acc: 23.628,41.963,97.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.795 | Acc: 23.615,41.885,97.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.795 | Acc: 23.563,41.823,97.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.949 | Acc: 22.656,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.985 | Acc: 22.396,41.220,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.953 | Acc: 22.656,41.025,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 22.951,40.996,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.778 | Acc: 18.750,51.562,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.787 | Acc: 23.921,40.625,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.793 | Acc: 23.438,41.006,97.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.796 | Acc: 23.770,40.971,97.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.797 | Acc: 23.727,40.866,97.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.797 | Acc: 23.956,41.468,97.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.794 | Acc: 23.909,41.684,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.792 | Acc: 24.263,41.850,97.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.796 | Acc: 24.141,41.741,97.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.795 | Acc: 23.930,41.825,97.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.793 | Acc: 23.873,41.737,97.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.793 | Acc: 23.717,41.707,97.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.793 | Acc: 23.726,41.669,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.792 | Acc: 23.722,41.747,97.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.792 | Acc: 23.796,41.801,97.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.793 | Acc: 23.733,41.892,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.794 | Acc: 23.603,41.764,97.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.794 | Acc: 23.527,41.798,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.794 | Acc: 23.528,41.804,97.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.794 | Acc: 23.534,41.788,97.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.899 | Acc: 22.656,40.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.978 | Acc: 22.545,40.885,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 22.885,40.739,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 23.002,40.740,71.196,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.846 | Acc: 17.188,29.688,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.791 | Acc: 23.549,41.890,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.788 | Acc: 23.457,42.168,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.788 | Acc: 23.553,41.586,97.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 23.611,42.014,97.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.785 | Acc: 23.499,41.863,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.786 | Acc: 23.392,41.890,97.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.783 | Acc: 23.515,42.265,97.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.784 | Acc: 23.438,42.212,97.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.783 | Acc: 23.299,42.045,97.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.785 | Acc: 23.212,41.892,97.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.787 | Acc: 23.194,41.742,97.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.788 | Acc: 23.211,41.889,97.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.787 | Acc: 23.315,41.861,97.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.787 | Acc: 23.307,41.876,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.788 | Acc: 23.290,41.915,97.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.788 | Acc: 23.347,41.981,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.788 | Acc: 23.350,41.958,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 23.331,42.034,97.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 23.409,42.023,97.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.925 | Acc: 22.656,44.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 22.693,41.295,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.935 | Acc: 22.809,40.816,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 23.079,40.958,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.789 | Acc: 20.312,41.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.804 | Acc: 21.838,40.960,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.796 | Acc: 21.875,41.235,97.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.794 | Acc: 22.285,41.816,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.789 | Acc: 22.589,41.802,97.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.788 | Acc: 22.625,41.917,97.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.787 | Acc: 22.940,41.878,97.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.787 | Acc: 23.077,42.182,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.786 | Acc: 22.879,42.212,97.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.787 | Acc: 23.027,42.196,97.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.786 | Acc: 23.123,42.273,97.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.786 | Acc: 23.321,42.322,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.786 | Acc: 23.311,42.194,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.787 | Acc: 23.363,42.262,97.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.787 | Acc: 23.354,42.296,97.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.787 | Acc: 23.430,42.341,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.788 | Acc: 23.382,42.209,97.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.788 | Acc: 23.403,42.171,97.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 23.403,42.116,97.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 23.460,42.087,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.936 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.978 | Acc: 22.396,41.778,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 22.809,41.120,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.953 | Acc: 22.900,41.124,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.779 | Acc: 23.438,42.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 22.991,42.448,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 23.285,42.359,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.786 | Acc: 23.527,42.047,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 23.708,42.323,98.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.785 | Acc: 23.592,42.172,98.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.788 | Acc: 23.496,42.116,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.788 | Acc: 23.548,42.104,98.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.788 | Acc: 23.379,42.013,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.787 | Acc: 23.545,42.036,98.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.788 | Acc: 23.558,41.943,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.788 | Acc: 23.582,41.937,98.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.789 | Acc: 23.668,41.967,97.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.789 | Acc: 23.752,41.969,97.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.788 | Acc: 23.732,41.901,97.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.788 | Acc: 23.679,41.967,97.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.789 | Acc: 23.681,41.981,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.789 | Acc: 23.651,41.984,97.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.788 | Acc: 23.699,42.051,97.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.788 | Acc: 23.702,42.040,97.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.907 | Acc: 23.438,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.984 | Acc: 22.284,41.369,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.942 | Acc: 22.561,41.044,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.956 | Acc: 22.925,41.009,71.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.804 | Acc: 25.781,38.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.791 | Acc: 24.368,41.778,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.786 | Acc: 23.780,42.397,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.786 | Acc: 23.796,42.585,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.783 | Acc: 23.939,42.400,97.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 23.786,42.505,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.781 | Acc: 23.812,42.633,97.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.903,42.548,98.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.780 | Acc: 23.850,42.139,98.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 23.968,42.149,98.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.781 | Acc: 23.951,42.215,98.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.782 | Acc: 23.833,42.152,97.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.784 | Acc: 23.784,41.974,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 23.800,42.020,97.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.784 | Acc: 23.729,42.048,97.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.784 | Acc: 23.679,42.055,97.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.784 | Acc: 23.695,42.056,97.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.784 | Acc: 23.756,42.126,97.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.783 | Acc: 23.764,42.188,98.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.783 | Acc: 23.815,42.200,97.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.919 | Acc: 21.875,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 22.656,41.518,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.944 | Acc: 22.999,41.082,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.957 | Acc: 23.066,41.176,71.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.833 | Acc: 18.750,35.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.798 | Acc: 22.693,40.774,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.793 | Acc: 23.056,40.968,97.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.789 | Acc: 23.309,41.560,98.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.785 | Acc: 23.794,42.004,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.786 | Acc: 23.677,41.909,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.784 | Acc: 23.980,42.278,98.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.783 | Acc: 24.003,42.398,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.783 | Acc: 23.729,42.372,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.784 | Acc: 23.748,42.287,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.784 | Acc: 23.640,42.149,98.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.783 | Acc: 23.611,42.184,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.783 | Acc: 23.648,42.246,98.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.783 | Acc: 23.701,42.235,98.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.783 | Acc: 23.649,42.201,98.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.630,42.120,98.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.782 | Acc: 23.730,42.248,98.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.782 | Acc: 23.575,42.100,98.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.783 | Acc: 23.550,42.099,98.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.782 | Acc: 23.589,42.159,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.940 | Acc: 21.875,42.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.981 | Acc: 22.879,41.257,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 22.771,40.796,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 22.989,40.843,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.763 | Acc: 24.219,49.219,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 24.442,43.713,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.361,42.664,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.630,42.354,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.872,42.332,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 23.863,42.195,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.767,42.323,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.720,42.370,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.748,42.289,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.778 | Acc: 23.774,42.304,98.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.779 | Acc: 23.570,42.289,98.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.779 | Acc: 23.529,42.212,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.780 | Acc: 23.489,42.165,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 23.446,42.071,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.780 | Acc: 23.440,42.096,98.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.427,42.107,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.445,42.195,98.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 23.454,42.231,98.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.483,42.211,98.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.528,42.247,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.953 | Acc: 24.219,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 22.247,41.220,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.934 | Acc: 22.790,40.987,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.950 | Acc: 22.964,41.048,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.730 | Acc: 21.094,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 23.661,41.964,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.772 | Acc: 24.181,41.768,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.886,41.598,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.777 | Acc: 23.862,41.561,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.780 | Acc: 23.863,41.654,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.780 | Acc: 23.851,41.974,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 23.748,41.761,98.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.782 | Acc: 23.680,41.780,98.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.783 | Acc: 23.614,41.665,98.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.589,41.783,98.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.784 | Acc: 23.565,41.721,97.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.784 | Acc: 23.431,41.727,97.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.784 | Acc: 23.569,41.843,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.784 | Acc: 23.618,41.946,97.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.784 | Acc: 23.585,41.892,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.784 | Acc: 23.554,41.900,97.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.785 | Acc: 23.527,41.901,97.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.785 | Acc: 23.537,41.908,97.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.784 | Acc: 23.602,42.001,98.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.935 | Acc: 24.219,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 22.359,41.555,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.956 | Acc: 23.056,41.101,70.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.970 | Acc: 23.105,41.265,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.812 | Acc: 22.656,38.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.786 | Acc: 22.061,40.290,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.787 | Acc: 22.828,41.082,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 23.143,41.675,98.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.783 | Acc: 23.225,41.811,98.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.785 | Acc: 23.321,41.785,97.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.784 | Acc: 23.463,42.045,98.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.782 | Acc: 23.947,42.182,98.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.782 | Acc: 23.879,42.081,98.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.782 | Acc: 23.873,42.002,98.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.780,41.861,98.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.783 | Acc: 23.699,41.774,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.783 | Acc: 23.710,41.789,98.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.782 | Acc: 23.740,41.822,98.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.782 | Acc: 23.657,41.848,98.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.781 | Acc: 23.635,41.946,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.781 | Acc: 23.856,42.027,98.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 23.804,42.052,98.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.823,42.064,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.827,42.077,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.898 | Acc: 22.656,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 22.545,41.704,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 22.961,40.739,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 23.181,41.009,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.735 | Acc: 25.000,45.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 24.293,42.522,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 23.514,42.092,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 23.348,42.008,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.782 | Acc: 23.370,42.033,97.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.782 | Acc: 23.391,41.762,97.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.782 | Acc: 23.373,41.845,97.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.782 | Acc: 23.327,42.005,97.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 23.253,41.901,98.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.782 | Acc: 23.157,41.790,98.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.782 | Acc: 23.274,41.919,98.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.781 | Acc: 23.346,42.074,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.781 | Acc: 23.399,42.084,98.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.781 | Acc: 23.438,42.161,98.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.782 | Acc: 23.340,42.054,98.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.783 | Acc: 23.393,42.078,98.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.783 | Acc: 23.474,42.100,98.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.783 | Acc: 23.520,42.142,97.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.783 | Acc: 23.472,42.079,98.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.783 | Acc: 23.505,42.017,98.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.949 | Acc: 22.656,44.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.582,41.332,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 23.018,41.044,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 23.079,41.009,71.094,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.694 | Acc: 28.125,49.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 24.033,41.443,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.778 | Acc: 24.066,42.168,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 23.822,42.559,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.843,41.917,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.762,42.064,98.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 23.735,42.136,98.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.792,42.215,98.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 23.787,42.260,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 23.580,42.274,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.780 | Acc: 23.725,42.355,98.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.780 | Acc: 23.674,42.336,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.779 | Acc: 23.690,42.359,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 23.707,42.310,98.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.779 | Acc: 23.816,42.402,98.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.796,42.341,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.844,42.329,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 23.793,42.291,98.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.766,42.242,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.737,42.239,98.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.884 | Acc: 24.219,45.312,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 22.768,41.667,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 23.095,41.178,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 23.297,41.240,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.765 | Acc: 31.250,49.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 24.107,43.192,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.770 | Acc: 23.838,42.740,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.778 | Acc: 23.950,42.777,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 23.736,42.612,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 23.902,42.652,98.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 23.948,42.710,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.780 | Acc: 23.908,42.293,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 23.826,42.280,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 23.787,42.265,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.781 | Acc: 23.710,42.199,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.782 | Acc: 23.657,42.209,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.780 | Acc: 23.583,42.181,98.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 23.602,42.140,98.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.780 | Acc: 23.549,42.235,98.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.536,42.156,98.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.525,42.219,98.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 23.614,42.323,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.781 | Acc: 23.552,42.307,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.781 | Acc: 23.546,42.323,98.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.896 | Acc: 22.656,42.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 22.545,41.295,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.942 | Acc: 22.923,40.720,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.956 | Acc: 23.066,40.843,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.849 | Acc: 19.531,40.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 23.772,43.043,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 23.457,42.207,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.348,42.303,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.775 | Acc: 23.495,42.419,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 23.639,42.327,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 23.567,42.200,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 23.471,42.304,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.779 | Acc: 23.408,42.003,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 23.425,41.950,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.780 | Acc: 23.263,41.966,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.780 | Acc: 23.370,42.067,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.781 | Acc: 23.369,42.129,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.781 | Acc: 23.423,42.188,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.781 | Acc: 23.390,42.093,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.780 | Acc: 23.505,42.219,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.780 | Acc: 23.542,42.292,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 23.570,42.259,98.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.780 | Acc: 23.641,42.330,98.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.780 | Acc: 23.645,42.364,98.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.909 | Acc: 22.656,42.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 22.991,41.667,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.951 | Acc: 23.418,41.292,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 23.450,41.227,71.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.788 | Acc: 16.406,36.719,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 22.321,42.039,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 23.152,42.207,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.781 | Acc: 23.143,42.034,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.781 | Acc: 23.196,42.226,98.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.144,42.450,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 23.470,42.743,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.779 | Acc: 23.576,42.675,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.779 | Acc: 23.520,42.357,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 23.602,42.222,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.780 | Acc: 23.542,42.215,98.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.779 | Acc: 23.597,42.308,98.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 23.664,42.431,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 23.689,42.628,98.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.668,42.624,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.658,42.476,98.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 23.790,42.596,98.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.797,42.515,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.740,42.419,98.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.784,42.384,98.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.911 | Acc: 23.438,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 23.028,41.815,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.952 | Acc: 23.266,41.139,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.968 | Acc: 23.361,41.176,71.235,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.801 | Acc: 19.531,38.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 23.400,42.076,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 24.524,42.168,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 24.577,42.777,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.775 | Acc: 24.171,42.477,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 24.459,42.481,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 24.096,42.265,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.775 | Acc: 24.097,42.509,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 23.840,42.265,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 23.917,42.231,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 23.737,42.211,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.776 | Acc: 23.635,42.230,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.668,42.191,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 23.647,42.247,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.615,42.160,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.624,42.024,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.528,41.981,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 23.580,42.107,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.619,42.157,98.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.636,42.192,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.944 | Acc: 22.656,42.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 22.582,41.629,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 22.771,41.254,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 22.989,41.189,71.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.784 | Acc: 26.562,40.625,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 24.182,43.229,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.770 | Acc: 23.933,43.007,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 23.899,42.956,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 23.900,42.969,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 23.886,43.031,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 23.786,42.691,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 23.842,42.598,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 23.772,42.420,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 23.576,42.459,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 23.632,42.370,98.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 23.756,42.474,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 23.681,42.486,98.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 23.653,42.508,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.638,42.435,98.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.572,42.431,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.669,42.438,98.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.678,42.442,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.654,42.460,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.649,42.356,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.914 | Acc: 23.438,43.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 22.396,41.778,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.944 | Acc: 22.904,41.101,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.130,41.060,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.780 | Acc: 23.438,43.750,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 24.256,42.560,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 24.009,42.264,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.527,42.303,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.778 | Acc: 23.438,42.168,98.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.731,42.211,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 23.851,42.129,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 23.853,42.088,98.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.981,42.236,98.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 23.869,42.088,98.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.873,42.199,98.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.742,42.074,98.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.849,42.226,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 23.863,42.232,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.768,42.215,98.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.879,42.263,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.868,42.246,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.896,42.318,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.957,42.302,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.778 | Acc: 23.895,42.229,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.930 | Acc: 25.000,42.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 22.731,42.299,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 23.114,41.730,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.156,41.406,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.728 | Acc: 27.344,40.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 24.442,41.518,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.990,42.340,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 23.899,42.175,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 23.929,42.853,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 23.902,42.853,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 23.889,42.530,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.774 | Acc: 23.964,42.476,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 23.903,42.372,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 23.947,42.412,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 23.943,42.335,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 23.947,42.375,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.927,42.275,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.752,42.214,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.693,42.285,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.694,42.289,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 23.661,42.292,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.618,42.233,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.637,42.233,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.618,42.202,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.898 | Acc: 25.000,43.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 23.103,41.927,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 23.323,41.101,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 23.348,41.112,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.766 | Acc: 21.094,42.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 23.810,42.708,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 23.552,42.530,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 24.027,42.341,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.778 | Acc: 23.872,42.622,98.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.778 | Acc: 23.909,42.481,98.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 23.715,42.323,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 23.820,42.365,98.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.758,42.425,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.532,42.270,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 23.628,42.397,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 23.618,42.301,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 23.749,42.265,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.775 | Acc: 23.833,42.265,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.835,42.257,98.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.824,42.265,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.824,42.297,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.825,42.194,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.903,42.246,98.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.856,42.286,98.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.934 | Acc: 22.656,42.188,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 22.582,41.815,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.037,41.178,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.066,41.035,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.780 | Acc: 22.656,51.562,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.790 | Acc: 23.363,41.295,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.779 | Acc: 23.876,41.902,98.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 23.809,42.290,98.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.778 | Acc: 23.476,41.831,98.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 23.654,42.404,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.722,42.607,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.803,42.575,98.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 23.918,42.648,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 23.839,42.537,98.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.791,42.580,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.774 | Acc: 23.731,42.566,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 23.674,42.589,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 23.659,42.562,98.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 23.674,42.677,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 23.788,42.637,98.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.795,42.647,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.770,42.549,98.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.775 | Acc: 23.779,42.521,98.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.775 | Acc: 23.805,42.520,98.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.945 | Acc: 24.219,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 22.731,41.481,70.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 23.209,41.101,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 23.258,40.868,71.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.816 | Acc: 17.188,37.500,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 25.260,42.783,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.776 | Acc: 24.657,42.530,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 24.372,42.021,98.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 24.296,42.380,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 23.925,42.365,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.883,42.110,98.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.774 | Acc: 23.892,42.359,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.773 | Acc: 23.918,42.343,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 23.809,42.330,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.773 | Acc: 23.803,42.417,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.773 | Acc: 23.816,42.438,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.773 | Acc: 23.807,42.515,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 23.800,42.448,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 23.768,42.468,98.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 23.855,42.551,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.774 | Acc: 23.815,42.424,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.786,42.410,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.784,42.389,98.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.776,42.405,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.943 | Acc: 24.219,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 22.879,41.890,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 22.980,41.368,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 23.245,41.227,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.830 | Acc: 17.188,36.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 23.177,42.560,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 23.780,42.950,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.773 | Acc: 23.835,42.380,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 24.296,42.834,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 24.350,42.644,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 24.090,42.259,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 23.914,42.243,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 23.869,42.047,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 23.899,42.222,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.881,42.160,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.774 | Acc: 23.752,42.276,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.775 | Acc: 23.716,42.129,98.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 23.797,42.229,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.738,42.213,98.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 23.681,42.141,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.774 | Acc: 23.742,42.226,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 23.715,42.192,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 23.743,42.233,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.774 | Acc: 23.790,42.237,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.911 | Acc: 23.438,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 23.065,41.890,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 23.209,41.406,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 23.258,41.304,71.286,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.770 | Acc: 29.688,47.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 22.731,42.262,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 22.027,41.006,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 22.579,41.624,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.780 | Acc: 22.685,41.512,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.779 | Acc: 23.113,41.692,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.780 | Acc: 23.308,41.897,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.778 | Acc: 23.709,42.276,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 23.700,42.134,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.780 | Acc: 23.731,42.123,98.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 23.780,42.172,98.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 23.742,42.117,98.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.846,42.272,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.818,42.277,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 23.871,42.363,98.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.776 | Acc: 23.876,42.335,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.777 | Acc: 23.827,42.295,98.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.893,42.375,98.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.788,42.255,98.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 23.780,42.257,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.933 | Acc: 23.438,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 22.731,41.704,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.933 | Acc: 23.056,41.025,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.950 | Acc: 23.040,40.971,71.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.757 | Acc: 27.344,53.125,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 24.033,42.783,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 24.428,42.988,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 24.129,42.546,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.775 | Acc: 23.698,41.898,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 23.724,42.041,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.592,42.104,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.774 | Acc: 23.775,42.287,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.775 | Acc: 23.641,42.168,98.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 23.705,42.084,98.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.632,42.036,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.773 | Acc: 23.674,42.060,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.772 | Acc: 23.814,42.055,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 23.761,42.029,98.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.773 | Acc: 23.724,42.101,98.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.773 | Acc: 23.697,42.130,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.773 | Acc: 23.647,42.173,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.773 | Acc: 23.678,42.208,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.773 | Acc: 23.647,42.291,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.773 | Acc: 23.663,42.288,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.976 | Acc: 23.438,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.582,41.815,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 23.018,41.444,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.207,41.393,71.363,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.723 | Acc: 29.688,45.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 24.256,42.597,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 23.780,41.997,98.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 23.783,42.392,98.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 23.920,42.467,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.963,42.806,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.954,42.827,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 23.703,42.769,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.661,42.644,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.627,42.615,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.770 | Acc: 23.799,42.732,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.777,42.732,98.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.862,42.615,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 23.746,42.499,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 23.766,42.421,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.773 | Acc: 23.765,42.496,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.773 | Acc: 23.698,42.375,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.773 | Acc: 23.676,42.394,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.773 | Acc: 23.766,42.473,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.773 | Acc: 23.831,42.532,98.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.935 | Acc: 24.219,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.981 | Acc: 22.768,41.964,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.938 | Acc: 23.323,41.254,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.954 | Acc: 23.386,41.368,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.778 | Acc: 21.094,32.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 23.810,43.080,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 23.933,43.864,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 24.001,43.135,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 23.775,42.650,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 23.948,42.319,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 23.760,42.239,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 23.742,42.465,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.690,42.265,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 23.554,42.084,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.772 | Acc: 23.678,42.199,98.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 23.791,42.421,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.772 | Acc: 23.784,42.291,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.772 | Acc: 23.761,42.277,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 23.696,42.390,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 23.578,42.278,98.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.773 | Acc: 23.576,42.280,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.773 | Acc: 23.600,42.279,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.772 | Acc: 23.682,42.393,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.772 | Acc: 23.702,42.446,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 24.219,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.984 | Acc: 22.731,42.113,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.285,41.521,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 23.386,41.534,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.713 | Acc: 28.125,49.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 23.549,42.299,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 23.838,41.825,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 23.911,42.533,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 23.418,42.188,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 23.337,42.180,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.771 | Acc: 23.438,42.246,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 23.321,42.304,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.471,42.236,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 23.407,42.149,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 23.539,42.234,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.773 | Acc: 23.646,42.375,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.773 | Acc: 23.726,42.470,98.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 23.794,42.430,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.773 | Acc: 23.782,42.385,98.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 23.731,42.390,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.773 | Acc: 23.734,42.445,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.773 | Acc: 23.728,42.497,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.772 | Acc: 23.697,42.495,98.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.772 | Acc: 23.712,42.487,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.965 | Acc: 23.438,43.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.984 | Acc: 22.954,41.890,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.418,41.273,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.463,41.240,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.748 | Acc: 24.219,45.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 24.442,42.522,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.777 | Acc: 23.171,41.997,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 23.322,42.021,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.777 | Acc: 23.515,41.917,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 23.755,42.095,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 23.644,42.168,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 23.703,42.453,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 23.685,42.396,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.684,42.369,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.647,42.440,98.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 23.653,42.442,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.772 | Acc: 23.632,42.346,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.772 | Acc: 23.713,42.325,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 23.782,42.315,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.771 | Acc: 23.842,42.419,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.772 | Acc: 23.832,42.387,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.772 | Acc: 23.777,42.373,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.773 | Acc: 23.715,42.278,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.774 | Acc: 23.700,42.294,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.955 | Acc: 24.219,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 23.065,41.704,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 23.361,41.521,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.957 | Acc: 23.335,41.406,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.728 | Acc: 27.344,50.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 23.475,43.824,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 23.361,43.007,98.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 23.655,43.340,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.768 | Acc: 23.274,43.036,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 23.708,43.255,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 23.631,42.924,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 23.559,42.664,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.627,42.707,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 23.528,42.636,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.772 | Acc: 23.519,42.561,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 23.452,42.537,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.773 | Acc: 23.392,42.392,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.772 | Acc: 23.500,42.544,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 23.549,42.499,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 23.617,42.372,98.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.773 | Acc: 23.564,42.299,98.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 23.564,42.254,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 23.554,42.231,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.774 | Acc: 23.616,42.249,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.957 | Acc: 23.438,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 22.768,42.039,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 23.018,41.463,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 23.117,41.393,71.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.769 | Acc: 27.344,40.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 25.372,44.048,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.771 | Acc: 24.695,42.511,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 23.975,42.162,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 24.007,41.966,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 23.886,41.878,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.896,42.039,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.942,42.221,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.806,42.071,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.817,42.218,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.721,42.269,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.798,42.357,98.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.804,42.356,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.878,42.325,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.957,42.324,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.900,42.338,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.854,42.290,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.882,42.233,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.976,42.339,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 24.014,42.337,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.944 | Acc: 24.219,42.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.917,41.369,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 23.209,41.139,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 23.425,41.163,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.764 | Acc: 20.312,42.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 22.917,41.629,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 23.552,42.569,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 23.617,42.226,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.495,41.966,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 23.608,42.126,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.775 | Acc: 23.754,42.220,98.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.737,42.287,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 23.525,42.139,98.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 23.606,42.192,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.773 | Acc: 23.702,42.394,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.773 | Acc: 23.671,42.294,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 23.603,42.200,98.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 23.698,42.167,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 23.677,42.093,98.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.774 | Acc: 23.630,42.066,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.774 | Acc: 23.591,42.056,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 23.609,42.057,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 23.639,42.149,98.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.773 | Acc: 23.630,42.118,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.987 | Acc: 25.000,44.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.999 | Acc: 22.433,41.257,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.953 | Acc: 22.923,41.178,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 23.194,41.355,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.774 | Acc: 21.094,45.312,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.762 | Acc: 23.400,43.006,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 23.133,42.835,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 23.988,42.700,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 23.804,42.863,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.886,42.520,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.728,42.381,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 23.753,42.581,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.840,42.561,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.826,42.554,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 23.912,42.526,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 23.840,42.499,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.769 | Acc: 23.755,42.447,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.769 | Acc: 23.698,42.415,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.777,42.477,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 23.824,42.515,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.769 | Acc: 23.805,42.514,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 23.827,42.584,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.699,42.415,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.749,42.362,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.973 | Acc: 25.000,43.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.619,41.778,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.018,41.254,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 23.156,41.291,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.727 | Acc: 22.656,46.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 23.251,42.336,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 23.895,43.140,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 23.860,42.777,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 23.601,42.294,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 23.654,42.427,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.773 | Acc: 23.592,42.323,98.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 23.831,42.575,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.772,42.522,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.895,42.528,98.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.773 | Acc: 23.877,42.335,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 23.904,42.477,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.771 | Acc: 23.888,42.453,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 23.881,42.439,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 23.888,42.413,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.894,42.431,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.919,42.557,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.793,42.536,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.821,42.536,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 23.798,42.448,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.912 | Acc: 22.656,41.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.997 | Acc: 22.545,42.039,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.951 | Acc: 23.133,41.482,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 23.258,41.317,71.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.724 | Acc: 24.219,48.438,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 23.400,40.960,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.772 | Acc: 23.304,41.559,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 23.835,41.790,98.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 23.736,41.917,98.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.772 | Acc: 23.716,42.133,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.683,41.942,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 23.709,41.988,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.748,42.231,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.804,42.278,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.472,42.141,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.604,42.304,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.771 | Acc: 23.600,42.181,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 23.689,42.217,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 23.696,42.288,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.687,42.281,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 23.625,42.234,98.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 23.657,42.226,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 23.704,42.213,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 23.766,42.313,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.963 | Acc: 21.875,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 22.433,41.890,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.934 | Acc: 22.942,41.349,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 22.938,41.406,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.766 | Acc: 21.875,35.938,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 23.363,41.667,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.777 | Acc: 23.647,41.254,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.774 | Acc: 23.566,41.714,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.771 | Acc: 23.852,42.361,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 23.708,42.273,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 23.702,42.433,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.498,42.343,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 23.685,42.590,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.731,42.589,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 23.605,42.584,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.565,42.545,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.626,42.596,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.716,42.520,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.652,42.479,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 23.656,42.463,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.705,42.424,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.788,42.458,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 23.702,42.378,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 23.643,42.364,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.951 | Acc: 23.438,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.693,41.518,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.944 | Acc: 22.885,41.368,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 22.964,41.291,71.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.796 | Acc: 26.562,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 22.321,41.964,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.685,42.035,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 23.233,42.008,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 23.457,42.313,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 23.670,42.450,98.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 23.747,42.788,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.958,42.924,98.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 24.131,42.857,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 24.102,42.878,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 24.122,42.934,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 23.929,42.743,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.768 | Acc: 23.969,42.826,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 23.997,42.849,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 23.969,42.810,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.954,42.764,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.912,42.674,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.944,42.726,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 23.909,42.588,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.825,42.550,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 23.438,42.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.999 | Acc: 22.656,42.299,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.950 | Acc: 23.152,41.845,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 23.284,41.855,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.845 | Acc: 17.969,32.812,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.772 | Acc: 23.772,41.369,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.771 | Acc: 23.590,40.816,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 23.117,41.176,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 23.409,41.348,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 23.453,41.476,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 23.438,41.729,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 23.665,42.016,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.777,42.299,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.769 | Acc: 23.895,42.485,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.675,42.537,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.759,42.537,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.895,42.573,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 23.761,42.361,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 23.807,42.360,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.827,42.447,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.824,42.480,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.806,42.453,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.773,42.434,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.716,42.372,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.991 | Acc: 25.000,42.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 22.879,42.150,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.953 | Acc: 23.266,41.559,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 23.220,41.611,71.798,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.758 | Acc: 25.000,47.656,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 23.251,41.443,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.209,42.416,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 22.938,42.175,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 23.312,42.332,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.492,42.288,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 23.328,42.355,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 23.360,42.420,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 23.525,42.493,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.580,42.528,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.770 | Acc: 23.593,42.421,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.544,42.506,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.587,42.385,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.563,42.394,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.613,42.276,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.759,42.320,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.695,42.382,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 23.683,42.456,98.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 23.736,42.527,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.725,42.555,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.008 | Acc: 24.219,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.006 | Acc: 22.619,41.927,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 22.961,41.463,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 23.105,41.483,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.813 | Acc: 18.750,35.156,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.759 | Acc: 23.996,43.676,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 24.047,43.426,98.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.764 | Acc: 23.835,43.097,98.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 23.968,43.017,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 23.863,43.108,98.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 23.799,43.046,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.766 | Acc: 23.637,42.719,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.588,42.590,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.576,42.511,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 23.480,42.397,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 23.420,42.375,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.460,42.340,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.476,42.349,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.532,42.363,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 23.676,42.566,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 23.574,42.411,98.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.641,42.419,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.684,42.475,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.712,42.561,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.966 | Acc: 24.219,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.982 | Acc: 22.693,41.741,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.936 | Acc: 23.209,41.178,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.953 | Acc: 23.386,41.304,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.793 | Acc: 27.344,36.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 24.293,42.039,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 24.657,42.454,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.773 | Acc: 24.103,42.072,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.771 | Acc: 23.968,42.091,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.948,42.311,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.771 | Acc: 23.954,42.246,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 23.997,42.176,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.942,42.197,98.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.951,42.317,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.989,42.417,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 24.010,42.364,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 24.037,42.560,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.769 | Acc: 24.012,42.472,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 24.032,42.393,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 24.071,42.315,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 24.063,42.222,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.942,42.188,98.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.935,42.257,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.909,42.198,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 24.219,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.693,42.225,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 23.114,41.349,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 23.258,41.355,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.763 | Acc: 27.344,42.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 23.735,41.704,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.771 | Acc: 23.323,41.654,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 23.835,41.893,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.768 | Acc: 23.939,42.332,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.909,42.342,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.935,42.194,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.770,42.265,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 23.748,42.139,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.769 | Acc: 23.830,42.183,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.770 | Acc: 23.896,42.207,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 23.936,42.375,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.966,42.395,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.901,42.430,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.955,42.457,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.954,42.489,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.769 | Acc: 23.849,42.394,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 23.914,42.373,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.855,42.345,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.821,42.352,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.953 | Acc: 24.219,41.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.998 | Acc: 22.433,42.150,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 23.037,41.273,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 23.015,41.278,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.799 | Acc: 19.531,35.938,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 23.289,41.964,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 23.857,41.806,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 24.168,42.303,98.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 23.939,42.024,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.700,41.963,98.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.702,41.942,98.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.768 | Acc: 23.731,42.188,98.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.884,42.280,98.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.843,42.317,98.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.791,42.374,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.717,42.389,98.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.846,42.427,98.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 23.767,42.439,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 23.799,42.560,98.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 23.798,42.535,98.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.766 | Acc: 23.778,42.390,98.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.766 | Acc: 23.728,42.414,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 23.766,42.456,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 23.718,42.411,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.965 | Acc: 22.656,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 22.470,42.150,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 23.228,41.463,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 23.220,41.586,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.762 | Acc: 22.656,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 23.958,44.234,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 23.495,42.607,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 23.399,42.444,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.766 | Acc: 23.476,42.342,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 23.430,42.327,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 23.463,42.588,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.460,42.575,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.777,42.644,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 23.770,42.494,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 23.838,42.588,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 23.777,42.449,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.769 | Acc: 23.775,42.586,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.632,42.457,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 23.649,42.424,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.771 | Acc: 23.622,42.509,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.632,42.545,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 23.657,42.529,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.624,42.519,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.626,42.571,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.936 | Acc: 25.000,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 22.693,41.778,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 23.152,41.235,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 23.284,41.227,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.808 | Acc: 22.656,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 22.991,41.853,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 22.828,42.931,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 22.720,42.405,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 22.897,42.236,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 22.881,42.048,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 23.115,42.078,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.766 | Acc: 23.393,42.248,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.766 | Acc: 23.510,42.357,98.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 23.438,42.205,98.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.767 | Acc: 23.465,42.250,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.501,42.371,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.768 | Acc: 23.515,42.307,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.623,42.328,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 23.679,42.407,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.746,42.478,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.766 | Acc: 23.744,42.487,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.692,42.421,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.760,42.462,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.755,42.446,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.952 | Acc: 22.656,43.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 22.879,41.890,70.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.932 | Acc: 23.114,41.368,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 23.194,41.381,71.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.741 | Acc: 24.219,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 24.182,42.448,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 23.666,41.597,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 23.425,41.906,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 23.688,42.081,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 23.646,42.133,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.405,42.181,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.681,42.409,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.782,42.527,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 23.860,42.537,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 24.021,42.673,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 23.925,42.629,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.768,42.495,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.769 | Acc: 23.785,42.511,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.716,42.532,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.702,42.463,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.703,42.424,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.731,42.446,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.710,42.413,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.720,42.432,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.959 | Acc: 25.000,42.969,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.991,42.299,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.942 | Acc: 23.152,41.578,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.143,41.368,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.799 | Acc: 21.875,42.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 24.963,42.299,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 24.867,42.283,97.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 24.129,41.970,98.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 23.794,42.255,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.776 | Acc: 23.554,42.048,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.773 | Acc: 23.754,42.142,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 23.703,42.171,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.622,42.212,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.772 | Acc: 23.632,42.364,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.791,42.506,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 23.777,42.248,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.772 | Acc: 23.758,42.330,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.772 | Acc: 23.773,42.328,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 23.682,42.352,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 23.687,42.356,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.772 | Acc: 23.588,42.343,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.772 | Acc: 23.591,42.327,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.772 | Acc: 23.676,42.371,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 23.780,42.464,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.938 | Acc: 25.781,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 22.656,42.113,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.938 | Acc: 23.056,41.482,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 23.220,41.483,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.740 | Acc: 26.562,37.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.762 | Acc: 24.070,42.783,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 24.047,42.893,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 23.924,42.828,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 23.997,42.930,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 24.265,42.876,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.767 | Acc: 24.406,42.878,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 24.346,42.891,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 24.418,42.954,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 24.236,42.697,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.769 | Acc: 24.199,42.895,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 24.180,42.919,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 24.128,42.839,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 24.000,42.747,98.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 23.966,42.677,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.912,42.673,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.873,42.684,98.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.932,42.682,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 23.924,42.642,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.868,42.628,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.971 | Acc: 26.562,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.990 | Acc: 22.954,41.555,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 23.361,41.063,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 23.489,41.099,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.751 | Acc: 16.406,41.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 23.177,41.146,98.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.759 | Acc: 23.895,42.226,98.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 23.527,41.919,98.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.760 | Acc: 23.852,42.631,98.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.762 | Acc: 24.033,42.907,98.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.763 | Acc: 23.948,42.575,98.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.763 | Acc: 24.053,42.636,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.764 | Acc: 24.112,42.605,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.764 | Acc: 24.158,42.576,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 24.094,42.440,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 24.081,42.587,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 24.079,42.521,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 24.126,42.586,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 24.030,42.599,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.925,42.564,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.980,42.572,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.898,42.495,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.847,42.452,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.839,42.493,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.949 | Acc: 23.438,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.768,42.299,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.944 | Acc: 23.247,41.864,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 23.271,41.739,71.785,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.733 | Acc: 21.875,46.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 25.409,43.936,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.779 | Acc: 24.676,43.197,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.772 | Acc: 23.732,43.251,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.771 | Acc: 23.679,43.056,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 23.646,42.737,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 23.541,42.756,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 23.615,42.703,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.748,42.624,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.770 | Acc: 23.886,42.908,98.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.811,42.774,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 23.830,42.697,98.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.771 | Acc: 23.995,42.871,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.931,42.852,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 23.846,42.766,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.835,42.784,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.769 | Acc: 23.783,42.750,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.703,42.675,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.766,42.726,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.751,42.745,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.020 | Acc: 22.656,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.999 | Acc: 22.582,41.667,70.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.950 | Acc: 23.171,41.159,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 23.335,41.368,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.792 | Acc: 17.969,37.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 22.396,40.774,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.760 | Acc: 23.418,41.825,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 23.245,41.675,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 23.129,42.226,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 22.888,42.149,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.767 | Acc: 23.076,42.271,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.188,42.226,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.389,42.265,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.450,42.369,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.767 | Acc: 23.472,42.471,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.703,42.495,98.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.742,42.609,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 23.788,42.592,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 23.707,42.516,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.733,42.520,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.776,42.455,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.799,42.513,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.827,42.490,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.747,42.436,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.977 | Acc: 25.000,44.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.954,41.555,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 23.342,41.235,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 23.361,41.176,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.780 | Acc: 17.969,40.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 22.545,42.001,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 22.828,41.883,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 23.117,41.829,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 23.582,42.294,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 23.685,42.450,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 23.722,42.601,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.676,42.514,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.769 | Acc: 23.607,42.469,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 23.675,42.412,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.767 | Acc: 23.706,42.506,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.635,42.357,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.577,42.450,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.491,42.298,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.538,42.301,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.570,42.312,98.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.649,42.358,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.602,42.252,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 23.669,42.348,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.694,42.345,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.982 | Acc: 24.219,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 22.842,42.188,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 23.190,41.711,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.335,41.867,71.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.859 | Acc: 21.094,32.031,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 24.144,41.443,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 24.009,42.321,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 23.668,42.111,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 23.862,42.226,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 23.824,42.327,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.767 | Acc: 23.741,42.478,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.792,42.393,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.729,42.299,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 23.895,42.403,98.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.769 | Acc: 23.741,42.417,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.706,42.435,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.769 | Acc: 23.661,42.486,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.769 | Acc: 23.767,42.616,98.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.827,42.677,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 23.866,42.657,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.805,42.436,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.820,42.453,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.760,42.499,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.790,42.483,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 23.438,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.619,41.964,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.171,41.273,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 23.450,41.522,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.767 | Acc: 19.531,39.062,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 24.814,43.899,98.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 24.790,43.407,98.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 24.475,43.366,98.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 24.267,43.027,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 24.366,42.597,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 24.193,42.485,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 24.030,42.415,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.766 | Acc: 24.000,42.425,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 23.895,42.308,98.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 23.729,42.184,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.734,42.219,98.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.820,42.337,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.872,42.292,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 23.810,42.324,98.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.837,42.325,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.849,42.409,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.795,42.398,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 23.797,42.449,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.776,42.401,98.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.969 | Acc: 24.219,42.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 22.805,41.778,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 23.133,41.216,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 23.220,41.483,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.768 | Acc: 29.688,41.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.773 | Acc: 23.475,42.150,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 23.552,41.101,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 23.335,41.009,98.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.773 | Acc: 23.293,40.847,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 23.252,41.112,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.502,41.303,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 23.510,41.329,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.438,41.411,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.769 | Acc: 23.649,41.631,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.769 | Acc: 23.768,41.807,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 23.745,41.763,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.769 | Acc: 23.749,41.857,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.755,41.855,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 23.724,41.754,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 23.879,41.819,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.910,41.934,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.955,41.949,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 23.968,42.049,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.895,42.134,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.930 | Acc: 24.219,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 23.028,42.113,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 23.495,41.540,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 23.438,41.547,71.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.790 | Acc: 25.000,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 21.503,40.662,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.773 | Acc: 23.304,41.139,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 23.463,41.662,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.766 | Acc: 23.727,41.956,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 24.025,42.257,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 24.180,42.510,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.768 | Acc: 24.158,42.387,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.769 | Acc: 24.141,42.294,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.770 | Acc: 24.020,42.213,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.943,42.114,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 23.908,42.223,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.820,42.285,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.824,42.298,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.760,42.338,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.752,42.385,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.705,42.404,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 23.696,42.444,98.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.732,42.445,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.751,42.466,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 23.438,42.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.805,41.890,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 23.304,41.330,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 23.284,41.560,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.793 | Acc: 22.656,33.594,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.779 | Acc: 23.512,40.774,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.772 | Acc: 23.838,41.463,98.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 23.783,41.995,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.766 | Acc: 24.450,42.477,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 24.165,42.350,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 23.909,42.291,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 23.914,42.154,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 23.860,42.231,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.705,42.175,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.577,42.199,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 23.505,42.120,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.486,42.184,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 23.518,42.164,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 23.518,42.126,98.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 23.604,42.195,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 23.686,42.265,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 23.710,42.263,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.684,42.291,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.690,42.259,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.947 | Acc: 24.219,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 22.917,41.667,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.285,41.101,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.335,41.445,71.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.753 | Acc: 28.125,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 23.363,41.964,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.772 | Acc: 24.238,42.054,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 24.629,41.957,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 24.730,42.245,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 24.675,42.481,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.771 | Acc: 24.406,42.368,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 24.352,42.575,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 24.277,42.464,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 24.283,42.477,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 24.172,42.409,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 23.936,42.368,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.966,42.473,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.925,42.421,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 23.899,42.304,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 23.842,42.193,98.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.849,42.270,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 23.783,42.194,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.702,42.138,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 23.729,42.044,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 25.000,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 22.954,42.225,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.939 | Acc: 23.247,41.578,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 23.361,41.701,71.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.779 | Acc: 25.781,39.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 23.847,41.890,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 24.238,41.940,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 24.347,42.456,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 24.016,42.313,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 24.087,42.706,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 23.864,42.678,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.748,42.559,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.766 | Acc: 23.709,42.450,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.727,42.477,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.830,42.693,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 23.911,42.820,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.833,42.742,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 23.851,42.750,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 23.802,42.724,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 23.874,42.735,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.766 | Acc: 23.800,42.628,98.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.766 | Acc: 23.848,42.687,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 23.851,42.780,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 23.782,42.719,98.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.966 | Acc: 25.000,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 22.917,42.039,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 23.228,41.521,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 23.450,41.342,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.787 | Acc: 20.312,36.719,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 23.661,41.257,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 23.609,42.054,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 23.758,42.764,98.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 23.756,42.853,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 23.739,42.768,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.657,42.685,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.715,42.531,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 23.661,42.352,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.770 | Acc: 23.507,42.209,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.770 | Acc: 23.515,42.277,98.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 23.593,42.385,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.768 | Acc: 23.635,42.414,98.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 23.734,42.478,98.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 23.802,42.585,98.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.868,42.657,98.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.805,42.579,98.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.802,42.504,98.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.743,42.484,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.768,42.544,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.927 | Acc: 24.219,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 22.768,42.001,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 23.190,41.463,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.956 | Acc: 23.386,41.509,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.775 | Acc: 20.312,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 24.330,42.374,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 24.009,42.797,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 23.796,42.789,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.768 | Acc: 23.534,42.544,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 23.716,42.876,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 23.625,42.723,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 23.737,42.769,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.770 | Acc: 23.753,42.615,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.770 | Acc: 23.636,42.585,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.770 | Acc: 23.562,42.634,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.769 | Acc: 23.544,42.679,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.515,42.486,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.769 | Acc: 23.548,42.499,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 23.588,42.591,98.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.645,42.642,98.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.705,42.745,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.692,42.747,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.671,42.698,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.645,42.651,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 23.438,43.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.731,41.592,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 23.114,41.273,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 23.181,41.240,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.803 | Acc: 19.531,36.719,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.777 | Acc: 22.582,40.327,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 22.980,42.092,98.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 23.578,42.200,98.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 23.823,42.332,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 24.041,42.358,98.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.765 | Acc: 24.077,42.562,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.764 | Acc: 24.113,42.503,98.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 23.976,42.416,98.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 23.968,42.395,98.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.958,42.506,98.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.996,42.548,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.885,42.557,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 23.910,42.639,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 24.010,42.668,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.967,42.696,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.849,42.645,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.854,42.621,98.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.818,42.540,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.759,42.419,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.944 | Acc: 25.000,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.010 | Acc: 22.842,41.704,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 23.190,41.254,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 23.361,41.278,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.745 | Acc: 25.000,43.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.774 | Acc: 24.293,42.485,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.772 | Acc: 23.780,42.054,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 23.758,42.252,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 23.968,42.757,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 23.979,42.427,98.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 23.915,42.497,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 23.820,42.343,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.769 | Acc: 23.636,42.493,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.769 | Acc: 23.580,42.610,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.769 | Acc: 23.585,42.701,98.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.664,42.746,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.794,42.907,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 23.803,42.990,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 23.843,42.960,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 23.837,42.961,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.730,42.923,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.726,42.827,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.745,42.780,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.725,42.723,98.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.966 | Acc: 23.438,40.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 22.545,41.778,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 23.075,41.425,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 23.233,41.547,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.774 | Acc: 29.688,42.969,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 23.214,42.894,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.770 | Acc: 23.247,42.302,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 23.284,42.239,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.768 | Acc: 23.322,42.216,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 23.461,42.311,98.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.767 | Acc: 23.605,42.562,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.293,42.332,98.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.766 | Acc: 23.379,42.401,98.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 23.390,42.399,98.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 23.399,42.436,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 23.420,42.492,98.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.765 | Acc: 23.587,42.612,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 23.512,42.475,98.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.765 | Acc: 23.549,42.535,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.765 | Acc: 23.523,42.496,98.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.765 | Acc: 23.576,42.538,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.765 | Acc: 23.635,42.522,98.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.561,42.415,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 23.593,42.444,98.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.939 | Acc: 24.219,42.188,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 22.433,41.369,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.944 | Acc: 22.999,40.987,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.066,41.060,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.762 | Acc: 24.219,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 24.219,42.597,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 23.819,42.397,98.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 23.719,42.495,98.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.768 | Acc: 23.843,42.477,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 23.917,42.420,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 23.864,42.562,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.768 | Acc: 23.770,42.210,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.884,42.469,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.767 | Acc: 23.869,42.546,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.811,42.460,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 23.840,42.417,98.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.765 | Acc: 23.843,42.518,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 23.803,42.496,98.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 23.813,42.471,98.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 23.845,42.473,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.766 | Acc: 23.861,42.465,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.765 | Acc: 23.893,42.543,98.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 23.818,42.568,98.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 23.766,42.446,98.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.971 | Acc: 24.219,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 22.656,41.704,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 22.999,41.216,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 23.092,41.189,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.748 | Acc: 21.875,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 22.731,42.225,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 23.075,42.454,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 23.053,42.431,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.766 | Acc: 23.341,42.670,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 23.492,42.481,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.771 | Acc: 23.502,42.497,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 23.593,42.465,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.452,42.377,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.772 | Acc: 23.524,42.455,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.772 | Acc: 23.577,42.378,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 23.593,42.438,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.707,42.518,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.779,42.436,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.760,42.421,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.824,42.406,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.769 | Acc: 23.839,42.399,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 23.802,42.430,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.770 | Acc: 23.762,42.387,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.821,42.403,98.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.978 | Acc: 25.000,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.992 | Acc: 23.177,41.741,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 23.190,41.387,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 23.297,41.176,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.787 | Acc: 24.219,37.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 24.665,42.597,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.768 | Acc: 24.276,42.454,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 23.847,42.713,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 23.804,42.679,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 23.987,42.853,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 23.954,42.672,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.825,42.609,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.764 | Acc: 23.903,42.784,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 23.744,42.654,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 23.772,42.739,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 23.710,42.605,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.784,42.622,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 23.818,42.690,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 23.757,42.657,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.692,42.590,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.661,42.458,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.765,42.405,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.775,42.471,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.768,42.477,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.950 | Acc: 24.219,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.997 | Acc: 22.917,41.890,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.952 | Acc: 23.514,41.444,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 23.463,41.611,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.728 | Acc: 28.125,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 23.847,42.374,98.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 23.380,41.940,98.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 23.924,42.072,98.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.762 | Acc: 24.122,42.380,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.759 | Acc: 24.358,42.621,98.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.761 | Acc: 24.057,42.562,98.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 24.152,42.764,98.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 24.194,42.906,98.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.763 | Acc: 24.094,42.887,98.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.764 | Acc: 23.989,42.732,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 23.918,42.636,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.950,42.577,98.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 23.892,42.505,98.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.765 | Acc: 23.899,42.518,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.887,42.504,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.924,42.574,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.937,42.591,98.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 23.927,42.581,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.889,42.544,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.964 | Acc: 24.219,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 22.954,41.853,70.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 23.285,41.273,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 23.309,41.278,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.828 | Acc: 22.656,47.656,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 24.777,40.923,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.779 | Acc: 23.819,41.254,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 24.052,42.123,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 23.920,42.159,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 23.724,42.296,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.774 | Acc: 23.547,42.291,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.772 | Acc: 23.764,42.260,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 23.860,42.124,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 23.766,42.282,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 23.710,42.296,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.770 | Acc: 23.763,42.241,98.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 23.707,42.317,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.794,42.292,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.843,42.332,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 23.977,42.429,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 23.963,42.438,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 23.882,42.398,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 23.810,42.365,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 23.860,42.366,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.932 | Acc: 25.000,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.985 | Acc: 23.140,42.188,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.937 | Acc: 23.285,41.616,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 23.322,41.611,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.749 | Acc: 33.594,48.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.757 | Acc: 25.037,43.118,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 24.962,42.931,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.764 | Acc: 24.539,42.738,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.766 | Acc: 24.074,42.641,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 24.010,42.404,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.767 | Acc: 23.857,42.233,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 23.814,42.415,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.724,42.348,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 23.614,42.364,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.769 | Acc: 23.535,42.304,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 23.614,42.378,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.677,42.411,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 23.752,42.439,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 23.760,42.374,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.733,42.291,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.713,42.336,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.766 | Acc: 23.717,42.357,98.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 23.654,42.313,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 23.714,42.376,98.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.959 | Acc: 25.781,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 23.065,41.853,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.937 | Acc: 23.438,41.330,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 23.386,41.163,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.765 | Acc: 18.750,40.625,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 24.665,42.150,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.765 | Acc: 24.409,42.226,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 24.206,41.919,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.764 | Acc: 24.151,42.313,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 23.577,41.971,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 23.767,41.974,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.766 | Acc: 23.787,42.082,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 23.777,42.042,98.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 23.822,42.300,98.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.756,42.238,98.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 23.731,42.304,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.804,42.285,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 23.722,42.403,98.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.765 | Acc: 23.749,42.352,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.765 | Acc: 23.775,42.390,98.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.765 | Acc: 23.771,42.353,98.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.765 | Acc: 23.799,42.302,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.765 | Acc: 23.851,42.352,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.765 | Acc: 23.932,42.393,98.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.930 | Acc: 24.219,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.996 | Acc: 22.991,42.857,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 23.342,41.730,71.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 23.450,41.726,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.740 | Acc: 20.312,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 24.033,42.820,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 23.876,43.007,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.763 | Acc: 23.694,43.481,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 23.910,43.027,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.770 | Acc: 23.739,42.884,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 23.663,42.872,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.769 | Acc: 23.798,42.869,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.768 | Acc: 23.782,42.731,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 23.632,42.723,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 23.807,42.907,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 23.759,42.697,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.769 | Acc: 23.878,42.777,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 23.869,42.666,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 23.802,42.593,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 23.731,42.579,98.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 23.744,42.548,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.769 | Acc: 23.836,42.703,98.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 23.784,42.664,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 23.805,42.618,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.947 | Acc: 23.438,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 22.879,42.225,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 23.342,41.540,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 23.322,41.547,71.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.816 | Acc: 14.844,38.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.760 | Acc: 23.028,42.485,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 23.228,42.473,98.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.764 | Acc: 23.348,42.239,98.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.766 | Acc: 23.293,42.178,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 23.739,42.458,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.763 | Acc: 23.896,42.788,98.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.763 | Acc: 23.742,42.686,98.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 23.685,42.406,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 23.649,42.576,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 23.698,42.677,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 23.678,42.619,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.764 | Acc: 23.827,42.732,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 23.842,42.666,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 23.760,42.588,98.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 23.778,42.556,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.795,42.518,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.765,42.524,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.658,42.374,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 23.727,42.444,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.949 | Acc: 24.219,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.989 | Acc: 22.805,42.076,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 23.304,41.616,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 23.245,41.573,71.811,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.744 | Acc: 22.656,42.969,100.000,% | Adaptive Acc: 97.656% | clf_exit: 0.000 0.109 0.891
Batch: 20 | Loss: 0.775 | Acc: 23.661,41.295,98.289,% | Adaptive Acc: 97.247% | clf_exit: 0.002 0.082 0.916
Batch: 40 | Loss: 0.774 | Acc: 24.104,42.397,98.399,% | Adaptive Acc: 97.466% | clf_exit: 0.002 0.080 0.918
Batch: 60 | Loss: 0.770 | Acc: 23.796,42.200,98.412,% | Adaptive Acc: 97.554% | clf_exit: 0.002 0.079 0.919
Batch: 80 | Loss: 0.771 | Acc: 23.592,42.062,98.312,% | Adaptive Acc: 97.463% | clf_exit: 0.002 0.079 0.918
Batch: 100 | Loss: 0.770 | Acc: 23.600,42.071,98.399,% | Adaptive Acc: 97.571% | clf_exit: 0.002 0.079 0.919
Batch: 120 | Loss: 0.769 | Acc: 23.534,42.007,98.373,% | Adaptive Acc: 97.585% | clf_exit: 0.002 0.079 0.919
Batch: 140 | Loss: 0.769 | Acc: 23.598,42.237,98.410,% | Adaptive Acc: 97.612% | clf_exit: 0.002 0.080 0.918
Batch: 160 | Loss: 0.769 | Acc: 23.690,42.314,98.438,% | Adaptive Acc: 97.656% | clf_exit: 0.002 0.080 0.918
Batch: 180 | Loss: 0.769 | Acc: 23.748,42.196,98.420,% | Adaptive Acc: 97.648% | clf_exit: 0.002 0.080 0.918
Batch: 200 | Loss: 0.768 | Acc: 23.888,42.320,98.476,% | Adaptive Acc: 97.722% | clf_exit: 0.002 0.080 0.918
Batch: 220 | Loss: 0.769 | Acc: 23.756,42.304,98.455,% | Adaptive Acc: 97.713% | clf_exit: 0.002 0.079 0.919
Batch: 240 | Loss: 0.770 | Acc: 23.820,42.463,98.399,% | Adaptive Acc: 97.650% | clf_exit: 0.002 0.080 0.918
Batch: 260 | Loss: 0.769 | Acc: 23.827,42.340,98.393,% | Adaptive Acc: 97.629% | clf_exit: 0.002 0.080 0.918
Batch: 280 | Loss: 0.769 | Acc: 23.830,42.349,98.426,% | Adaptive Acc: 97.670% | clf_exit: 0.002 0.079 0.919
Batch: 300 | Loss: 0.768 | Acc: 23.871,42.361,98.440,% | Adaptive Acc: 97.685% | clf_exit: 0.002 0.079 0.918
Batch: 320 | Loss: 0.768 | Acc: 23.900,42.431,98.450,% | Adaptive Acc: 97.676% | clf_exit: 0.002 0.079 0.918
Batch: 340 | Loss: 0.768 | Acc: 23.889,42.430,98.442,% | Adaptive Acc: 97.684% | clf_exit: 0.002 0.079 0.918
Batch: 360 | Loss: 0.768 | Acc: 23.888,42.395,98.442,% | Adaptive Acc: 97.687% | clf_exit: 0.002 0.079 0.918
Batch: 380 | Loss: 0.768 | Acc: 23.938,42.393,98.446,% | Adaptive Acc: 97.675% | clf_exit: 0.002 0.080 0.918
Batch: 0 | Loss: 1.958 | Acc: 24.219,42.188,69.531,% | Adaptive Acc: 69.531% | clf_exit: 0.008 0.148 0.844
Batch: 20 | Loss: 1.990 | Acc: 22.507,42.671,70.908,% | Adaptive Acc: 69.903% | clf_exit: 0.012 0.152 0.836
Batch: 40 | Loss: 1.948 | Acc: 22.904,41.692,71.284,% | Adaptive Acc: 70.103% | clf_exit: 0.011 0.155 0.835
Batch: 60 | Loss: 1.962 | Acc: 23.002,41.509,71.516,% | Adaptive Acc: 70.300% | clf_exit: 0.011 0.151 0.837
model is save as models/resnet56_cifar100_adaptive0_circles3_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 6.058 | Acc: 0.781,3.125,21.875,% | Adaptive Acc: 0.781% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 6.252 | Acc: 1.004,2.009,16.890,% | Adaptive Acc: 1.004% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 6.243 | Acc: 1.067,1.848,16.921,% | Adaptive Acc: 1.067% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 6.231 | Acc: 1.037,1.844,17.533,% | Adaptive Acc: 1.037% | clf_exit: 1.000 0.000 0.000
Batch: 0 | Loss: 5.040 | Acc: 0.781,3.906,34.375,% | Adaptive Acc: 0.781% | clf_exit: 1.000 0.000 0.000
Batch: 20 | Loss: 5.338 | Acc: 1.004,2.604,23.921,% | Adaptive Acc: 1.004% | clf_exit: 1.000 0.000 0.000
Batch: 40 | Loss: 5.350 | Acc: 1.067,2.572,23.457,% | Adaptive Acc: 1.105% | clf_exit: 1.000 0.000 0.000
Batch: 60 | Loss: 5.344 | Acc: 1.037,2.510,23.617,% | Adaptive Acc: 1.063% | clf_exit: 0.999 0.000 0.000
Batch: 0 | Loss: 3.143 | Acc: 1.562,6.250,57.812,% | Adaptive Acc: 42.969% | clf_exit: 0.242 0.078 0.680
Batch: 20 | Loss: 3.376 | Acc: 2.009,4.427,51.786,% | Adaptive Acc: 38.914% | clf_exit: 0.194 0.088 0.718
Batch: 40 | Loss: 3.363 | Acc: 1.886,4.325,51.658,% | Adaptive Acc: 39.653% | clf_exit: 0.192 0.079 0.729
Batch: 60 | Loss: 3.363 | Acc: 1.870,4.201,51.870,% | Adaptive Acc: 39.511% | clf_exit: 0.194 0.079 0.727
Batch: 0 | Loss: 1.958 | Acc: 24.219,42.188,69.531,% | Adaptive Acc: 69.531% | clf_exit: 0.008 0.148 0.844
Batch: 20 | Loss: 1.990 | Acc: 22.507,42.671,70.908,% | Adaptive Acc: 69.903% | clf_exit: 0.012 0.152 0.836
Batch: 40 | Loss: 1.948 | Acc: 22.904,41.692,71.284,% | Adaptive Acc: 70.103% | clf_exit: 0.011 0.155 0.835
Batch: 60 | Loss: 1.962 | Acc: 23.002,41.509,71.516,% | Adaptive Acc: 70.300% | clf_exit: 0.011 0.151 0.837







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 5.153 |  Acc: 1.960,2.306,6.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 4.829 |  Acc: 3.110,4.210,10.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 4.658 |  Acc: 3.280,5.548,13.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 4.525 |  Acc: 3.020,5.830,15.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 4.403 |  Acc: 3.656,7.732,16.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 4.368 |  Acc: 3.640,7.670,16.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 4.211 |  Acc: 4.270,9.166,20.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 4.167 |  Acc: 3.840,9.320,20.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 4.052 |  Acc: 4.610,10.278,22.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 3.974 |  Acc: 4.960,10.950,23.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 3.890 |  Acc: 5.022,11.288,25.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 3.857 |  Acc: 4.540,9.820,25.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 3.733 |  Acc: 5.292,11.966,28.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 3.730 |  Acc: 5.420,11.180,28.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 3.588 |  Acc: 5.806,12.880,30.794,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 3.584 |  Acc: 5.140,11.260,30.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 3.450 |  Acc: 6.486,13.622,33.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 3.557 |  Acc: 5.680,12.360,31.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 3.320 |  Acc: 7.004,14.446,36.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 3.764 |  Acc: 5.060,13.120,28.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 3.202 |  Acc: 7.526,15.672,38.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 3.605 |  Acc: 6.550,14.850,31.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 3.100 |  Acc: 7.942,16.512,40.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 3.367 |  Acc: 7.040,14.830,35.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 3.003 |  Acc: 8.322,17.014,42.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 3.294 |  Acc: 7.090,14.630,37.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 2.922 |  Acc: 8.666,17.796,44.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 3.141 |  Acc: 7.510,16.410,40.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 2.832 |  Acc: 8.814,18.070,45.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 3.162 |  Acc: 8.710,17.310,40.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 2.758 |  Acc: 9.240,18.800,47.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 2.944 |  Acc: 7.580,16.900,45.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 2.704 |  Acc: 9.830,19.330,48.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 2.879 |  Acc: 9.180,17.600,45.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 2.641 |  Acc: 10.016,19.754,50.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 2.896 |  Acc: 6.860,14.370,46.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 2.584 |  Acc: 10.110,19.876,51.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 2.907 |  Acc: 8.410,16.880,45.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 2.546 |  Acc: 10.410,20.378,52.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 2.843 |  Acc: 8.230,17.600,46.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 2.484 |  Acc: 10.792,21.102,53.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 2.797 |  Acc: 9.760,18.450,47.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 2.444 |  Acc: 10.956,21.606,54.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 2.943 |  Acc: 8.000,16.990,45.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 2.402 |  Acc: 11.224,21.666,55.608,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 2.653 |  Acc: 9.290,18.020,51.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 2.348 |  Acc: 11.448,22.108,57.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 2.698 |  Acc: 9.830,19.490,50.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 2.317 |  Acc: 11.836,22.368,57.656,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 2.678 |  Acc: 10.210,18.510,50.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 2.290 |  Acc: 11.982,22.648,58.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 2.602 |  Acc: 9.600,20.510,51.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 2.256 |  Acc: 11.832,22.874,59.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 2.592 |  Acc: 11.180,19.750,52.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 2.227 |  Acc: 12.472,23.368,59.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 2.530 |  Acc: 9.350,19.780,53.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.199 |  Acc: 12.702,23.546,60.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 2.562 |  Acc: 11.650,21.200,53.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.169 |  Acc: 12.918,23.854,61.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 2.590 |  Acc: 11.000,20.440,52.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.140 |  Acc: 12.736,23.848,62.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 2.826 |  Acc: 11.130,19.040,48.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.122 |  Acc: 13.042,24.164,62.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 2.596 |  Acc: 9.250,16.980,53.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.099 |  Acc: 13.152,24.540,62.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 2.617 |  Acc: 11.860,19.960,52.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.076 |  Acc: 13.432,24.544,63.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 2.649 |  Acc: 11.840,21.680,52.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.049 |  Acc: 13.722,24.930,64.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 2.517 |  Acc: 11.300,21.840,54.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.048 |  Acc: 13.634,24.960,64.074,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 2.519 |  Acc: 10.440,22.040,54.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.016 |  Acc: 13.898,25.126,64.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 2.619 |  Acc: 11.240,22.400,53.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.009 |  Acc: 14.058,25.236,65.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 2.679 |  Acc: 11.870,20.180,52.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 1.987 |  Acc: 14.204,25.502,65.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 2.434 |  Acc: 11.690,22.400,55.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 1.974 |  Acc: 14.344,25.756,65.880,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 2.614 |  Acc: 11.470,20.290,52.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 1.960 |  Acc: 14.480,25.732,66.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 2.471 |  Acc: 12.030,21.290,55.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 1.943 |  Acc: 14.620,26.172,66.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 2.643 |  Acc: 12.410,21.050,52.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 1.936 |  Acc: 14.652,26.166,66.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 2.575 |  Acc: 12.150,23.230,53.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 1.920 |  Acc: 15.058,26.504,67.286,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 2.614 |  Acc: 11.730,20.700,53.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 1.900 |  Acc: 15.030,26.772,67.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 2.694 |  Acc: 10.430,18.980,52.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 1.896 |  Acc: 15.148,26.620,67.494,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 2.455 |  Acc: 12.260,21.690,56.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 1.889 |  Acc: 15.088,26.606,67.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 2.634 |  Acc: 12.080,20.040,53.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 1.871 |  Acc: 15.376,26.700,68.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 2.520 |  Acc: 14.250,23.400,54.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 1.865 |  Acc: 15.372,27.044,68.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 2.425 |  Acc: 12.080,23.140,57.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 1.849 |  Acc: 15.664,27.074,68.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 2.497 |  Acc: 13.320,22.300,54.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 1.850 |  Acc: 15.624,27.394,69.006,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 2.556 |  Acc: 12.770,19.600,54.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 1.833 |  Acc: 15.676,27.204,69.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 2.695 |  Acc: 13.500,22.440,52.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 1.828 |  Acc: 16.024,27.230,69.382,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 2.391 |  Acc: 14.110,23.730,57.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 1.808 |  Acc: 16.196,27.376,69.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 2.389 |  Acc: 13.770,22.430,57.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 1.810 |  Acc: 16.132,27.606,69.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 2.509 |  Acc: 14.870,24.700,54.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 1.801 |  Acc: 16.236,27.746,70.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 2.439 |  Acc: 14.370,23.990,57.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 1.787 |  Acc: 16.290,27.856,70.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 2.310 |  Acc: 11.690,23.510,59.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 1.782 |  Acc: 16.322,28.250,70.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 2.322 |  Acc: 14.760,25.530,59.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 1.762 |  Acc: 16.718,28.532,71.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 2.648 |  Acc: 13.410,23.410,53.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 1.775 |  Acc: 16.840,28.372,70.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 2.381 |  Acc: 12.920,23.480,58.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 1.765 |  Acc: 16.670,28.138,70.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 2.312 |  Acc: 12.870,24.300,59.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 1.752 |  Acc: 16.886,28.610,71.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 2.479 |  Acc: 14.450,24.720,55.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 1.745 |  Acc: 16.978,28.812,71.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 2.408 |  Acc: 12.140,23.150,57.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 1.734 |  Acc: 17.052,28.902,71.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 2.240 |  Acc: 14.450,25.580,60.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 1.730 |  Acc: 17.434,28.932,71.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 2.478 |  Acc: 12.970,24.280,56.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 1.725 |  Acc: 17.358,29.012,72.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 2.324 |  Acc: 15.810,25.370,59.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 1.714 |  Acc: 17.496,29.054,72.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 2.409 |  Acc: 14.780,24.170,57.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 1.712 |  Acc: 17.584,29.150,71.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 2.369 |  Acc: 14.320,25.930,59.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 1.719 |  Acc: 17.578,29.418,72.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 2.365 |  Acc: 16.670,26.530,58.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 1.696 |  Acc: 17.642,29.312,72.620,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 2.349 |  Acc: 14.360,24.570,58.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 1.695 |  Acc: 17.610,29.826,72.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 2.627 |  Acc: 14.310,22.950,53.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 1.688 |  Acc: 17.774,29.698,72.828,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 2.351 |  Acc: 14.130,25.070,58.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 1.680 |  Acc: 17.768,29.532,73.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 2.244 |  Acc: 16.460,26.370,61.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 1.676 |  Acc: 17.968,29.994,72.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 2.450 |  Acc: 13.480,24.310,56.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 1.674 |  Acc: 17.870,29.984,73.004,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 2.312 |  Acc: 13.650,23.840,59.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 1.667 |  Acc: 17.904,30.342,73.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 2.413 |  Acc: 15.260,25.750,57.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 1.660 |  Acc: 18.290,30.062,73.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 2.398 |  Acc: 14.280,24.370,58.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 1.651 |  Acc: 18.214,30.446,73.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 2.365 |  Acc: 14.680,25.580,58.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 1.651 |  Acc: 18.488,30.478,73.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 2.470 |  Acc: 11.690,21.230,58.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 1.641 |  Acc: 18.328,30.526,73.944,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 2.373 |  Acc: 12.970,23.800,58.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 1.643 |  Acc: 18.582,30.836,73.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 2.333 |  Acc: 16.130,25.940,59.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 1.638 |  Acc: 18.488,30.984,73.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 2.407 |  Acc: 15.800,28.380,57.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 1.634 |  Acc: 18.420,30.882,73.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 2.608 |  Acc: 12.700,22.060,54.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 1.628 |  Acc: 18.664,31.100,74.054,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 2.254 |  Acc: 16.130,27.540,60.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 1.622 |  Acc: 18.610,31.206,74.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 2.241 |  Acc: 16.530,25.800,61.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 1.618 |  Acc: 18.964,31.220,74.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 2.357 |  Acc: 14.600,24.540,59.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 1.620 |  Acc: 18.620,31.290,74.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 2.334 |  Acc: 15.130,25.450,59.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 1.621 |  Acc: 19.052,31.504,74.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 2.508 |  Acc: 15.370,25.220,57.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 1.606 |  Acc: 18.746,31.402,74.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 2.546 |  Acc: 14.280,21.460,55.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 1.608 |  Acc: 18.918,31.502,74.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 2.281 |  Acc: 15.500,27.620,60.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 1.610 |  Acc: 18.906,31.618,74.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 2.313 |  Acc: 16.090,29.230,60.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 1.605 |  Acc: 19.042,31.788,74.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 2.482 |  Acc: 11.790,21.120,57.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 1.595 |  Acc: 18.826,31.988,74.744,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 2.345 |  Acc: 14.550,24.380,59.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 1.595 |  Acc: 19.040,31.752,74.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 2.250 |  Acc: 15.790,28.420,61.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 1.592 |  Acc: 19.124,31.672,74.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 2.468 |  Acc: 14.430,24.770,57.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 1.591 |  Acc: 19.344,32.024,74.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 2.301 |  Acc: 15.080,28.660,60.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 1.577 |  Acc: 19.488,31.922,75.172,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 2.385 |  Acc: 16.770,27.320,58.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 1.580 |  Acc: 19.424,32.420,75.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 2.252 |  Acc: 16.170,28.470,61.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 1.572 |  Acc: 19.476,32.366,75.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 2.479 |  Acc: 12.430,25.790,56.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 1.576 |  Acc: 19.480,32.164,75.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 2.379 |  Acc: 14.150,22.700,58.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 1.562 |  Acc: 19.320,32.546,75.766,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 2.553 |  Acc: 14.950,24.630,56.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 1.563 |  Acc: 19.482,32.396,75.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 2.349 |  Acc: 17.240,25.000,59.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 1.572 |  Acc: 19.682,32.680,75.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 2.408 |  Acc: 16.500,28.660,58.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 1.570 |  Acc: 19.516,32.400,75.252,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 2.328 |  Acc: 13.230,25.330,60.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 1.567 |  Acc: 19.576,32.440,75.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 2.181 |  Acc: 16.520,27.110,62.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 1.559 |  Acc: 19.912,32.648,75.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 2.446 |  Acc: 16.100,23.640,58.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 1.546 |  Acc: 19.654,33.044,75.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 2.382 |  Acc: 18.050,26.200,58.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 1.542 |  Acc: 19.720,32.942,76.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 2.378 |  Acc: 18.110,30.210,59.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 1.548 |  Acc: 19.776,32.742,75.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 2.261 |  Acc: 13.620,25.850,61.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 1.550 |  Acc: 19.778,33.308,75.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 2.221 |  Acc: 15.790,29.060,62.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 1.538 |  Acc: 19.804,33.076,76.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 2.274 |  Acc: 15.570,27.460,60.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.538 |  Acc: 19.870,33.374,76.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 2.245 |  Acc: 18.990,30.840,60.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 1.541 |  Acc: 19.786,33.312,76.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 2.410 |  Acc: 16.750,27.330,58.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 1.532 |  Acc: 19.918,33.492,76.208,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 2.277 |  Acc: 17.210,29.590,61.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 1.532 |  Acc: 20.012,33.342,76.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 2.360 |  Acc: 17.180,28.590,59.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 1.531 |  Acc: 19.912,33.332,76.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 2.297 |  Acc: 16.920,27.920,60.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.523 |  Acc: 19.770,33.652,76.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 2.245 |  Acc: 18.490,29.920,61.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.524 |  Acc: 20.118,33.572,76.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 2.311 |  Acc: 15.600,28.290,60.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.522 |  Acc: 20.166,33.642,76.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 2.529 |  Acc: 14.530,23.080,56.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.524 |  Acc: 20.076,33.614,76.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 2.221 |  Acc: 15.030,27.710,62.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.521 |  Acc: 20.114,33.718,76.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 2.301 |  Acc: 15.850,26.330,60.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.515 |  Acc: 20.354,33.626,76.536,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 2.218 |  Acc: 18.460,27.800,61.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.516 |  Acc: 20.494,33.724,76.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 2.390 |  Acc: 13.030,25.800,57.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.515 |  Acc: 20.444,34.026,76.550,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 2.340 |  Acc: 17.150,26.760,59.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.519 |  Acc: 20.390,33.994,76.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 2.623 |  Acc: 13.240,23.070,55.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.514 |  Acc: 20.134,33.902,76.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 2.228 |  Acc: 16.830,28.890,61.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.510 |  Acc: 20.288,34.160,76.712,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 2.335 |  Acc: 15.970,26.360,60.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.504 |  Acc: 20.360,34.132,76.914,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 2.267 |  Acc: 15.850,28.280,60.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.515 |  Acc: 20.182,33.844,76.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 2.296 |  Acc: 14.710,26.600,61.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.498 |  Acc: 20.414,34.118,76.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 2.227 |  Acc: 18.420,29.840,62.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.497 |  Acc: 20.418,34.206,77.148,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 2.264 |  Acc: 16.130,28.910,61.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.498 |  Acc: 20.194,34.376,76.982,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 2.181 |  Acc: 16.550,30.670,62.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.505 |  Acc: 20.176,34.258,76.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 2.285 |  Acc: 18.150,29.970,60.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.490 |  Acc: 20.342,34.372,77.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 2.261 |  Acc: 16.240,28.460,61.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.497 |  Acc: 20.186,34.210,76.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 2.465 |  Acc: 16.130,25.400,57.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.492 |  Acc: 20.498,34.626,77.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 2.290 |  Acc: 15.290,28.040,59.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.505 |  Acc: 20.220,34.404,76.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 2.330 |  Acc: 16.260,28.400,60.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.487 |  Acc: 20.574,34.558,77.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 2.237 |  Acc: 17.090,31.040,61.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.485 |  Acc: 20.450,34.616,77.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 2.488 |  Acc: 14.700,23.850,57.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.487 |  Acc: 20.624,34.514,77.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 2.289 |  Acc: 17.180,28.750,60.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.493 |  Acc: 20.334,34.758,76.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 2.451 |  Acc: 17.410,25.900,57.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.482 |  Acc: 20.600,34.836,77.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 2.316 |  Acc: 16.550,27.960,60.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.479 |  Acc: 20.498,34.942,77.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 2.351 |  Acc: 18.370,31.440,59.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.483 |  Acc: 20.672,34.722,77.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 2.269 |  Acc: 17.030,30.230,60.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.478 |  Acc: 20.606,34.862,77.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 2.273 |  Acc: 17.440,28.750,60.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.474 |  Acc: 20.464,35.240,77.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 2.306 |  Acc: 15.330,29.340,60.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.481 |  Acc: 20.382,34.762,77.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 2.394 |  Acc: 17.180,30.890,58.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.488 |  Acc: 20.584,34.966,77.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 2.299 |  Acc: 17.040,29.120,60.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.475 |  Acc: 20.636,35.016,77.306,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 2.235 |  Acc: 17.680,30.480,61.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.476 |  Acc: 20.658,34.976,77.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 2.334 |  Acc: 14.220,26.480,59.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.209 |  Acc: 21.500,37.044,85.254,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 1.775 |  Acc: 20.880,36.700,72.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.115 |  Acc: 21.858,37.820,88.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 1.765 |  Acc: 21.200,37.110,72.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.085 |  Acc: 21.718,37.988,89.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 1.775 |  Acc: 21.280,37.470,72.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.056 |  Acc: 22.024,38.276,90.088,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 1.776 |  Acc: 21.510,37.440,72.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.043 |  Acc: 21.978,38.648,90.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 1.791 |  Acc: 21.470,37.400,71.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.028 |  Acc: 21.988,38.658,90.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 1.788 |  Acc: 21.370,37.580,72.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.017 |  Acc: 21.922,38.630,91.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 1.802 |  Acc: 21.470,37.600,72.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 0.998 |  Acc: 22.124,38.934,91.970,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 1.793 |  Acc: 21.550,37.970,72.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 0.995 |  Acc: 22.146,38.956,92.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 1.800 |  Acc: 21.680,37.920,72.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 0.990 |  Acc: 22.092,38.848,92.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 1.804 |  Acc: 21.470,37.830,72.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 0.979 |  Acc: 22.222,39.030,92.610,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 1.802 |  Acc: 21.530,38.410,72.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 0.977 |  Acc: 22.270,39.234,92.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 1.818 |  Acc: 21.810,38.200,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 0.968 |  Acc: 22.278,39.260,92.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 1.818 |  Acc: 21.670,38.360,72.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 0.957 |  Acc: 22.274,39.300,93.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 1.829 |  Acc: 21.860,38.710,72.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 0.958 |  Acc: 22.388,39.516,93.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 1.832 |  Acc: 21.870,38.510,72.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 0.950 |  Acc: 22.422,39.242,93.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 1.828 |  Acc: 22.050,38.740,72.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 0.945 |  Acc: 22.364,39.498,93.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 1.839 |  Acc: 21.940,38.650,71.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 0.940 |  Acc: 22.338,39.620,93.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 1.831 |  Acc: 21.830,38.640,72.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 0.932 |  Acc: 22.560,39.520,93.962,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 1.840 |  Acc: 21.830,38.760,71.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 0.926 |  Acc: 22.522,39.876,94.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 1.848 |  Acc: 21.580,38.690,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 0.926 |  Acc: 22.426,39.584,94.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 1.850 |  Acc: 21.890,38.520,72.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 0.920 |  Acc: 22.590,39.758,94.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 1.857 |  Acc: 22.270,38.880,71.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 0.915 |  Acc: 22.652,39.876,94.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 1.879 |  Acc: 21.620,38.930,71.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 0.915 |  Acc: 22.718,39.972,94.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 1.872 |  Acc: 22.090,39.180,71.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 0.907 |  Acc: 22.662,40.034,94.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 1.858 |  Acc: 22.210,39.370,72.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 0.909 |  Acc: 22.410,39.956,94.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 1.885 |  Acc: 22.000,39.300,71.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 0.901 |  Acc: 22.576,40.076,94.842,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 1.863 |  Acc: 21.920,38.820,72.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 0.899 |  Acc: 22.490,40.100,94.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 1.885 |  Acc: 22.180,39.340,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 0.892 |  Acc: 22.568,40.318,95.102,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 1.887 |  Acc: 21.990,39.260,72.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 0.894 |  Acc: 22.466,40.008,95.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 1.888 |  Acc: 22.420,39.180,71.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 0.893 |  Acc: 22.710,40.332,95.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 1.880 |  Acc: 21.860,39.030,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 0.889 |  Acc: 22.886,40.128,95.184,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 1.887 |  Acc: 22.240,39.350,71.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 0.884 |  Acc: 22.732,40.266,95.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 1.895 |  Acc: 22.140,39.130,71.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 0.883 |  Acc: 22.804,40.468,95.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 1.899 |  Acc: 22.170,39.460,71.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 0.883 |  Acc: 22.984,40.572,95.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 1.897 |  Acc: 21.840,39.570,71.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 0.879 |  Acc: 22.902,40.412,95.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 1.913 |  Acc: 22.340,39.240,71.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 0.876 |  Acc: 22.734,40.454,95.584,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 1.916 |  Acc: 21.960,39.580,71.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 0.874 |  Acc: 22.898,40.350,95.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 1.915 |  Acc: 21.860,39.460,71.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 0.874 |  Acc: 22.952,40.518,95.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 1.922 |  Acc: 22.270,39.620,71.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.871 |  Acc: 22.950,40.460,95.648,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 1.926 |  Acc: 22.110,39.520,71.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.872 |  Acc: 22.876,40.770,95.518,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 1.927 |  Acc: 22.340,39.720,71.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.867 |  Acc: 23.024,40.592,95.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 1.923 |  Acc: 22.040,39.520,71.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.871 |  Acc: 22.994,40.570,95.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 1.927 |  Acc: 22.950,39.630,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.862 |  Acc: 22.902,40.600,95.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 1.931 |  Acc: 22.460,39.480,71.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.862 |  Acc: 23.076,40.758,95.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 1.914 |  Acc: 22.490,39.930,71.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.858 |  Acc: 23.156,40.774,96.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 1.935 |  Acc: 22.470,40.450,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.856 |  Acc: 22.932,40.956,96.012,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 1.948 |  Acc: 22.600,39.810,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.856 |  Acc: 23.000,40.856,96.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 1.946 |  Acc: 22.270,39.660,70.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.855 |  Acc: 23.184,40.810,96.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 1.946 |  Acc: 22.690,40.020,71.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.855 |  Acc: 22.954,40.958,96.040,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 1.962 |  Acc: 22.230,39.630,70.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.851 |  Acc: 22.998,41.074,96.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 1.965 |  Acc: 22.360,39.770,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.851 |  Acc: 23.138,41.020,96.080,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 1.933 |  Acc: 22.120,40.000,71.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.851 |  Acc: 23.120,41.178,96.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 1.954 |  Acc: 22.950,39.970,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.847 |  Acc: 23.064,41.352,96.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 1.956 |  Acc: 22.430,40.120,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.849 |  Acc: 23.226,41.082,96.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 1.949 |  Acc: 22.480,40.280,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.850 |  Acc: 23.182,41.202,96.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 1.953 |  Acc: 22.320,40.250,70.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.849 |  Acc: 23.312,41.260,96.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 1.930 |  Acc: 22.680,40.010,71.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.843 |  Acc: 23.266,41.168,96.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 1.956 |  Acc: 22.780,40.170,71.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.844 |  Acc: 23.416,41.120,96.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 1.953 |  Acc: 22.760,40.680,71.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.841 |  Acc: 23.242,41.400,96.372,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 1.975 |  Acc: 22.150,39.840,71.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.841 |  Acc: 23.034,41.316,96.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 1.972 |  Acc: 22.610,40.400,71.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.841 |  Acc: 23.244,41.358,96.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 1.963 |  Acc: 22.860,40.420,70.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.841 |  Acc: 23.066,41.440,96.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 1.983 |  Acc: 22.620,40.430,71.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.839 |  Acc: 23.382,41.448,96.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 1.992 |  Acc: 22.630,40.540,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.840 |  Acc: 23.254,41.276,96.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 1.960 |  Acc: 22.840,40.760,71.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.834 |  Acc: 23.492,41.382,96.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 1.984 |  Acc: 22.860,40.480,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.836 |  Acc: 23.348,41.408,96.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 1.989 |  Acc: 23.250,40.880,71.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.838 |  Acc: 23.340,41.264,96.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 1.978 |  Acc: 22.080,40.150,71.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.833 |  Acc: 23.254,41.492,96.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 2.030 |  Acc: 22.550,39.920,69.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.838 |  Acc: 23.344,41.352,96.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 1.998 |  Acc: 23.050,40.210,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.835 |  Acc: 23.440,41.766,96.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 1.992 |  Acc: 22.830,40.940,70.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.835 |  Acc: 23.372,41.518,96.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 1.998 |  Acc: 22.210,40.620,70.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.832 |  Acc: 23.446,41.612,96.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 1.995 |  Acc: 22.740,40.600,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.833 |  Acc: 23.296,41.318,96.522,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 1.999 |  Acc: 22.580,40.850,70.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.833 |  Acc: 23.502,41.560,96.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 2.028 |  Acc: 23.040,41.070,70.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.810 |  Acc: 23.402,41.702,97.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 1.966 |  Acc: 22.860,41.030,71.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.795 |  Acc: 23.576,41.818,97.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 1.963 |  Acc: 22.950,41.160,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.794 |  Acc: 23.530,41.754,97.688,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 1.953 |  Acc: 22.960,40.920,71.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.789 |  Acc: 23.420,42.020,97.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 1.946 |  Acc: 23.040,41.000,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.788 |  Acc: 23.456,42.056,97.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 1.957 |  Acc: 22.910,41.210,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.788 |  Acc: 23.742,42.098,97.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 1.960 |  Acc: 22.960,41.170,71.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.783 |  Acc: 23.774,42.174,98.000,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 1.958 |  Acc: 22.990,41.360,71.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.782 |  Acc: 23.562,42.098,98.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 1.959 |  Acc: 23.020,40.960,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.780 |  Acc: 23.560,42.254,98.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 1.951 |  Acc: 22.950,41.110,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.784 |  Acc: 23.624,42.048,97.988,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 1.969 |  Acc: 23.050,41.400,71.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.780 |  Acc: 23.806,42.080,98.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 1.966 |  Acc: 22.970,41.210,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.783 |  Acc: 23.530,42.062,98.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 1.965 |  Acc: 23.000,41.230,71.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.780 |  Acc: 23.772,42.298,98.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 1.961 |  Acc: 23.240,41.310,71.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.781 |  Acc: 23.514,42.252,98.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 1.960 |  Acc: 23.070,41.040,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.780 |  Acc: 23.648,42.310,98.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 1.968 |  Acc: 23.340,41.390,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.776 |  Acc: 23.802,42.368,98.210,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 1.971 |  Acc: 23.230,41.210,71.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.778 |  Acc: 23.624,42.186,98.220,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 1.973 |  Acc: 22.930,41.290,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.775 |  Acc: 23.658,42.326,98.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 1.963 |  Acc: 23.100,41.210,71.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.778 |  Acc: 23.888,42.188,98.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 1.966 |  Acc: 23.130,41.530,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.777 |  Acc: 23.642,42.220,98.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 1.969 |  Acc: 23.330,41.330,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.776 |  Acc: 23.792,42.216,98.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 1.967 |  Acc: 22.990,41.250,71.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.775 |  Acc: 23.792,42.484,98.230,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 1.963 |  Acc: 23.250,41.150,71.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.776 |  Acc: 23.744,42.416,98.250,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 1.967 |  Acc: 23.210,41.360,71.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.774 |  Acc: 23.772,42.210,98.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 1.965 |  Acc: 23.150,41.450,71.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.777 |  Acc: 23.726,42.252,98.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 1.958 |  Acc: 23.020,41.140,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.773 |  Acc: 23.656,42.278,98.342,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 1.966 |  Acc: 23.100,41.500,71.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.773 |  Acc: 23.852,42.512,98.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 1.957 |  Acc: 23.370,41.480,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.772 |  Acc: 23.696,42.448,98.314,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 1.961 |  Acc: 23.280,41.690,71.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.773 |  Acc: 23.692,42.438,98.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 1.964 |  Acc: 23.330,41.380,71.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.774 |  Acc: 23.690,42.272,98.246,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 1.962 |  Acc: 23.290,41.530,71.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.774 |  Acc: 23.626,42.226,98.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 1.964 |  Acc: 23.090,41.640,71.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.770 |  Acc: 23.980,42.316,98.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 1.960 |  Acc: 23.350,41.310,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.773 |  Acc: 23.640,42.076,98.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 1.972 |  Acc: 23.210,41.550,71.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.770 |  Acc: 23.752,42.314,98.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 1.965 |  Acc: 23.080,41.360,71.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.771 |  Acc: 23.812,42.424,98.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 1.974 |  Acc: 23.250,41.550,71.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.771 |  Acc: 23.726,42.296,98.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 1.957 |  Acc: 22.850,41.600,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.771 |  Acc: 23.612,42.338,98.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 1.968 |  Acc: 22.900,41.490,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.768 |  Acc: 23.804,42.574,98.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 1.971 |  Acc: 23.240,41.910,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.770 |  Acc: 23.758,42.406,98.462,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 1.979 |  Acc: 23.160,41.670,71.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.770 |  Acc: 23.736,42.598,98.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 1.974 |  Acc: 23.100,41.610,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.770 |  Acc: 23.666,42.548,98.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 1.958 |  Acc: 23.350,41.580,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.770 |  Acc: 23.904,42.174,98.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 1.966 |  Acc: 23.250,41.600,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.769 |  Acc: 23.776,42.328,98.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 1.968 |  Acc: 22.980,41.550,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.766 |  Acc: 23.740,42.438,98.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 1.965 |  Acc: 23.110,41.770,71.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.769 |  Acc: 23.632,42.576,98.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 1.962 |  Acc: 23.280,41.440,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.767 |  Acc: 23.762,42.420,98.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 1.957 |  Acc: 23.090,41.630,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.769 |  Acc: 23.728,42.384,98.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 1.965 |  Acc: 23.080,41.540,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.771 |  Acc: 23.780,42.398,98.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 1.963 |  Acc: 23.270,41.730,71.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.769 |  Acc: 23.816,42.564,98.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 1.961 |  Acc: 23.390,41.340,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.768 |  Acc: 23.834,42.492,98.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 1.968 |  Acc: 23.180,41.850,71.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.769 |  Acc: 23.728,42.698,98.482,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 1.974 |  Acc: 23.320,41.640,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.768 |  Acc: 23.760,42.398,98.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 1.970 |  Acc: 23.310,41.460,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.767 |  Acc: 23.686,42.368,98.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 1.965 |  Acc: 23.220,41.990,71.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.770 |  Acc: 23.752,42.496,98.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 1.961 |  Acc: 23.340,41.730,71.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.768 |  Acc: 23.768,42.428,98.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 1.966 |  Acc: 23.220,41.730,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.768 |  Acc: 23.914,42.134,98.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 1.971 |  Acc: 23.380,41.750,71.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.769 |  Acc: 23.740,42.440,98.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 1.973 |  Acc: 23.220,41.670,71.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.770 |  Acc: 23.726,42.286,98.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 1.966 |  Acc: 23.270,41.680,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.770 |  Acc: 23.778,42.108,98.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 1.964 |  Acc: 23.320,41.720,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.767 |  Acc: 23.730,42.658,98.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 1.966 |  Acc: 23.410,41.500,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.767 |  Acc: 23.790,42.530,98.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 1.962 |  Acc: 23.330,41.740,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.767 |  Acc: 23.598,42.600,98.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 1.972 |  Acc: 23.180,41.380,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.768 |  Acc: 23.760,42.444,98.504,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 1.978 |  Acc: 23.350,41.540,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.767 |  Acc: 23.738,42.710,98.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 1.967 |  Acc: 23.130,41.620,71.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.766 |  Acc: 23.632,42.468,98.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 1.965 |  Acc: 23.010,41.270,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.766 |  Acc: 23.750,42.462,98.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 1.964 |  Acc: 23.070,41.340,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.769 |  Acc: 23.832,42.432,98.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 1.969 |  Acc: 23.220,41.390,71.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.768 |  Acc: 23.840,42.482,98.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 1.973 |  Acc: 23.380,41.790,72.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.767 |  Acc: 23.940,42.612,98.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 1.969 |  Acc: 23.280,41.550,71.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.768 |  Acc: 23.826,42.366,98.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 1.958 |  Acc: 23.260,41.700,71.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.767 |  Acc: 23.714,42.318,98.528,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 1.963 |  Acc: 23.360,41.420,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.765 |  Acc: 23.922,42.366,98.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 1.965 |  Acc: 23.350,41.890,71.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.769 |  Acc: 23.814,42.614,98.386,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 1.968 |  Acc: 23.300,41.710,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.766 |  Acc: 23.738,42.472,98.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 1.968 |  Acc: 23.200,41.730,71.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=3, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.769 |  Acc: 23.898,42.372,98.442,% | Adaptive Acc:97.668% | clf_exit: 0.002 0.080 0.918
Testing: Epoch=299 | Loss: 1.968 |  Acc: 23.060,41.680,71.680,% | Adaptive Acc:70.520% | clf_exit: 0.012 0.153 0.835

circles: 0
Testing: Epoch=299 | Loss: 6.210 |  Acc: 1.000,1.840,17.640,% | Adaptive Acc:1.000% | clf_exit: 1.000 0.000 0.000
circles: 1
Testing: Epoch=299 | Loss: 5.317 |  Acc: 1.000,2.490,23.680,% | Adaptive Acc:1.020% | clf_exit: 0.999 0.000 0.001
circles: 2
Testing: Epoch=299 | Loss: 3.337 |  Acc: 1.840,4.190,52.050,% | Adaptive Acc:39.570% | clf_exit: 0.195 0.078 0.726
circles: 3
Testing: Epoch=299 | Loss: 1.968 |  Acc: 23.060,41.680,71.680,% | Adaptive Acc:70.520% | clf_exit: 0.012 0.153 0.835
