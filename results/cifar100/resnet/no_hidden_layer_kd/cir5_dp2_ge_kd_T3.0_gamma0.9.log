==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=16, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=132, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=132, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=164, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=164, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 5.964 | Acc: 0.781,1.562,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.894 | Acc: 0.967,1.302,1.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.821 | Acc: 1.048,1.105,1.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.754 | Acc: 0.973,1.127,1.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.691 | Acc: 0.993,1.331,1.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.640 | Acc: 1.013,1.377,2.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.599 | Acc: 1.143,1.472,2.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.562 | Acc: 1.197,1.574,2.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.527 | Acc: 1.242,1.718,3.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.498 | Acc: 1.342,1.834,3.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.467 | Acc: 1.380,1.866,3.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.443 | Acc: 1.449,1.973,3.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.416 | Acc: 1.436,2.107,3.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.394 | Acc: 1.512,2.254,3.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.371 | Acc: 1.571,2.385,4.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.350 | Acc: 1.599,2.525,4.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.330 | Acc: 1.618,2.638,4.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.311 | Acc: 1.679,2.701,4.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.292 | Acc: 1.710,2.822,4.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.275 | Acc: 1.747,2.871,5.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.999 | Acc: 5.469,4.688,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.998 | Acc: 1.711,4.427,7.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.994 | Acc: 1.391,4.249,7.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.005 | Acc: 1.396,3.996,7.364,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 4.809 | Acc: 3.125,3.906,7.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.911 | Acc: 2.716,4.576,8.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.907 | Acc: 2.858,4.688,8.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.894 | Acc: 2.741,4.559,9.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.878 | Acc: 2.681,4.533,9.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.867 | Acc: 2.785,4.595,9.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.860 | Acc: 2.705,4.558,9.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.846 | Acc: 2.737,4.721,10.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.838 | Acc: 2.790,4.925,10.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.832 | Acc: 2.788,5.007,10.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.823 | Acc: 2.853,5.080,10.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.817 | Acc: 2.817,5.066,10.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.809 | Acc: 2.836,5.083,10.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.802 | Acc: 2.847,5.145,10.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.797 | Acc: 2.883,5.219,10.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.791 | Acc: 2.873,5.282,10.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.783 | Acc: 2.891,5.362,10.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.778 | Acc: 2.898,5.439,10.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.771 | Acc: 2.917,5.488,11.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.766 | Acc: 2.918,5.592,11.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.771 | Acc: 1.562,7.031,11.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.743 | Acc: 2.009,6.138,11.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.739 | Acc: 2.115,6.040,11.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.748 | Acc: 2.139,6.109,11.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 4.644 | Acc: 1.562,7.812,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.645 | Acc: 2.716,7.254,13.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.643 | Acc: 2.725,6.879,12.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.621 | Acc: 3.087,6.788,13.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.610 | Acc: 3.221,6.732,13.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.609 | Acc: 3.303,6.614,13.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.607 | Acc: 3.267,6.573,13.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.604 | Acc: 3.247,6.588,13.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.602 | Acc: 3.232,6.755,13.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.600 | Acc: 3.246,6.708,13.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.591 | Acc: 3.226,6.740,13.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.590 | Acc: 3.217,6.752,13.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.583 | Acc: 3.190,6.801,13.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.578 | Acc: 3.191,6.795,13.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.573 | Acc: 3.214,6.809,13.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.567 | Acc: 3.216,6.899,13.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.563 | Acc: 3.259,6.975,13.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.558 | Acc: 3.256,7.013,13.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.555 | Acc: 3.251,7.044,14.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.551 | Acc: 3.250,7.072,14.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.511 | Acc: 3.906,9.375,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.524 | Acc: 3.311,7.961,14.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.498 | Acc: 2.992,7.622,14.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.513 | Acc: 2.882,7.672,14.511,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 4.270 | Acc: 4.688,9.375,21.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.442 | Acc: 4.167,7.775,15.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.442 | Acc: 3.449,7.508,15.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.423 | Acc: 3.560,7.556,15.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.426 | Acc: 3.713,7.735,15.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.426 | Acc: 3.813,8.014,15.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.427 | Acc: 3.848,8.090,15.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.422 | Acc: 3.845,8.084,15.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.415 | Acc: 3.897,8.210,16.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.414 | Acc: 3.816,8.210,16.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.409 | Acc: 3.716,8.151,16.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.400 | Acc: 3.712,8.240,16.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.393 | Acc: 3.721,8.325,16.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.391 | Acc: 3.730,8.300,16.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.387 | Acc: 3.726,8.316,16.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.383 | Acc: 3.797,8.337,16.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.377 | Acc: 3.843,8.448,16.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.371 | Acc: 3.826,8.408,16.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.367 | Acc: 3.850,8.460,16.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.362 | Acc: 3.863,8.469,16.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.442 | Acc: 3.906,5.469,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.373 | Acc: 2.493,8.296,16.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.355 | Acc: 2.401,8.175,17.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.357 | Acc: 2.459,8.133,16.650,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 4.137 | Acc: 1.562,10.938,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.221 | Acc: 3.981,9.301,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.232 | Acc: 3.906,8.727,19.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.223 | Acc: 3.983,9.439,19.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.228 | Acc: 3.897,9.394,19.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.219 | Acc: 3.929,9.522,19.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.221 | Acc: 3.984,9.588,19.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.220 | Acc: 3.962,9.735,19.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.222 | Acc: 3.998,9.749,19.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.225 | Acc: 3.954,9.608,19.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.224 | Acc: 3.972,9.558,19.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.218 | Acc: 4.016,9.619,19.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.212 | Acc: 4.029,9.689,19.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.203 | Acc: 4.110,9.719,19.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.198 | Acc: 4.112,9.667,19.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.198 | Acc: 4.109,9.609,19.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.195 | Acc: 4.084,9.645,19.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.190 | Acc: 4.096,9.689,19.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.185 | Acc: 4.099,9.745,19.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.178 | Acc: 4.120,9.785,19.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.228 | Acc: 5.469,8.594,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.222 | Acc: 3.906,8.705,19.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.199 | Acc: 3.887,9.261,19.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.199 | Acc: 3.932,9.093,19.582,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 4.067 | Acc: 5.469,12.500,17.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.050 | Acc: 4.241,11.682,20.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.069 | Acc: 4.230,11.242,20.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.069 | Acc: 4.342,11.014,21.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.055 | Acc: 4.234,10.938,21.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.056 | Acc: 4.324,11.038,21.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.050 | Acc: 4.378,11.105,21.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.048 | Acc: 4.444,11.264,22.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.052 | Acc: 4.498,11.156,21.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.050 | Acc: 4.528,11.084,22.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.040 | Acc: 4.551,11.058,22.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.034 | Acc: 4.599,11.005,22.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.028 | Acc: 4.603,11.009,22.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.021 | Acc: 4.622,11.045,22.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.020 | Acc: 4.610,11.018,22.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.017 | Acc: 4.604,11.044,22.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.013 | Acc: 4.644,11.122,22.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.011 | Acc: 4.665,11.130,22.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.005 | Acc: 4.655,11.154,22.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.000 | Acc: 4.675,11.165,22.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.991 | Acc: 5.469,9.375,17.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.107 | Acc: 4.129,8.929,20.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.115 | Acc: 3.639,8.556,21.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.135 | Acc: 3.573,8.466,20.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 3.923 | Acc: 7.031,10.938,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.858 | Acc: 4.427,11.979,26.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.894 | Acc: 4.649,11.757,24.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.870 | Acc: 4.611,11.770,24.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.864 | Acc: 4.716,12.027,24.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.868 | Acc: 4.718,11.850,24.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.865 | Acc: 4.681,11.932,24.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.870 | Acc: 4.582,11.735,24.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.864 | Acc: 4.668,11.811,24.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.862 | Acc: 4.636,11.801,24.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.864 | Acc: 4.598,11.793,24.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.864 | Acc: 4.567,11.793,24.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.861 | Acc: 4.577,11.881,24.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.859 | Acc: 4.604,11.931,24.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.855 | Acc: 4.599,11.919,24.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.850 | Acc: 4.599,11.976,25.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.848 | Acc: 4.600,11.991,25.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.845 | Acc: 4.610,12.012,25.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.844 | Acc: 4.618,11.987,25.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.842 | Acc: 4.599,11.991,25.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.548 | Acc: 7.812,13.281,32.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.860 | Acc: 4.390,10.603,25.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.854 | Acc: 4.421,11.319,24.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.861 | Acc: 4.444,11.603,24.744,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 3.571 | Acc: 6.250,10.938,29.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.768 | Acc: 5.692,13.616,27.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.761 | Acc: 4.726,12.862,27.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.745 | Acc: 4.688,12.859,27.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.753 | Acc: 4.610,12.915,27.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.747 | Acc: 4.726,12.778,27.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.738 | Acc: 4.901,12.900,27.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.736 | Acc: 4.959,12.760,27.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.740 | Acc: 4.882,12.665,27.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.736 | Acc: 4.938,12.716,27.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.731 | Acc: 5.014,12.776,27.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.727 | Acc: 5.030,12.694,27.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.724 | Acc: 5.060,12.785,27.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.721 | Acc: 5.113,12.778,27.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.721 | Acc: 5.141,12.772,27.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.715 | Acc: 5.121,12.793,27.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.709 | Acc: 5.130,12.877,27.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.708 | Acc: 5.102,12.869,28.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.701 | Acc: 5.185,12.916,28.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.699 | Acc: 5.200,12.949,28.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.612 | Acc: 5.469,14.844,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.675 | Acc: 3.720,12.909,28.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.667 | Acc: 3.868,13.300,28.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.682 | Acc: 4.022,13.294,28.253,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 3.581 | Acc: 4.688,11.719,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.600 | Acc: 5.543,13.653,29.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.595 | Acc: 5.526,13.777,30.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.591 | Acc: 5.635,13.384,30.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.593 | Acc: 5.507,13.407,30.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.599 | Acc: 5.476,13.351,29.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.596 | Acc: 5.488,13.314,29.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.598 | Acc: 5.463,13.209,29.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.591 | Acc: 5.449,13.335,30.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.591 | Acc: 5.495,13.342,30.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.594 | Acc: 5.539,13.343,29.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.592 | Acc: 5.504,13.331,30.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.588 | Acc: 5.495,13.421,30.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.589 | Acc: 5.508,13.311,30.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.586 | Acc: 5.586,13.404,30.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.584 | Acc: 5.528,13.380,30.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.584 | Acc: 5.583,13.474,30.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.579 | Acc: 5.643,13.623,30.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.579 | Acc: 5.629,13.656,30.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.579 | Acc: 5.569,13.607,30.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.481 | Acc: 2.344,14.062,25.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.570 | Acc: 5.097,12.612,29.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.554 | Acc: 4.897,12.443,30.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.567 | Acc: 4.892,12.398,30.187,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 3.456 | Acc: 6.250,17.969,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.439 | Acc: 6.324,14.286,32.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.455 | Acc: 6.136,14.215,32.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.464 | Acc: 5.904,13.730,32.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.482 | Acc: 5.787,13.918,32.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.480 | Acc: 5.794,13.923,32.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.484 | Acc: 5.759,13.991,32.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.489 | Acc: 5.812,14.068,32.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.492 | Acc: 5.740,14.135,32.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.490 | Acc: 5.758,14.214,32.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.486 | Acc: 5.725,14.311,32.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.486 | Acc: 5.755,14.384,32.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.481 | Acc: 5.757,14.448,32.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.479 | Acc: 5.855,14.437,32.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.478 | Acc: 5.925,14.488,32.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.477 | Acc: 5.926,14.483,32.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.475 | Acc: 5.890,14.467,32.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.469 | Acc: 5.904,14.532,32.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.468 | Acc: 5.930,14.545,32.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.468 | Acc: 5.924,14.555,32.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.558 | Acc: 5.469,14.062,26.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.665 | Acc: 4.464,14.286,28.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.641 | Acc: 4.516,13.910,29.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.641 | Acc: 4.598,14.075,28.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 3.166 | Acc: 9.375,18.750,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.339 | Acc: 6.250,15.625,35.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.369 | Acc: 6.650,15.549,33.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.365 | Acc: 6.442,15.459,33.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.365 | Acc: 6.182,15.326,33.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.379 | Acc: 6.165,15.231,33.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.381 | Acc: 6.153,14.992,33.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.376 | Acc: 6.150,15.154,34.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.373 | Acc: 6.143,15.120,34.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.372 | Acc: 6.198,15.206,34.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.362 | Acc: 6.234,15.209,34.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.363 | Acc: 6.211,15.254,34.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.360 | Acc: 6.260,15.255,34.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.360 | Acc: 6.274,15.251,34.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.358 | Acc: 6.256,15.328,34.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.358 | Acc: 6.266,15.389,34.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.355 | Acc: 6.260,15.452,34.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.352 | Acc: 6.239,15.483,34.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.354 | Acc: 6.222,15.476,34.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.353 | Acc: 6.174,15.471,34.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.271 | Acc: 3.906,14.844,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.510 | Acc: 5.208,14.137,32.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.491 | Acc: 4.878,14.120,32.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.498 | Acc: 5.020,14.139,32.018,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 3.372 | Acc: 4.688,7.812,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.267 | Acc: 6.027,14.583,36.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.277 | Acc: 5.926,15.396,36.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.281 | Acc: 6.007,15.292,36.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.286 | Acc: 6.134,15.316,36.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.280 | Acc: 6.188,15.463,36.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.285 | Acc: 6.153,15.580,36.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.284 | Acc: 6.184,15.658,36.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.278 | Acc: 6.265,15.751,36.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.276 | Acc: 6.246,15.884,36.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.273 | Acc: 6.215,15.924,36.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.271 | Acc: 6.211,15.993,36.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.272 | Acc: 6.150,16.011,36.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.269 | Acc: 6.106,16.026,36.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.269 | Acc: 6.133,16.028,36.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.266 | Acc: 6.198,16.048,36.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.263 | Acc: 6.226,16.119,36.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.261 | Acc: 6.204,16.143,36.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.259 | Acc: 6.222,16.181,36.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.256 | Acc: 6.264,16.244,36.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.141 | Acc: 2.344,11.719,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.344 | Acc: 4.985,12.872,35.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.337 | Acc: 4.630,12.862,36.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.336 | Acc: 4.534,12.871,35.502,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 2.939 | Acc: 3.906,13.281,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.184 | Acc: 5.208,15.551,39.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.181 | Acc: 5.526,15.720,39.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.165 | Acc: 5.686,16.163,39.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.171 | Acc: 6.134,16.242,38.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.184 | Acc: 6.080,16.236,38.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.181 | Acc: 6.353,16.477,38.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.189 | Acc: 6.433,16.462,38.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.183 | Acc: 6.464,16.382,38.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.179 | Acc: 6.492,16.531,38.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.181 | Acc: 6.487,16.573,38.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.181 | Acc: 6.466,16.537,38.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.180 | Acc: 6.516,16.614,38.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.181 | Acc: 6.486,16.613,38.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.175 | Acc: 6.475,16.662,38.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.170 | Acc: 6.520,16.648,38.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.168 | Acc: 6.557,16.681,38.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.167 | Acc: 6.575,16.729,38.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.163 | Acc: 6.570,16.770,38.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.162 | Acc: 6.570,16.872,38.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.069 | Acc: 6.250,15.625,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.207 | Acc: 5.878,15.327,37.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.206 | Acc: 5.793,15.663,37.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.212 | Acc: 5.686,15.702,37.935,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 3.147 | Acc: 10.156,22.656,34.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.064 | Acc: 7.403,17.113,40.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.069 | Acc: 6.955,17.035,40.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.075 | Acc: 6.685,17.149,40.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.080 | Acc: 7.031,17.255,40.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.083 | Acc: 6.877,17.481,40.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.088 | Acc: 6.728,17.265,40.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.091 | Acc: 6.787,17.082,39.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.083 | Acc: 6.764,17.319,40.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.087 | Acc: 6.798,17.295,40.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.090 | Acc: 6.852,17.320,40.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.085 | Acc: 6.816,17.262,40.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.087 | Acc: 6.824,17.207,40.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.087 | Acc: 6.819,17.262,40.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.086 | Acc: 6.828,17.232,40.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.088 | Acc: 6.787,17.208,40.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.086 | Acc: 6.822,17.207,40.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.085 | Acc: 6.752,17.176,40.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.083 | Acc: 6.739,17.151,40.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.082 | Acc: 6.746,17.190,40.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.200 | Acc: 9.375,14.062,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.312 | Acc: 6.622,15.923,36.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.325 | Acc: 6.479,16.101,36.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.324 | Acc: 6.570,15.958,36.206,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 2.933 | Acc: 6.250,17.188,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.953 | Acc: 6.250,17.113,43.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.948 | Acc: 6.460,17.873,43.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.972 | Acc: 6.545,17.892,42.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.988 | Acc: 6.694,17.911,42.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.983 | Acc: 6.745,17.628,42.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.986 | Acc: 6.889,17.853,42.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.984 | Acc: 6.865,17.841,42.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.992 | Acc: 6.944,17.862,42.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.994 | Acc: 6.975,17.844,42.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.990 | Acc: 6.919,17.957,42.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.987 | Acc: 6.989,18.039,42.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.989 | Acc: 6.934,17.946,42.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.986 | Acc: 6.938,18.023,42.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.987 | Acc: 6.970,18.063,42.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.990 | Acc: 6.925,17.997,42.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.991 | Acc: 6.890,17.942,42.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.992 | Acc: 6.903,17.987,42.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.991 | Acc: 6.858,18.040,42.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.992 | Acc: 6.890,18.045,42.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.300 | Acc: 9.375,16.406,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.290 | Acc: 6.027,15.365,37.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.280 | Acc: 6.383,15.568,37.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.308 | Acc: 6.506,15.535,37.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 2.817 | Acc: 3.906,15.625,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.992 | Acc: 6.845,18.006,42.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.968 | Acc: 6.784,18.216,42.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.952 | Acc: 6.749,18.737,42.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.938 | Acc: 6.780,18.846,43.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.934 | Acc: 6.660,18.533,43.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.936 | Acc: 6.657,18.511,43.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.929 | Acc: 6.793,18.462,43.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.929 | Acc: 6.837,18.430,43.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.925 | Acc: 6.794,18.418,43.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.921 | Acc: 6.817,18.435,43.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.916 | Acc: 6.872,18.545,43.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.914 | Acc: 6.953,18.601,44.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.918 | Acc: 6.920,18.564,43.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.921 | Acc: 6.906,18.489,43.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.921 | Acc: 6.977,18.503,43.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.924 | Acc: 6.985,18.458,43.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.922 | Acc: 7.043,18.578,43.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.921 | Acc: 7.122,18.611,43.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.918 | Acc: 7.158,18.602,43.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.991 | Acc: 7.812,21.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.169 | Acc: 5.506,15.513,40.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.193 | Acc: 5.907,15.663,39.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.213 | Acc: 5.981,15.356,38.934,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 2.521 | Acc: 10.156,22.656,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.846 | Acc: 6.994,18.713,45.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.827 | Acc: 7.222,18.731,46.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.812 | Acc: 7.006,18.993,46.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.824 | Acc: 6.954,18.962,45.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.825 | Acc: 6.853,19.005,45.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.819 | Acc: 6.947,18.982,46.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.824 | Acc: 7.037,19.094,45.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.831 | Acc: 7.017,18.978,45.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.839 | Acc: 7.083,18.754,45.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.844 | Acc: 7.109,18.847,45.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.846 | Acc: 7.173,18.796,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.852 | Acc: 7.219,18.799,45.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.853 | Acc: 7.244,18.774,45.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.847 | Acc: 7.301,18.908,45.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.844 | Acc: 7.319,18.986,45.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.844 | Acc: 7.355,18.940,45.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.845 | Acc: 7.320,18.887,45.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.846 | Acc: 7.326,18.878,45.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.849 | Acc: 7.292,18.932,45.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.873 | Acc: 4.688,18.750,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.125 | Acc: 5.655,15.625,41.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.138 | Acc: 5.431,16.292,40.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.144 | Acc: 5.443,16.035,40.420,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 2.856 | Acc: 5.469,14.062,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.739 | Acc: 6.845,17.820,46.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.755 | Acc: 7.470,18.045,46.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.760 | Acc: 7.454,18.366,46.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.762 | Acc: 7.514,18.721,46.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.761 | Acc: 7.534,18.936,46.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.753 | Acc: 7.761,19.008,47.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.758 | Acc: 7.724,18.866,47.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.761 | Acc: 7.725,19.128,47.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.764 | Acc: 7.627,19.156,47.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.764 | Acc: 7.618,19.279,47.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.770 | Acc: 7.572,19.301,46.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.771 | Acc: 7.631,19.522,47.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.771 | Acc: 7.615,19.546,47.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.771 | Acc: 7.573,19.626,46.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.774 | Acc: 7.545,19.581,46.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.771 | Acc: 7.516,19.602,47.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.770 | Acc: 7.526,19.593,47.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.769 | Acc: 7.514,19.644,47.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.770 | Acc: 7.497,19.624,47.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.801 | Acc: 7.812,22.656,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.947 | Acc: 6.771,16.667,43.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 6.631,16.635,42.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.986 | Acc: 6.865,16.201,42.444,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 2.628 | Acc: 14.062,24.219,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 7.292,18.787,49.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.709 | Acc: 7.412,20.008,48.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.703 | Acc: 7.544,19.954,49.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.711 | Acc: 7.610,20.235,48.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.723 | Acc: 7.681,20.034,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.724 | Acc: 7.780,20.087,48.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.719 | Acc: 7.779,20.047,48.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.720 | Acc: 7.686,20.050,48.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.713 | Acc: 7.812,20.403,48.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.714 | Acc: 7.855,20.320,48.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.713 | Acc: 7.883,20.330,48.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.716 | Acc: 7.858,20.449,48.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.718 | Acc: 7.827,20.456,48.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.717 | Acc: 7.801,20.499,48.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.719 | Acc: 7.740,20.458,48.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.718 | Acc: 7.725,20.463,48.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.722 | Acc: 7.703,20.406,48.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.723 | Acc: 7.680,20.412,48.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.724 | Acc: 7.655,20.345,48.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.883 | Acc: 10.938,17.188,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.886 | Acc: 7.217,16.629,46.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.905 | Acc: 7.088,16.616,45.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.903 | Acc: 7.172,16.573,45.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 2.825 | Acc: 6.250,29.688,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.666 | Acc: 7.887,19.382,49.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.650 | Acc: 7.584,20.370,49.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.641 | Acc: 7.684,20.466,49.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.627 | Acc: 7.967,20.833,50.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.636 | Acc: 8.021,20.653,50.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.644 | Acc: 8.097,20.648,50.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.641 | Acc: 8.112,20.606,50.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.644 | Acc: 8.065,20.613,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.649 | Acc: 8.063,20.606,49.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.655 | Acc: 8.073,20.592,49.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.659 | Acc: 8.014,20.433,49.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.656 | Acc: 7.997,20.475,49.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.653 | Acc: 8.037,20.510,49.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.654 | Acc: 8.029,20.518,49.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.654 | Acc: 7.997,20.580,49.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.657 | Acc: 7.956,20.541,49.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.658 | Acc: 7.950,20.606,49.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.656 | Acc: 7.938,20.698,49.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.655 | Acc: 7.933,20.753,49.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.663 | Acc: 3.906,18.750,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.854 | Acc: 7.478,18.304,46.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.833 | Acc: 7.450,18.826,46.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 7.441,18.673,46.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 2.456 | Acc: 7.812,17.969,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.584 | Acc: 8.445,20.424,51.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.560 | Acc: 8.194,21.456,51.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.567 | Acc: 8.017,21.644,51.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.581 | Acc: 7.909,21.267,51.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.586 | Acc: 7.789,21.117,51.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.588 | Acc: 7.838,20.965,51.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.593 | Acc: 7.840,21.055,51.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.590 | Acc: 7.793,20.972,51.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.597 | Acc: 7.877,20.990,51.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.601 | Acc: 7.890,20.997,50.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.601 | Acc: 7.940,21.048,50.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.603 | Acc: 7.923,21.055,50.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.601 | Acc: 7.998,21.121,50.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.602 | Acc: 7.996,21.127,50.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.606 | Acc: 8.023,21.089,50.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.605 | Acc: 8.070,21.140,50.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.606 | Acc: 8.097,21.128,50.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.609 | Acc: 8.109,21.098,50.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.608 | Acc: 8.124,21.153,50.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.911 | Acc: 8.594,17.969,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.992 | Acc: 7.440,19.345,44.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.001 | Acc: 7.393,19.836,44.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.998 | Acc: 7.403,19.672,44.595,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 2.317 | Acc: 9.375,21.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.531 | Acc: 8.185,21.057,52.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.510 | Acc: 9.032,21.532,53.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.505 | Acc: 8.952,21.516,53.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.520 | Acc: 8.941,21.653,53.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.530 | Acc: 8.810,21.744,52.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.526 | Acc: 8.652,22.043,52.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.531 | Acc: 8.799,22.108,52.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.539 | Acc: 8.822,21.948,52.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.542 | Acc: 8.771,22.035,52.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.547 | Acc: 8.773,21.972,52.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.550 | Acc: 8.735,21.939,52.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.558 | Acc: 8.587,21.787,51.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.560 | Acc: 8.522,21.728,51.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.557 | Acc: 8.530,21.792,51.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.563 | Acc: 8.503,21.686,51.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.563 | Acc: 8.516,21.712,51.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.563 | Acc: 8.456,21.685,51.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.565 | Acc: 8.369,21.591,51.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.566 | Acc: 8.366,21.586,51.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.836 | Acc: 7.031,21.875,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.884 | Acc: 7.589,18.750,45.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.898 | Acc: 7.412,19.398,45.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.894 | Acc: 7.492,19.057,45.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 2.542 | Acc: 4.688,16.406,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.544 | Acc: 8.333,21.205,51.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.518 | Acc: 8.098,20.808,53.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.488 | Acc: 8.248,21.171,53.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.489 | Acc: 8.555,21.547,53.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.501 | Acc: 8.578,21.419,53.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.508 | Acc: 8.561,21.178,52.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.505 | Acc: 8.549,21.354,53.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.505 | Acc: 8.628,21.516,53.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.508 | Acc: 8.732,21.547,52.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.512 | Acc: 8.683,21.549,52.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 8.721,21.751,52.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.518 | Acc: 8.659,21.800,52.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.520 | Acc: 8.660,21.845,52.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.522 | Acc: 8.685,21.894,52.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.524 | Acc: 8.646,21.826,52.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.524 | Acc: 8.657,21.826,52.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.522 | Acc: 8.649,21.831,52.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.520 | Acc: 8.611,21.840,52.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.519 | Acc: 8.639,21.871,52.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.612 | Acc: 7.031,22.656,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.715 | Acc: 7.924,20.499,48.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.708 | Acc: 7.889,20.541,49.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.727 | Acc: 7.748,20.338,48.681,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.486 | Acc: 10.938,17.188,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.411 | Acc: 9.263,22.507,55.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.436 | Acc: 8.899,22.180,54.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.449 | Acc: 8.735,22.477,54.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.467 | Acc: 8.893,22.396,53.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.475 | Acc: 8.849,22.386,53.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.470 | Acc: 8.852,22.314,53.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.478 | Acc: 8.782,22.340,53.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.469 | Acc: 8.749,22.258,53.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.471 | Acc: 8.633,22.130,53.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.473 | Acc: 8.706,22.244,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.474 | Acc: 8.880,22.282,53.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.474 | Acc: 8.817,22.339,53.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.476 | Acc: 8.821,22.315,53.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 8.802,22.334,53.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.474 | Acc: 8.838,22.288,54.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.475 | Acc: 8.842,22.284,54.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.476 | Acc: 8.878,22.281,54.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.479 | Acc: 8.895,22.241,54.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.479 | Acc: 8.926,22.205,54.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.754 | Acc: 10.938,19.531,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.824 | Acc: 9.115,18.862,46.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.830 | Acc: 9.032,18.769,46.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.832 | Acc: 9.016,18.699,46.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 2.348 | Acc: 6.250,22.656,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.405 | Acc: 9.449,23.251,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.396 | Acc: 9.832,23.361,56.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.388 | Acc: 9.887,23.540,56.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.400 | Acc: 9.828,23.177,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.412 | Acc: 9.870,22.765,56.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.410 | Acc: 9.859,22.934,55.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.415 | Acc: 9.730,22.712,55.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.419 | Acc: 9.584,22.448,55.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.420 | Acc: 9.500,22.509,55.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.419 | Acc: 9.426,22.415,55.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.421 | Acc: 9.357,22.416,55.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.423 | Acc: 9.394,22.390,55.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.421 | Acc: 9.426,22.480,55.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.421 | Acc: 9.378,22.562,55.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.420 | Acc: 9.401,22.547,55.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.425 | Acc: 9.382,22.581,55.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.426 | Acc: 9.380,22.608,55.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.427 | Acc: 9.407,22.630,55.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.425 | Acc: 9.396,22.599,55.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.493 | Acc: 10.938,21.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.686 | Acc: 7.924,19.792,48.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.705 | Acc: 7.603,20.008,49.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.707 | Acc: 7.684,19.544,49.116,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 2.352 | Acc: 16.406,29.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.319 | Acc: 10.007,23.810,57.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.355 | Acc: 9.546,23.209,56.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.369 | Acc: 9.439,22.784,56.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.373 | Acc: 9.394,22.695,56.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.371 | Acc: 9.414,22.997,56.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.367 | Acc: 9.414,23.082,56.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.370 | Acc: 9.425,23.088,56.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.377 | Acc: 9.443,22.972,56.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.378 | Acc: 9.561,22.920,56.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.383 | Acc: 9.554,22.909,56.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.392 | Acc: 9.400,22.741,55.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.391 | Acc: 9.336,22.766,55.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.393 | Acc: 9.291,22.725,55.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.395 | Acc: 9.267,22.754,55.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.396 | Acc: 9.295,22.711,55.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.398 | Acc: 9.300,22.744,55.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.400 | Acc: 9.357,22.741,55.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.399 | Acc: 9.407,22.780,55.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.399 | Acc: 9.393,22.851,55.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.671 | Acc: 7.812,20.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.688 | Acc: 7.143,20.275,50.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.690 | Acc: 7.127,20.713,50.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.700 | Acc: 7.159,20.581,50.269,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.217 | Acc: 10.156,15.625,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.337 | Acc: 9.263,21.652,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.322 | Acc: 9.318,21.532,57.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.325 | Acc: 9.670,22.605,57.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.318 | Acc: 9.616,22.569,57.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.321 | Acc: 9.684,22.741,57.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.326 | Acc: 9.840,23.031,57.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.343 | Acc: 9.973,22.756,56.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.345 | Acc: 9.948,22.923,56.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.348 | Acc: 9.884,23.084,56.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.353 | Acc: 9.869,23.060,56.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.352 | Acc: 9.831,22.996,56.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.351 | Acc: 9.864,23.100,56.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.352 | Acc: 9.824,23.036,56.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.354 | Acc: 9.820,23.121,56.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.353 | Acc: 9.868,23.149,56.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.354 | Acc: 9.896,23.209,56.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.357 | Acc: 9.865,23.080,56.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.359 | Acc: 9.875,23.100,56.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.358 | Acc: 9.898,23.136,56.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.584 | Acc: 8.594,23.438,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.657 | Acc: 8.147,21.280,51.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.688 | Acc: 7.698,21.704,50.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.701 | Acc: 7.646,21.593,50.166,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.355 | Acc: 15.625,25.000,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.273 | Acc: 10.491,23.251,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.314 | Acc: 9.794,22.485,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.315 | Acc: 9.823,22.823,57.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.303 | Acc: 9.848,23.110,57.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.304 | Acc: 9.831,23.082,58.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.308 | Acc: 9.879,23.115,58.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.306 | Acc: 9.890,23.293,58.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.310 | Acc: 9.860,23.146,57.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.315 | Acc: 9.854,23.217,57.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.317 | Acc: 10.012,23.200,57.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.321 | Acc: 9.969,23.300,57.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.321 | Acc: 9.903,23.201,57.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.323 | Acc: 9.956,23.249,57.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.325 | Acc: 9.945,23.182,57.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.327 | Acc: 9.912,23.100,57.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.325 | Acc: 9.906,23.070,57.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.327 | Acc: 9.964,23.112,57.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.329 | Acc: 9.981,23.141,57.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.330 | Acc: 9.990,23.271,57.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.830 | Acc: 10.938,23.438,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.717 | Acc: 8.780,19.754,48.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.737 | Acc: 8.918,20.084,48.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.757 | Acc: 8.927,19.980,48.617,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 2.111 | Acc: 13.281,22.656,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.251 | Acc: 10.789,24.107,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.251 | Acc: 10.156,24.447,59.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.273 | Acc: 10.182,23.886,59.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.288 | Acc: 10.050,23.833,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.291 | Acc: 10.017,23.631,58.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.290 | Acc: 10.111,23.657,58.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.284 | Acc: 10.095,23.554,58.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.285 | Acc: 10.049,23.612,58.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.292 | Acc: 9.984,23.429,58.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.296 | Acc: 10.051,23.379,58.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.295 | Acc: 10.064,23.381,58.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.295 | Acc: 10.095,23.441,58.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.296 | Acc: 10.171,23.414,58.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.299 | Acc: 10.076,23.335,58.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.300 | Acc: 10.094,23.399,58.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.303 | Acc: 10.117,23.435,58.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.306 | Acc: 10.133,23.415,57.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.309 | Acc: 10.106,23.474,57.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.309 | Acc: 10.087,23.470,57.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.288 | Acc: 13.281,24.219,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.708 | Acc: 8.259,19.680,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.694 | Acc: 8.346,20.103,50.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.705 | Acc: 8.248,20.248,49.693,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.269 | Acc: 13.281,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.223 | Acc: 10.714,24.926,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.226 | Acc: 9.966,24.409,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.242 | Acc: 10.361,24.360,58.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.239 | Acc: 10.426,24.373,58.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.247 | Acc: 10.427,24.172,58.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.251 | Acc: 10.466,23.812,58.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.250 | Acc: 10.500,23.764,58.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.258 | Acc: 10.423,23.714,58.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.257 | Acc: 10.325,23.671,58.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.257 | Acc: 10.444,23.717,58.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.260 | Acc: 10.354,23.635,58.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.263 | Acc: 10.399,23.700,58.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.266 | Acc: 10.435,23.722,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.265 | Acc: 10.493,23.788,58.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.266 | Acc: 10.491,23.868,58.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.264 | Acc: 10.495,23.902,58.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.264 | Acc: 10.521,23.939,58.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.267 | Acc: 10.537,23.961,58.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.269 | Acc: 10.552,23.919,58.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.488 | Acc: 8.594,21.094,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.581 | Acc: 8.817,19.903,51.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.607 | Acc: 9.261,19.893,51.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.644 | Acc: 9.349,19.723,51.652,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.446 | Acc: 7.031,17.969,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.236 | Acc: 10.156,22.396,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.216 | Acc: 10.747,23.418,60.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.228 | Acc: 10.400,23.630,60.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.227 | Acc: 10.426,23.640,60.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.218 | Acc: 10.497,23.956,60.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.221 | Acc: 10.544,23.812,60.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.228 | Acc: 10.544,23.903,59.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.230 | Acc: 10.569,23.962,59.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.236 | Acc: 10.635,23.917,59.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.242 | Acc: 10.533,23.865,59.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.245 | Acc: 10.524,23.759,59.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.248 | Acc: 10.568,23.872,59.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.249 | Acc: 10.512,23.713,59.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.248 | Acc: 10.512,23.802,59.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.252 | Acc: 10.600,23.765,59.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.249 | Acc: 10.628,23.778,59.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.253 | Acc: 10.651,23.804,59.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.256 | Acc: 10.635,23.777,59.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.254 | Acc: 10.650,23.819,59.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.462 | Acc: 11.719,23.438,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.585 | Acc: 10.305,20.164,51.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.568 | Acc: 10.423,19.779,52.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.577 | Acc: 10.630,19.762,52.318,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 2.195 | Acc: 8.594,22.656,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.195 | Acc: 10.231,24.405,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.170 | Acc: 10.880,24.257,61.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.176 | Acc: 10.528,23.706,61.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.181 | Acc: 10.610,23.862,61.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.181 | Acc: 10.628,24.025,61.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.188 | Acc: 10.673,24.057,61.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.188 | Acc: 10.943,24.346,61.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.193 | Acc: 10.865,24.432,61.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.194 | Acc: 10.773,24.357,61.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.201 | Acc: 10.782,24.215,60.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.205 | Acc: 10.793,24.208,60.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.208 | Acc: 10.785,24.164,60.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.210 | Acc: 10.728,24.063,60.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.213 | Acc: 10.698,23.996,60.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.214 | Acc: 10.725,23.900,60.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.217 | Acc: 10.718,23.953,60.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.216 | Acc: 10.763,24.100,60.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.214 | Acc: 10.754,24.154,60.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.217 | Acc: 10.771,24.155,60.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.435 | Acc: 10.938,21.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.529 | Acc: 9.003,21.875,53.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.542 | Acc: 8.899,22.123,53.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 9.016,22.144,53.035,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.436 | Acc: 13.281,27.344,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.132 | Acc: 10.714,24.182,62.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.131 | Acc: 10.842,24.676,61.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.146 | Acc: 10.579,24.232,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.152 | Acc: 10.629,24.306,61.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.147 | Acc: 10.736,24.629,61.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.148 | Acc: 10.944,24.929,61.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.159 | Acc: 11.026,24.873,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.164 | Acc: 11.088,24.898,61.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.168 | Acc: 11.011,24.879,61.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.170 | Acc: 11.089,24.798,61.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.173 | Acc: 11.036,24.675,61.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.171 | Acc: 11.083,24.656,61.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.172 | Acc: 11.087,24.728,61.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.175 | Acc: 11.090,24.708,61.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.178 | Acc: 11.130,24.613,61.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.179 | Acc: 11.164,24.628,61.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.184 | Acc: 11.146,24.627,61.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.183 | Acc: 11.152,24.673,61.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.185 | Acc: 11.143,24.623,61.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.512 | Acc: 8.594,21.875,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.733 | Acc: 9.747,19.382,49.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.727 | Acc: 9.470,19.512,49.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.717 | Acc: 9.337,19.672,49.949,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.192 | Acc: 16.406,21.094,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.117 | Acc: 10.045,23.847,62.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.124 | Acc: 9.832,23.933,62.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.131 | Acc: 10.438,23.975,61.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.142 | Acc: 10.532,24.248,61.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.156 | Acc: 10.868,24.381,61.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.162 | Acc: 10.944,24.283,61.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.160 | Acc: 10.932,24.429,61.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.161 | Acc: 10.996,24.481,61.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.162 | Acc: 11.045,24.391,61.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.166 | Acc: 11.109,24.491,61.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.170 | Acc: 11.242,24.604,60.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.169 | Acc: 11.294,24.630,60.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.169 | Acc: 11.258,24.665,61.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.169 | Acc: 11.224,24.619,61.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.170 | Acc: 11.236,24.626,61.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.172 | Acc: 11.227,24.608,61.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.176 | Acc: 11.240,24.606,60.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.177 | Acc: 11.262,24.619,60.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.174 | Acc: 11.300,24.727,61.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.740 | Acc: 14.844,21.875,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.696 | Acc: 10.491,22.024,50.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.692 | Acc: 10.385,22.790,50.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.674 | Acc: 10.720,22.567,50.884,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.045 | Acc: 7.031,26.562,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.179 | Acc: 11.384,23.289,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.115 | Acc: 11.643,24.657,62.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.109 | Acc: 11.898,24.910,62.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.108 | Acc: 11.931,24.932,62.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.112 | Acc: 11.935,24.892,62.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.115 | Acc: 11.893,24.851,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.119 | Acc: 11.741,24.895,62.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.117 | Acc: 11.893,24.927,62.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.116 | Acc: 11.909,25.030,62.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.116 | Acc: 11.913,25.124,62.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.119 | Acc: 11.860,25.113,62.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.120 | Acc: 11.822,25.042,62.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.125 | Acc: 11.761,25.018,62.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.128 | Acc: 11.774,25.003,62.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.132 | Acc: 11.781,25.003,61.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.138 | Acc: 11.760,25.034,61.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.142 | Acc: 11.661,25.016,61.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.144 | Acc: 11.580,24.985,61.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.144 | Acc: 11.528,24.957,61.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.497 | Acc: 11.719,20.312,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 10.714,22.247,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 10.575,22.409,53.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.542 | Acc: 10.464,22.170,53.599,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 2.092 | Acc: 9.375,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.033 | Acc: 11.942,26.116,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.058 | Acc: 11.547,25.324,63.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.055 | Acc: 11.603,25.307,63.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.057 | Acc: 11.709,25.280,63.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.081 | Acc: 11.580,25.008,62.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.087 | Acc: 11.770,25.394,62.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.097 | Acc: 11.868,25.449,62.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.099 | Acc: 11.952,25.514,62.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.104 | Acc: 11.835,25.237,62.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.110 | Acc: 11.637,25.183,62.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.116 | Acc: 11.489,25.032,62.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.118 | Acc: 11.592,25.003,62.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.117 | Acc: 11.629,25.069,62.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.116 | Acc: 11.724,25.122,62.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.121 | Acc: 11.711,25.083,62.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.122 | Acc: 11.760,25.037,62.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.124 | Acc: 11.794,25.137,62.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.124 | Acc: 11.823,25.249,62.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.127 | Acc: 11.836,25.226,61.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.429 | Acc: 17.188,21.094,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.551 | Acc: 10.677,21.726,52.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.559 | Acc: 10.785,22.466,52.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.569 | Acc: 10.745,22.285,52.600,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.035 | Acc: 10.938,25.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.076 | Acc: 11.161,24.591,63.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.075 | Acc: 11.452,24.581,63.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.068 | Acc: 11.719,24.641,63.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.071 | Acc: 11.854,24.672,63.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.078 | Acc: 11.920,24.899,63.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.081 | Acc: 11.925,25.181,63.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.084 | Acc: 11.996,25.211,63.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.086 | Acc: 12.000,25.291,63.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.083 | Acc: 11.965,25.488,63.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.089 | Acc: 11.960,25.288,63.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.086 | Acc: 12.016,25.385,63.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.087 | Acc: 11.887,25.366,63.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.089 | Acc: 11.922,25.431,63.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.089 | Acc: 11.977,25.436,63.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.090 | Acc: 11.968,25.361,63.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.094 | Acc: 11.952,25.336,63.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.095 | Acc: 11.998,25.399,63.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.097 | Acc: 11.946,25.472,63.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.106 | Acc: 11.926,25.443,62.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.585 | Acc: 14.062,22.656,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.614 | Acc: 10.528,20.126,52.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.628 | Acc: 11.014,20.884,52.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.622 | Acc: 11.078,20.799,51.857,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 1.953 | Acc: 13.281,28.906,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.018 | Acc: 12.463,27.083,65.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.068 | Acc: 12.005,26.029,64.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.072 | Acc: 11.744,26.089,63.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.064 | Acc: 11.815,25.810,63.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.074 | Acc: 11.757,25.704,63.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.071 | Acc: 11.925,25.723,63.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.070 | Acc: 12.018,25.820,63.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.076 | Acc: 12.097,25.869,63.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.074 | Acc: 12.189,25.876,63.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.077 | Acc: 12.181,25.770,63.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.076 | Acc: 12.083,25.640,63.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.075 | Acc: 12.108,25.603,63.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.079 | Acc: 12.153,25.629,63.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.079 | Acc: 12.208,25.628,63.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.082 | Acc: 12.217,25.553,63.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.083 | Acc: 12.186,25.579,63.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.085 | Acc: 12.113,25.603,62.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.086 | Acc: 12.097,25.643,63.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.086 | Acc: 12.090,25.656,62.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.381 | Acc: 14.062,25.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.583 | Acc: 9.338,20.833,53.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.590 | Acc: 9.775,20.808,53.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.605 | Acc: 9.682,20.966,52.920,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 2.119 | Acc: 10.156,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 11.719,26.228,65.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.007 | Acc: 11.757,25.743,65.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 11.693,26.153,65.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.026 | Acc: 11.883,25.685,65.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.035 | Acc: 11.688,25.503,64.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.048 | Acc: 11.893,25.555,64.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.051 | Acc: 12.195,25.670,64.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.050 | Acc: 12.257,25.951,64.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.049 | Acc: 12.245,25.932,64.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.054 | Acc: 12.337,25.983,64.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.054 | Acc: 12.426,26.050,64.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.054 | Acc: 12.448,26.076,64.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.055 | Acc: 12.341,25.880,64.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.057 | Acc: 12.367,25.929,64.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.056 | Acc: 12.336,25.986,64.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.057 | Acc: 12.325,25.927,64.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.061 | Acc: 12.280,25.903,63.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.063 | Acc: 12.301,25.885,63.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.067 | Acc: 12.295,25.818,63.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.467 | Acc: 10.938,23.438,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.529 | Acc: 11.272,22.545,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 11.338,22.389,53.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.554 | Acc: 11.539,22.029,53.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 2.134 | Acc: 7.031,18.750,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.031 | Acc: 12.686,26.042,64.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 12.843,26.372,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 12.884,26.678,65.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.009 | Acc: 12.828,26.562,65.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.019 | Acc: 13.034,26.694,64.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.025 | Acc: 12.874,26.401,64.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.021 | Acc: 12.722,26.092,64.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.028 | Acc: 12.772,25.917,64.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.028 | Acc: 12.802,25.893,64.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.030 | Acc: 12.757,25.773,64.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.031 | Acc: 12.758,25.827,64.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.035 | Acc: 12.746,25.820,64.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.041 | Acc: 12.674,25.724,64.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.045 | Acc: 12.692,25.784,64.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.047 | Acc: 12.713,25.799,64.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.050 | Acc: 12.683,25.708,64.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.051 | Acc: 12.770,25.795,64.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.053 | Acc: 12.775,25.855,64.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.052 | Acc: 12.785,25.904,64.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.511 | Acc: 12.500,21.875,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.630 | Acc: 10.082,22.247,52.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.672 | Acc: 10.309,22.694,51.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.695 | Acc: 10.336,22.323,50.832,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 2.306 | Acc: 11.719,30.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.967 | Acc: 13.467,27.344,66.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.981 | Acc: 13.434,26.658,65.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 13.409,26.652,65.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.979 | Acc: 13.310,26.698,65.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.996 | Acc: 13.119,26.369,65.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.993 | Acc: 13.075,26.530,65.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.001 | Acc: 13.010,26.452,65.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.005 | Acc: 12.990,26.300,65.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.009 | Acc: 12.841,26.230,64.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.013 | Acc: 12.850,26.294,64.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.016 | Acc: 12.723,26.174,64.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.019 | Acc: 12.808,26.161,64.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.022 | Acc: 12.811,26.278,64.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.024 | Acc: 12.803,26.307,64.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.023 | Acc: 12.850,26.456,64.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.024 | Acc: 12.841,26.409,64.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.028 | Acc: 12.798,26.393,64.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.033 | Acc: 12.822,26.298,64.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.037 | Acc: 12.853,26.269,64.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.364 | Acc: 15.625,25.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.541 | Acc: 12.128,22.768,53.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.566 | Acc: 12.386,22.885,53.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.566 | Acc: 12.718,22.528,52.882,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 1.934 | Acc: 12.500,24.219,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.019 | Acc: 12.314,25.595,65.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 12.691,26.067,65.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 13.012,26.652,65.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.969 | Acc: 13.436,26.399,65.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.968 | Acc: 13.188,26.284,65.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.978 | Acc: 13.049,26.207,65.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.984 | Acc: 12.893,26.208,65.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.987 | Acc: 12.762,26.160,65.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.991 | Acc: 12.893,26.273,65.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.998 | Acc: 12.838,26.294,64.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.002 | Acc: 12.892,26.280,64.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.004 | Acc: 12.860,26.326,64.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.009 | Acc: 12.847,26.314,64.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.008 | Acc: 12.884,26.360,64.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.007 | Acc: 12.970,26.492,64.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.007 | Acc: 12.921,26.402,64.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.009 | Acc: 12.915,26.379,64.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.011 | Acc: 12.946,26.344,64.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.012 | Acc: 12.949,26.398,64.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.168 | Acc: 17.188,28.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.423 | Acc: 11.644,23.363,56.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.430 | Acc: 11.433,23.780,56.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.433 | Acc: 11.475,23.066,55.751,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 2.152 | Acc: 11.719,24.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.991 | Acc: 12.909,26.190,66.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.971 | Acc: 13.415,26.791,66.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 13.665,26.601,65.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.977 | Acc: 13.513,26.505,65.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.981 | Acc: 13.529,26.733,65.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.978 | Acc: 13.514,26.821,65.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.979 | Acc: 13.414,27.028,65.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.986 | Acc: 13.301,26.820,65.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.992 | Acc: 13.346,26.847,65.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.994 | Acc: 13.421,26.796,65.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.997 | Acc: 13.373,26.768,65.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.998 | Acc: 13.379,26.822,65.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.997 | Acc: 13.347,26.841,65.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.996 | Acc: 13.334,26.866,65.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.999 | Acc: 13.328,26.874,65.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.001 | Acc: 13.376,26.808,65.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.002 | Acc: 13.405,26.842,65.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.003 | Acc: 13.379,26.798,64.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.006 | Acc: 13.347,26.784,64.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.461 | Acc: 10.156,22.656,53.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 9.859,23.549,54.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.509 | Acc: 9.356,23.399,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.503 | Acc: 9.823,23.527,54.828,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 2.344 | Acc: 18.750,24.219,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.948 | Acc: 13.839,26.749,65.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 13.300,26.715,65.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.955 | Acc: 13.358,26.908,65.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.954 | Acc: 13.358,26.929,65.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.953 | Acc: 13.173,26.795,65.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.946 | Acc: 13.178,26.918,65.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.948 | Acc: 13.115,26.773,65.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.956 | Acc: 13.160,26.791,65.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.964 | Acc: 13.264,26.683,65.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.973 | Acc: 13.301,26.625,65.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.974 | Acc: 13.384,26.679,65.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.981 | Acc: 13.379,26.660,65.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.981 | Acc: 13.467,26.700,65.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.983 | Acc: 13.468,26.688,65.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.985 | Acc: 13.416,26.614,65.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.988 | Acc: 13.430,26.577,65.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.988 | Acc: 13.513,26.608,65.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.991 | Acc: 13.528,26.608,65.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.994 | Acc: 13.531,26.558,65.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.584 | Acc: 14.844,28.906,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.538 | Acc: 12.686,24.368,53.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.557 | Acc: 13.091,24.905,53.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.570 | Acc: 13.179,24.590,52.959,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 2.043 | Acc: 12.500,25.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.907 | Acc: 13.616,26.004,67.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 13.986,26.696,67.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.895 | Acc: 14.293,27.651,67.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.921 | Acc: 13.937,27.267,66.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.926 | Acc: 13.645,26.880,66.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.927 | Acc: 13.778,26.898,66.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.935 | Acc: 13.896,26.812,66.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.940 | Acc: 13.854,26.839,66.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.945 | Acc: 13.799,26.809,66.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.943 | Acc: 13.841,26.951,66.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.950 | Acc: 13.829,26.859,66.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.954 | Acc: 13.797,26.776,66.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.959 | Acc: 13.826,26.814,66.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.965 | Acc: 13.854,26.743,66.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.967 | Acc: 13.806,26.731,66.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.972 | Acc: 13.758,26.636,65.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.974 | Acc: 13.719,26.590,65.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.976 | Acc: 13.705,26.545,65.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.975 | Acc: 13.730,26.521,65.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.289 | Acc: 13.281,25.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.446 | Acc: 11.198,24.740,55.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.441 | Acc: 11.757,25.133,55.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.445 | Acc: 11.975,24.834,55.341,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 2.201 | Acc: 8.594,17.969,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.915 | Acc: 13.356,28.869,66.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.894 | Acc: 13.834,28.716,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.920 | Acc: 13.345,27.805,67.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.930 | Acc: 13.744,27.701,66.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.932 | Acc: 13.707,27.491,66.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.926 | Acc: 13.617,27.460,67.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.934 | Acc: 13.680,27.227,66.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.941 | Acc: 13.844,27.116,66.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.947 | Acc: 13.782,26.968,66.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.952 | Acc: 13.752,26.990,66.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.956 | Acc: 13.932,26.958,66.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.953 | Acc: 13.959,26.955,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.956 | Acc: 14.039,26.937,66.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.959 | Acc: 14.012,26.946,66.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.963 | Acc: 13.992,26.931,66.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.965 | Acc: 13.960,26.842,66.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.966 | Acc: 13.996,26.833,65.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.967 | Acc: 13.956,26.848,65.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.968 | Acc: 14.030,26.903,65.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.350 | Acc: 12.500,27.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.534 | Acc: 11.830,22.842,53.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.540 | Acc: 12.024,22.466,53.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.548 | Acc: 11.885,22.182,53.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 1.661 | Acc: 7.812,25.781,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.887 | Acc: 15.067,27.493,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.895 | Acc: 14.939,27.611,67.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.919 | Acc: 14.421,27.011,66.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.914 | Acc: 14.458,26.842,67.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.911 | Acc: 14.550,27.135,67.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.907 | Acc: 14.437,27.240,67.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.916 | Acc: 14.423,27.150,67.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.922 | Acc: 14.325,27.222,66.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.921 | Acc: 14.408,27.305,66.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.929 | Acc: 14.358,27.107,66.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.927 | Acc: 14.338,27.252,66.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.932 | Acc: 14.225,27.068,66.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.932 | Acc: 14.248,27.017,66.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.936 | Acc: 14.274,26.968,66.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.939 | Acc: 14.197,26.851,66.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.942 | Acc: 14.189,26.847,66.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.946 | Acc: 14.214,26.908,66.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.949 | Acc: 14.207,26.915,66.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.952 | Acc: 14.220,26.882,66.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.422 | Acc: 14.062,28.125,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.527 | Acc: 12.872,24.330,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.536 | Acc: 13.396,24.848,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.536 | Acc: 13.794,24.936,54.457,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 1.648 | Acc: 14.062,31.250,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.888 | Acc: 13.095,26.935,67.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.896 | Acc: 14.043,27.382,67.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.896 | Acc: 14.139,27.626,67.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.889 | Acc: 13.850,27.479,67.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.898 | Acc: 14.124,27.344,67.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.907 | Acc: 14.166,27.169,67.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.909 | Acc: 13.968,27.094,67.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.914 | Acc: 13.995,27.111,67.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.918 | Acc: 13.998,26.985,66.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.921 | Acc: 13.989,27.021,66.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.922 | Acc: 14.094,27.068,66.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.922 | Acc: 14.144,27.084,66.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.926 | Acc: 14.176,27.068,66.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.927 | Acc: 14.199,27.035,66.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.931 | Acc: 14.270,27.025,66.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.932 | Acc: 14.294,27.066,66.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.932 | Acc: 14.282,27.085,66.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.933 | Acc: 14.307,27.067,66.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.939 | Acc: 14.280,27.024,66.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.330 | Acc: 10.938,25.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.466 | Acc: 10.528,22.619,55.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 10.252,22.351,55.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.481 | Acc: 10.105,21.965,55.533,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 1.824 | Acc: 11.719,25.781,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.882 | Acc: 15.067,28.385,67.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.871 | Acc: 14.768,28.354,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.873 | Acc: 14.613,28.112,68.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.875 | Acc: 14.680,28.154,68.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.887 | Acc: 14.728,27.785,67.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.887 | Acc: 14.876,27.912,67.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.883 | Acc: 14.733,28.031,68.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.886 | Acc: 14.829,27.999,67.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.890 | Acc: 14.744,27.901,67.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.891 | Acc: 14.782,27.771,67.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.898 | Acc: 14.773,27.694,67.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.904 | Acc: 14.695,27.655,67.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.907 | Acc: 14.706,27.688,67.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.910 | Acc: 14.699,27.708,67.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.913 | Acc: 14.672,27.715,67.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.914 | Acc: 14.737,27.755,67.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.916 | Acc: 14.748,27.662,67.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.917 | Acc: 14.727,27.619,67.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.920 | Acc: 14.663,27.508,67.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.314 | Acc: 17.969,27.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.333 | Acc: 12.984,24.963,57.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.372 | Acc: 13.529,25.267,56.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.374 | Acc: 13.806,24.872,56.737,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 1.828 | Acc: 14.844,21.875,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 14.174,26.116,68.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.855 | Acc: 14.558,27.153,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.853 | Acc: 15.177,27.933,68.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.853 | Acc: 15.278,27.942,69.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.865 | Acc: 15.084,27.792,68.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.871 | Acc: 15.044,27.712,68.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.873 | Acc: 14.999,27.610,68.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.881 | Acc: 14.951,27.504,68.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.885 | Acc: 14.917,27.426,68.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.890 | Acc: 14.848,27.320,67.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.892 | Acc: 14.837,27.390,67.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.897 | Acc: 14.944,27.503,67.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.897 | Acc: 14.907,27.440,67.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.900 | Acc: 14.888,27.502,67.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.903 | Acc: 14.890,27.518,67.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.907 | Acc: 14.858,27.514,67.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.908 | Acc: 14.798,27.445,67.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.910 | Acc: 14.837,27.487,67.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.918 | Acc: 14.827,27.446,67.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.187 | Acc: 19.531,23.438,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.276 | Acc: 13.058,25.707,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.295 | Acc: 13.415,25.686,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.301 | Acc: 13.614,25.448,58.888,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 2.010 | Acc: 20.312,32.812,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.827 | Acc: 15.327,27.902,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.850 | Acc: 14.844,27.420,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.849 | Acc: 14.869,27.971,68.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.833 | Acc: 14.988,28.154,69.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.829 | Acc: 15.099,28.264,69.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.835 | Acc: 14.844,27.763,69.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.846 | Acc: 14.877,27.610,69.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.849 | Acc: 14.873,27.747,69.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.856 | Acc: 14.969,27.741,68.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.859 | Acc: 14.960,27.872,68.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.866 | Acc: 15.045,27.980,68.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.870 | Acc: 14.957,27.879,68.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.876 | Acc: 14.886,27.883,68.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.884 | Acc: 14.847,27.839,67.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.887 | Acc: 14.826,27.850,67.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.888 | Acc: 14.871,27.886,67.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.890 | Acc: 14.862,27.836,67.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.893 | Acc: 14.822,27.820,67.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.898 | Acc: 14.829,27.844,67.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.266 | Acc: 16.406,29.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.355 | Acc: 12.946,26.935,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 13.053,26.429,58.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.396 | Acc: 13.051,26.396,57.928,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 1.695 | Acc: 14.844,25.781,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.856 | Acc: 14.844,27.790,70.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.864 | Acc: 15.130,27.839,69.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.852 | Acc: 15.266,28.291,69.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.845 | Acc: 15.490,28.212,69.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.856 | Acc: 15.501,28.218,68.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.874 | Acc: 15.360,27.931,68.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.870 | Acc: 15.309,27.931,68.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.875 | Acc: 15.373,27.785,68.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.882 | Acc: 15.185,27.853,68.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.882 | Acc: 15.061,27.697,68.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.883 | Acc: 15.024,27.506,68.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.892 | Acc: 14.931,27.399,68.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.896 | Acc: 14.841,27.398,67.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.899 | Acc: 14.788,27.347,67.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.901 | Acc: 14.815,27.383,67.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.904 | Acc: 14.832,27.417,67.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.906 | Acc: 14.908,27.502,67.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.907 | Acc: 14.987,27.454,67.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.909 | Acc: 15.010,27.469,67.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.238 | Acc: 14.844,25.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.267 | Acc: 13.058,24.330,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.289 | Acc: 12.919,24.466,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.298 | Acc: 12.705,24.232,58.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 1.629 | Acc: 15.625,36.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.786 | Acc: 14.658,28.088,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.810 | Acc: 14.348,27.287,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.825 | Acc: 14.447,27.856,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.835 | Acc: 14.477,27.730,69.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.835 | Acc: 14.898,28.048,69.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.848 | Acc: 15.031,28.170,69.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.850 | Acc: 15.027,28.142,68.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.856 | Acc: 15.101,27.921,68.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.855 | Acc: 15.224,27.866,68.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.855 | Acc: 15.287,27.907,68.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.860 | Acc: 15.378,27.874,68.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.860 | Acc: 15.463,27.875,68.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.862 | Acc: 15.415,27.823,68.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.864 | Acc: 15.453,27.761,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.873 | Acc: 15.378,27.637,68.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.877 | Acc: 15.457,27.670,68.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.880 | Acc: 15.474,27.770,68.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.880 | Acc: 15.430,27.735,68.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.882 | Acc: 15.438,27.717,68.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.337 | Acc: 14.062,25.781,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.286 | Acc: 12.463,24.702,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.303 | Acc: 11.947,24.505,59.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.316 | Acc: 12.090,23.975,58.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 1.795 | Acc: 15.625,27.344,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.736 | Acc: 15.439,27.493,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.782 | Acc: 14.672,26.258,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 14.613,26.857,70.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.797 | Acc: 14.834,27.247,69.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.811 | Acc: 15.161,27.367,69.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.819 | Acc: 15.096,27.537,69.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.822 | Acc: 15.054,27.482,69.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.831 | Acc: 15.033,27.494,68.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.833 | Acc: 15.085,27.478,68.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.836 | Acc: 15.100,27.402,68.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.840 | Acc: 15.074,27.503,68.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.842 | Acc: 15.148,27.613,68.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.846 | Acc: 15.155,27.598,68.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.849 | Acc: 15.225,27.583,68.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.855 | Acc: 15.249,27.583,68.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.856 | Acc: 15.287,27.643,68.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.859 | Acc: 15.270,27.644,68.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.859 | Acc: 15.253,27.690,68.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.864 | Acc: 15.209,27.688,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.729 | Acc: 14.062,23.438,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.629 | Acc: 12.463,23.549,53.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.622 | Acc: 12.691,23.685,52.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.636 | Acc: 12.551,23.297,52.088,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 1.933 | Acc: 17.188,25.781,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.800 | Acc: 15.067,28.013,70.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.808 | Acc: 15.225,28.430,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.823 | Acc: 15.433,28.138,69.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.832 | Acc: 15.480,27.980,69.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.833 | Acc: 15.664,28.434,69.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.837 | Acc: 15.528,28.235,69.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.843 | Acc: 15.481,28.047,69.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.848 | Acc: 15.421,28.241,68.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.849 | Acc: 15.491,28.233,68.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.850 | Acc: 15.365,28.106,68.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.848 | Acc: 15.310,28.224,69.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.847 | Acc: 15.259,28.248,69.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.848 | Acc: 15.191,28.203,68.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.857 | Acc: 15.289,28.217,68.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.858 | Acc: 15.251,28.268,68.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.861 | Acc: 15.289,28.288,68.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.861 | Acc: 15.410,28.354,68.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.863 | Acc: 15.406,28.298,68.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.865 | Acc: 15.455,28.254,68.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.237 | Acc: 13.281,30.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.421 | Acc: 12.314,24.330,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.414 | Acc: 12.652,24.466,56.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.420 | Acc: 12.705,24.462,56.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 2.002 | Acc: 18.750,32.031,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.851 | Acc: 14.955,28.013,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.828 | Acc: 15.263,27.649,69.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.828 | Acc: 15.215,28.023,69.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.827 | Acc: 15.287,28.308,69.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.829 | Acc: 15.238,28.434,69.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.828 | Acc: 15.283,28.616,69.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.836 | Acc: 15.553,28.502,69.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.839 | Acc: 15.538,28.499,69.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.838 | Acc: 15.552,28.466,69.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.836 | Acc: 15.625,28.397,69.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.841 | Acc: 15.522,28.277,69.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.844 | Acc: 15.482,28.258,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.845 | Acc: 15.478,28.335,68.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.850 | Acc: 15.422,28.144,68.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.850 | Acc: 15.467,28.257,68.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.850 | Acc: 15.547,28.222,68.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.853 | Acc: 15.575,28.262,68.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.854 | Acc: 15.582,28.257,68.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.853 | Acc: 15.549,28.184,68.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.326 | Acc: 13.281,28.125,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.327 | Acc: 12.388,24.591,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.374 | Acc: 12.900,24.581,57.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.394 | Acc: 12.769,24.565,57.326,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 1.898 | Acc: 16.406,33.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.781 | Acc: 16.369,28.274,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.790 | Acc: 16.082,28.163,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.770 | Acc: 16.099,28.804,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.769 | Acc: 16.107,29.061,71.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.781 | Acc: 15.965,28.628,70.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.792 | Acc: 15.819,28.441,70.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.794 | Acc: 15.824,28.430,70.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.790 | Acc: 15.761,28.377,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.797 | Acc: 15.785,28.354,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.803 | Acc: 15.753,28.347,69.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.807 | Acc: 15.819,28.372,69.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.815 | Acc: 15.852,28.268,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.817 | Acc: 15.844,28.287,69.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.822 | Acc: 15.847,28.286,69.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.827 | Acc: 15.820,28.312,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.833 | Acc: 15.798,28.232,68.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.837 | Acc: 15.749,28.189,68.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.840 | Acc: 15.740,28.196,68.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.844 | Acc: 15.734,28.146,68.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.327 | Acc: 14.844,28.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.287 | Acc: 13.207,26.674,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.311 | Acc: 13.681,26.391,59.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.328 | Acc: 13.665,25.948,59.298,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 1.852 | Acc: 17.969,28.125,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.779 | Acc: 15.662,28.423,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.776 | Acc: 15.130,27.992,70.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 15.497,28.227,70.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.772 | Acc: 15.741,28.395,70.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.782 | Acc: 16.089,28.496,70.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.791 | Acc: 16.077,28.338,70.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.797 | Acc: 15.969,28.252,70.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.796 | Acc: 15.858,28.305,70.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.799 | Acc: 15.979,28.397,70.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.807 | Acc: 15.878,28.269,69.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.816 | Acc: 15.901,28.394,69.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.820 | Acc: 15.926,28.264,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.818 | Acc: 16.011,28.332,69.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 15.981,28.439,69.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.825 | Acc: 15.939,28.499,69.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.828 | Acc: 15.893,28.480,69.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.830 | Acc: 15.927,28.615,69.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.833 | Acc: 15.904,28.599,69.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.833 | Acc: 15.955,28.724,69.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.263 | Acc: 15.625,24.219,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.379 | Acc: 12.165,23.438,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.415 | Acc: 12.767,23.266,56.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.409 | Acc: 12.577,23.117,57.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 1.655 | Acc: 19.531,27.344,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.726 | Acc: 16.183,28.646,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.734 | Acc: 16.254,29.249,72.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.765 | Acc: 16.150,28.471,71.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.768 | Acc: 16.194,28.183,71.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.771 | Acc: 16.058,28.086,70.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 15.916,28.067,70.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.785 | Acc: 15.957,28.086,70.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.790 | Acc: 15.906,28.086,70.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.795 | Acc: 16.044,28.177,70.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.799 | Acc: 16.126,28.292,70.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.803 | Acc: 16.141,28.344,69.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.808 | Acc: 16.124,28.423,69.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.811 | Acc: 16.107,28.373,69.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.807 | Acc: 16.148,28.367,69.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.812 | Acc: 16.061,28.327,69.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.814 | Acc: 16.078,28.276,69.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.816 | Acc: 16.138,28.299,69.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.821 | Acc: 16.131,28.268,69.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.823 | Acc: 16.097,28.330,69.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.212 | Acc: 15.625,30.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.458 | Acc: 13.616,26.525,56.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.470 | Acc: 13.986,26.239,55.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.465 | Acc: 14.203,26.524,55.776,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 1.780 | Acc: 17.188,32.812,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.762 | Acc: 17.894,30.283,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.768 | Acc: 16.749,29.421,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 16.534,29.649,71.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.775 | Acc: 16.541,29.427,71.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.763 | Acc: 16.607,29.045,71.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.761 | Acc: 16.355,28.835,71.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.767 | Acc: 16.323,28.751,70.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 16.280,28.848,70.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.780 | Acc: 16.320,28.850,70.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.787 | Acc: 16.332,28.759,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.794 | Acc: 16.307,28.687,70.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.794 | Acc: 16.387,28.728,70.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.799 | Acc: 16.307,28.661,70.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.804 | Acc: 16.312,28.667,69.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.810 | Acc: 16.261,28.538,69.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.812 | Acc: 16.260,28.570,69.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.814 | Acc: 16.225,28.567,69.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.817 | Acc: 16.149,28.566,69.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.817 | Acc: 16.154,28.584,69.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.196 | Acc: 16.406,23.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.344 | Acc: 13.170,23.958,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.347 | Acc: 13.948,24.733,58.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.336 | Acc: 13.986,24.654,58.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 1.828 | Acc: 18.750,29.688,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.732 | Acc: 16.071,30.320,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.766 | Acc: 15.987,28.735,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 16.419,28.829,70.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.764 | Acc: 16.368,29.118,71.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.767 | Acc: 16.190,29.123,71.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.763 | Acc: 16.322,29.197,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.771 | Acc: 16.478,29.272,70.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.779 | Acc: 16.421,29.115,70.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.785 | Acc: 16.393,28.941,70.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.789 | Acc: 16.286,28.867,70.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.795 | Acc: 16.233,28.821,69.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.795 | Acc: 16.234,28.903,70.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.798 | Acc: 16.251,28.942,69.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.802 | Acc: 16.237,29.040,69.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.804 | Acc: 16.297,29.070,69.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.808 | Acc: 16.212,28.994,69.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.810 | Acc: 16.312,29.108,69.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.811 | Acc: 16.348,29.131,69.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.812 | Acc: 16.402,29.167,69.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.422 | Acc: 15.625,27.344,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 12.760,25.037,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.493 | Acc: 12.767,24.714,54.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 12.961,24.334,55.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.718 | Acc: 10.938,23.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.756 | Acc: 17.039,29.464,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 16.273,29.364,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.756 | Acc: 16.381,29.201,71.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.761 | Acc: 16.213,29.225,71.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.761 | Acc: 15.965,29.162,71.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.770 | Acc: 15.851,29.152,70.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.781 | Acc: 15.874,29.012,70.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.784 | Acc: 15.965,29.231,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.781 | Acc: 16.216,29.234,70.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.785 | Acc: 16.336,29.361,70.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.786 | Acc: 16.339,29.221,70.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.787 | Acc: 16.351,29.179,70.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.789 | Acc: 16.403,29.179,70.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.790 | Acc: 16.431,29.229,70.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.791 | Acc: 16.448,29.200,70.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.793 | Acc: 16.526,29.279,69.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.800 | Acc: 16.537,29.209,69.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.805 | Acc: 16.456,29.086,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.806 | Acc: 16.480,29.037,69.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.421 | Acc: 18.750,28.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.408 | Acc: 14.323,26.674,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.417 | Acc: 14.710,26.753,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.410 | Acc: 14.652,26.255,58.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 1.742 | Acc: 15.625,30.469,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.776 | Acc: 15.476,29.204,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.756 | Acc: 15.930,28.868,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.770 | Acc: 16.445,29.278,70.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.782 | Acc: 16.300,29.379,70.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.790 | Acc: 16.228,29.231,70.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.786 | Acc: 16.348,29.442,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.789 | Acc: 16.390,29.532,70.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.781 | Acc: 16.309,29.668,70.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.783 | Acc: 16.277,29.536,70.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.782 | Acc: 16.262,29.470,70.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.782 | Acc: 16.198,29.426,70.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.783 | Acc: 16.140,29.376,70.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.781 | Acc: 16.221,29.259,70.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.781 | Acc: 16.298,29.307,70.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.785 | Acc: 16.258,29.280,70.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.788 | Acc: 16.287,29.228,70.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.789 | Acc: 16.379,29.348,70.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.791 | Acc: 16.372,29.465,70.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.793 | Acc: 16.308,29.374,70.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.242 | Acc: 14.844,29.688,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.486 | Acc: 13.765,24.554,55.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 13.948,25.095,55.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.455 | Acc: 14.101,25.077,55.405,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 1.521 | Acc: 24.219,35.156,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.720 | Acc: 18.080,28.311,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.715 | Acc: 16.921,28.868,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.716 | Acc: 16.688,28.957,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.719 | Acc: 16.782,29.225,71.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.733 | Acc: 16.739,29.146,71.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.739 | Acc: 16.497,28.926,71.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.741 | Acc: 16.390,29.222,71.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.748 | Acc: 16.280,29.227,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.755 | Acc: 16.303,29.295,71.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.757 | Acc: 16.356,29.264,71.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.759 | Acc: 16.424,29.316,71.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.767 | Acc: 16.393,29.253,70.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.768 | Acc: 16.514,29.316,70.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.769 | Acc: 16.565,29.304,70.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.775 | Acc: 16.546,29.353,70.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.779 | Acc: 16.528,29.322,70.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.785 | Acc: 16.486,29.254,70.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.788 | Acc: 16.456,29.220,70.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.791 | Acc: 16.474,29.152,70.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.296 | Acc: 18.750,27.344,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.228 | Acc: 14.286,26.190,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.263 | Acc: 14.863,26.562,60.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.273 | Acc: 14.626,26.447,59.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 1.815 | Acc: 19.531,34.375,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.723 | Acc: 17.411,30.246,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.714 | Acc: 17.168,29.840,72.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.712 | Acc: 17.533,30.085,72.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.719 | Acc: 17.419,30.035,72.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.726 | Acc: 17.048,30.159,72.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.732 | Acc: 17.045,29.939,71.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.737 | Acc: 16.894,29.748,71.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.740 | Acc: 16.780,29.639,71.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.746 | Acc: 16.734,29.515,71.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.753 | Acc: 16.690,29.377,71.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 16.622,29.292,71.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.758 | Acc: 16.610,29.227,71.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.762 | Acc: 16.607,29.241,70.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 16.681,29.290,70.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.769 | Acc: 16.731,29.275,70.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.775 | Acc: 16.723,29.196,70.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.777 | Acc: 16.759,29.193,70.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.780 | Acc: 16.722,29.183,70.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.785 | Acc: 16.652,29.117,70.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.185 | Acc: 15.625,31.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.362 | Acc: 14.211,25.186,56.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.371 | Acc: 13.853,25.210,56.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.375 | Acc: 14.165,24.974,57.441,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 1.667 | Acc: 11.719,22.656,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.772 | Acc: 16.555,29.129,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.754 | Acc: 16.883,29.192,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.763 | Acc: 16.675,28.381,71.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.749 | Acc: 16.744,28.762,71.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.741 | Acc: 16.646,28.721,71.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.747 | Acc: 16.568,28.693,71.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.750 | Acc: 16.838,29.084,71.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 16.828,29.037,71.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.756 | Acc: 16.752,28.893,71.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.758 | Acc: 16.880,28.945,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.758 | Acc: 16.912,29.062,71.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.760 | Acc: 16.857,28.841,70.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.762 | Acc: 16.936,28.921,70.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.765 | Acc: 16.887,28.903,70.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.769 | Acc: 16.835,28.917,70.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.772 | Acc: 16.786,28.899,70.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.771 | Acc: 16.864,29.023,70.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.772 | Acc: 16.863,29.082,70.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.775 | Acc: 16.808,29.054,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.323 | Acc: 11.719,24.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.439 | Acc: 11.049,23.549,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.454 | Acc: 11.261,23.037,57.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.467 | Acc: 11.527,22.618,56.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 1.599 | Acc: 19.531,27.344,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.723 | Acc: 17.262,29.501,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.740 | Acc: 16.959,28.773,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.727 | Acc: 16.406,28.983,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.725 | Acc: 16.445,28.829,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.732 | Acc: 16.507,29.146,71.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.730 | Acc: 16.613,29.313,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.736 | Acc: 16.728,29.410,71.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.736 | Acc: 16.736,29.362,71.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.743 | Acc: 16.622,29.334,71.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.743 | Acc: 16.717,29.345,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.742 | Acc: 16.777,29.383,71.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.744 | Acc: 16.844,29.350,71.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 16.867,29.328,71.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.747 | Acc: 16.812,29.295,71.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.751 | Acc: 16.780,29.353,71.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.752 | Acc: 16.798,29.434,71.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.755 | Acc: 16.771,29.429,71.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.759 | Acc: 16.714,29.380,70.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.762 | Acc: 16.681,29.335,70.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.269 | Acc: 17.188,33.594,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.372 | Acc: 13.914,25.372,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.378 | Acc: 14.177,25.171,58.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.397 | Acc: 13.947,25.205,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 1.795 | Acc: 14.062,21.875,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.694 | Acc: 16.667,28.497,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 16.883,29.173,72.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.694 | Acc: 16.957,29.355,72.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.702 | Acc: 16.879,29.389,72.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.713 | Acc: 16.855,29.386,71.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 16.781,29.223,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.722 | Acc: 16.683,29.100,71.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.732 | Acc: 16.712,29.081,71.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.739 | Acc: 16.881,29.152,71.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.742 | Acc: 16.923,29.310,71.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.747 | Acc: 16.795,29.210,70.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.752 | Acc: 16.834,29.237,70.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.756 | Acc: 16.858,29.224,70.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.757 | Acc: 16.865,29.351,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.757 | Acc: 16.886,29.259,70.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.762 | Acc: 16.951,29.330,70.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.763 | Acc: 17.027,29.424,70.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.762 | Acc: 17.034,29.495,70.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.767 | Acc: 16.954,29.427,70.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.347 | Acc: 14.844,28.906,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 14.174,25.074,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.490 | Acc: 14.634,25.171,56.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 14.741,24.859,56.545,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 1.597 | Acc: 18.750,30.469,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.704 | Acc: 17.597,29.948,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.689 | Acc: 16.997,29.707,73.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.694 | Acc: 16.778,29.854,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.685 | Acc: 17.081,29.986,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.700 | Acc: 17.164,30.183,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.710 | Acc: 17.091,30.133,72.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.717 | Acc: 17.132,29.909,72.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.721 | Acc: 17.241,29.882,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.725 | Acc: 17.308,29.951,71.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.731 | Acc: 17.184,29.917,71.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.733 | Acc: 17.152,29.815,71.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.734 | Acc: 17.045,29.720,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.736 | Acc: 17.074,29.577,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.739 | Acc: 17.062,29.512,71.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.741 | Acc: 17.066,29.485,71.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.744 | Acc: 17.097,29.573,71.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.744 | Acc: 17.100,29.587,71.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.748 | Acc: 17.097,29.601,71.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.748 | Acc: 17.136,29.653,71.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.463 | Acc: 13.281,23.438,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.467 | Acc: 13.839,23.214,56.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 13.700,23.476,56.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.455 | Acc: 13.781,23.732,56.660,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 1.574 | Acc: 20.312,36.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 17.336,30.804,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.668 | Acc: 17.588,30.450,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.676 | Acc: 17.444,30.674,73.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.683 | Acc: 17.805,30.662,72.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.695 | Acc: 17.729,30.453,72.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.694 | Acc: 17.517,30.320,72.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.696 | Acc: 17.431,30.280,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.704 | Acc: 17.299,30.066,72.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.709 | Acc: 17.343,30.020,72.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.714 | Acc: 17.374,30.100,72.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.715 | Acc: 17.340,29.953,72.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.717 | Acc: 17.333,30.057,71.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.723 | Acc: 17.430,30.098,71.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.725 | Acc: 17.429,30.132,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.730 | Acc: 17.429,30.059,71.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.730 | Acc: 17.346,29.960,71.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.733 | Acc: 17.249,29.891,71.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.734 | Acc: 17.246,29.861,71.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.737 | Acc: 17.251,29.753,71.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.482 | Acc: 13.281,27.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.581 | Acc: 12.351,24.740,54.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.548 | Acc: 12.500,25.400,54.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.547 | Acc: 12.769,24.910,54.944,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 1.731 | Acc: 13.281,29.688,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.679 | Acc: 17.076,29.911,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.676 | Acc: 17.626,30.640,73.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.668 | Acc: 17.341,30.443,73.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.689 | Acc: 17.294,30.208,72.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.686 | Acc: 17.536,30.631,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.699 | Acc: 17.504,30.443,72.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.700 | Acc: 17.387,30.236,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.696 | Acc: 17.406,30.377,72.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.698 | Acc: 17.533,30.434,72.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 17.483,30.271,72.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.707 | Acc: 17.435,30.264,72.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.710 | Acc: 17.405,30.161,72.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.714 | Acc: 17.496,30.262,71.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.717 | Acc: 17.454,30.205,71.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.719 | Acc: 17.354,30.186,71.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.720 | Acc: 17.299,30.050,71.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.725 | Acc: 17.293,30.015,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.727 | Acc: 17.205,30.014,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.729 | Acc: 17.142,30.024,71.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.140 | Acc: 17.188,28.906,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.245 | Acc: 14.062,27.195,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.287 | Acc: 14.405,26.944,60.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.292 | Acc: 14.267,26.562,60.233,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 1.572 | Acc: 17.188,35.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.695 | Acc: 17.485,30.171,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.672 | Acc: 17.835,29.973,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.673 | Acc: 17.674,29.841,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 17.728,29.919,72.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 17.899,29.889,72.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.680 | Acc: 17.749,29.888,72.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.684 | Acc: 17.636,29.682,72.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.688 | Acc: 17.571,29.901,72.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.691 | Acc: 17.641,29.955,72.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.703 | Acc: 17.553,29.734,71.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.703 | Acc: 17.400,29.670,71.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.709 | Acc: 17.369,29.584,71.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.713 | Acc: 17.280,29.637,71.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.719 | Acc: 17.304,29.674,71.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.722 | Acc: 17.343,29.734,71.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 17.341,29.675,71.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.727 | Acc: 17.364,29.699,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.729 | Acc: 17.400,29.726,71.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.731 | Acc: 17.386,29.755,71.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.276 | Acc: 17.969,31.250,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.344 | Acc: 14.546,25.632,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.366 | Acc: 14.958,26.258,57.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.361 | Acc: 15.164,26.345,57.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.614 | Acc: 19.531,22.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.655 | Acc: 17.932,30.990,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.656 | Acc: 17.302,30.869,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.651 | Acc: 17.546,30.943,74.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.651 | Acc: 17.535,30.739,73.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.653 | Acc: 17.582,30.678,73.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.666 | Acc: 17.330,30.436,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.674 | Acc: 17.210,30.247,73.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.682 | Acc: 17.386,30.207,73.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.688 | Acc: 17.451,30.296,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.693 | Acc: 17.440,30.298,72.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.697 | Acc: 17.442,30.465,72.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 17.470,30.543,72.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.707 | Acc: 17.451,30.454,72.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.711 | Acc: 17.493,30.488,72.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.712 | Acc: 17.535,30.531,72.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.715 | Acc: 17.506,30.510,72.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.721 | Acc: 17.465,30.462,71.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.728 | Acc: 17.419,30.337,71.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.730 | Acc: 17.462,30.358,71.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.393 | Acc: 16.406,26.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.286 | Acc: 14.583,25.558,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.301 | Acc: 14.520,25.038,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.307 | Acc: 14.395,25.115,59.413,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 1.862 | Acc: 16.406,32.031,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.677 | Acc: 18.043,30.952,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.640 | Acc: 17.569,30.335,74.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.662 | Acc: 17.482,30.251,73.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.667 | Acc: 17.708,30.305,73.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.674 | Acc: 17.597,30.306,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.673 | Acc: 17.930,30.430,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.678 | Acc: 17.897,30.419,72.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.686 | Acc: 17.804,30.430,72.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.694 | Acc: 17.861,30.369,72.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.702 | Acc: 17.771,30.298,72.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.703 | Acc: 17.753,30.437,72.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.705 | Acc: 17.758,30.433,72.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.707 | Acc: 17.759,30.520,71.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.712 | Acc: 17.621,30.435,71.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.713 | Acc: 17.515,30.329,71.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.716 | Acc: 17.445,30.335,71.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.722 | Acc: 17.437,30.279,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.723 | Acc: 17.447,30.231,71.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.725 | Acc: 17.466,30.180,71.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.473 | Acc: 20.312,26.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.454 | Acc: 13.951,25.558,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 14.272,25.038,55.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.491 | Acc: 14.229,24.744,56.045,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 1.639 | Acc: 13.281,26.562,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.649 | Acc: 17.448,31.138,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.647 | Acc: 17.702,31.059,74.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.650 | Acc: 17.649,30.879,73.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.640 | Acc: 17.757,30.941,74.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.648 | Acc: 17.899,30.724,73.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.659 | Acc: 17.672,30.443,73.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.653 | Acc: 17.664,30.485,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.661 | Acc: 17.648,30.381,73.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.667 | Acc: 17.528,30.262,73.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.678 | Acc: 17.611,30.212,72.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.682 | Acc: 17.665,30.193,72.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.684 | Acc: 17.667,30.200,72.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.688 | Acc: 17.675,30.214,72.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.695 | Acc: 17.632,30.149,72.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.699 | Acc: 17.572,30.059,72.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.699 | Acc: 17.567,30.057,72.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.702 | Acc: 17.511,30.008,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.703 | Acc: 17.545,30.053,72.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.706 | Acc: 17.524,30.071,72.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.233 | Acc: 14.844,24.219,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.354 | Acc: 13.728,27.158,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.367 | Acc: 13.891,26.982,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.362 | Acc: 14.114,26.383,58.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.764 | Acc: 16.406,26.562,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.669 | Acc: 17.262,30.952,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.674 | Acc: 17.454,30.736,73.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.674 | Acc: 17.316,30.456,73.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 17.255,30.498,73.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.681 | Acc: 17.234,30.283,73.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.675 | Acc: 17.394,30.507,73.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.674 | Acc: 17.586,30.701,73.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.675 | Acc: 17.459,30.629,73.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.678 | Acc: 17.559,30.667,72.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.686 | Acc: 17.526,30.667,72.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.693 | Acc: 17.583,30.585,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.701 | Acc: 17.645,30.524,72.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.701 | Acc: 17.544,30.484,72.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.703 | Acc: 17.460,30.352,72.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 17.489,30.357,72.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.707 | Acc: 17.499,30.405,72.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.708 | Acc: 17.540,30.423,72.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.710 | Acc: 17.499,30.369,71.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.715 | Acc: 17.522,30.317,71.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.401 | Acc: 14.844,27.344,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.340 | Acc: 14.472,25.521,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.373 | Acc: 15.187,25.972,58.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.349 | Acc: 15.126,25.820,59.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.825 | Acc: 16.406,30.469,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.706 | Acc: 16.853,30.729,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.690 | Acc: 16.502,30.107,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.664 | Acc: 17.162,30.648,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.665 | Acc: 17.438,30.797,73.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.667 | Acc: 17.520,30.739,73.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.671 | Acc: 17.659,30.553,72.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.673 | Acc: 17.670,30.524,72.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.682 | Acc: 17.498,30.454,72.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.689 | Acc: 17.416,30.201,72.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.694 | Acc: 17.339,30.134,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.700 | Acc: 17.396,30.165,72.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 17.408,30.268,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 17.514,30.391,72.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.705 | Acc: 17.554,30.391,72.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.707 | Acc: 17.499,30.331,72.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.710 | Acc: 17.506,30.347,72.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.710 | Acc: 17.449,30.338,72.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.712 | Acc: 17.445,30.345,71.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 17.423,30.352,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.113 | Acc: 15.625,35.156,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.357 | Acc: 13.504,26.972,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 13.891,26.658,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.386 | Acc: 14.344,26.972,59.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 1.676 | Acc: 21.875,32.812,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.622 | Acc: 17.746,30.655,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.639 | Acc: 18.483,30.145,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.643 | Acc: 17.623,30.187,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.649 | Acc: 17.737,30.392,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.657 | Acc: 17.752,30.337,73.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.669 | Acc: 17.853,30.462,73.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.677 | Acc: 17.841,30.424,73.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.681 | Acc: 17.852,30.338,72.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.679 | Acc: 17.956,30.456,72.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.680 | Acc: 17.860,30.399,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.683 | Acc: 17.750,30.444,72.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.683 | Acc: 17.774,30.491,72.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.687 | Acc: 17.639,30.439,72.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.690 | Acc: 17.643,30.391,72.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.691 | Acc: 17.704,30.487,72.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.697 | Acc: 17.655,30.469,72.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.698 | Acc: 17.701,30.464,72.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.699 | Acc: 17.657,30.428,72.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.701 | Acc: 17.632,30.467,72.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.169 | Acc: 14.062,23.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.359 | Acc: 12.426,26.637,58.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.348 | Acc: 13.262,26.543,59.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.356 | Acc: 13.486,26.294,58.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 1.679 | Acc: 16.406,29.688,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.643 | Acc: 17.262,30.655,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.641 | Acc: 17.931,30.888,73.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.645 | Acc: 18.199,30.866,73.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.641 | Acc: 17.892,30.797,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.643 | Acc: 17.830,30.763,73.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.645 | Acc: 17.717,30.727,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.653 | Acc: 17.747,30.641,73.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.662 | Acc: 17.653,30.444,73.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.666 | Acc: 17.697,30.417,73.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.665 | Acc: 17.736,30.601,73.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.666 | Acc: 17.700,30.617,73.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.674 | Acc: 17.609,30.566,72.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 17.565,30.514,72.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.680 | Acc: 17.502,30.558,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.683 | Acc: 17.457,30.495,72.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.690 | Acc: 17.436,30.413,72.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.694 | Acc: 17.481,30.460,72.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.699 | Acc: 17.469,30.402,72.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.699 | Acc: 17.522,30.483,72.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.101 | Acc: 18.750,25.000,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.269 | Acc: 15.551,26.302,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.287 | Acc: 15.930,26.658,60.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.296 | Acc: 16.009,26.447,60.003,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 1.562 | Acc: 19.531,28.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.597 | Acc: 18.787,30.804,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.602 | Acc: 18.902,32.317,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.601 | Acc: 18.494,31.404,75.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.611 | Acc: 18.383,31.732,74.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.626 | Acc: 17.953,31.235,74.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.637 | Acc: 17.756,31.192,73.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.644 | Acc: 17.764,31.178,73.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.652 | Acc: 17.678,31.109,73.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 17.723,31.004,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.663 | Acc: 17.545,30.729,73.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 17.566,30.836,73.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.669 | Acc: 17.615,30.783,73.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 17.705,30.909,73.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.670 | Acc: 17.721,30.925,72.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.672 | Acc: 17.730,30.977,72.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 17.682,30.890,72.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 17.648,30.883,72.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.682 | Acc: 17.640,30.778,72.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.682 | Acc: 17.702,30.869,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.310 | Acc: 14.844,28.125,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.262 | Acc: 14.174,26.153,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.280 | Acc: 14.844,27.210,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.282 | Acc: 15.382,26.806,59.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 1.808 | Acc: 19.531,31.250,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.626 | Acc: 17.188,32.254,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.604 | Acc: 18.140,32.317,73.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.598 | Acc: 18.468,32.428,74.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.603 | Acc: 18.306,31.973,74.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.613 | Acc: 18.394,31.753,74.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.633 | Acc: 18.137,31.089,73.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.636 | Acc: 18.235,31.172,73.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.644 | Acc: 18.245,31.129,73.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.645 | Acc: 18.167,31.004,73.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.651 | Acc: 18.058,31.118,73.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.655 | Acc: 17.916,30.935,73.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 17.927,30.877,73.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.667 | Acc: 17.903,30.792,72.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.671 | Acc: 17.871,30.661,72.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.674 | Acc: 17.764,30.645,72.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.676 | Acc: 17.786,30.676,72.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 17.836,30.728,72.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 17.824,30.726,72.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 17.868,30.787,72.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.407 | Acc: 15.625,28.906,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.438 | Acc: 14.137,25.112,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.437 | Acc: 14.082,25.457,56.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.433 | Acc: 14.267,25.269,57.031,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.652 | Acc: 15.625,32.812,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.594 | Acc: 16.332,30.022,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.626 | Acc: 17.035,30.316,74.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.623 | Acc: 17.495,30.174,74.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.632 | Acc: 17.641,30.208,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.647 | Acc: 17.605,30.190,73.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 17.581,30.056,73.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.652 | Acc: 17.575,30.225,73.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.656 | Acc: 17.673,30.270,73.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.663 | Acc: 17.598,30.257,73.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.662 | Acc: 17.600,30.434,73.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.663 | Acc: 17.590,30.564,73.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.661 | Acc: 17.557,30.699,73.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.660 | Acc: 17.729,30.840,73.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.660 | Acc: 17.794,30.947,73.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.661 | Acc: 17.844,30.962,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.664 | Acc: 17.774,30.878,73.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 17.836,30.918,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 17.869,30.912,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.672 | Acc: 17.879,30.912,73.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.588 | Acc: 17.969,24.219,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.305 | Acc: 14.472,28.646,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.301 | Acc: 15.263,28.735,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.306 | Acc: 15.215,28.586,60.169,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 1.484 | Acc: 17.969,27.344,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.619 | Acc: 17.336,29.836,74.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.620 | Acc: 18.159,31.326,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.628 | Acc: 18.186,30.994,74.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.624 | Acc: 17.843,31.105,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.629 | Acc: 17.984,31.242,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.641 | Acc: 17.865,31.063,73.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.646 | Acc: 17.875,31.206,73.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.640 | Acc: 17.944,31.279,73.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.645 | Acc: 17.943,31.440,73.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.652 | Acc: 17.942,31.374,73.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.656 | Acc: 17.944,31.264,73.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.660 | Acc: 17.923,31.269,73.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.663 | Acc: 17.918,31.238,73.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.662 | Acc: 18.030,31.253,73.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.667 | Acc: 18.070,31.263,73.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.673 | Acc: 18.049,31.133,73.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.674 | Acc: 18.019,31.115,73.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.679 | Acc: 17.973,31.086,72.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.678 | Acc: 18.006,31.217,72.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.119 | Acc: 15.625,26.562,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.369 | Acc: 15.625,26.525,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.381 | Acc: 16.082,27.172,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 16.163,26.755,58.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.654 | Acc: 13.281,30.469,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.634 | Acc: 17.746,31.734,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.623 | Acc: 18.102,31.117,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.612 | Acc: 18.020,31.199,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.612 | Acc: 18.152,31.356,75.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.625 | Acc: 18.054,31.188,74.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.626 | Acc: 18.091,31.508,74.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 18.024,31.782,74.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.634 | Acc: 17.935,31.784,74.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.638 | Acc: 18.016,31.764,73.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.642 | Acc: 18.046,31.767,73.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.648 | Acc: 17.902,31.476,73.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.650 | Acc: 17.907,31.577,73.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.655 | Acc: 17.867,31.477,73.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 17.894,31.428,73.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.665 | Acc: 17.888,31.356,73.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.670 | Acc: 17.891,31.301,73.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.674 | Acc: 17.889,31.227,72.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.674 | Acc: 17.878,31.198,72.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.677 | Acc: 17.846,31.188,72.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.128 | Acc: 17.969,30.469,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.290 | Acc: 15.439,26.042,59.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.323 | Acc: 15.377,25.762,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.333 | Acc: 15.625,25.692,58.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 1.725 | Acc: 21.875,36.719,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.639 | Acc: 17.746,31.436,74.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.634 | Acc: 17.569,31.212,74.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.618 | Acc: 17.700,31.532,74.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.615 | Acc: 18.142,31.520,74.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.617 | Acc: 18.263,31.513,74.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.619 | Acc: 18.246,31.767,74.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.625 | Acc: 18.174,31.549,74.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.627 | Acc: 18.085,31.502,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.631 | Acc: 18.146,31.561,73.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.637 | Acc: 18.078,31.468,73.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 18.138,31.406,73.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.647 | Acc: 18.199,31.435,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 18.202,31.445,73.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.651 | Acc: 18.149,31.436,73.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.654 | Acc: 18.080,31.341,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 17.996,31.352,73.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.663 | Acc: 17.948,31.305,73.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.666 | Acc: 17.969,31.250,73.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.669 | Acc: 17.909,31.131,72.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.274 | Acc: 14.844,25.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.400 | Acc: 14.621,26.935,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 14.901,27.458,58.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.380 | Acc: 14.908,27.382,58.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 1.674 | Acc: 13.281,25.781,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.610 | Acc: 18.638,31.436,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.603 | Acc: 18.464,30.583,74.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.603 | Acc: 18.558,30.789,74.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.615 | Acc: 18.383,30.768,73.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.612 | Acc: 18.286,30.809,74.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.617 | Acc: 18.317,30.947,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.623 | Acc: 18.523,31.161,73.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.623 | Acc: 18.488,31.308,74.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.628 | Acc: 18.400,31.116,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.631 | Acc: 18.264,31.199,73.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.639 | Acc: 18.220,31.356,73.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.643 | Acc: 18.235,31.338,73.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.650 | Acc: 18.232,31.337,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 18.222,31.356,73.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.654 | Acc: 18.226,31.333,73.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.657 | Acc: 18.210,31.235,73.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.657 | Acc: 18.159,31.202,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.659 | Acc: 18.101,31.224,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.662 | Acc: 18.053,31.141,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.463 | Acc: 15.625,21.094,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.914 | Acc: 14.249,22.098,49.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.921 | Acc: 14.139,22.275,48.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.908 | Acc: 14.178,22.336,48.732,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.663 | Acc: 13.281,33.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.630 | Acc: 18.118,32.403,74.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.617 | Acc: 17.816,32.241,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.612 | Acc: 17.649,32.223,75.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.616 | Acc: 17.747,31.925,75.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.617 | Acc: 17.845,31.629,74.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.616 | Acc: 17.704,31.547,74.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.614 | Acc: 17.742,31.588,74.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.613 | Acc: 17.716,31.619,74.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.619 | Acc: 17.541,31.626,74.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.623 | Acc: 17.646,31.503,74.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.625 | Acc: 17.753,31.561,74.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.629 | Acc: 17.888,31.603,74.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.635 | Acc: 17.942,31.606,74.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.638 | Acc: 17.921,31.547,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.640 | Acc: 17.904,31.569,73.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.643 | Acc: 17.932,31.406,73.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.645 | Acc: 17.953,31.445,73.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.649 | Acc: 17.988,31.410,73.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.651 | Acc: 18.024,31.406,73.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.244 | Acc: 18.750,28.125,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.419 | Acc: 15.141,28.906,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.437 | Acc: 16.063,28.659,57.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.419 | Acc: 16.124,28.496,58.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 1.646 | Acc: 12.500,28.125,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.607 | Acc: 18.601,31.027,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.580 | Acc: 18.197,31.136,75.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.577 | Acc: 18.327,31.442,75.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.572 | Acc: 18.528,31.858,75.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.570 | Acc: 18.425,31.923,75.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.580 | Acc: 18.459,32.005,75.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.584 | Acc: 18.351,31.909,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.598 | Acc: 18.221,31.590,74.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.608 | Acc: 18.310,31.673,74.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.617 | Acc: 18.221,31.658,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.626 | Acc: 18.146,31.395,74.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.627 | Acc: 18.244,31.535,73.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.629 | Acc: 18.205,31.546,73.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.633 | Acc: 18.216,31.459,73.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.640 | Acc: 18.236,31.450,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.645 | Acc: 18.178,31.401,73.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.647 | Acc: 18.189,31.436,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.646 | Acc: 18.200,31.495,73.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.651 | Acc: 18.123,31.420,73.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.019 | Acc: 18.750,25.781,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.319 | Acc: 15.737,28.646,59.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.320 | Acc: 15.968,28.849,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.331 | Acc: 16.739,28.753,59.055,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 1.617 | Acc: 15.625,25.781,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.585 | Acc: 17.932,32.292,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.587 | Acc: 18.655,32.698,75.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.574 | Acc: 18.891,32.364,75.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.581 | Acc: 18.567,32.157,75.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.584 | Acc: 18.595,32.310,75.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.592 | Acc: 18.395,32.160,75.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 18.323,32.258,74.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.602 | Acc: 18.338,32.347,74.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 18.262,32.156,74.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.616 | Acc: 18.284,32.097,74.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.627 | Acc: 18.322,31.890,74.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.632 | Acc: 18.215,31.898,73.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.634 | Acc: 18.106,31.813,73.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.637 | Acc: 18.116,31.720,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.645 | Acc: 18.052,31.678,73.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.643 | Acc: 18.071,31.751,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.649 | Acc: 18.092,31.662,73.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.651 | Acc: 18.166,31.685,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 18.164,31.588,73.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.171 | Acc: 17.969,25.000,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 15.253,25.409,58.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.429 | Acc: 15.473,25.534,58.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.432 | Acc: 15.523,25.359,58.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 1.510 | Acc: 14.844,34.375,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.559 | Acc: 17.597,33.333,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.565 | Acc: 18.083,33.060,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.555 | Acc: 18.455,33.069,75.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.563 | Acc: 18.451,32.514,75.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.572 | Acc: 18.178,32.201,75.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.589 | Acc: 18.066,31.986,74.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.592 | Acc: 18.102,31.970,74.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.598 | Acc: 18.114,31.876,74.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.604 | Acc: 18.064,31.850,74.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.612 | Acc: 18.089,31.794,74.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.617 | Acc: 18.138,31.851,74.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.620 | Acc: 18.166,31.785,74.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.621 | Acc: 18.106,31.618,74.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.629 | Acc: 18.108,31.567,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.633 | Acc: 18.070,31.439,73.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.636 | Acc: 18.047,31.379,73.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.642 | Acc: 17.973,31.305,73.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.645 | Acc: 18.023,31.354,73.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.645 | Acc: 18.030,31.365,73.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.111 | Acc: 17.969,26.562,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.222 | Acc: 14.993,26.823,61.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.249 | Acc: 15.282,27.420,61.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.256 | Acc: 15.561,27.164,61.002,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.724 | Acc: 21.875,35.938,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.604 | Acc: 18.155,31.882,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.594 | Acc: 18.331,31.803,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.592 | Acc: 18.315,31.967,75.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.608 | Acc: 18.065,31.867,74.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.602 | Acc: 18.000,31.993,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.603 | Acc: 17.956,31.734,75.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.601 | Acc: 18.129,31.799,75.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.604 | Acc: 18.177,31.735,75.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.613 | Acc: 18.133,31.613,74.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.615 | Acc: 18.015,31.386,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.618 | Acc: 17.940,31.441,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.619 | Acc: 17.904,31.461,74.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.619 | Acc: 17.927,31.561,74.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.625 | Acc: 17.930,31.506,74.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.625 | Acc: 18.036,31.572,74.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.626 | Acc: 18.081,31.659,74.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.629 | Acc: 18.159,31.630,74.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.632 | Acc: 18.151,31.661,73.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.635 | Acc: 18.170,31.666,73.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.156 | Acc: 16.406,31.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.288 | Acc: 15.737,28.423,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.313 | Acc: 15.511,28.049,60.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.306 | Acc: 16.009,28.112,60.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 1.614 | Acc: 21.875,38.281,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.633 | Acc: 18.415,30.841,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.618 | Acc: 17.664,30.335,74.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.602 | Acc: 17.982,30.981,74.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.590 | Acc: 18.229,31.211,74.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.588 | Acc: 18.209,31.180,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.587 | Acc: 18.272,31.431,74.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.591 | Acc: 18.357,31.366,74.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.595 | Acc: 18.444,31.371,74.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.596 | Acc: 18.534,31.608,74.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.597 | Acc: 18.521,31.681,74.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.597 | Acc: 18.435,31.763,74.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.602 | Acc: 18.442,31.837,74.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.604 | Acc: 18.478,31.876,74.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.609 | Acc: 18.475,31.759,74.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 18.537,31.795,74.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.617 | Acc: 18.521,31.717,74.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.619 | Acc: 18.480,31.814,74.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.623 | Acc: 18.376,31.670,73.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.628 | Acc: 18.317,31.566,73.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.314 | Acc: 12.500,25.781,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.302 | Acc: 14.509,25.707,60.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.329 | Acc: 14.558,25.781,59.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.330 | Acc: 15.010,25.935,59.016,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.547 | Acc: 16.406,31.250,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.597 | Acc: 17.448,30.246,74.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.578 | Acc: 17.988,31.479,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.574 | Acc: 18.571,31.749,75.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.582 | Acc: 18.287,31.665,75.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.599 | Acc: 18.247,31.528,74.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.600 | Acc: 18.259,31.411,74.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.605 | Acc: 18.074,31.516,74.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.610 | Acc: 18.046,31.575,74.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.614 | Acc: 18.116,31.582,74.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.619 | Acc: 18.124,31.526,74.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.620 | Acc: 18.333,31.547,74.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.621 | Acc: 18.299,31.616,74.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.620 | Acc: 18.304,31.729,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.623 | Acc: 18.163,31.689,73.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.624 | Acc: 18.163,31.805,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.631 | Acc: 18.112,31.756,73.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.636 | Acc: 18.125,31.724,73.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.636 | Acc: 18.142,31.802,73.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.638 | Acc: 18.213,31.806,73.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.461 | Acc: 14.844,32.031,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.424 | Acc: 15.030,27.418,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.461 | Acc: 14.825,26.715,56.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 14.946,26.268,56.596,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.435 | Acc: 25.000,35.156,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.581 | Acc: 17.671,31.957,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.562 | Acc: 18.274,32.431,75.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.585 | Acc: 17.956,32.223,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.588 | Acc: 17.930,32.041,75.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.590 | Acc: 17.868,31.985,75.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.596 | Acc: 17.982,32.122,74.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.597 | Acc: 18.102,32.159,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.603 | Acc: 18.080,32.187,74.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.605 | Acc: 18.202,32.213,74.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.612 | Acc: 18.186,32.179,74.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.614 | Acc: 18.160,32.286,74.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.623 | Acc: 18.176,32.200,74.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.626 | Acc: 18.136,32.109,74.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.626 | Acc: 18.200,32.095,74.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.624 | Acc: 18.236,32.153,74.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.628 | Acc: 18.319,32.209,74.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.630 | Acc: 18.397,32.139,74.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.633 | Acc: 18.412,32.163,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.635 | Acc: 18.420,32.115,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.184 | Acc: 20.312,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.194 | Acc: 16.183,28.274,62.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.196 | Acc: 16.216,28.754,62.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.185 | Acc: 16.662,28.791,62.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 1.589 | Acc: 19.531,37.500,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.559 | Acc: 18.713,32.031,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.584 | Acc: 18.407,32.336,74.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.577 | Acc: 18.071,31.929,74.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.573 | Acc: 18.605,32.427,74.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.584 | Acc: 18.642,32.078,74.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.576 | Acc: 18.731,32.406,75.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.594 | Acc: 18.584,32.092,74.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.593 | Acc: 18.585,32.434,74.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.591 | Acc: 18.659,32.605,74.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.592 | Acc: 18.630,32.564,74.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.598 | Acc: 18.651,32.625,74.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.605 | Acc: 18.607,32.505,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.612 | Acc: 18.606,32.480,73.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.616 | Acc: 18.558,32.398,73.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.618 | Acc: 18.496,32.389,73.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.622 | Acc: 18.465,32.160,73.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.625 | Acc: 18.509,32.178,73.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.626 | Acc: 18.490,32.172,73.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.627 | Acc: 18.568,32.193,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.652 | Acc: 17.188,32.031,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.357 | Acc: 16.667,29.129,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.371 | Acc: 16.806,29.287,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.373 | Acc: 17.123,28.842,58.005,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 1.465 | Acc: 15.625,36.719,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.573 | Acc: 17.634,33.147,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.566 | Acc: 18.064,33.175,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.564 | Acc: 18.238,32.364,75.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.555 | Acc: 18.355,32.600,76.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.562 | Acc: 18.549,32.751,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.576 | Acc: 18.227,32.535,75.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.582 | Acc: 18.357,32.419,75.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.583 | Acc: 18.372,32.371,75.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.582 | Acc: 18.422,32.437,75.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.588 | Acc: 18.462,32.381,75.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.595 | Acc: 18.495,32.250,74.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.596 | Acc: 18.445,32.145,74.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.597 | Acc: 18.376,32.070,74.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.602 | Acc: 18.330,31.965,74.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.607 | Acc: 18.355,31.992,74.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.610 | Acc: 18.370,31.924,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.613 | Acc: 18.370,31.944,74.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.618 | Acc: 18.345,31.917,74.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.621 | Acc: 18.412,31.943,74.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.367 | Acc: 21.875,34.375,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.354 | Acc: 15.513,28.311,59.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 15.949,27.572,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.370 | Acc: 16.253,27.741,58.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 1.683 | Acc: 17.969,33.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.574 | Acc: 18.155,31.734,76.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.575 | Acc: 18.731,32.946,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.572 | Acc: 18.648,32.287,75.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.570 | Acc: 18.731,32.552,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.576 | Acc: 18.557,32.519,75.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.580 | Acc: 18.692,32.741,75.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.588 | Acc: 18.684,32.402,74.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.593 | Acc: 18.648,32.366,74.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.600 | Acc: 18.539,32.303,74.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.601 | Acc: 18.486,32.311,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.606 | Acc: 18.428,32.236,74.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.605 | Acc: 18.358,32.119,74.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.607 | Acc: 18.511,32.097,74.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.610 | Acc: 18.472,32.079,74.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.611 | Acc: 18.470,32.140,74.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.614 | Acc: 18.531,32.260,74.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.613 | Acc: 18.505,32.325,74.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.614 | Acc: 18.560,32.414,74.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.616 | Acc: 18.547,32.398,74.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.254 | Acc: 17.188,31.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.252 | Acc: 15.179,29.055,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.286 | Acc: 15.720,28.678,60.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.290 | Acc: 15.689,28.535,59.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 1.765 | Acc: 13.281,24.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.556 | Acc: 17.671,31.138,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.594 | Acc: 18.064,31.822,74.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.590 | Acc: 18.122,31.916,75.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.596 | Acc: 18.393,32.022,74.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.594 | Acc: 18.371,31.993,74.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.594 | Acc: 18.356,31.909,74.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.598 | Acc: 18.434,32.059,74.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.597 | Acc: 18.575,32.128,74.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.603 | Acc: 18.517,32.083,74.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.607 | Acc: 18.595,32.093,74.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.610 | Acc: 18.474,32.091,74.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.613 | Acc: 18.393,31.979,74.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.612 | Acc: 18.460,32.106,74.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.613 | Acc: 18.383,32.079,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.616 | Acc: 18.402,32.140,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.623 | Acc: 18.402,32.158,73.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.624 | Acc: 18.473,32.265,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.626 | Acc: 18.473,32.250,73.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.626 | Acc: 18.461,32.218,73.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.190 | Acc: 15.625,31.250,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.363 | Acc: 14.062,28.348,58.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 14.348,27.820,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.389 | Acc: 14.447,27.946,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.622 | Acc: 12.500,28.906,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.600 | Acc: 17.076,30.915,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.555 | Acc: 17.950,32.088,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.545 | Acc: 18.494,32.620,76.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.550 | Acc: 18.480,32.465,76.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 18.711,32.727,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.560 | Acc: 18.530,32.290,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.564 | Acc: 18.606,32.330,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.570 | Acc: 18.391,32.143,75.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.575 | Acc: 18.327,32.096,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.578 | Acc: 18.392,32.136,75.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.583 | Acc: 18.432,32.166,75.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.586 | Acc: 18.416,32.167,75.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.585 | Acc: 18.463,32.214,75.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.587 | Acc: 18.516,32.301,75.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.590 | Acc: 18.599,32.371,75.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.596 | Acc: 18.611,32.343,74.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.601 | Acc: 18.560,32.210,74.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.606 | Acc: 18.547,32.148,74.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.609 | Acc: 18.502,32.199,74.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.319 | Acc: 17.188,32.812,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.360 | Acc: 14.211,25.409,59.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.368 | Acc: 14.882,26.048,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.380 | Acc: 14.933,25.961,59.042,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.499 | Acc: 20.312,37.500,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.557 | Acc: 19.159,33.259,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.565 | Acc: 18.369,32.127,75.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.562 | Acc: 18.455,31.839,75.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.564 | Acc: 18.383,32.157,75.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.560 | Acc: 18.263,32.302,76.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.568 | Acc: 18.246,32.173,75.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.572 | Acc: 18.235,32.125,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.571 | Acc: 18.478,32.279,75.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.573 | Acc: 18.504,32.316,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.581 | Acc: 18.466,32.284,75.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.587 | Acc: 18.421,32.314,75.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.590 | Acc: 18.393,32.268,74.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.594 | Acc: 18.325,32.247,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.598 | Acc: 18.400,32.129,74.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.605 | Acc: 18.324,32.036,74.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.605 | Acc: 18.378,32.046,74.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.608 | Acc: 18.377,32.038,74.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.613 | Acc: 18.399,32.025,74.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.614 | Acc: 18.365,32.058,74.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.212 | Acc: 18.750,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.336 | Acc: 16.406,29.985,60.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.344 | Acc: 16.425,29.040,60.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.357 | Acc: 16.675,28.868,59.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 1.668 | Acc: 17.188,33.594,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.557 | Acc: 18.601,31.808,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.552 | Acc: 19.169,32.527,75.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.557 | Acc: 19.134,32.812,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.555 | Acc: 19.261,32.822,75.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 19.268,32.998,75.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.557 | Acc: 19.196,33.090,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.562 | Acc: 19.160,33.084,75.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.565 | Acc: 19.158,32.953,75.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.568 | Acc: 19.031,32.873,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.570 | Acc: 19.104,32.937,75.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.575 | Acc: 19.029,32.933,75.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.582 | Acc: 19.019,32.689,75.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.584 | Acc: 19.097,32.690,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.587 | Acc: 19.056,32.715,74.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.592 | Acc: 19.015,32.722,74.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.598 | Acc: 18.964,32.708,74.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.600 | Acc: 18.890,32.611,74.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.602 | Acc: 18.795,32.568,74.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.604 | Acc: 18.752,32.554,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.114 | Acc: 17.969,30.469,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.238 | Acc: 15.885,27.158,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.249 | Acc: 16.597,27.077,61.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.247 | Acc: 16.573,27.190,61.655,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 1.570 | Acc: 21.875,36.719,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.545 | Acc: 19.159,34.003,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.568 | Acc: 18.769,32.870,74.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.560 | Acc: 19.057,32.941,75.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.561 | Acc: 18.654,32.523,75.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.567 | Acc: 18.502,32.271,75.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.562 | Acc: 18.834,32.535,75.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.563 | Acc: 19.121,32.680,75.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.564 | Acc: 19.119,32.754,75.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.567 | Acc: 19.052,32.890,75.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.571 | Acc: 18.933,32.929,75.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.577 | Acc: 18.934,32.873,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.581 | Acc: 18.902,32.783,74.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.584 | Acc: 18.903,32.815,74.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.590 | Acc: 18.806,32.718,74.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.591 | Acc: 18.716,32.631,74.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.593 | Acc: 18.672,32.569,74.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.595 | Acc: 18.668,32.595,74.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.596 | Acc: 18.635,32.637,74.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.596 | Acc: 18.670,32.642,74.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.245 | Acc: 17.188,30.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.208 | Acc: 13.988,28.311,61.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.259 | Acc: 14.310,28.716,61.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.265 | Acc: 14.472,28.522,61.117,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.520 | Acc: 18.750,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 19.234,32.812,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.512 | Acc: 19.398,33.251,76.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.536 | Acc: 18.840,32.992,76.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.555 | Acc: 18.682,32.774,75.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.568 | Acc: 18.549,32.155,75.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.573 | Acc: 18.640,32.367,75.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.573 | Acc: 18.811,32.691,75.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.575 | Acc: 18.735,32.638,75.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.576 | Acc: 18.767,32.735,75.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.579 | Acc: 18.676,32.540,75.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.581 | Acc: 18.739,32.632,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.586 | Acc: 18.763,32.670,74.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 18.693,32.567,74.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.597 | Acc: 18.592,32.401,74.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.601 | Acc: 18.470,32.304,74.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.600 | Acc: 18.499,32.323,74.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.604 | Acc: 18.507,32.297,74.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.606 | Acc: 18.475,32.304,74.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.610 | Acc: 18.440,32.255,74.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.185 | Acc: 17.188,31.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.502 | Acc: 14.100,25.893,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.524 | Acc: 14.653,26.543,56.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.522 | Acc: 15.010,26.332,56.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.475 | Acc: 18.750,28.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.582 | Acc: 18.638,31.882,74.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.562 | Acc: 18.636,32.698,75.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.540 | Acc: 19.019,33.222,76.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.542 | Acc: 18.895,33.208,76.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.537 | Acc: 19.059,33.393,76.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.541 | Acc: 18.982,33.374,76.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 18.983,33.389,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.557 | Acc: 18.949,33.230,75.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.558 | Acc: 18.966,33.166,75.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.563 | Acc: 19.030,33.244,75.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.568 | Acc: 19.086,33.141,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.569 | Acc: 19.019,33.062,75.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 18.983,33.004,75.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.575 | Acc: 19.014,32.979,75.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.582 | Acc: 18.960,32.992,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.588 | Acc: 18.903,32.898,75.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.590 | Acc: 18.851,32.900,75.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.594 | Acc: 18.750,32.802,74.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.595 | Acc: 18.703,32.722,74.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.205 | Acc: 18.750,25.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.302 | Acc: 15.402,28.162,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.322 | Acc: 15.720,27.934,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.325 | Acc: 15.471,27.587,59.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.570 | Acc: 17.969,31.250,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.555 | Acc: 20.201,34.859,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.555 | Acc: 19.036,33.308,76.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.542 | Acc: 19.121,33.286,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.539 | Acc: 18.875,33.054,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.544 | Acc: 18.812,33.037,76.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.542 | Acc: 18.705,32.903,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 18.733,32.824,76.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.550 | Acc: 18.687,32.861,76.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.557 | Acc: 18.586,32.765,75.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.564 | Acc: 18.715,32.638,75.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.566 | Acc: 18.768,32.714,75.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.566 | Acc: 18.740,32.780,75.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.566 | Acc: 18.744,32.792,75.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.568 | Acc: 18.786,32.815,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.573 | Acc: 18.680,32.755,75.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.577 | Acc: 18.606,32.722,75.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.582 | Acc: 18.532,32.565,75.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.583 | Acc: 18.627,32.620,75.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.587 | Acc: 18.576,32.509,74.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.130 | Acc: 18.750,28.125,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.345 | Acc: 15.141,28.832,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.316 | Acc: 14.844,28.544,60.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.326 | Acc: 15.049,28.010,59.951,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.608 | Acc: 14.844,28.125,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.556 | Acc: 17.857,32.701,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.528 | Acc: 18.140,33.079,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.536 | Acc: 17.866,32.620,76.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.545 | Acc: 18.220,33.092,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 18.642,33.308,75.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.554 | Acc: 18.679,33.103,75.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.558 | Acc: 18.534,32.873,75.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.564 | Acc: 18.604,32.861,75.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.566 | Acc: 18.539,32.951,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 18.521,32.921,75.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.576 | Acc: 18.396,32.848,75.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.576 | Acc: 18.442,32.890,75.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.578 | Acc: 18.517,32.893,75.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.582 | Acc: 18.580,32.854,74.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 18.522,32.825,74.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.589 | Acc: 18.502,32.757,74.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.592 | Acc: 18.487,32.719,74.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.592 | Acc: 18.570,32.771,74.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.598 | Acc: 18.545,32.749,74.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.166 | Acc: 15.625,32.031,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.363 | Acc: 14.583,29.501,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.373 | Acc: 15.301,29.211,59.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.377 | Acc: 15.471,28.740,58.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.618 | Acc: 14.844,29.688,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.545 | Acc: 18.229,33.854,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.522 | Acc: 19.131,33.803,77.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.523 | Acc: 18.788,33.568,77.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.529 | Acc: 18.711,33.594,76.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.540 | Acc: 18.611,33.315,76.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.542 | Acc: 18.492,33.213,76.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.549 | Acc: 18.501,33.217,76.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.556 | Acc: 18.682,33.201,75.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.561 | Acc: 18.633,33.197,75.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.563 | Acc: 18.630,33.302,75.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 18.619,33.389,75.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.566 | Acc: 18.633,33.334,75.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.569 | Acc: 18.672,33.327,75.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.572 | Acc: 18.605,33.207,75.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.577 | Acc: 18.610,33.176,75.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.580 | Acc: 18.660,33.234,75.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.583 | Acc: 18.681,33.211,75.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.584 | Acc: 18.624,33.124,75.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.588 | Acc: 18.617,33.069,74.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.343 | Acc: 12.500,25.781,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.337 | Acc: 13.393,27.307,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.381 | Acc: 13.472,26.867,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.397 | Acc: 13.435,27.062,59.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.860 | Acc: 13.281,28.125,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.543 | Acc: 19.717,32.068,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.542 | Acc: 18.979,31.898,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.541 | Acc: 18.840,32.428,76.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.535 | Acc: 18.692,32.456,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.541 | Acc: 18.742,32.418,76.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.540 | Acc: 18.472,32.419,76.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 18.556,32.303,76.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.550 | Acc: 18.643,32.390,75.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.552 | Acc: 18.694,32.549,75.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.555 | Acc: 18.645,32.723,75.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.559 | Acc: 18.686,32.622,75.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.564 | Acc: 18.688,32.670,75.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.568 | Acc: 18.693,32.585,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.569 | Acc: 18.750,32.687,75.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.570 | Acc: 18.784,32.732,75.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.576 | Acc: 18.689,32.628,75.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.578 | Acc: 18.757,32.684,75.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 18.702,32.637,74.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.585 | Acc: 18.711,32.581,74.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.113 | Acc: 17.969,30.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.371 | Acc: 15.885,29.018,59.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.386 | Acc: 16.292,29.802,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.393 | Acc: 16.329,29.880,58.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 1.492 | Acc: 19.531,35.156,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 18.415,32.552,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.545 | Acc: 18.788,32.508,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.548 | Acc: 18.852,32.339,76.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.554 | Acc: 18.885,32.398,76.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 18.881,32.596,76.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.554 | Acc: 18.995,32.767,76.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.549 | Acc: 19.060,32.851,76.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.552 | Acc: 19.036,32.822,76.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 19.039,32.877,75.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.561 | Acc: 18.960,32.762,75.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.565 | Acc: 18.969,32.851,75.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 18.964,32.890,75.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.566 | Acc: 19.049,33.010,75.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.566 | Acc: 19.059,32.940,75.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.568 | Acc: 19.054,33.020,75.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.573 | Acc: 18.920,32.898,75.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.576 | Acc: 18.940,32.913,75.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.582 | Acc: 18.854,32.821,75.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.581 | Acc: 18.928,32.827,75.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.132 | Acc: 19.531,34.375,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.272 | Acc: 15.662,31.213,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.298 | Acc: 16.120,30.316,59.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.286 | Acc: 16.726,30.507,60.143,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.483 | Acc: 18.750,35.938,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.548 | Acc: 18.824,33.445,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.547 | Acc: 18.483,33.708,75.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.542 | Acc: 18.929,33.863,75.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.547 | Acc: 19.068,33.613,76.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.550 | Acc: 18.936,33.323,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.549 | Acc: 19.015,33.665,76.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.556 | Acc: 18.839,33.256,75.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.562 | Acc: 18.677,33.181,75.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.567 | Acc: 18.733,33.197,75.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.565 | Acc: 18.649,33.116,75.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.565 | Acc: 18.778,33.219,75.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.568 | Acc: 18.789,33.247,75.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.570 | Acc: 18.870,33.306,75.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.574 | Acc: 18.831,33.149,75.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.577 | Acc: 18.867,33.077,75.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.581 | Acc: 18.937,33.143,75.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.586 | Acc: 18.947,33.035,75.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.586 | Acc: 18.984,32.992,74.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.589 | Acc: 18.906,32.880,74.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.651 | Acc: 21.094,31.250,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.493 | Acc: 16.034,28.051,56.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 16.006,28.068,56.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.473 | Acc: 16.086,28.266,56.199,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 1.616 | Acc: 20.312,34.375,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.562 | Acc: 19.568,33.891,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.539 | Acc: 19.760,33.441,76.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.529 | Acc: 18.929,33.069,77.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.518 | Acc: 18.991,33.324,76.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.518 | Acc: 18.758,33.075,77.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.534 | Acc: 18.718,33.026,76.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.539 | Acc: 18.789,33.173,76.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 18.701,33.206,76.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.543 | Acc: 18.694,33.166,76.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.545 | Acc: 18.676,33.065,76.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 18.860,33.074,76.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.546 | Acc: 19.006,33.146,76.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.548 | Acc: 18.954,33.043,76.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.552 | Acc: 18.906,32.990,75.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.560 | Acc: 18.864,32.893,75.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.563 | Acc: 18.891,32.932,75.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.566 | Acc: 18.917,32.945,75.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.567 | Acc: 18.975,32.925,75.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.570 | Acc: 18.959,32.921,75.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.265 | Acc: 19.531,25.781,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.356 | Acc: 15.737,28.646,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.371 | Acc: 15.644,28.754,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.354 | Acc: 15.907,28.548,59.349,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.281 | Acc: 20.312,35.156,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.503 | Acc: 19.159,32.738,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.502 | Acc: 19.684,33.155,77.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.508 | Acc: 19.121,33.043,77.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.519 | Acc: 18.972,33.131,76.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 18.959,33.338,76.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.531 | Acc: 18.873,33.407,76.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 18.756,33.206,76.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 18.881,33.346,75.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.538 | Acc: 18.936,33.326,76.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.537 | Acc: 19.026,33.411,76.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.542 | Acc: 18.973,33.307,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.547 | Acc: 18.896,33.189,75.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.550 | Acc: 18.921,33.202,75.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.557 | Acc: 18.975,33.160,75.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.561 | Acc: 19.004,33.168,75.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.565 | Acc: 18.991,33.107,75.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.569 | Acc: 18.995,33.168,75.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.572 | Acc: 18.990,33.068,75.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.575 | Acc: 18.976,33.069,75.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.098 | Acc: 17.969,28.906,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.263 | Acc: 14.472,29.204,61.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.286 | Acc: 14.748,28.830,60.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.293 | Acc: 14.780,28.778,60.336,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.258 | Acc: 20.312,38.281,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.514 | Acc: 19.568,32.924,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.538 | Acc: 19.607,32.812,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.534 | Acc: 19.736,33.158,76.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.525 | Acc: 19.618,33.507,76.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.537 | Acc: 19.585,33.439,76.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.539 | Acc: 19.557,33.394,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.541 | Acc: 19.520,33.389,76.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.540 | Acc: 19.463,33.434,76.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.541 | Acc: 19.423,33.387,75.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.536 | Acc: 19.275,33.423,76.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.543 | Acc: 19.185,33.311,75.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 19.249,33.325,75.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.544 | Acc: 19.349,33.426,76.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.548 | Acc: 19.281,33.407,75.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.550 | Acc: 19.292,33.490,75.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.555 | Acc: 19.324,33.384,75.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.559 | Acc: 19.243,33.255,75.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.563 | Acc: 19.224,33.241,75.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 19.234,33.221,75.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.237 | Acc: 16.406,30.469,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.439 | Acc: 14.211,26.562,57.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.464 | Acc: 14.825,26.944,57.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.465 | Acc: 14.600,26.883,57.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.683 | Acc: 22.656,28.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.531 | Acc: 20.796,35.045,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.509 | Acc: 20.198,33.803,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 19.518,33.594,77.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.531 | Acc: 19.560,33.642,76.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.535 | Acc: 19.500,33.586,76.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.546 | Acc: 19.157,33.355,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.552 | Acc: 19.310,33.594,76.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.556 | Acc: 19.196,33.599,76.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.555 | Acc: 19.108,33.460,76.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.563 | Acc: 19.034,33.267,75.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.564 | Acc: 18.980,33.258,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 19.003,33.263,75.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.568 | Acc: 19.037,33.241,75.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.568 | Acc: 19.009,33.271,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.571 | Acc: 19.072,33.376,75.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.574 | Acc: 19.020,33.270,75.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.576 | Acc: 19.094,33.310,75.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.578 | Acc: 19.090,33.258,75.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.581 | Acc: 19.047,33.198,75.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.376 | Acc: 18.750,22.656,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.407 | Acc: 14.732,26.823,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.450 | Acc: 15.396,26.886,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.475 | Acc: 15.471,26.575,57.992,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.549 | Acc: 22.656,30.469,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.523 | Acc: 19.420,33.371,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 19.627,34.146,75.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.528 | Acc: 19.454,33.735,75.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 19.010,33.623,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 18.998,33.733,76.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.524 | Acc: 19.034,33.949,76.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 19.110,34.054,76.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 19.153,33.992,76.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.524 | Acc: 19.147,33.930,76.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.531 | Acc: 19.150,33.811,76.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 19.012,33.774,76.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.540 | Acc: 19.009,33.675,75.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.544 | Acc: 19.025,33.773,75.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.552 | Acc: 18.908,33.633,75.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.554 | Acc: 18.786,33.487,75.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.559 | Acc: 18.774,33.462,75.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.562 | Acc: 18.812,33.388,75.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.564 | Acc: 18.889,33.401,75.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 18.869,33.360,75.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.214 | Acc: 17.969,23.438,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.318 | Acc: 13.542,22.656,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.343 | Acc: 13.453,22.485,60.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.339 | Acc: 13.806,22.400,60.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.410 | Acc: 20.312,35.156,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.543 | Acc: 19.568,32.850,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.530 | Acc: 19.512,33.003,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.515 | Acc: 19.378,33.389,77.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 19.203,33.266,77.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.506 | Acc: 19.044,33.308,77.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.513 | Acc: 19.208,33.174,77.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 19.177,33.162,76.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.527 | Acc: 19.036,33.123,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.529 | Acc: 18.987,33.197,76.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.533 | Acc: 18.890,33.127,76.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.539 | Acc: 18.994,33.166,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.542 | Acc: 19.022,33.198,76.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.544 | Acc: 19.028,33.285,75.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.547 | Acc: 19.034,33.202,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.548 | Acc: 19.072,33.254,75.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.552 | Acc: 19.037,33.282,75.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.555 | Acc: 19.057,33.236,75.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.557 | Acc: 19.042,33.247,75.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.563 | Acc: 19.021,33.204,75.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.420 | Acc: 17.969,32.031,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.361 | Acc: 14.546,27.567,59.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.385 | Acc: 14.920,27.782,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.395 | Acc: 15.087,27.357,59.106,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.560 | Acc: 14.844,33.594,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.533 | Acc: 18.341,32.217,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.528 | Acc: 19.665,33.422,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.518 | Acc: 19.160,33.543,76.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.514 | Acc: 19.329,34.211,76.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.511 | Acc: 19.562,34.646,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.515 | Acc: 19.654,34.330,76.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.520 | Acc: 19.598,34.264,76.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 19.502,34.137,76.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.531 | Acc: 19.432,34.008,76.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.532 | Acc: 19.411,33.928,76.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.540 | Acc: 19.259,33.650,76.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.545 | Acc: 19.217,33.568,75.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.550 | Acc: 19.202,33.537,75.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.550 | Acc: 19.109,33.610,75.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.552 | Acc: 19.129,33.563,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.556 | Acc: 18.986,33.538,75.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.560 | Acc: 19.023,33.603,75.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.562 | Acc: 19.034,33.644,75.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.566 | Acc: 18.982,33.579,75.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.407 | Acc: 13.281,34.375,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.483 | Acc: 16.481,27.530,57.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.477 | Acc: 16.311,27.630,57.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.464 | Acc: 16.547,27.100,57.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.484 | Acc: 17.188,31.250,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.539 | Acc: 18.378,32.589,76.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.549 | Acc: 18.655,32.870,75.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.537 | Acc: 18.750,33.299,75.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.533 | Acc: 18.760,33.439,76.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.544 | Acc: 18.889,33.315,75.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.537 | Acc: 18.821,33.555,75.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.544 | Acc: 18.800,33.599,75.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.552 | Acc: 18.837,33.555,75.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.549 | Acc: 18.918,33.641,75.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.553 | Acc: 18.836,33.520,75.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.555 | Acc: 18.856,33.597,75.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.555 | Acc: 18.828,33.415,75.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.561 | Acc: 18.846,33.300,75.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.562 | Acc: 18.786,33.357,75.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.566 | Acc: 18.711,33.241,75.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.570 | Acc: 18.728,33.190,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.573 | Acc: 18.757,33.179,75.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.577 | Acc: 18.731,33.180,74.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 18.719,33.177,74.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.071 | Acc: 18.750,31.250,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.186 | Acc: 14.732,30.022,62.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.207 | Acc: 15.091,29.859,62.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.203 | Acc: 15.254,29.636,62.334,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 1.415 | Acc: 13.281,33.594,83.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.463 | Acc: 19.345,34.301,79.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.467 | Acc: 19.055,33.841,78.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 18.852,33.504,77.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 18.682,33.468,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 18.773,33.315,77.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 18.802,33.381,76.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 18.844,33.561,76.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 19.056,33.671,76.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.521 | Acc: 19.307,33.892,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.529 | Acc: 19.216,33.854,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.533 | Acc: 19.114,33.778,76.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.536 | Acc: 19.051,33.665,76.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.540 | Acc: 19.118,33.642,75.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.544 | Acc: 19.167,33.691,75.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.545 | Acc: 19.183,33.677,75.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.548 | Acc: 19.208,33.657,75.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.553 | Acc: 19.137,33.672,75.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.558 | Acc: 19.101,33.585,75.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.562 | Acc: 19.086,33.575,75.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.385 | Acc: 15.625,29.688,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.306 | Acc: 14.546,29.836,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.304 | Acc: 14.672,29.230,60.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.322 | Acc: 14.831,28.945,59.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.407 | Acc: 28.125,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 18.564,33.594,77.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.497 | Acc: 19.036,34.146,77.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.495 | Acc: 18.724,33.965,77.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 19.223,33.980,76.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.506 | Acc: 19.098,34.058,77.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.509 | Acc: 19.112,34.084,76.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 19.071,33.937,76.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.523 | Acc: 18.997,33.798,76.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 19.130,33.814,76.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.527 | Acc: 19.166,33.753,76.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.532 | Acc: 19.047,33.590,76.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.538 | Acc: 19.016,33.464,76.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.541 | Acc: 19.037,33.408,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.543 | Acc: 19.109,33.366,76.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.542 | Acc: 19.155,33.456,76.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 19.066,33.406,75.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.546 | Acc: 19.087,33.472,75.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 19.157,33.509,75.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.551 | Acc: 19.140,33.510,75.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.336 | Acc: 18.750,31.250,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.249 | Acc: 17.374,30.692,63.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.264 | Acc: 17.626,30.297,62.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.270 | Acc: 17.725,30.341,62.180,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.518 | Acc: 23.438,39.062,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.527 | Acc: 18.490,33.854,76.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.512 | Acc: 18.731,33.251,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.506 | Acc: 19.249,33.824,77.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.504 | Acc: 19.338,34.356,77.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 19.578,34.545,77.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 19.279,34.356,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.507 | Acc: 19.193,34.198,77.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 19.201,34.113,77.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 19.056,34.099,77.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.515 | Acc: 19.073,33.936,77.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 19.019,33.848,76.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 19.009,33.785,76.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 19.070,33.791,76.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.533 | Acc: 19.111,33.830,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.536 | Acc: 19.132,33.760,76.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.540 | Acc: 19.181,33.837,76.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.545 | Acc: 19.151,33.745,76.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 19.161,33.721,75.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.549 | Acc: 19.142,33.661,75.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.088 | Acc: 19.531,33.594,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.172 | Acc: 15.997,30.655,63.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.188 | Acc: 16.635,30.164,62.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.189 | Acc: 17.059,29.918,62.718,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 1.499 | Acc: 21.094,36.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.476 | Acc: 18.824,33.333,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 18.826,33.175,77.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.486 | Acc: 18.788,33.555,77.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 18.904,33.748,77.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 18.881,33.818,77.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.490 | Acc: 18.957,33.794,77.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.491 | Acc: 18.999,34.037,77.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.496 | Acc: 19.002,34.050,77.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 18.914,33.896,77.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.506 | Acc: 18.913,33.811,77.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.512 | Acc: 18.870,33.809,76.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.519 | Acc: 19.000,33.873,76.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.525 | Acc: 18.909,33.707,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 19.014,33.752,76.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.532 | Acc: 19.004,33.607,76.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.537 | Acc: 18.923,33.543,76.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.540 | Acc: 18.855,33.498,76.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.542 | Acc: 18.895,33.535,75.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.544 | Acc: 18.894,33.563,75.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.174 | Acc: 21.875,31.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.207 | Acc: 17.076,30.692,62.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.207 | Acc: 17.378,30.278,62.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.213 | Acc: 17.021,29.931,62.577,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.451 | Acc: 10.156,31.250,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.504 | Acc: 19.308,35.603,77.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.510 | Acc: 18.883,34.909,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.499 | Acc: 19.083,34.477,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.491 | Acc: 19.724,34.655,76.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 19.663,34.537,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 19.699,34.582,76.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 19.603,34.453,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.500 | Acc: 19.488,34.360,76.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.506 | Acc: 19.402,34.176,76.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.512 | Acc: 19.481,34.204,76.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 19.383,34.106,76.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 19.340,34.138,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.531 | Acc: 19.447,34.049,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.533 | Acc: 19.270,33.855,75.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.537 | Acc: 19.235,33.838,75.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.538 | Acc: 19.285,33.876,75.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.543 | Acc: 19.103,33.724,75.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.546 | Acc: 19.194,33.747,75.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.553 | Acc: 19.113,33.631,75.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.092 | Acc: 15.625,35.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.293 | Acc: 13.876,30.171,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.309 | Acc: 14.425,29.192,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.307 | Acc: 14.460,28.881,60.118,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.588 | Acc: 7.812,32.812,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.491 | Acc: 18.452,34.710,78.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.484 | Acc: 19.131,34.566,78.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 19.378,34.759,78.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 19.329,34.558,77.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.490 | Acc: 19.338,34.445,77.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.487 | Acc: 19.363,34.330,77.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.494 | Acc: 19.287,34.386,77.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.498 | Acc: 19.293,34.317,77.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.502 | Acc: 19.259,34.276,77.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.508 | Acc: 19.170,34.278,77.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.512 | Acc: 19.199,34.184,76.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.520 | Acc: 19.139,33.976,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.523 | Acc: 19.106,33.977,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.526 | Acc: 19.086,33.919,76.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.527 | Acc: 19.098,33.869,76.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 19.122,33.866,76.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.533 | Acc: 19.094,33.860,76.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.535 | Acc: 19.135,33.899,76.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 19.215,33.957,76.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.330 | Acc: 17.188,33.594,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.402 | Acc: 14.323,26.116,60.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.425 | Acc: 14.158,25.800,59.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.428 | Acc: 14.536,25.384,58.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.563 | Acc: 17.969,32.812,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.512 | Acc: 18.973,33.147,77.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 19.436,34.146,76.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.477 | Acc: 18.916,33.978,77.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.485 | Acc: 18.991,33.825,77.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.496 | Acc: 18.905,33.640,77.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 18.899,33.697,76.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.508 | Acc: 18.839,33.693,76.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 19.007,33.802,76.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.513 | Acc: 19.031,33.840,76.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 19.119,33.831,76.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.522 | Acc: 19.086,33.795,76.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.525 | Acc: 19.188,33.928,76.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.531 | Acc: 19.079,33.908,76.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.535 | Acc: 19.056,33.877,75.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.537 | Acc: 19.085,33.918,75.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.539 | Acc: 19.083,33.888,75.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.542 | Acc: 19.103,33.910,75.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 19.049,33.806,75.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.550 | Acc: 19.092,33.774,75.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.271 | Acc: 17.969,32.031,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.457 | Acc: 15.848,29.874,57.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.472 | Acc: 15.816,29.306,57.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.478 | Acc: 16.214,29.175,57.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 1.510 | Acc: 22.656,39.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.554 | Acc: 18.229,33.519,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.525 | Acc: 18.521,33.689,76.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.515 | Acc: 18.981,34.298,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.513 | Acc: 18.760,33.922,76.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.510 | Acc: 18.735,33.826,76.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 18.931,33.936,77.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 18.955,33.954,77.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.504 | Acc: 18.968,33.851,76.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.515 | Acc: 18.901,33.840,76.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.518 | Acc: 18.870,33.784,76.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.519 | Acc: 18.891,33.954,76.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.525 | Acc: 18.766,33.824,76.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.528 | Acc: 18.834,33.785,76.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 18.883,33.752,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.534 | Acc: 18.937,33.677,76.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.538 | Acc: 18.964,33.630,76.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.541 | Acc: 19.007,33.628,75.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 19.044,33.698,75.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.547 | Acc: 19.019,33.663,75.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.448 | Acc: 17.188,28.125,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.358 | Acc: 16.257,28.683,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.381 | Acc: 16.635,28.335,59.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.356 | Acc: 17.034,28.356,59.772,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 1.366 | Acc: 21.094,31.250,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.495 | Acc: 19.643,32.589,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.489 | Acc: 19.360,33.308,77.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.494 | Acc: 18.942,33.389,77.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.499 | Acc: 18.991,33.642,76.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.498 | Acc: 19.261,33.895,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 19.267,33.768,77.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 19.243,33.771,76.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.501 | Acc: 19.284,33.885,76.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.503 | Acc: 19.259,33.961,76.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.511 | Acc: 19.170,33.769,76.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.513 | Acc: 19.036,33.788,76.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.515 | Acc: 19.094,33.840,76.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.517 | Acc: 19.226,33.911,76.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.520 | Acc: 19.253,33.922,76.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.522 | Acc: 19.220,33.887,76.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.523 | Acc: 19.256,33.927,76.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.528 | Acc: 19.277,33.885,76.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.532 | Acc: 19.282,33.838,75.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.537 | Acc: 19.295,33.871,75.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.183 | Acc: 15.625,28.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.310 | Acc: 13.318,25.595,59.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.341 | Acc: 13.529,25.419,59.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.349 | Acc: 13.537,25.589,59.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.539 | Acc: 14.062,30.469,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.501 | Acc: 18.080,33.705,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.490 | Acc: 17.702,33.937,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.484 | Acc: 18.391,34.477,77.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.488 | Acc: 18.490,33.922,77.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 18.704,34.081,77.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 18.789,33.942,77.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.500 | Acc: 18.889,33.921,76.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 18.891,33.885,76.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.514 | Acc: 18.961,33.900,76.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.520 | Acc: 18.909,33.765,76.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.531 | Acc: 19.022,33.714,76.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 19.162,33.753,75.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.535 | Acc: 19.139,33.713,75.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.536 | Acc: 19.164,33.802,75.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.537 | Acc: 19.191,33.781,75.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.539 | Acc: 19.159,33.703,75.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.544 | Acc: 19.188,33.651,75.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.547 | Acc: 19.174,33.533,75.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.549 | Acc: 19.220,33.604,75.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.195 | Acc: 15.625,30.469,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.134 | Acc: 17.225,31.882,63.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.180 | Acc: 17.530,31.326,62.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.182 | Acc: 17.789,31.148,63.153,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.568 | Acc: 14.062,28.125,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.502 | Acc: 18.787,31.994,76.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.487 | Acc: 19.627,33.060,77.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.498 | Acc: 19.775,33.184,76.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.510 | Acc: 19.483,33.439,76.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.506 | Acc: 19.524,33.663,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 19.622,33.755,76.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 19.681,33.705,76.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.509 | Acc: 19.517,33.686,76.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 19.505,33.684,76.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.513 | Acc: 19.702,33.963,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.518 | Acc: 19.747,34.000,76.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.523 | Acc: 19.671,33.879,76.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 19.579,33.956,76.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.532 | Acc: 19.428,33.919,76.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.535 | Acc: 19.453,34.043,76.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.536 | Acc: 19.407,34.015,76.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.540 | Acc: 19.343,34.038,75.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.542 | Acc: 19.282,33.981,75.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.546 | Acc: 19.209,33.946,75.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.390 | Acc: 15.625,24.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.394 | Acc: 17.039,29.204,58.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.437 | Acc: 17.378,28.811,58.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.446 | Acc: 17.687,28.983,58.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.567 | Acc: 16.406,34.375,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.509 | Acc: 18.452,33.817,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.481 | Acc: 19.150,35.080,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.477 | Acc: 19.198,34.759,77.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.466 | Acc: 19.464,34.963,78.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.467 | Acc: 19.647,35.032,78.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.473 | Acc: 19.570,35.059,77.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.476 | Acc: 19.664,34.890,77.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.477 | Acc: 19.769,34.904,77.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.481 | Acc: 19.661,34.716,77.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 19.675,34.550,77.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.495 | Acc: 19.620,34.439,77.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 19.509,34.453,77.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 19.489,34.408,77.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.507 | Acc: 19.326,34.233,76.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.508 | Acc: 19.282,34.204,76.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.510 | Acc: 19.210,34.200,76.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.516 | Acc: 19.245,34.189,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.519 | Acc: 19.267,34.193,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.523 | Acc: 19.248,34.162,76.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.331 | Acc: 18.750,31.250,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.300 | Acc: 15.811,29.241,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.330 | Acc: 15.987,28.887,59.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.328 | Acc: 16.060,28.676,59.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.414 | Acc: 19.531,39.062,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.518 | Acc: 19.568,34.338,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 19.950,34.623,76.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 19.800,34.426,76.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 20.149,34.790,76.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 19.817,34.406,76.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.496 | Acc: 19.861,34.446,76.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 19.814,34.514,76.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.501 | Acc: 19.478,34.273,76.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.512 | Acc: 19.354,34.060,76.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.515 | Acc: 19.360,34.064,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 19.468,34.142,76.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.519 | Acc: 19.402,34.168,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.524 | Acc: 19.489,34.151,76.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 19.417,34.047,76.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 19.453,33.970,76.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.534 | Acc: 19.388,33.915,76.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.536 | Acc: 19.337,33.937,75.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.540 | Acc: 19.345,33.860,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.542 | Acc: 19.402,33.866,75.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.104 | Acc: 18.750,34.375,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.230 | Acc: 16.964,29.539,61.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.224 | Acc: 17.416,29.783,61.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.245 | Acc: 17.661,29.777,61.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.533 | Acc: 21.875,33.594,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.517 | Acc: 19.085,33.333,76.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.506 | Acc: 19.131,33.556,76.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.505 | Acc: 18.724,33.107,76.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.505 | Acc: 19.030,33.960,76.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.503 | Acc: 19.052,34.197,77.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.502 | Acc: 19.144,34.175,77.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.506 | Acc: 19.121,34.020,77.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.506 | Acc: 19.099,33.982,77.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 19.177,33.961,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 19.248,33.889,76.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.514 | Acc: 19.333,33.954,76.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.517 | Acc: 19.324,34.038,76.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.520 | Acc: 19.379,34.094,76.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.522 | Acc: 19.328,34.097,76.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.522 | Acc: 19.381,34.126,76.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.524 | Acc: 19.439,34.105,76.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.528 | Acc: 19.385,34.015,76.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.531 | Acc: 19.308,33.936,76.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.534 | Acc: 19.277,33.899,76.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.161 | Acc: 21.094,33.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.337 | Acc: 16.481,30.246,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.356 | Acc: 17.302,29.954,59.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.357 | Acc: 17.405,30.110,59.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.733 | Acc: 20.312,32.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.499 | Acc: 18.452,34.226,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.475 | Acc: 19.207,34.794,77.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 19.121,35.015,78.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.454 | Acc: 19.252,35.021,78.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.467 | Acc: 19.284,34.916,77.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.470 | Acc: 19.350,34.659,77.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.474 | Acc: 19.581,34.741,77.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.480 | Acc: 19.585,34.695,77.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 19.626,34.707,77.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.489 | Acc: 19.621,34.639,77.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 19.634,34.598,77.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 19.502,34.488,76.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 19.501,34.456,76.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.510 | Acc: 19.506,34.439,76.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 19.487,34.308,76.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.520 | Acc: 19.497,34.253,76.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.522 | Acc: 19.495,34.290,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 19.507,34.243,76.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.529 | Acc: 19.484,34.190,76.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.103 | Acc: 18.750,29.688,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.356 | Acc: 15.848,27.158,60.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.392 | Acc: 15.930,26.601,59.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.412 | Acc: 15.753,26.511,59.068,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.547 | Acc: 18.750,36.719,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.497 | Acc: 18.043,32.589,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 19.322,34.508,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.486 | Acc: 19.595,34.439,77.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.489 | Acc: 19.792,34.414,77.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.487 | Acc: 20.119,34.653,77.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 19.886,34.388,77.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 19.703,34.286,77.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.496 | Acc: 19.643,34.215,77.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.498 | Acc: 19.738,34.384,77.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 19.780,34.441,77.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.507 | Acc: 19.651,34.350,76.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.509 | Acc: 19.573,34.291,76.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.511 | Acc: 19.573,34.258,76.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.514 | Acc: 19.576,34.275,76.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.517 | Acc: 19.612,34.297,76.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.519 | Acc: 19.577,34.297,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.522 | Acc: 19.527,34.276,76.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.523 | Acc: 19.546,34.381,76.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.527 | Acc: 19.455,34.293,76.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.330 | Acc: 19.531,33.594,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.292 | Acc: 15.513,30.543,59.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.325 | Acc: 15.873,30.069,59.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.327 | Acc: 16.150,30.289,59.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.401 | Acc: 17.188,31.250,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.477 | Acc: 19.940,33.668,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.478 | Acc: 19.741,34.108,78.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.476 | Acc: 19.903,33.991,78.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.472 | Acc: 19.705,33.951,78.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 19.694,34.367,78.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 19.635,34.304,78.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.473 | Acc: 19.531,34.309,77.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.478 | Acc: 19.575,34.448,77.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.484 | Acc: 19.566,34.379,77.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.491 | Acc: 19.621,34.321,77.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 19.620,34.329,77.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 19.505,34.265,77.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 19.376,34.201,76.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 19.420,34.217,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 19.487,34.354,76.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 19.480,34.270,76.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.517 | Acc: 19.446,34.306,76.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.518 | Acc: 19.434,34.366,76.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.520 | Acc: 19.377,34.330,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.978 | Acc: 19.531,27.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.133 | Acc: 15.960,30.580,64.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.139 | Acc: 16.082,30.602,63.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.143 | Acc: 16.342,30.853,63.371,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.402 | Acc: 23.438,34.375,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.506 | Acc: 20.461,34.263,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.517 | Acc: 19.703,34.851,76.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.502 | Acc: 19.890,34.657,76.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.508 | Acc: 19.888,34.693,76.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.514 | Acc: 19.640,34.360,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.517 | Acc: 19.538,34.117,76.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.510 | Acc: 19.664,34.104,76.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.513 | Acc: 19.691,33.909,76.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.510 | Acc: 19.730,34.107,76.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.513 | Acc: 19.656,33.986,76.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.517 | Acc: 19.662,33.923,76.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.522 | Acc: 19.538,33.908,76.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.522 | Acc: 19.522,33.869,76.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.527 | Acc: 19.448,33.869,76.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.530 | Acc: 19.448,33.983,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.533 | Acc: 19.551,34.049,76.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.537 | Acc: 19.550,33.928,75.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.538 | Acc: 19.529,34.007,75.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 19.517,34.080,75.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.253 | Acc: 18.750,29.688,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.365 | Acc: 15.104,27.865,59.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 15.206,28.373,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.378 | Acc: 15.420,28.458,59.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.369 | Acc: 17.188,37.500,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.488 | Acc: 17.746,34.189,77.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.491 | Acc: 18.293,33.899,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.472 | Acc: 19.070,33.978,77.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.471 | Acc: 19.608,33.980,77.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.477 | Acc: 19.524,33.857,77.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.481 | Acc: 19.279,33.839,77.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 19.271,33.971,77.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 19.274,33.904,77.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 19.272,33.913,76.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.495 | Acc: 19.298,34.200,77.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.497 | Acc: 19.319,34.255,77.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 19.405,34.219,76.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 19.385,34.294,76.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.508 | Acc: 19.476,34.333,76.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 19.482,34.331,76.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.514 | Acc: 19.417,34.195,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 19.389,34.134,76.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.520 | Acc: 19.382,34.137,76.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.522 | Acc: 19.445,34.207,76.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.301 | Acc: 20.312,31.250,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.335 | Acc: 17.634,29.650,59.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.342 | Acc: 17.873,28.773,59.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.336 | Acc: 18.545,28.407,59.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.416 | Acc: 14.062,32.031,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.484 | Acc: 19.122,33.519,77.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.473 | Acc: 20.046,34.318,77.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.474 | Acc: 19.173,34.362,77.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.475 | Acc: 19.136,34.404,77.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.481 | Acc: 19.121,34.251,77.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.482 | Acc: 19.228,34.356,77.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.481 | Acc: 19.310,34.558,77.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.484 | Acc: 19.497,34.530,77.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 19.475,34.479,77.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.494 | Acc: 19.450,34.344,77.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 19.524,34.410,77.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.501 | Acc: 19.479,34.417,76.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.505 | Acc: 19.525,34.468,76.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.510 | Acc: 19.484,34.486,76.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.511 | Acc: 19.614,34.539,76.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.515 | Acc: 19.631,34.538,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 19.602,34.437,76.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.521 | Acc: 19.622,34.407,76.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.521 | Acc: 19.572,34.396,76.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.130 | Acc: 20.312,30.469,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 16.927,31.436,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.318 | Acc: 17.092,31.117,59.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.318 | Acc: 17.533,31.122,59.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.411 | Acc: 21.875,38.281,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.469 | Acc: 19.940,35.417,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.470 | Acc: 19.874,35.061,78.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.467 | Acc: 19.851,34.990,77.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.464 | Acc: 19.551,34.626,78.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.466 | Acc: 19.299,34.646,78.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.479 | Acc: 19.376,34.491,77.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.486 | Acc: 19.376,34.563,77.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 19.410,34.491,77.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.499 | Acc: 19.298,34.384,77.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.501 | Acc: 19.224,34.344,77.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 19.188,34.403,76.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.505 | Acc: 19.353,34.475,76.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 19.340,34.585,76.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.512 | Acc: 19.323,34.692,76.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.513 | Acc: 19.331,34.585,76.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 19.315,34.601,76.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 19.293,34.595,76.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.515 | Acc: 19.360,34.546,76.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.518 | Acc: 19.341,34.500,76.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.213 | Acc: 15.625,33.594,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 14.918,29.911,62.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.261 | Acc: 15.282,29.535,61.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.264 | Acc: 15.612,29.585,61.360,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.507 | Acc: 14.844,35.156,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.480 | Acc: 18.973,33.705,78.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 19.912,34.184,77.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.472 | Acc: 19.480,34.196,77.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.476 | Acc: 19.618,34.259,77.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.479 | Acc: 19.547,34.360,77.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 19.744,34.536,77.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.482 | Acc: 19.703,34.580,77.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.492 | Acc: 19.536,34.472,77.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.496 | Acc: 19.505,34.483,77.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.498 | Acc: 19.485,34.468,77.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.502 | Acc: 19.443,34.393,76.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.503 | Acc: 19.405,34.339,76.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.509 | Acc: 19.543,34.366,76.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 19.584,34.356,76.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 19.591,34.359,76.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.520 | Acc: 19.668,34.458,76.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 19.673,34.448,76.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 19.676,34.477,76.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.525 | Acc: 19.687,34.451,76.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.224 | Acc: 16.406,26.562,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.313 | Acc: 16.704,28.348,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.350 | Acc: 16.730,27.325,59.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.369 | Acc: 16.560,27.062,59.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.554 | Acc: 18.750,35.938,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.504 | Acc: 20.164,35.565,76.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.462 | Acc: 20.198,35.480,78.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.472 | Acc: 19.775,34.951,77.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.474 | Acc: 19.821,34.896,77.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.479 | Acc: 19.717,34.576,77.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 19.376,34.291,77.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.487 | Acc: 19.520,34.464,77.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 19.502,34.783,77.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 19.432,34.664,77.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.497 | Acc: 19.399,34.534,77.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.496 | Acc: 19.340,34.559,77.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.500 | Acc: 19.460,34.537,76.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 19.576,34.620,76.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.505 | Acc: 19.492,34.539,76.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.507 | Acc: 19.495,34.546,76.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.512 | Acc: 19.490,34.550,76.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.512 | Acc: 19.529,34.609,76.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.515 | Acc: 19.451,34.565,76.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.518 | Acc: 19.377,34.506,76.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.373 | Acc: 13.281,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.372 | Acc: 13.132,28.423,60.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.360 | Acc: 13.529,28.582,60.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.350 | Acc: 13.742,28.381,60.207,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.526 | Acc: 17.188,36.719,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.465 | Acc: 17.671,34.226,78.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.450 | Acc: 19.207,34.718,78.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.462 | Acc: 18.929,34.093,78.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.450 | Acc: 19.309,34.606,78.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.452 | Acc: 19.384,34.599,78.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.458 | Acc: 19.589,34.556,78.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 19.564,34.624,78.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.461 | Acc: 19.648,34.686,78.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.466 | Acc: 19.674,34.664,78.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.467 | Acc: 19.652,34.690,78.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.476 | Acc: 19.549,34.608,77.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.483 | Acc: 19.444,34.599,77.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.490 | Acc: 19.447,34.650,77.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.496 | Acc: 19.384,34.620,77.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 19.355,34.606,77.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.502 | Acc: 19.337,34.614,76.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.503 | Acc: 19.353,34.618,76.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.505 | Acc: 19.278,34.568,76.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 19.289,34.572,76.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.424 | Acc: 19.531,35.938,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.413 | Acc: 16.183,30.506,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.407 | Acc: 16.425,29.802,57.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.413 | Acc: 16.573,29.649,57.723,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.496 | Acc: 23.438,32.031,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.443 | Acc: 20.387,35.900,79.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.466 | Acc: 19.245,34.889,78.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.466 | Acc: 19.531,35.323,78.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.468 | Acc: 19.483,35.253,77.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.468 | Acc: 19.245,35.017,77.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.475 | Acc: 19.247,34.840,77.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.475 | Acc: 19.254,34.824,77.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.485 | Acc: 19.347,34.744,77.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.488 | Acc: 19.458,34.945,77.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.492 | Acc: 19.547,35.028,77.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.494 | Acc: 19.701,35.089,77.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 19.723,35.130,77.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 19.663,35.034,76.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 19.667,35.020,76.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.505 | Acc: 19.651,34.964,76.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.509 | Acc: 19.553,34.937,76.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.509 | Acc: 19.492,34.890,76.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.513 | Acc: 19.486,34.754,76.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.516 | Acc: 19.466,34.795,76.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.075 | Acc: 17.188,32.812,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.221 | Acc: 15.476,31.324,62.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.256 | Acc: 15.873,30.431,61.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.268 | Acc: 16.201,29.956,61.219,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.554 | Acc: 18.750,36.719,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.468 | Acc: 19.234,34.821,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.454 | Acc: 19.474,35.004,78.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.461 | Acc: 19.185,34.234,78.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.461 | Acc: 19.300,34.934,78.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.455 | Acc: 19.570,34.955,78.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.454 | Acc: 19.596,35.130,78.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.458 | Acc: 19.614,35.079,77.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.467 | Acc: 19.623,35.093,77.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.473 | Acc: 19.475,34.897,77.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.477 | Acc: 19.582,34.904,77.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.481 | Acc: 19.634,34.951,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.487 | Acc: 19.560,34.735,77.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.489 | Acc: 19.540,34.755,77.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.495 | Acc: 19.495,34.750,77.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 19.472,34.707,76.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.500 | Acc: 19.458,34.643,76.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.502 | Acc: 19.430,34.636,76.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.508 | Acc: 19.395,34.576,76.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 19.390,34.584,76.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.123 | Acc: 20.312,28.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.380 | Acc: 15.774,27.753,59.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.408 | Acc: 15.434,27.420,58.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.407 | Acc: 15.587,27.626,58.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.570 | Acc: 19.531,33.594,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.462 | Acc: 18.452,33.185,78.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.439 | Acc: 19.436,34.870,79.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.440 | Acc: 19.582,34.823,78.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.450 | Acc: 19.637,35.050,78.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.462 | Acc: 19.663,35.149,77.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 19.828,35.059,77.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.468 | Acc: 19.891,34.940,77.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.471 | Acc: 19.691,34.972,77.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.476 | Acc: 19.518,34.915,77.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 19.527,34.904,77.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 19.535,34.721,77.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.494 | Acc: 19.512,34.738,76.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.494 | Acc: 19.600,34.740,76.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.495 | Acc: 19.592,34.770,76.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.500 | Acc: 19.534,34.723,76.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 19.529,34.669,76.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.504 | Acc: 19.543,34.764,76.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.507 | Acc: 19.542,34.758,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.510 | Acc: 19.599,34.769,76.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.452 | Acc: 17.188,24.219,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.453 | Acc: 15.253,26.153,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.434 | Acc: 15.473,25.877,57.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.397 | Acc: 15.420,26.127,58.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.504 | Acc: 16.406,27.344,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.451 | Acc: 20.126,34.970,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.441 | Acc: 19.379,34.813,77.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.457 | Acc: 19.608,35.182,77.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.456 | Acc: 19.117,34.751,77.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.462 | Acc: 19.469,34.677,77.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 19.557,34.633,77.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.478 | Acc: 19.537,34.835,77.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.483 | Acc: 19.483,34.724,77.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.481 | Acc: 19.561,35.014,77.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.485 | Acc: 19.481,34.865,77.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.491 | Acc: 19.521,34.679,76.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.496 | Acc: 19.489,34.696,76.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.501 | Acc: 19.415,34.647,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.504 | Acc: 19.495,34.795,76.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.505 | Acc: 19.516,34.686,76.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.507 | Acc: 19.490,34.706,76.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.506 | Acc: 19.465,34.652,76.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.510 | Acc: 19.432,34.659,76.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 19.472,34.637,76.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.234 | Acc: 15.625,33.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.267 | Acc: 14.844,28.013,61.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.283 | Acc: 15.396,28.239,60.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.302 | Acc: 15.241,28.612,60.707,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.447 | Acc: 16.406,32.812,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.458 | Acc: 19.196,34.449,77.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.461 | Acc: 19.131,34.184,78.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 19.224,34.426,78.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.475 | Acc: 19.039,33.700,77.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.470 | Acc: 19.454,33.926,78.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.468 | Acc: 19.421,34.388,78.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 19.415,34.868,78.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.474 | Acc: 19.497,34.938,77.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.475 | Acc: 19.579,34.992,77.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.478 | Acc: 19.656,35.009,77.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.489 | Acc: 19.517,34.888,77.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.493 | Acc: 19.489,34.803,77.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.498 | Acc: 19.525,34.824,77.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.502 | Acc: 19.531,34.848,76.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.504 | Acc: 19.523,34.863,76.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.508 | Acc: 19.461,34.803,76.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.511 | Acc: 19.483,34.744,76.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.511 | Acc: 19.477,34.728,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.512 | Acc: 19.519,34.746,76.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.126 | Acc: 19.531,31.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.261 | Acc: 15.811,30.283,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.274 | Acc: 16.444,29.878,60.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.297 | Acc: 16.624,29.598,60.861,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.450 | Acc: 19.531,31.250,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.460 | Acc: 19.903,34.933,78.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.475 | Acc: 18.750,34.489,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.466 | Acc: 19.506,34.708,78.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.473 | Acc: 19.252,34.674,77.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.463 | Acc: 19.377,34.553,78.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.466 | Acc: 19.137,34.452,77.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.467 | Acc: 19.293,34.702,77.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.467 | Acc: 19.522,34.686,77.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.471 | Acc: 19.557,34.656,77.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.479 | Acc: 19.632,34.608,77.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.483 | Acc: 19.545,34.584,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.485 | Acc: 19.544,34.634,77.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.481 | Acc: 19.687,34.815,77.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.486 | Acc: 19.654,34.803,77.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.492 | Acc: 19.625,34.702,77.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.494 | Acc: 19.551,34.774,77.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.499 | Acc: 19.520,34.801,76.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.502 | Acc: 19.499,34.771,76.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.507 | Acc: 19.478,34.740,76.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.428 | Acc: 15.625,27.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.565 | Acc: 13.281,25.484,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.577 | Acc: 13.662,24.924,56.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.609 | Acc: 13.550,24.513,56.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.447 | Acc: 18.750,31.250,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.453 | Acc: 18.304,34.896,78.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.471 | Acc: 18.960,35.690,77.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.466 | Acc: 19.378,35.540,77.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.467 | Acc: 19.184,35.021,77.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.462 | Acc: 19.276,34.916,77.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.472 | Acc: 19.480,35.021,77.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.471 | Acc: 19.509,34.901,77.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.473 | Acc: 19.386,34.841,77.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.475 | Acc: 19.359,34.781,77.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.483 | Acc: 19.228,34.795,77.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.485 | Acc: 19.178,34.806,77.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.490 | Acc: 19.282,34.800,77.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.491 | Acc: 19.483,34.887,77.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.496 | Acc: 19.598,34.887,76.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.499 | Acc: 19.578,34.808,76.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.503 | Acc: 19.592,34.884,76.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.508 | Acc: 19.609,34.760,76.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.509 | Acc: 19.579,34.708,76.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.511 | Acc: 19.675,34.765,76.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.382 | Acc: 20.312,32.812,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.301 | Acc: 15.439,31.473,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.326 | Acc: 15.720,30.774,59.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.329 | Acc: 15.920,30.456,59.567,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.429 | Acc: 28.125,32.031,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.469 | Acc: 20.461,33.445,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.431 | Acc: 20.084,34.585,78.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.444 | Acc: 19.787,35.067,78.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.452 | Acc: 19.734,34.973,78.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.461 | Acc: 19.678,34.739,77.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.464 | Acc: 19.647,34.833,77.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.466 | Acc: 19.637,34.846,77.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.468 | Acc: 19.507,34.593,77.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.474 | Acc: 19.397,34.595,77.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.475 | Acc: 19.384,34.608,77.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.474 | Acc: 19.439,34.718,77.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.478 | Acc: 19.457,34.819,77.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.482 | Acc: 19.534,34.920,77.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.484 | Acc: 19.553,34.900,77.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.486 | Acc: 19.568,34.998,77.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.492 | Acc: 19.590,34.979,77.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.496 | Acc: 19.621,35.049,77.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.498 | Acc: 19.585,35.052,77.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.502 | Acc: 19.609,35.048,76.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.181 | Acc: 16.406,26.562,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.289 | Acc: 15.923,28.609,60.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.302 | Acc: 15.644,28.049,60.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.309 | Acc: 15.612,27.933,60.464,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.403 | Acc: 19.531,34.375,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.464 | Acc: 19.159,34.040,78.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.418 | Acc: 19.684,35.175,79.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.377 | Acc: 19.890,35.310,80.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.353 | Acc: 20.168,35.725,81.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.337 | Acc: 20.173,36.015,81.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.325 | Acc: 20.061,36.293,81.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.318 | Acc: 20.119,36.314,82.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.304 | Acc: 20.026,36.384,82.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.294 | Acc: 20.131,36.486,82.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.284 | Acc: 20.200,36.816,83.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.277 | Acc: 20.143,36.789,83.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.271 | Acc: 20.160,36.916,83.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.264 | Acc: 20.187,36.943,83.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.259 | Acc: 20.173,36.997,83.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.253 | Acc: 20.268,37.033,83.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.249 | Acc: 20.193,37.069,84.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.245 | Acc: 20.180,37.042,84.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.241 | Acc: 20.198,37.065,84.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.238 | Acc: 20.200,37.178,84.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.728 | Acc: 19.531,37.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.738 | Acc: 17.857,37.240,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.773 | Acc: 18.598,36.719,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.780 | Acc: 19.006,36.757,71.811,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.101 | Acc: 17.969,45.312,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.109 | Acc: 19.643,38.653,88.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.129 | Acc: 20.351,38.472,87.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.129 | Acc: 20.415,38.204,87.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.121 | Acc: 20.245,37.982,88.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.126 | Acc: 20.320,38.072,87.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.127 | Acc: 20.280,37.978,87.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.126 | Acc: 20.479,38.071,87.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.128 | Acc: 20.516,38.179,87.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.128 | Acc: 20.433,38.195,87.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.128 | Acc: 20.301,38.188,87.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.129 | Acc: 20.175,38.020,87.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.131 | Acc: 20.128,38.048,87.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.130 | Acc: 20.109,38.060,87.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.127 | Acc: 20.201,38.167,87.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.126 | Acc: 20.242,38.188,87.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.126 | Acc: 20.283,38.167,87.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.126 | Acc: 20.310,38.233,87.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.123 | Acc: 20.312,38.255,87.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.124 | Acc: 20.284,38.166,87.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.726 | Acc: 20.312,36.719,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 18.415,38.244,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.775 | Acc: 19.131,37.557,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.781 | Acc: 19.288,37.410,71.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.139 | Acc: 17.969,36.719,85.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.091 | Acc: 21.540,38.170,89.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.093 | Acc: 20.884,38.624,89.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.102 | Acc: 20.722,38.230,88.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.099 | Acc: 21.181,38.715,89.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.099 | Acc: 21.171,38.753,89.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.100 | Acc: 20.913,38.501,88.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.101 | Acc: 20.800,38.431,88.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.100 | Acc: 20.837,38.495,88.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.096 | Acc: 20.787,38.428,88.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.097 | Acc: 20.697,38.289,88.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.097 | Acc: 20.860,38.532,88.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.095 | Acc: 20.951,38.560,88.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.092 | Acc: 20.872,38.631,88.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.093 | Acc: 20.757,38.454,88.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.091 | Acc: 20.769,38.421,88.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.094 | Acc: 20.692,38.405,88.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.097 | Acc: 20.684,38.311,88.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.097 | Acc: 20.676,38.307,88.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.096 | Acc: 20.692,38.402,88.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.707 | Acc: 21.094,36.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.732 | Acc: 18.006,38.318,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 18.769,37.729,72.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.769 | Acc: 19.109,37.526,72.503,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 1.069 | Acc: 14.062,37.500,88.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.076 | Acc: 20.685,38.765,89.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.067 | Acc: 20.312,38.072,89.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.064 | Acc: 20.786,38.217,89.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.065 | Acc: 20.766,38.117,89.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.064 | Acc: 20.606,38.289,89.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.070 | Acc: 20.719,38.540,89.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.066 | Acc: 20.700,38.680,89.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.066 | Acc: 20.769,38.694,89.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.066 | Acc: 20.714,38.704,89.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.067 | Acc: 20.581,38.647,89.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.069 | Acc: 20.496,38.642,89.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.069 | Acc: 20.501,38.622,89.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.068 | Acc: 20.471,38.697,89.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.068 | Acc: 20.577,38.804,89.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.069 | Acc: 20.619,38.842,89.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.072 | Acc: 20.639,38.858,89.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.073 | Acc: 20.658,38.877,89.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.072 | Acc: 20.592,38.835,89.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.072 | Acc: 20.491,38.784,89.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.762 | Acc: 20.312,37.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.737 | Acc: 18.192,39.062,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.776 | Acc: 18.941,38.262,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.782 | Acc: 19.467,37.743,72.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 1.096 | Acc: 18.750,39.062,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.028 | Acc: 21.875,40.327,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.033 | Acc: 21.875,39.615,90.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.045 | Acc: 21.324,38.730,89.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.050 | Acc: 21.132,38.532,89.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.049 | Acc: 21.125,38.575,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.050 | Acc: 20.894,38.630,89.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.049 | Acc: 20.922,38.592,89.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.049 | Acc: 21.103,38.694,89.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.050 | Acc: 21.055,38.696,89.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.053 | Acc: 20.962,38.619,89.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.054 | Acc: 20.942,38.681,89.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.053 | Acc: 21.006,38.729,89.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.056 | Acc: 20.866,38.622,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.055 | Acc: 20.905,38.734,89.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.057 | Acc: 20.775,38.663,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.056 | Acc: 20.799,38.785,89.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.056 | Acc: 20.764,38.744,89.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.056 | Acc: 20.802,38.827,89.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.055 | Acc: 20.774,38.907,89.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.721 | Acc: 19.531,36.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.739 | Acc: 18.378,38.467,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.762 | Acc: 19.036,38.034,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.772 | Acc: 19.518,37.859,72.234,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.054 | Acc: 20.312,39.062,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.057 | Acc: 21.429,38.021,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.041 | Acc: 20.617,38.777,90.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.038 | Acc: 20.082,38.204,90.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.037 | Acc: 20.129,38.339,90.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.032 | Acc: 20.135,38.482,90.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.031 | Acc: 20.241,38.778,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.030 | Acc: 20.196,38.780,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.030 | Acc: 20.288,38.844,90.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.033 | Acc: 20.226,38.782,90.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.033 | Acc: 20.355,38.938,90.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.036 | Acc: 20.348,38.734,90.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.036 | Acc: 20.222,38.716,90.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.036 | Acc: 20.327,38.805,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.037 | Acc: 20.449,38.754,90.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.035 | Acc: 20.629,38.883,90.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.037 | Acc: 20.702,38.899,90.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.038 | Acc: 20.674,38.957,90.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.039 | Acc: 20.635,38.972,90.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.039 | Acc: 20.663,39.011,90.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.754 | Acc: 21.875,39.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.742 | Acc: 18.936,38.765,73.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.775 | Acc: 19.379,38.053,72.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 19.839,37.897,72.426,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 0.992 | Acc: 25.781,40.625,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.029 | Acc: 20.015,39.323,90.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.023 | Acc: 19.684,39.215,90.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.029 | Acc: 19.557,38.883,90.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.026 | Acc: 19.801,38.783,90.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.026 | Acc: 19.972,38.970,90.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.021 | Acc: 20.158,39.024,90.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.024 | Acc: 20.235,38.841,90.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.023 | Acc: 20.444,38.883,90.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.024 | Acc: 20.489,38.989,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.023 | Acc: 20.577,39.210,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.022 | Acc: 20.655,39.239,90.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.024 | Acc: 20.740,39.150,90.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.024 | Acc: 20.776,39.137,90.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.025 | Acc: 20.732,39.121,90.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.027 | Acc: 20.606,38.956,90.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.028 | Acc: 20.614,39.014,90.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.028 | Acc: 20.567,39.003,90.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.028 | Acc: 20.696,39.017,90.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.029 | Acc: 20.686,39.017,90.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.692 | Acc: 19.531,38.281,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.734 | Acc: 18.973,39.137,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.767 | Acc: 19.512,38.319,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.781 | Acc: 19.800,38.076,72.503,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 0.964 | Acc: 27.344,50.000,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.023 | Acc: 20.685,39.137,90.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.003 | Acc: 21.056,39.062,91.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.009 | Acc: 20.479,38.691,91.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.009 | Acc: 20.583,39.275,91.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.008 | Acc: 20.490,39.055,91.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.008 | Acc: 20.506,38.927,91.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.008 | Acc: 20.512,38.952,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.009 | Acc: 20.487,38.898,91.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.010 | Acc: 20.511,38.825,91.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.009 | Acc: 20.651,38.876,91.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.010 | Acc: 20.701,38.857,91.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.008 | Acc: 20.786,39.053,91.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.010 | Acc: 20.711,39.003,91.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.009 | Acc: 20.696,39.040,91.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.010 | Acc: 20.715,39.101,91.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.010 | Acc: 20.729,39.136,91.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.010 | Acc: 20.775,39.140,91.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.008 | Acc: 20.841,39.268,91.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.008 | Acc: 20.885,39.307,91.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.706 | Acc: 21.875,38.281,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.757 | Acc: 18.676,38.951,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 19.264,38.472,72.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.798 | Acc: 19.647,38.192,72.246,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 0.993 | Acc: 17.969,35.938,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.984 | Acc: 19.866,38.988,92.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.990 | Acc: 19.950,39.748,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.991 | Acc: 20.338,39.242,91.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.996 | Acc: 20.197,39.005,91.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.996 | Acc: 20.173,38.916,91.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.001 | Acc: 20.087,38.817,91.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.000 | Acc: 20.119,39.007,91.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.001 | Acc: 20.211,39.009,91.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.999 | Acc: 20.330,39.058,91.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.998 | Acc: 20.363,39.059,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.998 | Acc: 20.457,39.207,91.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.998 | Acc: 20.368,39.079,91.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.997 | Acc: 20.408,39.293,91.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.999 | Acc: 20.371,39.313,91.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.000 | Acc: 20.523,39.361,91.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.001 | Acc: 20.505,39.420,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.002 | Acc: 20.626,39.443,91.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.002 | Acc: 20.680,39.459,91.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.002 | Acc: 20.727,39.415,91.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.754 | Acc: 20.312,36.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.763 | Acc: 18.490,39.323,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.788 | Acc: 19.379,38.834,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.805 | Acc: 19.813,38.422,72.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 1.030 | Acc: 26.562,39.062,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.972 | Acc: 21.429,40.067,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.979 | Acc: 20.979,39.901,92.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.976 | Acc: 20.876,39.895,92.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.981 | Acc: 21.007,39.612,92.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.984 | Acc: 21.218,39.627,92.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.985 | Acc: 21.275,39.740,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.986 | Acc: 21.110,39.750,92.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.986 | Acc: 21.021,39.815,92.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.989 | Acc: 20.904,39.736,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.992 | Acc: 20.740,39.692,91.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.992 | Acc: 20.715,39.628,91.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.993 | Acc: 20.669,39.643,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.993 | Acc: 20.699,39.733,91.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.993 | Acc: 20.696,39.632,91.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.994 | Acc: 20.707,39.665,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.994 | Acc: 20.804,39.742,91.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.994 | Acc: 20.778,39.727,91.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.996 | Acc: 20.756,39.608,91.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.996 | Acc: 20.844,39.682,91.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.749 | Acc: 20.312,36.719,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.764 | Acc: 18.824,39.509,73.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.797 | Acc: 19.436,38.548,72.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.813 | Acc: 19.813,38.371,71.977,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 0.918 | Acc: 17.188,39.062,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.962 | Acc: 22.173,39.658,92.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.984 | Acc: 21.513,39.596,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.979 | Acc: 21.350,40.100,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.979 | Acc: 21.219,39.786,92.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.979 | Acc: 21.117,39.813,92.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 21.197,39.954,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.978 | Acc: 21.133,39.905,92.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.979 | Acc: 21.322,40.096,92.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.979 | Acc: 21.348,39.952,92.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.982 | Acc: 21.280,39.921,92.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.982 | Acc: 21.348,39.939,92.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.985 | Acc: 21.159,39.828,92.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.984 | Acc: 21.091,39.739,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.982 | Acc: 21.174,39.808,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.983 | Acc: 21.011,39.719,92.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.984 | Acc: 20.957,39.649,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.984 | Acc: 20.961,39.686,92.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.985 | Acc: 20.996,39.716,92.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.985 | Acc: 21.030,39.768,92.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.745 | Acc: 20.312,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.789 | Acc: 18.936,39.137,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.817 | Acc: 19.550,38.681,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 19.954,38.525,72.131,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 1.038 | Acc: 21.875,36.719,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.993 | Acc: 22.470,41.853,91.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.974 | Acc: 21.570,40.854,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.975 | Acc: 21.055,40.190,92.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.982 | Acc: 21.074,40.230,92.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.981 | Acc: 21.140,40.362,92.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.979 | Acc: 21.275,40.360,92.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.976 | Acc: 21.299,40.348,92.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.978 | Acc: 21.040,40.028,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.975 | Acc: 21.085,40.016,92.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.975 | Acc: 21.098,40.058,92.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.974 | Acc: 21.051,40.102,92.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.973 | Acc: 21.084,40.064,92.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.973 | Acc: 21.190,40.077,92.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.974 | Acc: 21.199,40.022,92.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.975 | Acc: 21.089,40.015,92.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.977 | Acc: 21.045,39.909,92.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.978 | Acc: 21.062,39.821,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.977 | Acc: 21.040,39.844,92.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.978 | Acc: 20.942,39.801,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.740 | Acc: 19.531,38.281,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.781 | Acc: 18.527,39.435,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.807 | Acc: 19.341,38.929,72.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.816 | Acc: 19.647,38.537,72.400,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.911 | Acc: 19.531,34.375,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.958 | Acc: 20.908,38.170,93.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.962 | Acc: 21.723,39.463,93.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.967 | Acc: 21.414,39.703,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.963 | Acc: 21.296,39.931,92.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.964 | Acc: 21.101,39.356,92.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.964 | Acc: 21.055,39.708,92.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.965 | Acc: 21.282,39.716,92.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.964 | Acc: 21.404,39.863,92.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.967 | Acc: 21.275,39.749,92.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.967 | Acc: 21.144,39.704,92.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.968 | Acc: 21.140,39.815,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.966 | Acc: 21.162,39.909,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.967 | Acc: 21.091,39.838,92.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.967 | Acc: 21.110,39.916,92.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.969 | Acc: 20.998,39.903,92.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.969 | Acc: 21.057,39.982,92.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.970 | Acc: 21.007,39.782,92.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.971 | Acc: 21.074,39.759,92.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.971 | Acc: 21.071,39.829,92.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.736 | Acc: 19.531,35.156,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.789 | Acc: 18.750,39.472,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.815 | Acc: 19.112,38.739,72.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.826 | Acc: 19.531,38.742,72.362,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 0.909 | Acc: 25.781,39.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.951 | Acc: 21.057,41.555,93.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.953 | Acc: 21.170,40.168,93.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.955 | Acc: 21.196,40.330,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.956 | Acc: 21.017,40.210,92.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.954 | Acc: 20.784,40.037,92.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.952 | Acc: 21.003,40.380,92.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.953 | Acc: 21.011,40.342,92.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.952 | Acc: 21.069,40.635,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.953 | Acc: 20.943,40.327,93.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.953 | Acc: 20.977,40.380,93.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.955 | Acc: 20.871,40.194,92.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.955 | Acc: 20.899,40.213,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.955 | Acc: 20.956,40.257,92.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.956 | Acc: 20.877,40.225,92.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.956 | Acc: 21.011,40.308,92.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.955 | Acc: 21.050,40.406,92.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.956 | Acc: 21.023,40.249,92.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.956 | Acc: 21.003,40.192,92.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.957 | Acc: 20.999,40.192,92.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.749 | Acc: 20.312,41.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.793 | Acc: 18.713,39.323,73.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.828 | Acc: 19.646,38.872,72.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.839 | Acc: 19.864,38.678,72.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 1.005 | Acc: 17.969,35.938,91.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.961 | Acc: 20.387,37.984,93.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.955 | Acc: 20.598,39.196,93.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.957 | Acc: 20.594,39.191,93.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.964 | Acc: 20.544,38.773,92.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.956 | Acc: 20.777,38.900,93.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.958 | Acc: 20.907,39.108,93.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.955 | Acc: 20.939,39.489,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.955 | Acc: 20.943,39.582,93.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.955 | Acc: 20.956,39.710,93.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.953 | Acc: 21.043,39.789,93.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.955 | Acc: 20.935,39.755,92.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.956 | Acc: 20.954,39.769,92.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.956 | Acc: 20.806,39.619,92.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.956 | Acc: 20.805,39.682,92.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.956 | Acc: 20.811,39.665,92.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.957 | Acc: 20.892,39.669,92.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.958 | Acc: 20.844,39.679,92.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.958 | Acc: 20.875,39.697,92.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.958 | Acc: 20.944,39.811,92.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.752 | Acc: 21.094,39.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.778 | Acc: 19.457,40.253,72.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.809 | Acc: 19.817,39.577,72.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 20.248,39.165,72.349,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 1.029 | Acc: 20.312,35.938,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.950 | Acc: 21.168,40.216,93.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 21.037,40.949,93.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.951 | Acc: 20.530,40.574,93.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.946 | Acc: 20.525,40.693,93.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.947 | Acc: 20.483,40.679,93.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.951 | Acc: 20.881,40.573,93.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.949 | Acc: 21.022,40.653,93.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.948 | Acc: 21.006,40.572,93.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.947 | Acc: 21.133,40.556,93.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.947 | Acc: 21.070,40.543,93.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.948 | Acc: 20.984,40.303,93.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.949 | Acc: 20.935,40.165,93.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.949 | Acc: 20.950,40.164,93.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.949 | Acc: 21.002,40.094,93.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.949 | Acc: 21.011,40.028,93.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.948 | Acc: 21.021,40.094,93.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.950 | Acc: 21.027,40.050,92.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.950 | Acc: 20.999,40.008,92.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.951 | Acc: 21.014,39.998,92.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.723 | Acc: 19.531,37.500,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.787 | Acc: 19.271,39.732,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.825 | Acc: 19.836,38.910,72.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.835 | Acc: 20.108,38.819,72.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 0.985 | Acc: 16.406,39.062,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.956 | Acc: 21.205,40.551,92.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.945 | Acc: 21.037,40.339,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.945 | Acc: 20.902,40.151,93.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.946 | Acc: 20.833,40.075,93.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.943 | Acc: 20.777,40.308,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.939 | Acc: 20.939,40.612,93.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.940 | Acc: 20.994,40.315,93.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.940 | Acc: 20.948,40.276,93.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.939 | Acc: 20.960,40.047,93.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.940 | Acc: 21.008,40.143,93.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.942 | Acc: 20.938,40.102,93.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.942 | Acc: 20.928,40.058,93.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.942 | Acc: 20.920,40.068,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.943 | Acc: 20.985,40.105,93.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.942 | Acc: 21.109,40.256,93.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.942 | Acc: 21.096,40.260,93.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.942 | Acc: 21.133,40.279,93.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.943 | Acc: 21.087,40.341,93.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.944 | Acc: 21.075,40.258,93.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.761 | Acc: 19.531,40.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.815 | Acc: 19.196,40.179,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.838 | Acc: 19.950,39.596,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.841 | Acc: 20.338,39.434,72.234,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 0.831 | Acc: 25.000,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.915 | Acc: 22.693,41.034,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.925 | Acc: 21.684,41.139,93.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.929 | Acc: 21.542,40.971,93.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.934 | Acc: 21.460,40.818,93.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.933 | Acc: 21.535,40.602,93.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.931 | Acc: 21.533,40.864,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.934 | Acc: 21.332,40.603,93.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.937 | Acc: 21.142,40.470,93.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.936 | Acc: 21.146,40.444,93.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.937 | Acc: 21.156,40.520,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.938 | Acc: 21.051,40.413,93.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.937 | Acc: 21.120,40.456,93.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.938 | Acc: 20.923,40.326,93.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.938 | Acc: 21.060,40.366,93.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.938 | Acc: 21.156,40.337,93.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.938 | Acc: 21.159,40.372,93.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.938 | Acc: 21.126,40.428,93.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.938 | Acc: 21.182,40.404,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.938 | Acc: 21.221,40.467,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.755 | Acc: 21.875,39.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.808 | Acc: 19.159,39.732,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.840 | Acc: 19.912,39.425,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.846 | Acc: 20.120,39.127,72.451,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 0.964 | Acc: 12.500,32.031,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.913 | Acc: 21.019,39.955,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.922 | Acc: 21.189,40.072,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.923 | Acc: 21.516,40.369,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.927 | Acc: 21.258,40.220,93.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.925 | Acc: 21.411,40.416,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.929 | Acc: 21.417,40.238,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.931 | Acc: 21.121,40.038,93.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.929 | Acc: 21.201,40.247,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.929 | Acc: 21.146,40.448,93.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.931 | Acc: 21.195,40.446,93.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.929 | Acc: 21.263,40.438,93.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.929 | Acc: 21.330,40.518,93.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.928 | Acc: 21.231,40.517,93.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.929 | Acc: 21.213,40.428,93.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.929 | Acc: 21.224,40.436,93.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.929 | Acc: 21.308,40.569,93.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.931 | Acc: 21.266,40.510,93.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.931 | Acc: 21.250,40.545,93.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.930 | Acc: 21.211,40.475,93.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.741 | Acc: 20.312,41.406,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.832 | Acc: 19.234,39.769,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.851 | Acc: 19.817,39.215,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.857 | Acc: 20.082,38.986,72.054,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 0.929 | Acc: 14.062,38.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.926 | Acc: 21.652,40.067,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.929 | Acc: 21.570,39.901,93.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.926 | Acc: 21.183,39.844,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.925 | Acc: 21.190,40.210,93.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.925 | Acc: 21.426,40.524,93.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.923 | Acc: 21.223,40.515,93.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.920 | Acc: 21.326,40.603,93.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.924 | Acc: 21.210,40.445,93.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.924 | Acc: 21.180,40.452,93.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.925 | Acc: 21.300,40.594,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.927 | Acc: 21.196,40.540,93.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.927 | Acc: 21.259,40.576,93.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.928 | Acc: 21.246,40.562,93.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.930 | Acc: 21.183,40.425,93.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.928 | Acc: 21.172,40.563,93.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.929 | Acc: 21.247,40.562,93.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.930 | Acc: 21.227,40.565,93.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.931 | Acc: 21.239,40.551,93.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.931 | Acc: 21.227,40.461,93.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.794 | Acc: 21.094,39.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.813 | Acc: 18.750,40.141,73.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.844 | Acc: 19.341,39.444,72.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 19.608,39.114,72.336,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 0.907 | Acc: 20.312,50.000,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.911 | Acc: 22.098,41.890,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.909 | Acc: 21.399,41.368,93.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.918 | Acc: 21.260,40.663,93.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.918 | Acc: 21.508,40.789,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.915 | Acc: 21.604,40.726,94.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.917 | Acc: 21.572,40.786,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.917 | Acc: 21.548,40.570,94.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.918 | Acc: 21.647,40.572,94.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.918 | Acc: 21.676,40.590,93.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.919 | Acc: 21.568,40.438,93.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.922 | Acc: 21.476,40.197,93.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.921 | Acc: 21.535,40.421,93.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.921 | Acc: 21.480,40.406,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.922 | Acc: 21.514,40.492,93.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.922 | Acc: 21.579,40.519,93.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.926 | Acc: 21.561,40.564,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.928 | Acc: 21.495,40.549,93.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.926 | Acc: 21.412,40.554,93.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.927 | Acc: 21.364,40.529,93.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.767 | Acc: 20.312,41.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.834 | Acc: 19.271,40.699,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.857 | Acc: 19.703,40.053,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.867 | Acc: 20.146,39.562,71.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 0.897 | Acc: 20.312,34.375,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.912 | Acc: 20.685,39.397,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.915 | Acc: 21.227,40.034,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.912 | Acc: 21.427,40.356,94.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.916 | Acc: 21.441,40.365,94.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.920 | Acc: 21.442,40.532,93.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.919 | Acc: 21.494,40.528,93.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 21.676,40.503,94.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.916 | Acc: 21.608,40.547,94.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.916 | Acc: 21.521,40.366,94.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.918 | Acc: 21.467,40.314,94.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.917 | Acc: 21.514,40.370,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.918 | Acc: 21.395,40.278,94.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.918 | Acc: 21.363,40.275,94.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.918 | Acc: 21.249,40.269,94.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.918 | Acc: 21.216,40.259,94.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.919 | Acc: 21.147,40.245,94.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.919 | Acc: 21.162,40.229,93.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.919 | Acc: 21.185,40.244,93.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.919 | Acc: 21.223,40.268,93.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.833 | Acc: 21.094,44.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 19.792,40.960,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.883 | Acc: 20.027,40.034,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.891 | Acc: 20.364,39.652,71.901,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 0.916 | Acc: 21.094,37.500,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.919 | Acc: 21.019,40.327,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.918 | Acc: 21.799,40.454,93.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.909 | Acc: 21.516,40.996,94.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.912 | Acc: 21.788,40.847,94.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.912 | Acc: 21.380,40.687,94.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.912 | Acc: 21.378,40.502,94.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.915 | Acc: 21.476,40.536,93.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.917 | Acc: 21.438,40.465,93.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.915 | Acc: 21.310,40.483,94.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.915 | Acc: 21.323,40.512,94.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.913 | Acc: 21.292,40.438,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.914 | Acc: 21.210,40.362,94.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.915 | Acc: 21.196,40.526,94.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.915 | Acc: 21.138,40.581,94.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.915 | Acc: 21.213,40.604,93.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.916 | Acc: 21.172,40.515,93.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.918 | Acc: 21.162,40.467,93.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.919 | Acc: 21.141,40.445,93.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.919 | Acc: 21.186,40.447,93.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.771 | Acc: 21.094,41.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.846 | Acc: 19.345,40.923,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.881 | Acc: 19.970,40.072,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.882 | Acc: 20.184,39.613,71.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 0.864 | Acc: 22.656,45.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.918 | Acc: 21.838,40.104,94.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.914 | Acc: 20.732,39.901,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.906 | Acc: 20.966,40.266,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.909 | Acc: 21.441,40.336,94.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.910 | Acc: 21.403,40.486,94.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.910 | Acc: 21.281,40.573,94.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.910 | Acc: 21.371,40.714,94.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.910 | Acc: 21.385,40.674,94.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.911 | Acc: 21.469,40.660,94.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.913 | Acc: 21.444,40.536,94.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.912 | Acc: 21.327,40.519,94.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.912 | Acc: 21.298,40.473,94.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.913 | Acc: 21.285,40.499,94.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.913 | Acc: 21.338,40.539,94.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.914 | Acc: 21.330,40.524,94.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.914 | Acc: 21.371,40.562,94.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.916 | Acc: 21.346,40.552,94.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.915 | Acc: 21.444,40.642,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.915 | Acc: 21.385,40.607,94.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.815 | Acc: 21.094,41.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.838 | Acc: 19.568,40.811,72.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.874 | Acc: 19.874,40.168,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.887 | Acc: 20.248,39.767,71.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 0.891 | Acc: 20.312,42.188,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.923 | Acc: 20.833,40.551,94.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.904 | Acc: 21.742,41.311,94.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.904 | Acc: 21.516,41.317,94.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.904 | Acc: 21.595,41.618,94.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.901 | Acc: 21.496,41.623,94.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.903 | Acc: 21.584,41.613,94.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.903 | Acc: 21.371,41.622,94.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.904 | Acc: 21.332,41.382,94.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.907 | Acc: 21.301,41.290,94.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.908 | Acc: 21.296,41.181,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.906 | Acc: 21.302,41.081,94.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.909 | Acc: 21.285,40.998,94.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.908 | Acc: 21.345,40.966,94.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.908 | Acc: 21.391,40.884,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.907 | Acc: 21.361,40.872,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.908 | Acc: 21.379,40.915,94.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.908 | Acc: 21.392,40.872,94.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.909 | Acc: 21.444,40.893,94.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.911 | Acc: 21.399,40.836,94.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.907 | Acc: 21.875,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.847 | Acc: 19.382,40.551,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.880 | Acc: 19.646,39.691,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.889 | Acc: 20.095,39.395,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.890 | Acc: 22.656,35.156,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.900 | Acc: 20.945,40.513,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.899 | Acc: 21.056,40.701,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.899 | Acc: 21.107,40.446,94.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.902 | Acc: 20.997,40.548,94.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.901 | Acc: 21.233,40.857,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.901 | Acc: 21.429,40.677,94.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.903 | Acc: 21.410,40.869,94.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.904 | Acc: 21.312,40.872,94.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.903 | Acc: 21.379,40.871,94.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.904 | Acc: 21.280,40.784,94.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.903 | Acc: 21.362,40.770,94.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.902 | Acc: 21.366,40.784,94.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.901 | Acc: 21.327,40.757,94.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.902 | Acc: 21.430,40.750,94.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.903 | Acc: 21.447,40.685,94.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.904 | Acc: 21.478,40.722,94.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.904 | Acc: 21.481,40.746,94.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.904 | Acc: 21.410,40.774,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.904 | Acc: 21.440,40.801,94.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.811 | Acc: 19.531,39.844,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.854 | Acc: 19.345,40.923,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.888 | Acc: 19.703,40.206,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.891 | Acc: 20.248,39.985,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 0.823 | Acc: 28.125,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.886 | Acc: 21.466,40.439,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.891 | Acc: 22.428,40.911,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.894 | Acc: 22.541,40.958,94.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.893 | Acc: 22.608,41.184,94.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.895 | Acc: 22.602,41.646,94.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.895 | Acc: 22.585,41.322,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.894 | Acc: 22.390,41.284,94.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.895 | Acc: 22.292,41.251,94.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.896 | Acc: 22.251,41.190,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.896 | Acc: 22.190,41.165,94.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.898 | Acc: 22.098,40.993,94.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.898 | Acc: 22.011,40.910,94.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.899 | Acc: 21.896,40.852,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.900 | Acc: 21.872,40.836,94.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.901 | Acc: 21.787,40.851,94.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.902 | Acc: 21.641,40.795,94.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.902 | Acc: 21.689,40.866,94.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.903 | Acc: 21.650,40.807,94.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.903 | Acc: 21.633,40.836,94.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.887 | Acc: 19.531,39.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.849 | Acc: 19.048,40.290,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.885 | Acc: 19.627,39.787,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.890 | Acc: 19.928,39.562,71.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 0.829 | Acc: 21.875,41.406,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.895 | Acc: 20.685,39.249,94.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.888 | Acc: 21.418,40.568,94.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.879 | Acc: 21.568,40.753,95.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.886 | Acc: 21.287,40.451,95.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.890 | Acc: 21.542,40.702,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.888 | Acc: 21.733,40.832,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.888 | Acc: 21.714,40.741,94.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.891 | Acc: 21.671,40.756,94.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.891 | Acc: 21.577,40.914,94.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.890 | Acc: 21.611,40.994,94.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.891 | Acc: 21.447,41.017,94.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.891 | Acc: 21.554,41.102,94.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.891 | Acc: 21.477,40.996,94.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.893 | Acc: 21.458,40.986,94.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.895 | Acc: 21.457,40.892,94.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.896 | Acc: 21.444,40.815,94.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.898 | Acc: 21.453,40.774,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.898 | Acc: 21.496,40.781,94.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.899 | Acc: 21.471,40.699,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.696 | Acc: 19.531,39.062,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.847 | Acc: 19.606,40.365,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.878 | Acc: 20.046,39.768,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.888 | Acc: 20.492,39.613,71.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 1.018 | Acc: 17.969,42.188,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.882 | Acc: 21.019,41.332,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.886 | Acc: 21.646,40.930,95.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.885 | Acc: 21.388,40.548,95.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.893 | Acc: 21.576,40.577,94.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.893 | Acc: 21.465,40.455,94.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.891 | Acc: 21.726,40.644,94.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.893 | Acc: 21.703,40.669,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 21.759,40.727,94.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.895 | Acc: 21.914,40.767,94.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.896 | Acc: 21.774,40.734,94.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.895 | Acc: 21.705,40.766,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.895 | Acc: 21.625,40.781,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.894 | Acc: 21.630,40.829,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.895 | Acc: 21.547,40.764,94.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.895 | Acc: 21.522,40.757,94.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.896 | Acc: 21.486,40.766,94.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.896 | Acc: 21.529,40.868,94.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.896 | Acc: 21.466,40.902,94.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.896 | Acc: 21.494,40.935,94.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.829 | Acc: 21.875,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 20.201,41.741,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.892 | Acc: 20.541,40.682,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.892 | Acc: 20.838,40.420,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 0.926 | Acc: 24.219,40.625,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.900 | Acc: 21.205,39.918,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.897 | Acc: 21.380,40.301,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.895 | Acc: 21.158,40.996,94.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.893 | Acc: 21.026,40.750,94.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.891 | Acc: 21.310,40.934,94.539,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.895 | Acc: 21.423,40.851,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.894 | Acc: 21.509,40.808,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 21.637,41.047,94.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.894 | Acc: 21.681,40.953,94.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.893 | Acc: 21.591,40.967,94.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.894 | Acc: 21.525,40.837,94.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.894 | Acc: 21.603,40.894,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.894 | Acc: 21.540,40.960,94.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.895 | Acc: 21.603,40.959,94.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.895 | Acc: 21.532,40.892,94.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.896 | Acc: 21.456,40.827,94.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.896 | Acc: 21.486,40.820,94.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.896 | Acc: 21.540,40.896,94.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.897 | Acc: 21.451,40.871,94.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.774 | Acc: 21.094,38.281,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.886 | Acc: 19.680,41.071,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 19.893,39.977,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.919 | Acc: 20.236,39.613,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.962 | Acc: 25.000,36.719,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.881 | Acc: 22.359,40.588,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.884 | Acc: 22.256,40.854,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 21.849,40.907,94.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.887 | Acc: 21.682,40.808,94.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.888 | Acc: 21.326,40.648,94.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.887 | Acc: 21.333,40.935,94.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.886 | Acc: 21.526,40.963,94.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.887 | Acc: 21.530,41.033,94.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.889 | Acc: 21.525,40.949,94.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.891 | Acc: 21.479,40.897,94.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.891 | Acc: 21.479,40.855,94.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.891 | Acc: 21.496,40.865,94.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.891 | Acc: 21.516,41.002,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.891 | Acc: 21.597,41.042,94.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.891 | Acc: 21.631,41.027,94.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.891 | Acc: 21.615,40.985,94.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.891 | Acc: 21.589,40.962,94.721,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.891 | Acc: 21.546,40.915,94.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.892 | Acc: 21.496,40.877,94.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.816 | Acc: 21.875,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.864 | Acc: 20.089,40.476,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.903 | Acc: 20.255,39.958,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.918 | Acc: 20.543,39.447,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 0.940 | Acc: 25.781,40.625,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.894 | Acc: 21.205,41.815,94.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.893 | Acc: 20.846,41.139,94.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.891 | Acc: 20.735,41.291,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.884 | Acc: 20.959,40.905,94.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.888 | Acc: 20.792,40.787,94.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.886 | Acc: 20.894,40.754,94.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.885 | Acc: 21.038,40.885,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.886 | Acc: 21.045,40.863,94.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.887 | Acc: 21.284,40.906,94.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 21.397,41.177,94.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 21.408,41.226,94.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.883 | Acc: 21.369,41.134,94.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.884 | Acc: 21.435,41.026,94.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.884 | Acc: 21.444,41.120,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.884 | Acc: 21.486,41.084,94.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.884 | Acc: 21.452,41.112,94.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.884 | Acc: 21.497,41.166,94.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.885 | Acc: 21.451,41.157,94.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.885 | Acc: 21.475,41.197,94.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.822 | Acc: 21.094,42.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.850 | Acc: 20.015,40.885,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.882 | Acc: 20.408,40.149,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.896 | Acc: 20.684,39.741,71.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 0.821 | Acc: 20.312,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 21.801,42.783,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.871 | Acc: 22.066,42.245,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 21.350,41.419,95.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.876 | Acc: 21.325,40.702,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 21.326,40.981,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.872 | Acc: 21.165,40.974,95.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.871 | Acc: 21.360,40.980,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 21.487,41.173,95.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.874 | Acc: 21.633,41.259,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 21.576,41.309,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 21.550,41.343,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.877 | Acc: 21.518,41.179,95.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.878 | Acc: 21.534,41.242,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.878 | Acc: 21.514,41.173,95.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.880 | Acc: 21.405,41.105,95.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.880 | Acc: 21.386,41.058,95.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.880 | Acc: 21.378,41.051,95.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.881 | Acc: 21.332,41.025,95.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.881 | Acc: 21.311,41.047,95.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.730 | Acc: 20.312,42.188,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.876 | Acc: 19.940,41.257,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.915 | Acc: 20.332,40.663,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.922 | Acc: 20.722,40.228,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 0.892 | Acc: 25.000,42.969,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 22.061,41.369,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 22.332,41.825,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 22.131,41.547,95.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 22.029,41.146,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 22.006,41.035,95.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 21.875,41.109,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 21.753,41.074,95.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.872 | Acc: 21.647,41.173,95.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.874 | Acc: 21.499,40.884,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.873 | Acc: 21.665,41.002,95.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.874 | Acc: 21.705,41.049,95.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.876 | Acc: 21.668,41.098,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.877 | Acc: 21.683,41.158,95.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.877 | Acc: 21.614,41.061,95.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.878 | Acc: 21.574,41.020,95.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.879 | Acc: 21.605,41.048,95.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.880 | Acc: 21.575,41.076,94.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.881 | Acc: 21.511,41.008,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.882 | Acc: 21.555,40.974,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.786 | Acc: 21.875,40.625,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.895 | Acc: 19.792,39.993,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.922 | Acc: 20.465,39.882,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.934 | Acc: 20.710,39.652,70.876,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 0.915 | Acc: 17.969,39.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.861 | Acc: 22.061,40.997,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 21.780,41.254,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.868 | Acc: 21.939,41.278,95.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 21.595,40.982,95.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 21.542,40.958,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.872 | Acc: 21.559,40.903,95.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 21.471,40.786,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 21.404,40.712,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.875 | Acc: 21.491,40.707,95.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.876 | Acc: 21.529,40.707,95.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 21.369,40.781,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.878 | Acc: 21.405,40.826,95.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.879 | Acc: 21.474,40.879,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.878 | Acc: 21.533,40.920,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.879 | Acc: 21.553,40.926,95.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.880 | Acc: 21.561,40.939,95.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.881 | Acc: 21.467,40.969,95.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.880 | Acc: 21.429,40.926,95.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.881 | Acc: 21.524,41.006,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.873 | Acc: 19.531,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.867 | Acc: 19.159,41.109,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.909 | Acc: 19.931,40.091,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.922 | Acc: 20.338,39.857,71.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.900 | Acc: 21.094,42.969,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.872 | Acc: 21.689,41.518,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.875 | Acc: 21.570,41.330,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.870 | Acc: 21.926,42.059,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 22.338,42.207,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.871 | Acc: 22.130,41.878,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 22.082,41.884,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.874 | Acc: 21.864,41.578,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 21.744,41.416,95.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.877 | Acc: 21.763,41.346,95.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.877 | Acc: 21.731,41.391,95.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.878 | Acc: 21.557,41.254,95.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.878 | Acc: 21.561,41.205,95.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.878 | Acc: 21.543,41.233,95.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.878 | Acc: 21.494,41.170,95.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 21.525,41.212,95.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 21.539,41.238,95.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.878 | Acc: 21.518,41.198,95.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.878 | Acc: 21.488,41.108,95.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 21.545,41.177,95.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.811 | Acc: 21.875,41.406,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.868 | Acc: 19.568,41.518,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.905 | Acc: 20.103,40.492,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.918 | Acc: 20.300,39.844,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 0.802 | Acc: 25.000,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.873 | Acc: 22.135,40.699,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.868 | Acc: 21.627,41.349,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 21.862,41.304,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.871 | Acc: 21.943,41.098,95.206,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.865 | Acc: 22.231,41.422,95.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 21.810,41.335,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.867 | Acc: 21.753,41.218,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.868 | Acc: 21.759,41.222,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.869 | Acc: 21.633,41.031,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 21.673,41.189,95.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 21.695,41.219,95.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 21.648,41.387,95.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.871 | Acc: 21.656,41.349,95.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 21.555,41.326,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.872 | Acc: 21.587,41.300,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.873 | Acc: 21.585,41.243,95.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.873 | Acc: 21.641,41.248,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.874 | Acc: 21.617,41.222,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.874 | Acc: 21.654,41.183,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.870 | Acc: 21.875,42.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.886 | Acc: 19.606,41.146,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.916 | Acc: 20.351,40.263,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.922 | Acc: 20.684,39.793,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 0.925 | Acc: 22.656,36.719,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.876 | Acc: 22.173,42.150,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.865 | Acc: 21.818,42.264,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 21.811,41.688,95.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.867 | Acc: 22.078,41.975,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.865 | Acc: 21.914,41.530,95.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.866 | Acc: 21.965,41.426,95.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.865 | Acc: 21.986,41.606,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 21.909,41.571,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.866 | Acc: 21.845,41.583,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.867 | Acc: 21.867,41.709,95.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.868 | Acc: 21.797,41.615,95.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 21.690,41.568,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.870 | Acc: 21.651,41.409,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.870 | Acc: 21.658,41.462,95.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 21.719,41.494,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.868 | Acc: 21.714,41.535,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 21.754,41.551,95.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.868 | Acc: 21.778,41.437,95.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.870 | Acc: 21.707,41.300,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.810 | Acc: 21.875,39.062,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.881 | Acc: 20.089,41.146,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.912 | Acc: 20.541,40.682,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.916 | Acc: 20.761,40.164,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.855 | Acc: 28.125,43.750,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.859 | Acc: 20.275,40.885,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.862 | Acc: 20.427,41.025,95.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 20.594,41.329,95.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 20.930,41.001,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.865 | Acc: 21.388,41.190,95.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.867 | Acc: 21.462,40.980,95.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.866 | Acc: 21.277,41.052,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.865 | Acc: 21.535,41.343,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 21.482,41.264,95.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 21.580,41.192,95.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 21.564,41.116,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 21.599,41.267,95.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 21.624,41.266,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 21.533,41.217,95.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 21.460,41.269,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.866 | Acc: 21.422,41.338,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.866 | Acc: 21.476,41.383,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 21.559,41.534,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 21.676,41.529,95.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.929 | Acc: 21.094,39.062,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.923 | Acc: 20.573,41.443,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 20.541,40.720,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.947 | Acc: 21.030,40.356,71.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.865 | Acc: 24.219,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.875 | Acc: 22.433,41.964,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.873 | Acc: 21.761,42.111,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.873 | Acc: 22.067,41.816,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.869 | Acc: 22.058,41.937,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.867 | Acc: 21.658,41.499,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.869 | Acc: 21.662,41.426,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 21.803,41.323,95.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 21.865,41.489,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.870 | Acc: 21.888,41.337,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.869 | Acc: 21.999,41.562,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 22.041,41.608,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.867 | Acc: 22.037,41.546,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.867 | Acc: 21.923,41.481,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 21.936,41.512,95.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.868 | Acc: 21.810,41.456,95.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.869 | Acc: 21.705,41.431,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.870 | Acc: 21.735,41.436,95.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.870 | Acc: 21.700,41.350,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.871 | Acc: 21.744,41.330,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.866 | Acc: 23.438,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.897 | Acc: 20.164,41.629,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.922 | Acc: 20.598,40.644,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 20.914,40.420,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 0.919 | Acc: 20.312,39.062,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.869 | Acc: 21.652,40.067,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.865 | Acc: 22.085,40.358,95.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.867 | Acc: 21.504,39.985,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 21.634,40.548,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.859 | Acc: 21.643,40.702,95.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 21.520,40.838,95.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 21.548,40.935,95.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.862 | Acc: 21.695,41.130,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 21.642,41.147,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.861 | Acc: 21.708,41.317,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.861 | Acc: 21.712,41.346,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.861 | Acc: 21.697,41.202,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 21.800,41.325,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.861 | Acc: 21.750,41.362,95.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.861 | Acc: 21.779,41.318,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 21.887,41.379,95.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 21.854,41.454,95.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.863 | Acc: 21.853,41.463,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 21.871,41.396,95.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.917 | Acc: 19.531,37.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 19.978,41.220,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.952 | Acc: 20.522,40.530,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 20.966,40.394,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.842 | Acc: 19.531,43.750,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.858 | Acc: 20.908,40.885,95.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.858 | Acc: 21.284,40.549,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.857 | Acc: 21.324,40.523,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.860 | Acc: 21.537,40.799,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.854 | Acc: 21.604,41.445,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 21.365,41.393,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.857 | Acc: 21.504,41.417,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 21.540,41.343,95.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 21.508,41.402,95.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.862 | Acc: 21.591,41.422,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.861 | Acc: 21.596,41.371,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.863 | Acc: 21.612,41.465,95.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 21.665,41.370,95.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 21.714,41.320,95.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.864 | Acc: 21.675,41.391,95.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 21.675,41.280,95.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.864 | Acc: 21.660,41.349,95.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.864 | Acc: 21.698,41.389,95.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.864 | Acc: 21.719,41.496,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.894 | Acc: 20.312,39.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.901 | Acc: 19.457,41.146,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.931 | Acc: 20.274,40.854,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.940 | Acc: 20.838,40.330,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.825 | Acc: 23.438,46.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.849 | Acc: 21.466,41.332,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.855 | Acc: 22.104,41.883,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 21.952,41.470,95.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.858 | Acc: 21.894,41.310,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.858 | Acc: 21.937,41.244,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.860 | Acc: 21.946,41.167,95.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.861 | Acc: 21.842,41.223,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.860 | Acc: 21.744,41.353,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.861 | Acc: 21.543,41.130,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.863 | Acc: 21.638,41.192,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.865 | Acc: 21.663,41.212,95.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.865 | Acc: 21.658,41.170,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.864 | Acc: 21.752,41.257,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 21.808,41.187,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.864 | Acc: 21.898,41.261,95.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.864 | Acc: 21.868,41.231,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.865 | Acc: 21.889,41.292,95.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.865 | Acc: 21.910,41.406,95.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.865 | Acc: 21.902,41.365,95.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.025 | Acc: 22.656,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.915 | Acc: 20.201,41.220,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.936 | Acc: 20.789,40.701,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.940 | Acc: 21.132,40.292,71.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.955 | Acc: 19.531,38.281,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.864 | Acc: 22.098,41.481,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.861 | Acc: 22.027,41.711,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.856 | Acc: 22.272,41.765,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 22.164,41.782,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 22.184,41.692,95.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.856 | Acc: 22.133,41.652,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.858 | Acc: 21.903,41.633,95.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.858 | Acc: 21.885,41.576,95.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.858 | Acc: 21.845,41.514,95.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.858 | Acc: 21.813,41.535,95.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 21.765,41.463,95.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 21.775,41.361,95.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.859 | Acc: 21.797,41.361,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.859 | Acc: 21.767,41.387,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.860 | Acc: 21.737,41.404,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 21.802,41.360,95.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 21.818,41.354,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 21.741,41.328,95.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 21.785,41.289,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.944 | Acc: 18.750,40.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.900 | Acc: 19.903,41.741,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.934 | Acc: 20.675,40.568,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 20.748,40.164,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 0.877 | Acc: 21.094,35.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.858 | Acc: 21.689,41.220,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.859 | Acc: 21.989,41.597,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.859 | Acc: 21.670,41.496,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 21.653,41.329,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.859 | Acc: 21.813,41.584,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.859 | Acc: 21.991,41.555,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.860 | Acc: 21.786,41.417,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.856 | Acc: 21.890,41.668,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.854 | Acc: 21.819,41.644,95.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 21.879,41.577,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.855 | Acc: 21.995,41.587,95.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 21.937,41.672,95.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 21.908,41.822,95.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.854 | Acc: 21.911,41.793,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.855 | Acc: 21.911,41.749,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.856 | Acc: 21.814,41.650,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.856 | Acc: 21.825,41.674,95.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.856 | Acc: 21.801,41.683,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.856 | Acc: 21.779,41.650,95.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.844 | Acc: 22.656,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.909 | Acc: 20.387,41.220,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.921 | Acc: 20.636,40.701,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.933 | Acc: 20.735,40.446,71.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.852 | Acc: 21.094,42.188,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.861 | Acc: 21.540,40.327,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.857 | Acc: 21.380,39.405,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 21.811,40.023,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.855 | Acc: 21.721,40.258,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.855 | Acc: 21.867,40.687,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.854 | Acc: 22.056,40.774,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 22.185,40.941,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.856 | Acc: 22.263,41.042,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 22.199,41.052,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.860 | Acc: 22.201,41.072,95.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.859 | Acc: 22.211,41.145,95.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 22.212,41.315,95.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.858 | Acc: 22.120,41.355,95.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.858 | Acc: 22.214,41.542,95.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.858 | Acc: 22.114,41.417,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 22.031,41.375,95.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 22.102,41.441,95.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.857 | Acc: 22.018,41.439,95.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.859 | Acc: 21.959,41.330,95.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.904 | Acc: 20.312,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.930 | Acc: 19.606,41.629,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 20.408,40.835,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 20.658,40.510,70.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 0.904 | Acc: 25.000,36.719,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.841 | Acc: 22.173,41.815,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.847 | Acc: 21.513,40.587,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.847 | Acc: 21.657,41.099,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.841 | Acc: 22.049,41.590,96.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 22.177,41.584,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.843 | Acc: 21.985,41.639,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 21.858,41.512,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.844 | Acc: 21.729,41.557,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.845 | Acc: 21.685,41.596,96.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 21.692,41.628,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 21.681,41.753,95.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 21.638,41.714,95.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 21.686,41.739,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.850 | Acc: 21.636,41.695,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 21.675,41.736,95.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 21.661,41.735,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 21.694,41.720,95.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 21.711,41.701,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 21.711,41.749,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.855 | Acc: 22.656,41.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.924 | Acc: 20.238,41.071,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 20.694,40.739,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.953 | Acc: 20.850,40.369,71.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 0.879 | Acc: 21.875,45.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.844 | Acc: 20.722,42.076,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.848 | Acc: 20.903,42.073,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 22.234,43.071,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.847 | Acc: 22.174,42.612,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 22.153,42.365,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.845 | Acc: 22.379,42.433,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 22.213,42.210,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 22.176,42.158,95.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.850 | Acc: 22.065,42.179,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.849 | Acc: 22.069,42.110,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.851 | Acc: 22.013,41.958,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 22.066,42.048,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 22.043,41.972,95.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.853 | Acc: 22.056,41.985,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 22.088,41.902,95.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 22.021,41.893,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.851 | Acc: 21.962,41.869,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.852 | Acc: 21.951,41.852,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 21.941,41.888,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.951 | Acc: 22.656,41.406,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.917 | Acc: 20.350,42.001,71.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 20.770,41.197,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.957 | Acc: 21.043,40.843,71.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.945 | Acc: 19.531,36.719,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.842 | Acc: 21.801,41.518,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 21.113,41.806,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.854 | Acc: 21.119,41.368,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 21.316,41.271,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.849 | Acc: 21.496,41.406,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 21.475,41.497,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.851 | Acc: 21.609,41.766,95.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.853 | Acc: 21.516,41.760,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.853 | Acc: 21.607,41.903,95.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.853 | Acc: 21.696,41.981,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.854 | Acc: 21.776,41.975,95.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.855 | Acc: 21.752,41.786,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.855 | Acc: 21.776,41.906,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.856 | Acc: 21.844,41.957,95.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.856 | Acc: 21.875,41.982,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.858 | Acc: 21.899,42.005,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 21.912,41.858,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.858 | Acc: 21.814,41.811,95.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 21.787,41.823,95.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.869 | Acc: 21.875,40.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.909 | Acc: 20.424,41.295,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.933 | Acc: 20.694,41.044,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.947 | Acc: 20.978,40.484,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.776 | Acc: 28.906,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 23.363,42.076,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 22.885,42.245,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 23.271,42.316,96.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 22.868,42.342,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.842 | Acc: 22.649,42.226,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.844 | Acc: 22.327,42.291,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.845 | Acc: 22.130,42.027,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.845 | Acc: 22.006,41.935,96.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.845 | Acc: 21.987,41.769,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 22.100,41.756,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 22.094,41.838,95.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.846 | Acc: 22.086,41.769,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.847 | Acc: 22.055,41.727,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 22.045,41.654,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.849 | Acc: 22.051,41.661,95.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.850 | Acc: 22.040,41.676,95.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 22.113,41.809,95.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 22.020,41.750,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.852 | Acc: 21.973,41.734,95.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.953 | Acc: 21.094,40.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.902 | Acc: 19.903,41.183,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.928 | Acc: 20.484,40.625,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 20.914,40.305,71.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 0.874 | Acc: 22.656,33.594,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.856 | Acc: 22.619,41.778,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.852 | Acc: 22.466,41.616,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 22.477,41.867,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.845 | Acc: 22.377,42.284,95.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 22.416,42.358,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 22.262,41.994,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 22.163,41.910,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.848 | Acc: 21.972,41.765,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.848 | Acc: 22.056,41.752,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 22.058,41.729,95.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.848 | Acc: 21.893,41.534,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.847 | Acc: 21.959,41.607,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.848 | Acc: 22.040,41.628,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 22.036,41.679,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 21.994,41.668,95.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 21.994,41.723,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 22.031,41.809,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.849 | Acc: 22.024,41.837,95.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.848 | Acc: 22.033,41.841,95.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.935 | Acc: 20.312,42.188,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.940 | Acc: 20.126,41.667,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 20.579,41.197,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.977 | Acc: 20.991,40.548,70.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.879 | Acc: 23.438,44.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 22.470,43.638,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.836 | Acc: 21.551,42.835,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 21.798,42.700,95.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.843 | Acc: 21.721,42.458,95.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 21.689,42.435,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.843 | Acc: 21.578,42.259,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.842 | Acc: 21.631,42.282,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 21.851,42.537,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.842 | Acc: 21.948,42.412,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 21.685,42.137,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 21.783,42.096,95.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 21.891,42.191,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 21.926,42.155,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.844 | Acc: 21.847,42.107,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 21.870,42.107,95.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.845 | Acc: 21.885,42.041,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.845 | Acc: 21.866,42.016,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.845 | Acc: 21.832,41.913,95.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 21.834,41.872,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.996 | Acc: 20.312,37.500,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.935 | Acc: 20.052,41.257,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 20.541,40.949,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.954 | Acc: 20.889,40.356,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.840 | Acc: 25.781,42.188,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.836 | Acc: 21.168,42.448,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 21.208,41.349,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.848 | Acc: 21.388,41.150,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.843 | Acc: 21.373,41.406,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.845 | Acc: 21.519,41.368,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.847 | Acc: 21.643,41.703,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.846 | Acc: 21.520,41.761,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.845 | Acc: 21.560,41.659,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.845 | Acc: 21.646,41.708,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.845 | Acc: 21.809,41.849,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 21.723,41.859,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 21.833,41.925,95.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.845 | Acc: 21.761,41.876,95.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.846 | Acc: 21.867,41.921,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.846 | Acc: 21.901,41.941,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 21.914,41.937,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.846 | Acc: 21.909,42.013,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 21.992,42.064,95.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.846 | Acc: 21.973,42.009,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.987 | Acc: 21.094,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.958 | Acc: 20.461,41.890,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.965 | Acc: 20.675,41.368,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 20.748,40.881,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.801 | Acc: 19.531,39.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.840 | Acc: 21.801,42.299,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 21.742,42.473,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.842 | Acc: 21.696,42.059,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 21.634,41.561,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.840 | Acc: 21.836,42.025,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.840 | Acc: 21.694,41.897,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.839 | Acc: 21.681,41.905,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 21.817,41.945,96.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.840 | Acc: 21.823,41.777,96.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.841 | Acc: 21.828,41.737,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 21.801,41.728,95.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.844 | Acc: 21.765,41.802,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.844 | Acc: 21.887,41.885,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.845 | Acc: 21.900,41.982,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 21.950,42.050,95.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.845 | Acc: 21.941,42.068,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.845 | Acc: 21.937,42.039,95.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 21.881,41.906,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.847 | Acc: 21.830,41.814,95.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.864 | Acc: 20.312,40.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 20.201,41.146,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.977 | Acc: 20.427,41.235,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.991 | Acc: 20.978,40.856,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.767 | Acc: 20.312,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 22.396,42.671,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 22.123,42.359,95.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.844 | Acc: 22.080,42.354,95.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.842 | Acc: 22.242,42.332,95.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 22.030,42.056,95.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 22.166,42.149,95.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 22.180,42.204,95.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 22.156,42.076,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.842 | Acc: 22.017,41.877,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.844 | Acc: 22.011,41.764,95.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 21.956,41.668,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 21.943,41.646,95.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 21.995,41.819,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 22.036,41.884,95.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.843 | Acc: 22.085,42.060,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.845 | Acc: 22.002,41.937,95.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.846 | Acc: 21.967,41.835,95.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.846 | Acc: 21.931,41.798,95.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 21.926,41.868,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.910 | Acc: 21.875,39.844,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.935 | Acc: 20.833,41.853,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 21.056,41.044,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.942 | Acc: 21.363,40.689,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 0.809 | Acc: 21.875,44.531,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.837 | Acc: 20.871,41.369,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.842 | Acc: 21.246,41.101,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.838 | Acc: 21.043,41.483,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 21.364,41.618,96.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 21.573,41.948,96.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 21.655,41.903,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 21.930,41.922,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.836 | Acc: 22.025,42.086,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 21.940,41.911,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.838 | Acc: 21.770,41.919,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.840 | Acc: 21.755,41.912,95.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.839 | Acc: 21.800,41.818,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 21.872,41.795,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.840 | Acc: 21.783,41.732,95.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 21.852,41.780,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 21.921,41.793,95.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 21.893,41.867,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 21.858,41.843,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 21.910,41.888,95.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.910 | Acc: 21.094,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.961 | Acc: 20.424,42.597,70.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.966 | Acc: 20.675,41.711,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 21.017,41.265,70.850,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.827 | Acc: 17.969,37.500,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.830 | Acc: 22.433,42.746,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.838 | Acc: 22.256,42.283,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.835 | Acc: 22.106,41.893,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 22.193,42.072,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.832 | Acc: 22.037,41.986,96.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.831 | Acc: 22.075,42.020,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.831 | Acc: 21.925,42.043,96.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.832 | Acc: 21.822,41.993,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.833 | Acc: 21.987,42.118,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.834 | Acc: 21.995,42.129,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.836 | Acc: 21.921,42.096,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.836 | Acc: 21.875,41.967,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 21.896,42.017,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.839 | Acc: 21.928,42.021,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.839 | Acc: 22.051,42.164,96.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 22.060,42.146,96.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.839 | Acc: 22.070,42.174,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.839 | Acc: 22.031,42.181,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 22.045,42.157,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.917 | Acc: 21.094,39.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 20.089,41.778,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.988 | Acc: 20.655,40.987,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.982 | Acc: 20.966,40.382,71.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.949 | Acc: 18.750,37.500,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.850 | Acc: 23.028,43.713,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.843 | Acc: 21.970,42.759,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.837 | Acc: 22.208,42.930,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 21.875,42.612,96.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.837 | Acc: 21.999,42.683,95.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.838 | Acc: 21.843,42.388,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 21.936,42.337,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 21.914,42.343,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.839 | Acc: 21.879,42.036,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 21.995,42.086,95.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.836 | Acc: 22.137,42.343,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 22.053,42.200,95.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.837 | Acc: 21.953,42.092,95.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.838 | Acc: 21.894,42.154,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.839 | Acc: 21.924,42.107,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.839 | Acc: 21.982,42.144,95.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 21.996,42.133,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.840 | Acc: 22.005,42.136,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.840 | Acc: 22.045,42.040,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.020 | Acc: 21.094,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.005 | Acc: 20.424,42.039,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 20.808,41.235,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 21.145,40.958,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.833 | Acc: 17.969,42.188,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 22.433,42.262,95.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 21.551,41.825,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.852 | Acc: 21.145,41.432,95.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.848 | Acc: 21.605,41.831,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.844 | Acc: 21.821,42.071,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.841 | Acc: 21.978,42.233,95.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.841 | Acc: 21.986,42.160,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.842 | Acc: 21.904,42.192,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.843 | Acc: 21.940,41.898,95.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 21.937,41.985,95.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 21.875,41.982,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.843 | Acc: 21.979,41.974,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 22.025,41.972,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 22.061,41.957,95.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.842 | Acc: 22.020,41.897,95.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.842 | Acc: 22.004,42.037,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.842 | Acc: 21.980,42.073,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.843 | Acc: 22.052,42.019,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 21.998,41.962,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.981 | Acc: 21.875,41.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 20.499,41.592,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.988 | Acc: 20.713,41.159,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.005 | Acc: 20.953,40.791,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 0.906 | Acc: 20.312,35.156,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.832 | Acc: 23.661,43.713,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 22.942,42.931,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 23.117,43.046,95.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 22.868,42.660,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 22.563,42.783,95.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.839 | Acc: 22.282,42.426,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 22.418,42.531,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.839 | Acc: 22.326,42.386,95.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.839 | Acc: 22.354,42.295,95.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.840 | Acc: 22.314,42.234,95.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.842 | Acc: 22.342,42.089,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 22.238,42.025,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.843 | Acc: 22.285,41.963,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.843 | Acc: 22.259,41.987,95.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 22.199,41.860,95.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.845 | Acc: 22.114,41.796,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.844 | Acc: 22.221,41.860,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.844 | Acc: 22.204,41.943,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 22.111,41.861,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.966 | Acc: 21.875,39.844,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 20.238,42.039,70.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 20.617,41.616,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 20.966,41.163,70.108,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.754 | Acc: 31.250,44.531,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 21.317,42.560,96.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.821 | Acc: 22.656,42.683,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.823 | Acc: 22.387,42.905,96.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.824 | Acc: 22.299,42.708,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.827 | Acc: 22.215,42.450,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.825 | Acc: 21.998,42.330,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.825 | Acc: 22.097,42.282,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.830 | Acc: 22.074,42.018,96.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 22.190,42.136,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.830 | Acc: 22.097,42.063,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.830 | Acc: 22.087,42.067,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 22.066,42.103,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 22.061,42.089,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.834 | Acc: 22.036,42.104,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.835 | Acc: 21.994,42.060,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.836 | Acc: 21.992,42.029,96.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 22.067,42.059,96.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 22.074,42.144,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.837 | Acc: 21.998,42.044,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.974 | Acc: 20.312,39.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 20.350,41.667,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 20.846,41.387,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.994 | Acc: 21.427,41.189,70.530,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.882 | Acc: 19.531,45.312,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 22.991,42.336,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.820 | Acc: 22.656,41.616,96.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.826 | Acc: 22.349,41.317,96.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.827 | Acc: 22.193,41.310,96.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.829 | Acc: 22.068,41.313,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.830 | Acc: 22.024,41.658,96.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.830 | Acc: 22.124,41.861,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.283,41.998,96.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 22.238,41.842,96.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.829 | Acc: 22.236,41.912,96.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.828 | Acc: 22.412,42.110,96.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.829 | Acc: 22.300,42.003,96.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.831 | Acc: 22.267,42.005,96.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.832 | Acc: 22.228,42.043,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.832 | Acc: 22.267,42.094,96.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.831 | Acc: 22.272,42.156,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.832 | Acc: 22.262,42.139,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 22.239,42.146,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.832 | Acc: 22.271,42.253,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.034 | Acc: 22.656,42.188,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 20.499,42.113,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.976 | Acc: 20.675,41.444,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.986 | Acc: 21.017,40.907,70.914,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 0.786 | Acc: 22.656,39.844,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.819 | Acc: 22.024,42.560,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.816 | Acc: 22.675,42.969,96.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.822 | Acc: 22.579,42.764,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.827 | Acc: 22.145,42.342,96.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.830 | Acc: 22.192,42.265,96.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.831 | Acc: 22.185,42.375,96.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.831 | Acc: 21.986,42.470,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.832 | Acc: 22.089,42.775,96.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 22.091,42.775,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 21.945,42.728,96.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 21.882,42.431,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 21.849,42.304,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 21.899,42.307,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.834 | Acc: 21.933,42.232,96.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.835 | Acc: 21.953,42.167,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 21.924,42.122,96.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 21.990,42.162,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 21.962,42.155,96.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 21.930,42.161,96.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.012 | Acc: 21.094,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 20.201,41.853,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.978 | Acc: 20.675,41.273,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.985 | Acc: 21.081,41.022,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.880 | Acc: 15.625,39.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.850 | Acc: 21.726,41.109,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.835 | Acc: 21.761,42.016,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 21.401,41.714,96.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.832 | Acc: 21.692,41.532,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.829 | Acc: 21.867,41.808,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.828 | Acc: 21.991,41.884,96.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 22.030,42.121,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.829 | Acc: 22.142,42.285,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 22.151,42.369,96.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 22.030,42.327,96.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 22.080,42.407,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.832 | Acc: 22.193,42.434,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.832 | Acc: 22.192,42.451,96.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 22.261,42.441,96.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.834 | Acc: 22.212,42.348,96.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 22.179,42.302,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.835 | Acc: 22.136,42.295,96.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 22.152,42.270,96.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 22.111,42.329,96.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.028 | Acc: 20.312,39.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 20.759,41.853,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 21.094,41.273,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.976 | Acc: 21.299,40.561,71.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.812 | Acc: 20.312,37.500,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.831 | Acc: 21.577,41.295,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 21.132,40.835,96.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 21.222,41.073,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 21.373,41.705,96.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.829 | Acc: 21.465,41.839,96.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 21.759,42.071,96.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 21.626,42.215,96.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 21.671,42.352,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 21.711,42.200,96.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 21.774,42.265,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.833 | Acc: 21.787,42.258,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 21.810,42.262,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 21.941,42.310,96.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 21.942,42.307,96.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.834 | Acc: 21.896,42.284,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 21.904,42.270,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.833 | Acc: 21.951,42.249,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 21.951,42.278,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.832 | Acc: 21.980,42.308,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.087 | Acc: 22.656,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.981 | Acc: 20.201,42.001,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 20.579,41.521,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 20.786,41.112,70.453,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.851 | Acc: 18.750,42.188,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.815 | Acc: 21.577,42.113,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.813 | Acc: 22.104,43.464,96.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.817 | Acc: 21.798,42.905,96.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.819 | Acc: 21.836,42.313,96.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.819 | Acc: 21.875,42.095,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.822 | Acc: 21.765,41.962,96.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.823 | Acc: 21.692,41.850,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.822 | Acc: 21.705,41.940,96.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.823 | Acc: 21.698,41.954,96.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.822 | Acc: 21.766,42.016,96.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.823 | Acc: 21.772,41.961,96.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.825 | Acc: 21.843,42.012,96.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.826 | Acc: 21.893,42.059,96.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.826 | Acc: 21.797,42.060,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.827 | Acc: 21.942,42.107,96.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.828 | Acc: 22.092,42.158,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.828 | Acc: 22.141,42.213,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.829 | Acc: 22.126,42.207,96.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.829 | Acc: 22.113,42.284,96.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.086 | Acc: 21.875,39.062,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 20.201,40.997,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.014 | Acc: 20.522,40.682,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.034 | Acc: 20.607,40.100,70.556,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.849 | Acc: 20.312,39.844,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.814 | Acc: 24.070,43.564,96.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 22.790,43.216,96.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 22.170,42.546,96.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.828 | Acc: 22.377,42.554,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.826 | Acc: 22.231,42.110,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.825 | Acc: 22.269,42.220,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.827 | Acc: 22.174,42.193,96.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.127,42.226,96.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 22.013,42.278,96.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.831 | Acc: 21.980,42.452,96.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 22.038,42.435,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.832 | Acc: 22.050,42.440,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 22.034,42.328,96.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 22.014,42.279,96.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.832 | Acc: 21.945,42.224,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.833 | Acc: 21.958,42.209,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.833 | Acc: 22.033,42.249,96.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 22.044,42.285,96.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.833 | Acc: 22.062,42.290,96.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 21.094,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.987 | Acc: 19.978,42.336,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.996 | Acc: 20.655,41.444,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.006 | Acc: 20.953,41.073,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.853 | Acc: 27.344,37.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 22.396,42.634,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.830 | Acc: 22.428,42.740,96.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.832 | Acc: 22.477,43.148,96.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 22.502,43.104,96.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.826 | Acc: 22.401,43.023,96.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.826 | Acc: 22.327,43.001,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.825 | Acc: 22.335,42.941,96.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.423,42.954,96.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.827 | Acc: 22.225,42.904,96.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.827 | Acc: 22.209,43.004,96.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.825 | Acc: 22.207,42.933,96.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.825 | Acc: 22.206,42.995,96.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.826 | Acc: 22.129,42.852,96.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.827 | Acc: 22.270,42.771,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.826 | Acc: 22.254,42.637,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.827 | Acc: 22.223,42.669,96.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.828 | Acc: 22.161,42.543,96.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.829 | Acc: 22.159,42.477,96.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.828 | Acc: 22.176,42.440,96.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.025 | Acc: 24.219,38.281,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.002 | Acc: 20.536,41.406,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.991 | Acc: 20.789,41.292,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 21.132,41.124,70.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.837 | Acc: 21.875,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.816 | Acc: 23.400,42.932,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.824 | Acc: 22.389,41.825,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 22.016,41.765,96.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 21.914,41.686,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.833 | Acc: 21.952,41.708,96.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.831 | Acc: 22.069,42.110,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 21.991,42.043,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.832 | Acc: 22.210,42.056,96.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.832 | Acc: 22.268,42.011,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.830 | Acc: 22.205,42.086,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.830 | Acc: 22.246,42.131,96.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.832 | Acc: 22.228,42.100,96.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.831 | Acc: 22.294,42.202,96.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.830 | Acc: 22.323,42.265,96.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.830 | Acc: 22.389,42.255,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.829 | Acc: 22.364,42.278,96.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.829 | Acc: 22.365,42.341,96.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.830 | Acc: 22.286,42.226,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.830 | Acc: 22.258,42.210,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.933 | Acc: 21.875,39.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 20.387,41.778,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 21.132,41.235,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.981 | Acc: 21.465,41.060,71.043,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.835 | Acc: 18.750,34.375,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.822 | Acc: 20.945,42.485,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.822 | Acc: 21.170,42.893,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.822 | Acc: 21.811,43.033,96.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.822 | Acc: 21.971,43.027,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.824 | Acc: 22.215,43.069,96.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.825 | Acc: 22.017,42.859,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.825 | Acc: 22.207,42.614,96.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.826 | Acc: 22.200,42.590,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.827 | Acc: 22.216,42.546,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.828 | Acc: 22.198,42.537,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.827 | Acc: 22.122,42.509,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.828 | Acc: 22.095,42.502,96.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.828 | Acc: 22.153,42.424,96.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.829 | Acc: 22.081,42.290,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.829 | Acc: 22.080,42.320,96.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.829 | Acc: 22.096,42.270,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.830 | Acc: 22.143,42.339,96.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.830 | Acc: 22.165,42.371,96.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.831 | Acc: 22.199,42.374,96.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.954 | Acc: 23.438,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 20.796,41.295,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 21.208,41.120,70.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.007 | Acc: 21.324,40.779,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.811 | Acc: 27.344,42.188,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.818 | Acc: 23.028,43.973,96.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 22.428,43.216,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.825 | Acc: 21.926,42.828,96.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.822 | Acc: 22.367,42.978,96.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.824 | Acc: 22.200,42.466,96.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.825 | Acc: 22.198,42.401,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.826 | Acc: 22.047,42.370,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.827 | Acc: 22.059,42.255,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.827 | Acc: 22.173,42.330,96.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.827 | Acc: 22.248,42.514,96.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.828 | Acc: 22.186,42.552,96.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.828 | Acc: 22.267,42.505,96.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.828 | Acc: 22.273,42.544,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.827 | Acc: 22.278,42.607,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.827 | Acc: 22.194,42.569,96.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.827 | Acc: 22.150,42.560,96.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.827 | Acc: 22.148,42.465,96.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.828 | Acc: 22.117,42.462,96.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.828 | Acc: 22.109,42.481,96.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.958 | Acc: 21.875,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 20.387,42.039,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.991 | Acc: 20.941,41.159,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.998 | Acc: 21.132,40.856,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.764 | Acc: 24.219,45.312,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 22.061,42.076,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.816 | Acc: 22.389,42.873,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.817 | Acc: 22.131,42.802,96.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.818 | Acc: 22.270,43.027,96.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.820 | Acc: 22.115,42.976,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.817 | Acc: 21.998,42.769,96.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.819 | Acc: 22.219,42.670,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.818 | Acc: 22.195,42.615,96.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.820 | Acc: 22.177,42.589,96.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.822 | Acc: 22.093,42.533,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.822 | Acc: 22.013,42.545,96.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.822 | Acc: 22.060,42.641,96.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.823 | Acc: 22.099,42.601,96.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.822 | Acc: 22.189,42.657,96.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 22.114,42.592,96.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.824 | Acc: 22.116,42.514,96.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.824 | Acc: 22.097,42.561,96.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 22.096,42.579,96.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.826 | Acc: 22.127,42.557,96.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.012 | Acc: 20.312,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.014 | Acc: 20.573,42.634,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 21.151,41.864,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 21.363,41.304,70.248,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.808 | Acc: 26.562,47.656,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.822 | Acc: 22.619,43.452,96.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.817 | Acc: 23.133,44.284,96.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.821 | Acc: 22.823,43.712,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.824 | Acc: 22.502,43.383,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.823 | Acc: 22.494,43.108,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.824 | Acc: 22.353,42.943,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.824 | Acc: 22.523,43.074,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.824 | Acc: 22.496,43.090,96.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.824 | Acc: 22.553,43.016,96.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.824 | Acc: 22.555,43.008,96.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.824 | Acc: 22.381,42.866,96.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.826 | Acc: 22.306,42.807,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.827 | Acc: 22.267,42.663,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.827 | Acc: 22.364,42.724,96.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.825 | Acc: 22.293,42.735,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.826 | Acc: 22.230,42.747,96.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.826 | Acc: 22.253,42.776,96.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.826 | Acc: 22.252,42.772,96.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.827 | Acc: 22.240,42.692,96.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.900 | Acc: 21.094,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 20.610,42.671,69.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.980 | Acc: 20.884,41.902,70.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.988 | Acc: 21.081,41.445,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.911 | Acc: 20.312,44.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.831 | Acc: 22.024,42.708,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 20.808,41.368,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.826 | Acc: 21.580,41.880,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.824 | Acc: 21.576,42.139,96.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.824 | Acc: 21.929,42.427,96.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.823 | Acc: 21.965,42.523,96.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.821 | Acc: 21.975,42.465,96.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.821 | Acc: 21.972,42.217,96.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.824 | Acc: 21.901,41.954,96.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.823 | Acc: 22.015,42.184,96.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.822 | Acc: 22.175,42.336,96.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.823 | Acc: 22.144,42.317,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.824 | Acc: 22.264,42.325,96.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.823 | Acc: 22.239,42.379,96.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.824 | Acc: 22.197,42.322,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.824 | Acc: 22.308,42.385,96.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.825 | Acc: 22.235,42.366,96.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 22.178,42.397,96.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.825 | Acc: 22.187,42.395,96.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.982 | Acc: 21.875,41.406,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.983 | Acc: 20.685,42.076,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 21.056,41.578,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 21.171,41.124,70.710,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.848 | Acc: 22.656,38.281,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.824 | Acc: 21.726,41.890,96.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.825 | Acc: 21.704,41.940,96.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.824 | Acc: 21.734,42.085,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.825 | Acc: 21.981,42.149,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.825 | Acc: 22.053,42.412,96.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 22.262,42.665,96.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.827 | Acc: 22.374,42.570,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.826 | Acc: 22.321,42.770,96.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.828 | Acc: 22.268,42.693,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.828 | Acc: 22.225,42.708,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.828 | Acc: 22.186,42.506,96.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.827 | Acc: 22.115,42.440,96.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.827 | Acc: 22.138,42.364,96.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.828 | Acc: 22.058,42.352,96.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.829 | Acc: 22.015,42.390,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.830 | Acc: 22.004,42.307,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.830 | Acc: 22.047,42.339,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.830 | Acc: 22.091,42.352,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.830 | Acc: 22.074,42.292,96.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.860 | Acc: 24.219,42.969,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 20.833,42.560,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 20.903,42.111,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.980 | Acc: 21.017,41.522,70.799,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.801 | Acc: 24.219,47.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.819 | Acc: 22.693,43.080,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.817 | Acc: 22.637,42.188,96.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.815 | Acc: 22.682,42.200,96.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.811 | Acc: 22.733,42.612,96.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.812 | Acc: 22.710,42.915,96.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.810 | Acc: 22.443,42.911,96.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.807 | Acc: 22.612,42.764,96.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.806 | Acc: 22.477,42.736,96.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.806 | Acc: 22.484,42.818,96.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.806 | Acc: 22.505,42.961,96.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.805 | Acc: 22.426,43.008,96.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.805 | Acc: 22.364,42.985,96.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.804 | Acc: 22.276,42.909,96.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.804 | Acc: 22.328,42.999,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.803 | Acc: 22.397,43.031,96.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.803 | Acc: 22.391,42.993,96.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.802 | Acc: 22.356,43.026,96.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.802 | Acc: 22.414,43.057,96.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.801 | Acc: 22.402,43.024,96.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.820 | Acc: 22.656,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.928 | Acc: 20.833,43.341,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.935 | Acc: 21.075,42.683,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.939 | Acc: 21.427,42.277,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.768 | Acc: 28.125,52.344,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.803 | Acc: 22.619,43.006,97.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.788 | Acc: 23.304,44.188,97.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.792 | Acc: 22.912,43.993,97.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.793 | Acc: 22.618,43.721,97.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.790 | Acc: 22.664,43.812,97.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.790 | Acc: 22.385,43.563,97.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.792 | Acc: 22.324,43.462,97.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.791 | Acc: 22.239,43.396,97.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.790 | Acc: 22.367,43.409,97.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.790 | Acc: 22.357,43.330,97.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.791 | Acc: 22.419,43.290,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.792 | Acc: 22.394,43.076,97.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.793 | Acc: 22.351,42.888,97.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.792 | Acc: 22.342,42.941,97.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.791 | Acc: 22.306,42.935,97.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.790 | Acc: 22.286,42.981,97.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.791 | Acc: 22.297,42.996,97.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.791 | Acc: 22.226,42.871,97.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.791 | Acc: 22.236,42.879,97.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.871 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.947 | Acc: 20.796,43.304,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 21.075,42.683,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 21.414,41.995,71.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.786 | Acc: 25.781,42.188,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.793 | Acc: 21.540,42.299,97.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.785 | Acc: 21.742,43.293,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.785 | Acc: 21.977,43.609,97.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.789 | Acc: 22.232,43.422,97.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.787 | Acc: 22.192,43.402,97.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.787 | Acc: 22.308,43.382,97.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.786 | Acc: 22.429,43.229,97.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.785 | Acc: 22.545,43.304,97.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.787 | Acc: 22.488,43.042,97.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.787 | Acc: 22.489,42.969,97.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.787 | Acc: 22.511,43.110,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.786 | Acc: 22.455,43.004,97.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.785 | Acc: 22.480,43.026,97.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.786 | Acc: 22.467,43.022,97.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.786 | Acc: 22.407,42.927,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.785 | Acc: 22.469,43.022,97.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.785 | Acc: 22.356,42.957,97.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.786 | Acc: 22.293,42.977,97.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.786 | Acc: 22.271,42.940,97.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.883 | Acc: 21.094,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.941 | Acc: 20.908,42.820,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 21.246,42.245,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.941 | Acc: 21.593,41.816,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.873 | Acc: 20.312,35.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 21.429,42.448,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.779 | Acc: 21.627,42.264,97.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 21.965,42.661,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.776 | Acc: 22.029,42.988,97.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.778 | Acc: 21.991,43.193,97.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.777 | Acc: 22.062,43.272,97.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 22.174,43.268,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 22.176,43.250,97.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 22.307,43.362,97.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 22.392,43.369,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 22.533,43.365,97.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 22.452,43.325,97.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 22.471,43.307,97.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.777 | Acc: 22.523,43.375,97.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 22.462,43.298,97.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.779 | Acc: 22.483,43.292,97.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.779 | Acc: 22.397,43.287,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 22.433,43.244,97.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 22.396,43.198,97.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.864 | Acc: 21.094,40.625,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.945 | Acc: 20.982,43.118,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.940 | Acc: 21.151,42.550,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.941 | Acc: 21.606,42.085,71.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.740 | Acc: 29.688,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 23.921,44.940,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 22.999,43.636,97.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 22.746,43.020,97.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 22.849,43.268,97.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.778 | Acc: 22.687,42.845,97.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 22.527,42.807,97.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.781 | Acc: 22.363,42.747,97.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.781 | Acc: 22.351,42.513,97.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.781 | Acc: 22.169,42.524,97.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.781 | Acc: 22.217,42.596,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.780 | Acc: 22.122,42.704,97.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.781 | Acc: 22.138,42.602,97.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.780 | Acc: 22.207,42.639,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.781 | Acc: 22.239,42.638,97.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.781 | Acc: 22.301,42.655,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.781 | Acc: 22.359,42.677,97.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.780 | Acc: 22.395,42.808,97.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 22.490,42.919,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 22.513,42.932,97.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.859 | Acc: 21.875,41.406,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.945 | Acc: 20.908,42.969,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 20.979,42.302,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 21.440,41.855,71.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.727 | Acc: 26.562,48.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.784 | Acc: 22.805,43.266,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.775 | Acc: 22.732,43.617,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.778 | Acc: 22.592,43.046,97.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.781 | Acc: 22.541,42.959,97.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.780 | Acc: 22.494,43.054,97.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.779 | Acc: 22.514,43.137,97.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.779 | Acc: 22.568,43.218,97.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.778 | Acc: 22.598,43.211,97.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.779 | Acc: 22.596,43.219,97.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.778 | Acc: 22.571,43.237,97.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.778 | Acc: 22.670,43.266,97.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.778 | Acc: 22.705,43.166,97.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.778 | Acc: 22.686,43.193,97.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 22.665,43.124,97.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 22.667,43.153,97.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 22.554,43.139,97.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.778 | Acc: 22.590,43.193,97.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.779 | Acc: 22.522,43.153,97.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.779 | Acc: 22.433,43.053,97.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.854 | Acc: 21.875,39.844,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.940 | Acc: 20.461,43.043,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.938 | Acc: 20.903,42.321,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 21.196,41.931,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.774 | Acc: 21.875,47.656,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 23.251,44.010,97.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.781 | Acc: 22.713,43.121,97.599,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.779 | Acc: 22.925,43.302,97.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.779 | Acc: 22.569,43.326,97.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 22.594,43.487,97.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.778 | Acc: 22.559,43.382,97.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.777 | Acc: 22.479,43.434,97.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 22.583,43.536,97.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.776 | Acc: 22.419,43.409,97.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.775 | Acc: 22.431,43.427,97.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 22.395,43.195,97.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 22.407,43.079,97.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.777 | Acc: 22.312,43.097,97.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.778 | Acc: 22.387,43.113,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.778 | Acc: 22.316,43.062,97.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.778 | Acc: 22.371,43.008,97.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.777 | Acc: 22.457,43.051,97.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.778 | Acc: 22.453,42.969,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 22.447,42.983,97.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.922 | Acc: 22.656,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.942 | Acc: 21.168,43.378,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 21.361,42.759,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.945 | Acc: 21.593,42.175,71.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.764 | Acc: 22.656,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 22.173,43.415,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 22.752,44.188,98.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 22.451,43.878,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 22.676,43.924,98.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.768 | Acc: 22.687,43.951,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 22.611,43.950,97.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.770 | Acc: 22.484,43.744,97.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.771 | Acc: 22.414,43.522,97.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.772 | Acc: 22.415,43.517,97.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.772 | Acc: 22.275,43.412,97.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 22.296,43.446,97.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.772 | Acc: 22.290,43.449,97.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.772 | Acc: 22.333,43.379,97.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.771 | Acc: 22.373,43.394,97.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.771 | Acc: 22.464,43.330,97.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 22.457,43.356,97.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 22.478,43.349,97.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 22.472,43.367,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 22.502,43.332,97.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.885 | Acc: 21.875,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.943 | Acc: 20.982,43.155,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 21.265,42.492,71.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 21.516,42.059,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.780 | Acc: 23.438,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.769 | Acc: 23.140,43.378,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 22.542,43.445,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.770 | Acc: 22.592,43.686,98.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 22.521,43.422,97.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 22.324,43.417,97.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 22.314,43.453,97.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 22.213,43.296,98.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.773 | Acc: 22.394,43.420,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.773 | Acc: 22.440,43.461,97.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 22.415,43.268,97.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 22.430,43.266,97.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 22.397,43.270,97.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.773 | Acc: 22.423,43.295,97.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.773 | Acc: 22.406,43.227,97.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 22.363,43.275,98.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 22.359,43.271,98.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 22.361,43.354,98.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 22.358,43.315,98.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 22.406,43.285,97.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.902 | Acc: 21.094,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 20.796,43.564,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.945 | Acc: 21.227,42.778,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 21.606,42.252,71.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.839 | Acc: 21.094,35.938,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 21.801,43.118,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.763 | Acc: 22.694,43.559,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 22.874,43.852,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.770 | Acc: 22.762,43.605,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 22.602,43.657,97.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 22.527,43.834,97.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 22.634,43.528,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 22.491,43.430,97.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.772 | Acc: 22.376,43.646,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.771 | Acc: 22.256,43.486,97.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.771 | Acc: 22.183,43.492,97.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.770 | Acc: 22.245,43.497,97.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.771 | Acc: 22.067,43.337,97.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 22.100,43.344,97.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 22.111,43.343,97.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.771 | Acc: 22.221,43.426,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.770 | Acc: 22.283,43.466,97.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 22.256,43.417,97.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.771 | Acc: 22.310,43.330,97.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.854 | Acc: 21.875,39.844,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.945 | Acc: 20.833,43.452,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.941 | Acc: 21.189,42.588,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 21.414,41.919,71.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.742 | Acc: 23.438,44.531,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.780 | Acc: 21.168,41.406,97.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.774 | Acc: 21.837,42.092,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.775 | Acc: 21.811,41.752,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 22.222,42.081,98.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.773 | Acc: 22.099,42.280,97.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.773 | Acc: 22.185,42.504,97.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.773 | Acc: 22.086,42.559,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 22.215,42.770,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.774 | Acc: 22.397,42.805,97.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.773 | Acc: 22.458,42.938,97.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 22.617,43.029,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.773 | Acc: 22.692,42.959,97.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.772 | Acc: 22.758,43.062,97.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.772 | Acc: 22.606,43.105,97.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.772 | Acc: 22.576,43.156,97.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.772 | Acc: 22.537,43.176,97.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.772 | Acc: 22.475,43.193,97.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.772 | Acc: 22.444,43.185,97.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.772 | Acc: 22.480,43.274,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.906 | Acc: 21.094,42.969,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.958 | Acc: 21.168,43.378,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.951 | Acc: 21.513,42.569,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 21.798,42.123,71.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.729 | Acc: 25.000,35.938,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 21.466,42.262,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 22.466,43.312,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 23.040,43.507,98.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.772 | Acc: 22.772,43.297,98.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.771 | Acc: 23.066,43.394,97.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.772 | Acc: 22.973,43.421,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.771 | Acc: 22.961,43.562,97.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.772 | Acc: 23.112,43.575,97.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.771 | Acc: 22.950,43.746,97.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.772 | Acc: 22.878,43.692,97.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.772 | Acc: 22.784,43.616,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.771 | Acc: 22.679,43.598,98.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.770 | Acc: 22.740,43.624,98.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.770 | Acc: 22.631,43.622,98.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.770 | Acc: 22.610,43.589,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.770 | Acc: 22.583,43.550,98.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.771 | Acc: 22.581,43.482,98.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.771 | Acc: 22.477,43.415,98.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.770 | Acc: 22.480,43.393,98.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.906 | Acc: 21.094,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 21.243,42.783,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.943 | Acc: 21.627,42.340,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.948 | Acc: 21.875,41.944,71.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.813 | Acc: 17.969,37.500,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 23.214,43.899,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 23.266,43.712,97.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 23.297,43.443,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 23.148,43.692,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 23.167,43.510,98.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.765 | Acc: 23.308,43.782,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.765 | Acc: 23.144,43.761,98.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 23.146,43.789,98.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 23.032,43.793,98.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.025,43.859,98.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 22.798,43.662,98.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 22.799,43.633,98.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 22.806,43.558,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 22.837,43.558,98.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 22.719,43.413,98.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 22.651,43.414,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 22.597,43.429,98.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.769 | Acc: 22.492,43.322,98.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.769 | Acc: 22.425,43.311,98.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.902 | Acc: 21.875,40.625,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.952 | Acc: 21.243,42.969,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 21.742,42.435,71.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.951 | Acc: 22.080,41.906,71.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.764 | Acc: 22.656,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.763 | Acc: 22.061,42.225,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.760 | Acc: 22.713,43.788,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 22.976,43.648,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.760 | Acc: 23.061,43.731,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.762 | Acc: 22.850,43.881,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 22.843,43.685,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 22.856,43.567,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.766 | Acc: 22.850,43.629,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 22.704,43.633,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 22.575,43.478,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 22.639,43.594,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.765 | Acc: 22.737,43.698,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 22.701,43.627,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 22.653,43.544,98.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 22.628,43.516,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.766 | Acc: 22.603,43.475,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.765 | Acc: 22.620,43.493,98.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 22.604,43.445,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 22.593,43.381,98.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.872 | Acc: 21.094,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.952 | Acc: 21.615,43.080,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.946 | Acc: 21.818,42.683,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.953 | Acc: 22.003,42.021,71.798,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.740 | Acc: 23.438,50.000,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.776 | Acc: 23.103,43.787,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 23.552,44.017,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.763 | Acc: 23.040,43.315,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.761 | Acc: 22.550,43.461,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.761 | Acc: 22.556,43.332,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.404,43.266,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.763 | Acc: 22.573,43.080,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.764 | Acc: 22.540,43.148,98.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 22.453,43.085,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 22.579,43.214,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 22.624,43.276,98.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 22.624,43.312,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 22.662,43.268,98.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 22.712,43.272,98.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 22.674,43.343,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 22.637,43.390,98.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 22.631,43.312,98.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 22.678,43.302,98.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 22.595,43.326,98.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.907 | Acc: 22.656,44.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.961 | Acc: 20.833,43.192,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.965 | Acc: 21.189,42.740,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 21.363,42.290,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.752 | Acc: 20.312,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 23.065,44.122,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 23.095,43.826,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 23.015,44.326,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.760 | Acc: 23.061,44.416,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 23.082,44.245,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.764 | Acc: 22.915,44.105,98.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.765 | Acc: 22.911,44.071,98.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 22.812,43.866,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 22.747,43.862,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.764 | Acc: 22.738,43.804,98.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 22.723,43.655,98.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.765 | Acc: 22.679,43.624,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 22.653,43.612,98.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.765 | Acc: 22.648,43.669,98.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 22.555,43.615,98.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.765 | Acc: 22.627,43.679,98.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.766 | Acc: 22.606,43.677,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 22.609,43.605,98.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 22.628,43.652,98.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.890 | Acc: 22.656,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 21.280,43.006,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 21.418,42.550,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 21.785,42.175,71.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.758 | Acc: 23.438,50.000,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 21.987,43.899,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.769 | Acc: 22.504,43.426,97.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 23.284,43.891,98.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 22.888,43.654,98.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 22.819,43.804,97.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.767 | Acc: 22.488,43.808,97.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.768 | Acc: 22.446,43.706,97.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 22.651,43.842,98.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 22.682,43.901,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.767 | Acc: 22.559,43.734,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 22.373,43.612,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 22.335,43.578,98.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 22.378,43.531,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 22.417,43.478,98.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 22.360,43.519,98.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 22.410,43.536,98.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 22.400,43.480,98.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 22.407,43.473,98.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.768 | Acc: 22.394,43.504,98.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.925 | Acc: 21.094,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.945 | Acc: 21.168,43.490,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 21.303,42.721,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.954 | Acc: 21.529,42.252,71.452,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.725 | Acc: 24.219,50.000,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.759 | Acc: 22.582,43.229,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.763 | Acc: 22.828,43.521,98.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.763 | Acc: 22.490,43.417,98.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 22.483,43.355,98.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.764 | Acc: 22.324,43.278,98.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.764 | Acc: 22.262,43.395,98.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.764 | Acc: 22.224,43.617,98.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 22.292,43.527,98.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 22.337,43.413,98.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 22.411,43.416,98.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 22.349,43.435,98.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 22.413,43.261,98.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 22.435,43.280,98.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.769 | Acc: 22.462,43.122,97.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.769 | Acc: 22.545,43.124,97.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.768 | Acc: 22.474,43.003,98.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.768 | Acc: 22.462,42.980,98.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.768 | Acc: 22.507,43.114,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 22.539,43.159,98.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.869 | Acc: 21.094,39.844,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 21.615,43.266,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.608,42.664,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 21.977,42.162,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.782 | Acc: 25.000,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.755 | Acc: 23.140,43.229,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 22.790,43.197,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.762 | Acc: 22.746,43.507,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 22.512,43.297,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 22.440,43.201,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.766 | Acc: 22.495,42.962,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 22.612,42.913,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 22.394,42.944,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.768 | Acc: 22.363,42.969,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 22.369,43.089,98.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.768 | Acc: 22.469,43.206,98.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.768 | Acc: 22.543,43.257,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.768 | Acc: 22.420,43.154,98.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.768 | Acc: 22.495,43.152,98.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.768 | Acc: 22.482,43.117,98.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 22.513,43.166,98.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.766 | Acc: 22.445,43.166,98.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 22.492,43.220,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 22.464,43.213,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.909 | Acc: 21.875,42.188,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 21.131,42.783,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.954 | Acc: 21.475,42.473,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 21.824,42.008,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.767 | Acc: 17.188,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 22.693,43.899,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 22.771,43.731,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 22.746,43.186,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.758 | Acc: 22.270,43.220,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.759 | Acc: 22.277,43.201,98.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 22.437,43.317,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.390,43.185,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 22.336,43.294,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.762 | Acc: 22.471,43.133,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.762 | Acc: 22.400,43.171,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.763 | Acc: 22.402,43.191,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.763 | Acc: 22.371,43.118,98.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.763 | Acc: 22.381,43.068,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.764 | Acc: 22.364,43.124,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.765 | Acc: 22.345,43.158,98.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.764 | Acc: 22.376,43.251,98.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.763 | Acc: 22.510,43.351,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.763 | Acc: 22.440,43.298,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.763 | Acc: 22.519,43.348,98.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.960 | Acc: 21.875,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 21.354,43.527,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.962 | Acc: 21.570,42.626,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 21.875,41.970,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.793 | Acc: 26.562,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.770 | Acc: 22.805,44.048,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.770 | Acc: 22.694,44.550,98.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 22.720,44.249,98.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.769 | Acc: 22.174,43.769,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 22.293,43.619,98.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.769 | Acc: 22.107,43.459,98.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 22.185,43.517,98.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 22.409,43.430,98.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.764 | Acc: 22.466,43.534,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 22.407,43.396,98.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.765 | Acc: 22.292,43.386,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 22.283,43.202,98.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 22.222,43.241,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 22.261,43.152,98.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 22.371,43.239,98.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.765 | Acc: 22.391,43.268,98.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.765 | Acc: 22.377,43.216,98.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.765 | Acc: 22.384,43.172,98.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.765 | Acc: 22.439,43.233,98.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.925 | Acc: 22.656,40.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 21.317,43.341,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.494,42.893,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 21.760,42.341,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.742 | Acc: 29.688,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 20.610,42.671,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.770 | Acc: 21.227,42.873,98.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 22.029,43.430,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.764 | Acc: 22.049,43.412,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.763 | Acc: 21.914,43.356,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.172,43.337,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.279,43.368,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.763 | Acc: 22.331,43.333,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.763 | Acc: 22.242,43.267,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.764 | Acc: 22.209,43.132,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.763 | Acc: 22.271,43.248,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.763 | Acc: 22.355,43.348,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.763 | Acc: 22.399,43.322,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.763 | Acc: 22.362,43.372,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.763 | Acc: 22.392,43.340,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.764 | Acc: 22.476,43.436,98.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.764 | Acc: 22.480,43.411,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.765 | Acc: 22.451,43.397,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.765 | Acc: 22.410,43.321,98.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.909 | Acc: 21.875,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 21.429,43.378,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.956 | Acc: 21.646,42.664,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 21.952,42.162,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.816 | Acc: 19.531,39.062,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 21.726,42.336,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.769 | Acc: 21.818,42.511,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.767 | Acc: 22.106,42.866,97.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.768 | Acc: 22.232,42.612,98.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.767 | Acc: 22.231,42.737,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 22.256,42.743,98.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 22.346,42.869,98.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.767 | Acc: 22.399,42.969,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 22.445,42.986,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.768 | Acc: 22.442,43.113,98.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 22.451,43.124,98.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.768 | Acc: 22.455,43.121,98.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 22.453,43.088,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 22.400,43.158,98.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 22.417,43.259,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.766 | Acc: 22.345,43.144,98.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.766 | Acc: 22.418,43.251,98.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.766 | Acc: 22.336,43.257,98.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.766 | Acc: 22.373,43.307,98.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.928 | Acc: 21.875,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.967 | Acc: 21.577,43.341,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.962 | Acc: 21.818,43.064,71.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 22.144,42.469,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.724 | Acc: 19.531,42.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 22.507,42.522,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 22.713,43.788,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 23.066,43.609,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.760 | Acc: 22.888,43.335,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.761 | Acc: 22.734,43.541,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.482,43.685,98.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.656,43.600,98.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.763 | Acc: 22.579,43.512,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.763 | Acc: 22.518,43.491,98.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.762 | Acc: 22.497,43.548,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.762 | Acc: 22.540,43.577,98.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.763 | Acc: 22.452,43.530,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.763 | Acc: 22.450,43.490,98.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.763 | Acc: 22.473,43.511,98.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.763 | Acc: 22.459,43.454,98.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.763 | Acc: 22.369,43.414,98.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.764 | Acc: 22.402,43.516,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.764 | Acc: 22.427,43.549,98.163,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.764 | Acc: 22.418,43.555,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.910 | Acc: 21.094,41.406,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 21.652,43.527,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.723,43.064,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 22.041,42.623,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.774 | Acc: 25.000,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.759 | Acc: 23.438,44.159,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 23.590,44.245,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.762 | Acc: 23.450,44.301,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.761 | Acc: 23.216,44.155,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.761 | Acc: 23.291,44.330,98.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.760 | Acc: 23.244,44.260,98.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.762 | Acc: 23.066,44.049,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 23.093,44.138,98.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.762 | Acc: 23.010,44.044,98.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.761 | Acc: 23.018,44.108,98.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.762 | Acc: 22.773,43.951,98.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.762 | Acc: 22.812,43.932,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.762 | Acc: 22.695,43.864,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.763 | Acc: 22.667,43.789,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.763 | Acc: 22.584,43.773,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.763 | Acc: 22.578,43.830,98.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.764 | Acc: 22.462,43.668,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.764 | Acc: 22.513,43.644,98.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.764 | Acc: 22.484,43.701,98.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.941 | Acc: 21.875,43.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 21.652,43.676,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.761,43.121,71.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 22.029,42.431,71.529,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.780 | Acc: 20.312,34.375,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.762 | Acc: 23.103,42.001,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.769 | Acc: 22.866,42.950,98.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 22.413,42.828,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.767 | Acc: 22.155,42.892,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.769 | Acc: 21.999,42.760,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.770 | Acc: 21.888,42.865,98.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.768 | Acc: 22.058,42.958,98.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.766 | Acc: 22.089,43.027,98.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.766 | Acc: 22.099,43.133,98.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 22.112,43.416,98.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 22.038,43.340,98.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.765 | Acc: 22.164,43.403,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 22.276,43.508,98.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.764 | Acc: 22.342,43.511,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.764 | Acc: 22.329,43.431,98.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.764 | Acc: 22.362,43.448,98.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.763 | Acc: 22.306,43.525,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.764 | Acc: 22.342,43.501,98.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.764 | Acc: 22.437,43.500,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.916 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 21.429,43.824,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.949 | Acc: 21.856,43.293,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.952 | Acc: 22.093,42.572,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.746 | Acc: 28.125,47.656,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 22.582,44.048,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.757 | Acc: 22.904,44.055,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 22.964,43.532,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 22.936,43.586,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.762 | Acc: 22.819,43.170,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.643,43.324,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.762 | Acc: 22.689,43.467,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.761 | Acc: 22.768,43.682,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.761 | Acc: 22.842,43.733,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.761 | Acc: 22.963,43.801,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.761 | Acc: 22.925,43.739,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.761 | Acc: 22.922,43.614,98.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.761 | Acc: 22.926,43.549,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.761 | Acc: 22.993,43.564,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.761 | Acc: 22.939,43.566,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.761 | Acc: 22.868,43.650,98.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.762 | Acc: 22.782,43.626,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.762 | Acc: 22.687,43.609,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.761 | Acc: 22.695,43.650,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.921 | Acc: 22.656,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 21.540,43.676,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.970 | Acc: 21.589,42.759,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.975 | Acc: 21.875,42.175,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.776 | Acc: 23.438,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 23.251,43.043,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 23.018,43.197,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.766 | Acc: 22.579,43.302,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 22.512,43.248,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 22.393,43.170,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.392,43.414,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.762 | Acc: 22.368,43.517,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 22.414,43.527,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.761 | Acc: 22.333,43.633,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.762 | Acc: 22.462,43.874,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.762 | Acc: 22.554,43.934,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.761 | Acc: 22.523,43.808,98.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.761 | Acc: 22.602,43.798,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.762 | Acc: 22.673,43.783,98.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.762 | Acc: 22.659,43.719,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.761 | Acc: 22.671,43.728,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 22.649,43.752,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 22.611,43.746,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.613,43.645,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.944 | Acc: 21.094,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.969 | Acc: 21.094,43.564,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 21.303,42.797,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 21.670,42.188,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.799 | Acc: 20.312,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 22.321,41.555,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 22.104,42.035,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 22.426,42.623,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 22.618,42.872,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.763 | Acc: 22.602,42.752,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.761 | Acc: 22.669,43.072,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.784,42.963,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.759 | Acc: 22.802,43.313,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.885,43.435,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.759 | Acc: 22.921,43.412,98.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.900,43.556,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.760 | Acc: 22.825,43.455,98.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 22.794,43.418,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 22.751,43.478,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.760 | Acc: 22.659,43.428,98.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.760 | Acc: 22.603,43.373,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 22.588,43.427,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 22.628,43.477,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.576,43.440,98.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.929 | Acc: 21.875,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 21.205,43.862,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.959 | Acc: 21.341,43.083,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 21.696,42.444,71.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.736 | Acc: 22.656,42.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 22.768,43.899,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 22.637,43.388,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.753 | Acc: 23.194,44.045,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.755 | Acc: 22.946,43.981,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.754 | Acc: 23.082,44.230,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 22.895,43.989,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 22.906,44.082,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.756 | Acc: 22.821,43.949,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.915,43.862,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.760 | Acc: 22.750,43.536,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.759,43.602,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.961,43.640,98.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 22.944,43.561,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.761 | Acc: 22.926,43.539,98.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.761 | Acc: 22.804,43.553,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.761 | Acc: 22.698,43.519,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.761 | Acc: 22.606,43.441,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.761 | Acc: 22.568,43.397,98.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.761 | Acc: 22.578,43.477,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.906 | Acc: 22.656,42.188,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.946 | Acc: 21.763,42.969,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.947 | Acc: 21.589,42.607,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 22.067,42.239,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.744 | Acc: 20.312,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 23.549,44.792,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 22.656,43.197,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 22.669,43.545,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.758 | Acc: 22.550,43.576,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.758 | Acc: 22.455,43.557,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 22.488,43.821,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 22.324,43.689,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.321,43.609,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.760 | Acc: 22.363,43.720,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.760 | Acc: 22.404,43.742,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.448,43.630,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.760 | Acc: 22.494,43.549,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 22.510,43.555,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 22.514,43.561,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.760 | Acc: 22.506,43.584,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 22.496,43.555,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 22.500,43.576,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 22.457,43.471,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.521,43.524,98.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.929 | Acc: 20.312,41.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.057,43.118,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.475,42.607,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 21.798,42.175,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.779 | Acc: 15.625,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 21.949,43.750,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 23.037,44.207,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 22.733,44.147,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.756 | Acc: 22.483,43.808,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.755 | Acc: 22.447,43.827,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.269,43.802,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.758 | Acc: 22.346,43.861,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.759 | Acc: 22.501,43.784,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.759 | Acc: 22.514,43.582,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.760 | Acc: 22.376,43.528,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.292,43.538,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.290,43.669,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 22.261,43.648,98.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.759 | Acc: 22.350,43.683,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.759 | Acc: 22.316,43.683,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 22.267,43.653,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 22.345,43.670,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 22.293,43.581,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.336,43.557,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.914 | Acc: 21.875,42.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 22.024,43.787,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.964 | Acc: 22.104,43.064,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 22.362,42.444,71.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.776 | Acc: 20.312,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 21.949,41.890,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 22.447,43.026,98.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 22.246,42.892,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.761 | Acc: 22.222,42.978,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.679,43.154,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.763 | Acc: 22.256,42.962,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.235,43.085,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.759 | Acc: 22.472,43.381,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.759 | Acc: 22.427,43.564,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.759 | Acc: 22.415,43.408,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.593,43.478,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.614,43.572,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 22.584,43.540,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.759 | Acc: 22.631,43.644,98.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 22.552,43.649,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.642,43.665,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 22.581,43.631,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.630,43.583,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.681,43.637,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.907 | Acc: 21.875,44.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.962 | Acc: 21.094,43.899,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.361,43.255,71.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 21.734,42.495,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.774 | Acc: 18.750,43.750,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.742 | Acc: 22.507,44.271,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.749 | Acc: 22.771,43.979,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.749 | Acc: 22.656,44.032,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.748 | Acc: 22.531,44.010,98.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 22.571,43.897,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 22.579,43.782,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 22.617,43.905,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.753 | Acc: 22.710,43.818,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 22.764,43.651,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 22.843,43.719,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 22.674,43.686,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 22.595,43.640,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.545,43.633,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 22.562,43.672,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.490,43.477,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 22.515,43.582,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.407,43.452,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.386,43.486,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.371,43.496,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.923 | Acc: 24.219,44.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 21.168,43.787,71.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 21.475,43.216,71.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.975 | Acc: 21.721,42.495,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.734 | Acc: 24.219,42.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.760 | Acc: 21.615,42.597,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 22.389,43.769,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 22.490,43.737,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 22.444,44.039,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.759 | Acc: 22.432,43.781,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 22.463,43.873,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.759 | Acc: 22.551,43.938,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.438,43.847,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.561,43.797,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.520,43.847,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.444,43.909,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.565,43.782,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 22.447,43.603,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 22.395,43.522,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.761 | Acc: 22.386,43.402,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.760 | Acc: 22.469,43.490,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 22.489,43.521,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 22.472,43.529,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.541,43.529,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.928 | Acc: 21.875,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.391,43.304,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.589,43.064,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.970 | Acc: 21.888,42.482,71.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.752 | Acc: 24.219,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 22.173,44.606,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 22.675,43.712,97.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.757 | Acc: 23.066,43.840,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.761 | Acc: 22.772,43.383,98.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 23.012,43.742,98.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 23.250,43.963,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 23.149,44.060,98.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.845,43.769,98.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.761 | Acc: 22.781,43.694,98.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.762 | Acc: 22.648,43.478,98.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.762 | Acc: 22.681,43.541,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.763 | Acc: 22.728,43.507,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.762 | Acc: 22.692,43.511,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.762 | Acc: 22.653,43.511,98.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.762 | Acc: 22.633,43.449,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.762 | Acc: 22.603,43.414,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.761 | Acc: 22.613,43.429,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.762 | Acc: 22.507,43.404,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.761 | Acc: 22.582,43.494,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.927 | Acc: 21.094,44.531,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 21.577,44.048,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.966 | Acc: 21.742,43.255,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.975 | Acc: 22.003,42.687,71.504,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.741 | Acc: 25.000,39.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 21.577,42.597,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.760 | Acc: 22.161,43.636,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 22.208,43.814,98.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.760 | Acc: 21.962,43.538,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.076,43.657,98.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 22.295,43.679,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 22.252,43.390,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.171,43.488,98.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.759 | Acc: 22.294,43.616,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.759 | Acc: 22.373,43.699,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.335,43.704,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.296,43.669,98.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 22.405,43.717,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 22.445,43.650,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.759 | Acc: 22.433,43.607,98.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 22.401,43.594,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 22.400,43.587,98.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 22.410,43.583,98.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.418,43.684,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.941 | Acc: 21.875,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 21.615,44.048,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 21.894,43.236,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 22.195,42.585,71.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.747 | Acc: 21.094,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.762 | Acc: 23.326,43.192,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.759 | Acc: 23.399,44.455,97.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 22.618,43.955,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.761 | Acc: 22.222,43.760,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.761 | Acc: 22.416,43.580,98.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.761 | Acc: 22.321,43.576,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.418,43.551,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.761 | Acc: 22.511,43.692,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.761 | Acc: 22.596,43.737,98.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.760 | Acc: 22.544,43.769,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.760 | Acc: 22.522,43.662,98.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.761 | Acc: 22.491,43.643,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 22.566,43.546,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.759 | Acc: 22.651,43.644,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.759 | Acc: 22.654,43.651,98.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 22.673,43.713,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 22.599,43.718,98.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 22.650,43.769,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.697,43.779,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.974 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.962 | Acc: 21.280,43.787,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 21.780,42.931,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 21.977,42.623,71.670,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.767 | Acc: 18.750,48.438,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.760 | Acc: 21.949,42.522,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 22.809,43.579,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 22.605,43.494,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.756 | Acc: 22.242,43.499,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 22.579,43.704,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 22.204,43.472,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.759 | Acc: 22.174,43.451,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.759 | Acc: 22.220,43.294,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.276,43.491,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.369,43.525,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.405,43.421,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 22.433,43.423,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.414,43.421,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.459,43.391,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.760 | Acc: 22.451,43.418,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.760 | Acc: 22.420,43.453,98.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 22.411,43.512,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 22.485,43.529,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.759 | Acc: 22.537,43.510,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.956 | Acc: 22.656,46.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 21.503,43.899,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.978 | Acc: 21.627,43.121,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.983 | Acc: 21.926,42.533,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.742 | Acc: 21.875,45.312,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.755 | Acc: 22.247,42.560,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.757 | Acc: 22.694,43.426,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 22.643,43.776,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.762 | Acc: 22.743,43.470,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.587,43.294,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.761 | Acc: 22.456,43.272,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 22.407,43.063,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.761 | Acc: 22.409,43.037,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.763 | Acc: 22.324,42.917,98.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.762 | Acc: 22.392,43.113,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.760 | Acc: 22.515,43.354,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.760 | Acc: 22.481,43.461,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 22.468,43.448,98.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 22.556,43.553,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.760 | Acc: 22.550,43.535,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 22.542,43.533,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 22.539,43.544,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.759 | Acc: 22.500,43.479,98.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 22.523,43.418,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.933 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.280,43.304,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.964 | Acc: 21.589,42.969,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.968 | Acc: 21.952,42.444,71.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.781 | Acc: 21.875,41.406,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.765 | Acc: 21.763,43.304,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.763 | Acc: 22.046,42.950,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 22.733,43.276,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 22.868,43.171,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.579,43.247,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.398,43.085,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.762 | Acc: 22.462,43.041,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.559,43.129,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.708,43.210,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.637,43.260,98.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.582,43.372,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 22.669,43.319,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.668,43.346,98.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.737,43.478,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 22.807,43.628,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.702,43.609,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.758 | Acc: 22.789,43.658,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.717,43.616,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.693,43.576,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.940 | Acc: 22.656,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.972 | Acc: 21.689,43.452,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.962 | Acc: 21.837,42.873,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 22.118,42.341,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.791 | Acc: 21.094,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.748 | Acc: 20.833,44.978,98.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 20.979,43.979,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 21.747,43.929,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 21.750,43.731,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.754 | Acc: 22.177,43.905,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.411,43.957,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.756 | Acc: 22.484,43.866,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 22.525,43.832,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.592,43.884,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.520,43.933,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.504,43.828,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.546,43.854,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.757 | Acc: 22.653,43.882,98.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.656,43.847,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.724,43.877,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.625,43.772,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.758 | Acc: 22.581,43.716,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.617,43.668,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.603,43.670,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.934 | Acc: 20.312,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 21.280,43.229,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.951 | Acc: 21.494,42.816,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.956 | Acc: 21.837,42.405,71.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.713 | Acc: 22.656,50.000,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 22.545,44.457,98.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.741 | Acc: 22.428,44.760,98.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.747 | Acc: 22.541,44.173,98.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 22.328,44.049,98.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 22.262,43.881,98.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.754 | Acc: 21.998,43.808,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.135,43.850,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 22.137,43.701,98.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 22.315,43.759,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.756 | Acc: 22.439,43.808,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 22.409,43.746,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.420,43.721,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.453,43.720,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 22.576,43.783,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.555,43.732,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.539,43.672,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.514,43.693,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.518,43.540,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.511,43.508,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.910 | Acc: 21.094,44.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.354,43.750,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 21.608,43.083,71.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 21.913,42.610,71.747,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.739 | Acc: 35.938,52.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 22.693,44.494,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 22.294,44.093,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.756 | Acc: 22.234,43.865,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.755 | Acc: 22.338,44.039,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.752 | Acc: 22.687,44.214,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 22.760,44.202,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 22.512,44.071,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.753 | Acc: 22.608,44.099,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.755 | Acc: 22.458,43.966,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.756 | Acc: 22.264,43.902,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.193,43.853,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 22.251,43.795,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.342,43.897,98.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.328,43.870,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 22.379,43.849,98.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.425,43.782,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 22.397,43.690,98.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.429,43.674,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.443,43.709,98.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 21.094,45.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 21.429,43.266,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.968 | Acc: 21.570,42.778,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 21.875,42.328,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.724 | Acc: 28.125,46.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 21.429,44.048,98.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 21.818,43.693,98.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.754 | Acc: 21.568,43.340,98.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 21.682,42.978,98.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.754 | Acc: 21.844,42.953,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.755 | Acc: 21.856,43.059,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.025,43.163,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 22.079,43.401,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 22.082,43.331,98.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 22.314,43.595,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 22.260,43.651,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.290,43.662,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.300,43.711,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.345,43.608,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.443,43.677,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 22.459,43.679,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.487,43.649,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.505,43.562,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.539,43.533,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.913 | Acc: 21.875,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 21.577,43.415,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 21.723,42.912,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 22.003,42.431,71.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.758 | Acc: 24.219,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.768 | Acc: 22.991,43.824,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 22.523,43.350,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 22.323,43.263,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.755 | Acc: 22.589,43.586,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.757 | Acc: 22.718,43.603,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.757 | Acc: 22.734,43.685,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 22.695,43.600,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 22.588,43.449,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.557,43.353,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.594,43.268,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.663,43.361,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 22.656,43.429,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.757 | Acc: 22.680,43.415,98.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.684,43.386,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.641,43.332,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 22.647,43.353,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.604,43.468,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.509,43.438,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.529,43.447,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.976 | Acc: 22.656,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 21.057,43.638,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.513,43.083,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 21.785,42.508,71.888,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.755 | Acc: 18.750,40.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 22.768,45.126,98.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 22.389,44.169,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 21.965,43.622,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 22.377,44.145,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.200,43.773,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.760 | Acc: 22.249,43.750,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 22.291,43.600,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.380,43.546,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.759 | Acc: 22.389,43.703,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.759 | Acc: 22.442,43.595,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.508,43.651,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.520,43.559,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.757 | Acc: 22.459,43.531,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.514,43.519,98.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.532,43.568,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.481,43.456,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.581,43.663,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.641,43.702,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.599,43.695,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 21.094,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 21.354,43.936,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.952 | Acc: 21.684,43.369,71.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 22.003,42.853,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.728 | Acc: 22.656,49.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.749 | Acc: 23.028,45.164,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 22.332,43.883,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 22.131,43.776,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.753 | Acc: 22.145,43.904,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.755 | Acc: 22.130,43.441,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.243,43.214,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 22.379,43.556,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 22.530,43.595,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.755 | Acc: 22.497,43.487,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 22.439,43.501,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.755 | Acc: 22.554,43.513,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 22.588,43.627,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.754 | Acc: 22.659,43.705,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 22.781,43.733,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.754 | Acc: 22.770,43.807,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 22.807,43.894,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.748,43.764,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 22.726,43.689,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.754 | Acc: 22.703,43.672,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.935 | Acc: 21.094,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.466,43.713,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.704,43.197,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 22.144,42.597,71.785,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.800 | Acc: 24.219,36.719,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 23.065,43.118,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 22.790,43.674,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.757 | Acc: 22.387,43.622,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.758 | Acc: 22.000,43.461,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.757 | Acc: 22.146,43.317,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.437,43.459,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 22.518,43.346,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.756 | Acc: 22.554,43.304,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 22.656,43.521,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 22.660,43.478,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 22.812,43.647,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.754 | Acc: 22.958,43.734,98.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 22.986,43.828,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 22.934,43.703,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.754 | Acc: 22.879,43.651,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 22.907,43.665,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.798,43.569,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 22.883,43.694,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.754 | Acc: 22.845,43.691,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.916 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 21.168,43.713,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 21.475,43.178,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 21.747,42.661,71.785,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.768 | Acc: 22.656,42.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.733 | Acc: 23.661,44.717,99.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.738 | Acc: 23.152,44.493,98.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 22.746,44.070,98.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.749 | Acc: 22.589,44.097,98.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 22.393,43.796,98.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.755 | Acc: 22.469,43.866,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 22.224,43.794,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 22.195,43.794,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.755 | Acc: 22.147,43.711,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 22.116,43.804,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 22.091,43.768,98.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 22.167,43.731,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 22.237,43.618,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 22.259,43.644,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.319,43.631,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.420,43.638,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.491,43.700,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.446,43.700,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.498,43.729,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.942 | Acc: 21.094,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 21.168,43.676,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.399,42.893,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 21.696,42.431,71.952,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.736 | Acc: 19.531,45.312,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.752 | Acc: 21.429,44.606,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.752 | Acc: 21.723,44.322,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 22.554,44.185,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 22.618,44.174,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.754 | Acc: 22.842,44.469,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.754 | Acc: 22.895,44.396,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 22.950,44.138,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.797,43.954,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.753 | Acc: 22.699,43.953,98.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.753 | Acc: 22.753,43.964,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 22.649,43.817,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.754 | Acc: 22.634,43.763,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.754 | Acc: 22.596,43.765,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 22.612,43.803,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.754 | Acc: 22.563,43.776,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 22.542,43.701,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.516,43.619,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.561,43.635,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.615,43.629,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.923 | Acc: 21.875,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 21.280,44.010,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.513,43.159,71.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.958 | Acc: 21.734,42.546,71.773,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.761 | Acc: 20.312,42.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 21.726,44.792,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 22.409,44.569,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.752 | Acc: 22.592,44.813,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.753 | Acc: 22.762,44.763,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 22.633,44.446,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.755 | Acc: 22.482,44.086,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.501,44.110,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 22.486,43.760,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 22.354,43.534,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.756 | Acc: 22.303,43.493,98.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 22.359,43.457,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.300,43.471,98.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.294,43.591,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 22.345,43.633,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.407,43.708,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 22.491,43.752,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.491,43.741,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.472,43.726,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.537,43.652,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.932 | Acc: 21.094,44.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 21.243,43.638,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.475,43.045,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 21.837,42.482,71.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.738 | Acc: 22.656,47.656,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.755 | Acc: 22.991,43.378,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 22.447,43.807,98.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.753 | Acc: 22.656,43.481,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.755 | Acc: 22.444,43.808,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 22.463,43.735,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.482,43.679,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.584,43.678,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.482,43.595,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 22.462,43.655,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 22.547,43.820,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 22.589,43.980,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.754 | Acc: 22.575,43.909,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 22.528,43.831,98.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 22.526,43.775,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.563,43.758,98.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 22.559,43.743,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.686,43.892,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 22.632,43.945,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.652,43.974,98.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.946 | Acc: 22.656,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.964 | Acc: 21.391,43.713,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.532,42.893,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 21.888,42.213,71.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.731 | Acc: 27.344,49.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.771 | Acc: 21.615,41.071,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.763 | Acc: 22.256,42.168,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.762 | Acc: 22.323,42.533,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 22.106,42.728,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.548,43.294,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 22.301,43.350,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 22.257,43.351,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.756 | Acc: 22.399,43.464,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.354,43.366,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.756 | Acc: 22.431,43.424,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 22.356,43.591,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.394,43.581,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.492,43.552,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 22.590,43.528,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 22.643,43.545,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 22.564,43.531,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.756 | Acc: 22.574,43.521,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.619,43.527,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.642,43.586,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.945 | Acc: 21.875,41.406,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 21.205,43.229,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.589,42.778,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.959 | Acc: 21.837,42.303,72.054,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.736 | Acc: 21.875,46.875,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.749 | Acc: 23.214,44.308,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.745 | Acc: 23.590,44.341,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.747 | Acc: 22.848,44.275,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.751 | Acc: 23.081,44.695,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 22.981,44.431,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 22.695,44.131,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.479,44.110,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.491,43.997,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 22.596,44.160,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 22.544,44.146,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.755 | Acc: 22.540,44.157,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 22.530,43.983,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.444,43.792,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 22.501,43.744,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 22.539,43.727,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.617,43.731,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.704,43.757,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.667,43.685,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.589,43.664,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 22.656,39.844,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.967 | Acc: 21.689,43.415,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.958 | Acc: 21.704,42.912,71.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 22.054,42.495,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.798 | Acc: 25.781,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.759 | Acc: 21.503,43.787,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.760 | Acc: 22.428,43.540,98.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.757 | Acc: 22.631,43.724,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.760 | Acc: 22.116,43.181,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.761 | Acc: 22.161,42.860,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 22.314,42.969,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.759 | Acc: 22.412,43.168,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.757 | Acc: 22.549,43.338,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.548,43.357,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.641,43.571,98.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.720,43.619,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.721,43.640,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.770,43.648,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.701,43.617,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 22.654,43.659,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 22.678,43.704,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.610,43.679,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.581,43.624,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 22.541,43.641,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.912 | Acc: 21.094,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 21.577,43.601,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.959 | Acc: 21.837,42.988,71.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 22.041,42.444,71.875,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.755 | Acc: 22.656,37.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.763 | Acc: 22.507,43.043,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 23.095,43.941,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.757 | Acc: 22.656,43.788,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 22.627,43.490,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.758 | Acc: 22.888,43.495,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 22.869,43.388,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 22.678,43.373,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.535,43.439,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.691,43.698,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.785,43.633,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.819,43.686,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.682,43.588,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.764,43.675,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.698,43.580,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.687,43.680,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 22.651,43.667,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.756 | Acc: 22.620,43.587,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.680,43.674,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.648,43.621,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.980 | Acc: 21.094,42.188,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.980 | Acc: 21.615,43.564,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.967 | Acc: 21.723,42.797,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 22.041,42.328,71.657,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.777 | Acc: 21.094,42.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 22.396,43.713,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.763 | Acc: 21.989,43.426,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.764 | Acc: 21.760,43.289,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 21.962,43.355,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.169,43.479,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.275,43.304,98.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.760 | Acc: 22.396,43.412,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 22.156,43.260,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.760 | Acc: 22.311,43.176,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.760 | Acc: 22.264,43.062,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.760 | Acc: 22.264,43.149,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.760 | Acc: 22.329,43.199,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 22.444,43.409,98.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.528,43.391,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 22.526,43.397,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.574,43.424,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.610,43.468,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.561,43.460,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.664,43.537,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.939 | Acc: 22.656,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 21.577,43.527,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.974 | Acc: 21.532,42.969,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.978 | Acc: 21.990,42.392,71.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.764 | Acc: 21.875,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 22.842,43.415,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.754 | Acc: 22.104,42.854,98.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 22.259,42.841,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 22.724,43.519,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 22.633,43.502,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.437,43.511,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.756 | Acc: 22.346,43.423,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.756 | Acc: 22.418,43.435,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.423,43.435,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.411,43.373,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.472,43.400,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.465,43.491,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.617,43.663,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 22.645,43.731,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 22.623,43.620,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 22.661,43.619,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.756 | Acc: 22.606,43.626,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.490,43.540,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.414,43.510,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.928 | Acc: 21.094,42.969,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.956 | Acc: 21.466,43.638,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.589,43.083,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 21.901,42.585,72.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.726 | Acc: 24.219,51.562,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 22.656,43.824,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.752 | Acc: 23.361,43.540,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 22.964,43.404,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 23.110,43.586,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.755 | Acc: 22.865,43.518,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.757 | Acc: 22.585,43.434,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.758 | Acc: 22.579,43.418,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 22.574,43.527,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.721,43.517,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.575,43.334,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.469,43.241,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.530,43.484,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.757 | Acc: 22.495,43.540,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.514,43.578,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 22.498,43.506,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 22.520,43.541,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.516,43.562,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.526,43.648,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.527,43.598,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.947 | Acc: 21.094,43.750,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 21.577,43.341,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.959 | Acc: 21.742,42.912,72.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 22.080,42.469,71.939,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.746 | Acc: 13.281,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 23.065,44.085,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 22.580,43.998,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.751 | Acc: 22.861,44.134,98.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.753 | Acc: 22.676,43.837,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 22.618,44.067,98.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 22.463,43.802,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 22.601,43.800,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.569,43.629,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.753 | Acc: 22.686,43.772,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 22.672,43.801,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 22.663,43.902,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.752 | Acc: 22.692,43.977,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.754 | Acc: 22.680,43.741,98.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 22.692,43.717,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.669,43.716,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.578,43.655,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.542,43.670,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.587,43.700,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.574,43.623,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 21.094,43.750,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.972 | Acc: 21.168,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 21.341,43.007,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.966 | Acc: 21.721,42.585,71.632,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.717 | Acc: 29.688,46.094,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 23.400,43.304,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 22.542,43.178,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 22.631,43.276,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 22.627,43.335,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 22.679,43.255,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 22.534,43.343,98.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.758 | Acc: 22.407,43.174,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 22.448,43.216,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.371,43.137,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.376,43.307,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.568,43.527,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.741,43.682,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.757 | Acc: 22.686,43.669,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.576,43.572,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.568,43.563,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 22.595,43.543,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.533,43.505,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.563,43.599,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.603,43.574,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.949 | Acc: 21.875,41.406,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.317,43.415,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.959 | Acc: 21.284,43.064,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.965 | Acc: 21.644,42.623,71.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.840 | Acc: 22.656,42.969,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 22.656,44.568,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 22.142,43.617,98.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.749 | Acc: 22.387,43.519,98.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.749 | Acc: 22.270,43.663,98.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.752 | Acc: 22.440,43.386,98.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 22.366,43.395,98.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 22.268,43.262,98.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.220,43.405,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.755 | Acc: 22.203,43.521,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.753 | Acc: 22.163,43.715,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 22.289,43.842,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 22.274,43.731,98.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.753 | Acc: 22.327,43.702,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 22.350,43.700,98.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.754 | Acc: 22.410,43.734,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.753 | Acc: 22.398,43.755,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.429,43.741,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 22.334,43.627,98.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.334,43.666,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.926 | Acc: 22.656,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.503,43.824,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.684,43.140,72.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.970 | Acc: 22.093,42.713,71.939,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.776 | Acc: 23.438,42.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.762 | Acc: 21.689,42.932,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.759 | Acc: 21.208,43.159,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 21.721,43.186,98.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.756 | Acc: 22.531,43.538,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.755 | Acc: 22.695,43.773,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.755 | Acc: 22.850,43.931,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.950,44.055,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.860,44.061,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 22.747,44.134,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.753 | Acc: 22.788,44.174,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 22.921,44.019,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 22.929,44.032,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.752 | Acc: 22.983,43.995,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.753 | Acc: 22.887,43.911,98.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.804,43.914,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.702,43.811,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.756 | Acc: 22.714,43.901,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 22.715,43.876,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.669,43.781,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.953 | Acc: 21.875,41.406,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.956 | Acc: 21.429,43.490,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.955 | Acc: 21.570,42.835,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.961 | Acc: 21.952,42.444,71.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.746 | Acc: 17.969,40.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 22.582,43.080,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.754 | Acc: 22.123,43.636,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.753 | Acc: 22.413,43.686,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 22.560,43.904,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 22.502,43.688,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 22.669,43.892,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.751 | Acc: 22.562,43.772,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.752 | Acc: 22.569,43.731,98.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.753 | Acc: 22.635,43.633,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.752 | Acc: 22.625,43.657,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.752 | Acc: 22.642,43.853,98.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.752 | Acc: 22.640,43.893,98.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.752 | Acc: 22.584,43.897,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.752 | Acc: 22.551,43.825,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.753 | Acc: 22.493,43.597,98.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.753 | Acc: 22.466,43.594,98.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.753 | Acc: 22.503,43.516,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.753 | Acc: 22.511,43.560,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.753 | Acc: 22.570,43.553,98.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.928 | Acc: 21.094,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 21.057,43.750,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.532,43.216,71.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 21.862,42.649,71.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.806 | Acc: 20.312,31.250,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.755 | Acc: 22.805,43.378,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.754 | Acc: 23.209,44.379,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 22.682,43.993,98.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 23.322,44.387,98.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.758 | Acc: 23.236,44.191,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 23.166,44.415,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.758 | Acc: 22.983,44.154,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 23.010,43.862,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 23.019,43.983,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.756 | Acc: 22.975,44.049,98.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.784,43.959,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.757 | Acc: 22.809,43.857,98.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.929,43.972,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 22.818,43.817,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.757 | Acc: 22.820,43.714,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.802,43.665,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.780,43.693,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.723,43.722,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.726,43.713,98.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.929 | Acc: 21.875,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 21.317,43.564,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 21.475,43.159,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 21.824,42.469,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.746 | Acc: 21.094,45.312,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.759 | Acc: 21.615,42.857,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 22.123,42.893,98.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 21.965,42.879,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 21.971,43.036,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.758 | Acc: 22.099,43.116,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 22.327,43.272,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 22.473,43.196,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.757 | Acc: 22.569,43.381,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 22.505,43.409,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.590,43.424,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.757 | Acc: 22.635,43.527,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.773,43.617,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.757 | Acc: 22.728,43.564,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.784,43.589,98.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 22.838,43.683,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 22.751,43.577,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.743,43.578,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.732,43.594,98.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.740,43.606,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.923 | Acc: 21.094,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.969 | Acc: 21.391,43.415,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.959 | Acc: 21.456,42.969,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 21.888,42.533,71.683,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.743 | Acc: 26.562,47.656,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.766 | Acc: 21.391,42.783,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 22.351,42.988,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 21.862,43.071,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 22.174,43.412,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.759 | Acc: 22.525,43.580,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.757 | Acc: 22.469,43.815,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 22.318,43.772,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 22.365,43.789,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 22.423,43.780,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.493,43.742,98.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.426,43.662,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 22.436,43.685,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.315,43.534,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.331,43.458,98.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 22.443,43.511,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.393,43.475,98.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 22.468,43.487,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.457,43.518,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.486,43.543,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.970 | Acc: 21.875,43.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 21.243,43.601,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.962 | Acc: 21.513,42.759,71.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.970 | Acc: 21.709,42.303,71.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.730 | Acc: 23.438,45.312,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 22.619,41.741,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.757 | Acc: 22.637,42.530,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 23.335,43.340,98.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.756 | Acc: 23.380,43.731,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.757 | Acc: 23.229,43.773,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.756 | Acc: 23.483,43.840,98.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 23.343,43.916,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.753 | Acc: 23.200,43.760,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.753 | Acc: 23.109,43.685,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 23.029,43.789,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 23.133,43.817,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 23.052,43.786,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.753 | Acc: 22.929,43.792,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.753 | Acc: 22.993,43.833,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.753 | Acc: 22.988,43.820,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.846,43.636,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.807,43.610,98.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.767,43.555,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.742,43.526,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.946 | Acc: 21.094,39.844,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.540,43.824,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.957 | Acc: 21.646,43.293,71.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 22.054,42.649,71.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.726 | Acc: 23.438,49.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.747 | Acc: 22.135,44.420,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.745 | Acc: 22.370,44.550,98.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.748 | Acc: 22.669,44.326,98.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.752 | Acc: 22.560,44.213,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.752 | Acc: 22.656,44.036,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 22.792,43.976,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 22.612,43.877,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 22.719,43.876,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 22.522,43.737,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 22.497,43.769,98.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 22.529,43.789,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.754 | Acc: 22.601,43.763,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.754 | Acc: 22.483,43.621,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 22.523,43.583,98.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.602,43.581,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.608,43.580,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.626,43.576,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.557,43.564,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.546,43.537,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.943 | Acc: 20.312,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 20.982,43.973,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.960 | Acc: 21.341,43.255,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.967 | Acc: 21.747,42.636,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.725 | Acc: 23.438,49.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 23.921,44.568,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 23.037,43.598,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.754 | Acc: 23.002,43.122,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.751 | Acc: 22.926,43.268,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 23.167,43.386,98.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 22.940,43.653,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.751 | Acc: 23.144,43.634,98.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 23.108,43.876,98.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.752 | Acc: 23.097,43.871,98.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.752 | Acc: 23.138,43.964,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.752 | Acc: 23.035,43.902,98.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 22.974,43.701,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.754 | Acc: 22.929,43.720,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.754 | Acc: 23.001,43.853,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.754 | Acc: 23.001,43.776,98.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 22.958,43.787,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 22.904,43.768,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 22.814,43.709,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.753 | Acc: 22.826,43.754,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.964 | Acc: 21.615,43.973,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.962 | Acc: 21.704,43.178,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.968 | Acc: 22.016,42.623,71.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.727 | Acc: 21.094,44.531,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 22.284,44.196,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 21.665,43.502,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 21.939,43.891,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.758 | Acc: 21.933,43.509,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.355,43.425,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.760 | Acc: 22.566,43.789,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.759 | Acc: 22.762,43.911,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.759 | Acc: 22.545,43.745,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.759 | Acc: 22.449,43.577,98.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.759 | Acc: 22.575,43.707,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 22.578,43.785,98.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 22.588,43.789,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.677,43.843,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.757 | Acc: 22.723,43.872,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 22.724,43.914,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 22.707,43.816,98.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.756 | Acc: 22.675,43.768,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 22.585,43.715,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 22.646,43.670,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.890 | Acc: 21.094,44.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.959 | Acc: 21.168,44.234,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.952 | Acc: 21.361,43.369,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.963 | Acc: 21.798,42.853,71.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.754 | Acc: 28.125,42.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.762 | Acc: 21.763,43.118,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.757 | Acc: 21.665,43.159,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.754 | Acc: 22.106,43.276,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.753 | Acc: 22.068,43.528,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 22.084,43.441,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.755 | Acc: 22.262,43.421,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.756 | Acc: 22.285,43.340,98.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.757 | Acc: 22.399,43.410,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 22.410,43.564,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.756 | Acc: 22.454,43.598,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 22.423,43.644,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 22.403,43.737,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 22.450,43.819,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 22.431,43.725,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 22.495,43.810,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 22.505,43.808,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 22.500,43.677,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 22.457,43.637,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 22.478,43.707,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.920 | Acc: 21.875,42.188,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 21.429,43.452,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.956 | Acc: 21.494,43.007,71.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.962 | Acc: 21.773,42.520,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.698 | Acc: 24.219,48.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.755 | Acc: 21.652,43.750,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.760 | Acc: 21.818,43.236,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 22.118,43.468,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 22.155,43.625,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.760 | Acc: 22.300,43.433,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.760 | Acc: 22.133,43.382,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.759 | Acc: 22.219,43.479,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 22.346,43.658,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.440,43.586,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.656,43.633,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.607,43.644,98.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.559,43.568,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 22.501,43.520,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.759 | Acc: 22.570,43.541,98.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.759 | Acc: 22.558,43.594,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 22.542,43.648,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.758 | Acc: 22.549,43.638,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.622,43.707,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 22.652,43.719,98.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 21.094,43.750,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 21.057,43.638,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.965 | Acc: 21.437,43.121,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 21.811,42.585,71.849,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.734 | Acc: 32.812,48.438,98.438,% | Adaptive Acc: 97.656% | clf_exit: 0.008 0.094 0.898
Batch: 20 | Loss: 0.759 | Acc: 22.098,43.378,98.624,% | Adaptive Acc: 97.619% | clf_exit: 0.006 0.084 0.910
Batch: 40 | Loss: 0.752 | Acc: 22.218,43.255,98.800,% | Adaptive Acc: 97.866% | clf_exit: 0.005 0.090 0.905
Batch: 60 | Loss: 0.750 | Acc: 22.605,43.750,98.694,% | Adaptive Acc: 97.656% | clf_exit: 0.006 0.091 0.904
Batch: 80 | Loss: 0.751 | Acc: 22.386,43.470,98.717,% | Adaptive Acc: 97.637% | clf_exit: 0.006 0.091 0.903
Batch: 100 | Loss: 0.751 | Acc: 22.169,43.510,98.755,% | Adaptive Acc: 97.695% | clf_exit: 0.006 0.089 0.905
Batch: 120 | Loss: 0.752 | Acc: 22.346,43.511,98.644,% | Adaptive Acc: 97.553% | clf_exit: 0.006 0.090 0.904
Batch: 140 | Loss: 0.752 | Acc: 22.346,43.617,98.620,% | Adaptive Acc: 97.507% | clf_exit: 0.006 0.090 0.904
Batch: 160 | Loss: 0.753 | Acc: 22.229,43.522,98.632,% | Adaptive Acc: 97.491% | clf_exit: 0.006 0.090 0.904
Batch: 180 | Loss: 0.753 | Acc: 22.246,43.366,98.636,% | Adaptive Acc: 97.509% | clf_exit: 0.006 0.090 0.904
Batch: 200 | Loss: 0.753 | Acc: 22.248,43.439,98.585,% | Adaptive Acc: 97.474% | clf_exit: 0.006 0.091 0.904
Batch: 220 | Loss: 0.753 | Acc: 22.398,43.457,98.565,% | Adaptive Acc: 97.455% | clf_exit: 0.005 0.091 0.904
Batch: 240 | Loss: 0.753 | Acc: 22.462,43.533,98.574,% | Adaptive Acc: 97.475% | clf_exit: 0.005 0.091 0.903
Batch: 260 | Loss: 0.754 | Acc: 22.459,43.451,98.548,% | Adaptive Acc: 97.453% | clf_exit: 0.005 0.091 0.904
Batch: 280 | Loss: 0.753 | Acc: 22.512,43.555,98.540,% | Adaptive Acc: 97.442% | clf_exit: 0.005 0.091 0.904
Batch: 300 | Loss: 0.754 | Acc: 22.488,43.452,98.534,% | Adaptive Acc: 97.443% | clf_exit: 0.005 0.090 0.905
Batch: 320 | Loss: 0.754 | Acc: 22.371,43.480,98.540,% | Adaptive Acc: 97.469% | clf_exit: 0.005 0.089 0.906
Batch: 340 | Loss: 0.753 | Acc: 22.402,43.509,98.554,% | Adaptive Acc: 97.487% | clf_exit: 0.005 0.089 0.906
Batch: 360 | Loss: 0.753 | Acc: 22.466,43.484,98.582,% | Adaptive Acc: 97.513% | clf_exit: 0.005 0.089 0.906
Batch: 380 | Loss: 0.752 | Acc: 22.486,43.516,98.579,% | Adaptive Acc: 97.515% | clf_exit: 0.005 0.090 0.905
Batch: 0 | Loss: 1.953 | Acc: 21.875,43.750,71.094,% | Adaptive Acc: 69.531% | clf_exit: 0.031 0.180 0.789
Batch: 20 | Loss: 1.961 | Acc: 21.652,43.564,72.098,% | Adaptive Acc: 71.057% | clf_exit: 0.017 0.167 0.815
Batch: 40 | Loss: 1.956 | Acc: 21.818,42.950,71.665,% | Adaptive Acc: 70.389% | clf_exit: 0.015 0.164 0.820
Batch: 60 | Loss: 1.964 | Acc: 22.080,42.546,71.696,% | Adaptive Acc: 70.453% | clf_exit: 0.015 0.163 0.822
model is save as models/resnet56_cifar100_adaptive0_circles5_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 4.925 | Acc: 0.781,0.781,15.625,% | Adaptive Acc: 15.625% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: 5.061 | Acc: 1.823,1.042,11.421,% | Adaptive Acc: 11.421% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: 5.059 | Acc: 1.467,1.105,11.852,% | Adaptive Acc: 11.852% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: 5.054 | Acc: 1.486,1.037,11.898,% | Adaptive Acc: 11.898% | clf_exit: 0.000 0.000 1.000
Batch: 0 | Loss: 3.769 | Acc: 1.562,5.469,46.094,% | Adaptive Acc: 46.094% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: 3.985 | Acc: 3.832,5.469,36.124,% | Adaptive Acc: 36.161% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: 3.990 | Acc: 3.030,5.030,36.414,% | Adaptive Acc: 36.452% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: 3.986 | Acc: 3.010,4.982,35.758,% | Adaptive Acc: 35.784% | clf_exit: 0.000 0.000 1.000
Batch: 0 | Loss: 2.958 | Acc: 2.344,6.250,60.938,% | Adaptive Acc: 60.938% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: 3.179 | Acc: 4.129,6.734,52.269,% | Adaptive Acc: 52.269% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: 3.193 | Acc: 3.697,6.155,52.420,% | Adaptive Acc: 52.420% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: 3.187 | Acc: 3.817,6.404,52.254,% | Adaptive Acc: 52.254% | clf_exit: 0.000 0.001 0.999
Batch: 0 | Loss: 2.406 | Acc: 3.906,10.156,67.188,% | Adaptive Acc: 67.188% | clf_exit: 0.000 0.008 0.992
Batch: 20 | Loss: 2.526 | Acc: 5.134,11.830,63.281,% | Adaptive Acc: 63.356% | clf_exit: 0.001 0.004 0.996
Batch: 40 | Loss: 2.537 | Acc: 4.859,11.471,62.995,% | Adaptive Acc: 63.053% | clf_exit: 0.001 0.003 0.997
Batch: 60 | Loss: 2.538 | Acc: 5.072,11.988,63.076,% | Adaptive Acc: 63.102% | clf_exit: 0.001 0.003 0.997
Batch: 0 | Loss: 2.015 | Acc: 9.375,30.469,71.875,% | Adaptive Acc: 71.875% | clf_exit: 0.000 0.031 0.969
Batch: 20 | Loss: 2.064 | Acc: 11.905,32.329,69.382,% | Adaptive Acc: 69.420% | clf_exit: 0.004 0.021 0.975
Batch: 40 | Loss: 2.064 | Acc: 11.757,32.336,69.474,% | Adaptive Acc: 69.455% | clf_exit: 0.004 0.020 0.976
Batch: 60 | Loss: 2.072 | Acc: 11.796,32.134,69.506,% | Adaptive Acc: 69.467% | clf_exit: 0.004 0.019 0.977
Batch: 0 | Loss: 1.953 | Acc: 21.875,43.750,71.094,% | Adaptive Acc: 69.531% | clf_exit: 0.031 0.180 0.789
Batch: 20 | Loss: 1.961 | Acc: 21.652,43.564,72.098,% | Adaptive Acc: 71.057% | clf_exit: 0.017 0.167 0.815
Batch: 40 | Loss: 1.956 | Acc: 21.818,42.950,71.665,% | Adaptive Acc: 70.389% | clf_exit: 0.015 0.164 0.820
Batch: 60 | Loss: 1.964 | Acc: 22.080,42.546,71.696,% | Adaptive Acc: 70.453% | clf_exit: 0.015 0.163 0.822







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 5.266 |  Acc: 1.760,2.910,5.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 5.006 |  Acc: 1.340,3.920,7.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 4.764 |  Acc: 2.920,5.616,11.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 4.736 |  Acc: 2.100,6.160,11.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 4.549 |  Acc: 3.274,7.100,14.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 4.506 |  Acc: 2.960,7.870,14.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 4.359 |  Acc: 3.868,8.464,16.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 4.353 |  Acc: 2.570,8.130,16.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 4.175 |  Acc: 4.140,9.810,19.938,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 4.188 |  Acc: 3.930,9.240,19.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 3.999 |  Acc: 4.682,11.148,22.996,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 4.130 |  Acc: 3.430,8.690,20.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 3.841 |  Acc: 4.598,11.992,25.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 3.855 |  Acc: 4.490,11.530,24.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 3.699 |  Acc: 5.198,12.982,28.158,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 3.671 |  Acc: 4.230,13.040,28.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 3.579 |  Acc: 5.592,13.652,30.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 3.556 |  Acc: 5.210,12.370,30.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 3.468 |  Acc: 5.922,14.578,32.702,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 3.635 |  Acc: 4.790,14.060,29.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 3.350 |  Acc: 6.180,15.486,34.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 3.497 |  Acc: 5.250,14.090,32.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 3.255 |  Acc: 6.244,16.262,36.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 3.334 |  Acc: 4.460,12.940,35.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 3.159 |  Acc: 6.604,16.908,38.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 3.204 |  Acc: 5.870,15.700,37.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 3.081 |  Acc: 6.746,17.160,40.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 3.319 |  Acc: 6.510,16.140,36.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 2.992 |  Acc: 6.884,18.000,42.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 3.292 |  Acc: 6.750,15.780,37.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 2.918 |  Acc: 7.138,18.590,43.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 3.211 |  Acc: 6.110,15.460,38.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 2.849 |  Acc: 7.280,18.882,45.174,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 3.135 |  Acc: 5.580,16.110,40.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 2.769 |  Acc: 7.504,19.656,47.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 2.984 |  Acc: 6.870,16.370,42.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 2.724 |  Acc: 7.664,20.368,48.140,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 2.896 |  Acc: 7.320,16.470,45.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 2.654 |  Acc: 7.958,20.776,49.530,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 2.824 |  Acc: 7.590,18.860,46.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 2.610 |  Acc: 8.118,21.130,50.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 2.992 |  Acc: 7.490,19.770,44.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 2.566 |  Acc: 8.372,21.570,51.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 2.888 |  Acc: 7.680,19.160,45.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 2.520 |  Acc: 8.626,21.880,52.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 2.713 |  Acc: 7.940,20.400,49.130,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 2.480 |  Acc: 8.946,22.204,54.008,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 2.827 |  Acc: 9.320,18.770,46.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 2.426 |  Acc: 9.398,22.616,55.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 2.703 |  Acc: 7.790,19.460,49.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 2.400 |  Acc: 9.390,22.858,55.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 2.683 |  Acc: 7.280,20.600,50.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 2.359 |  Acc: 9.888,23.140,56.548,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 2.689 |  Acc: 7.770,21.610,50.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 2.330 |  Acc: 10.002,23.258,57.432,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 2.740 |  Acc: 9.000,19.940,48.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.309 |  Acc: 10.094,23.452,57.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 2.703 |  Acc: 8.400,20.660,49.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.269 |  Acc: 10.560,23.934,58.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 2.636 |  Acc: 9.410,19.580,51.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.255 |  Acc: 10.608,23.812,59.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 2.569 |  Acc: 10.780,19.910,51.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.217 |  Acc: 10.816,24.176,60.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 2.541 |  Acc: 9.290,22.050,53.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.188 |  Acc: 11.154,24.574,60.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 2.696 |  Acc: 9.260,20.120,50.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.174 |  Acc: 11.334,24.790,61.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 2.665 |  Acc: 10.810,22.670,51.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.145 |  Acc: 11.536,24.986,61.652,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 2.531 |  Acc: 10.310,22.040,53.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.130 |  Acc: 11.784,25.200,61.912,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 2.570 |  Acc: 10.860,22.350,52.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.107 |  Acc: 11.882,25.432,62.704,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 2.608 |  Acc: 11.220,21.230,52.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.086 |  Acc: 12.104,25.652,63.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 2.583 |  Acc: 9.640,20.810,53.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 2.069 |  Acc: 12.272,25.806,63.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 2.542 |  Acc: 11.690,22.240,53.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 2.054 |  Acc: 12.766,25.956,64.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 2.681 |  Acc: 10.330,22.340,51.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 2.038 |  Acc: 12.830,26.250,64.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 2.546 |  Acc: 12.600,22.940,53.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 2.016 |  Acc: 12.914,26.374,64.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 2.427 |  Acc: 11.310,22.870,56.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 2.007 |  Acc: 13.352,26.736,64.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 2.495 |  Acc: 9.960,23.340,54.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 1.996 |  Acc: 13.514,26.538,65.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 2.559 |  Acc: 13.070,24.510,53.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 1.973 |  Acc: 13.724,26.518,65.908,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 2.428 |  Acc: 11.810,24.610,55.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 1.970 |  Acc: 14.004,26.884,65.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 2.539 |  Acc: 11.920,22.390,54.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 1.954 |  Acc: 14.194,26.932,66.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 2.516 |  Acc: 13.770,24.840,54.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 1.941 |  Acc: 14.278,27.078,66.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 2.464 |  Acc: 10.100,21.830,56.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 1.924 |  Acc: 14.640,27.438,67.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 2.357 |  Acc: 14.000,24.850,57.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 1.917 |  Acc: 14.804,27.462,67.098,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 2.284 |  Acc: 13.680,25.420,59.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 1.900 |  Acc: 14.792,27.770,67.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 2.384 |  Acc: 13.230,26.310,57.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 1.909 |  Acc: 15.004,27.440,67.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 2.288 |  Acc: 12.760,24.340,59.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 1.883 |  Acc: 15.434,27.686,68.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 2.301 |  Acc: 12.140,23.980,58.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 1.866 |  Acc: 15.260,27.706,68.192,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 2.627 |  Acc: 12.970,23.270,52.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 1.866 |  Acc: 15.416,28.236,68.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 2.405 |  Acc: 12.660,24.400,56.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 1.855 |  Acc: 15.542,28.142,68.672,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 2.380 |  Acc: 12.820,24.630,57.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 1.845 |  Acc: 15.752,28.174,68.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 2.325 |  Acc: 13.860,26.070,59.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 1.835 |  Acc: 15.924,28.676,69.136,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 2.396 |  Acc: 12.520,23.420,57.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 1.827 |  Acc: 16.062,28.330,69.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 2.453 |  Acc: 14.260,26.310,56.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 1.818 |  Acc: 16.162,28.592,69.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 2.330 |  Acc: 14.120,24.810,58.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 1.814 |  Acc: 16.370,29.104,69.650,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 2.473 |  Acc: 13.010,24.300,55.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 1.809 |  Acc: 16.434,28.964,69.680,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 2.396 |  Acc: 14.810,26.080,58.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 1.794 |  Acc: 16.268,29.286,70.030,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 2.426 |  Acc: 14.360,25.090,56.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 1.791 |  Acc: 16.508,29.210,70.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 2.254 |  Acc: 14.820,26.450,60.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 1.786 |  Acc: 16.616,29.130,70.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 2.378 |  Acc: 14.240,25.020,57.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 1.776 |  Acc: 16.796,29.062,70.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 2.451 |  Acc: 11.540,22.750,57.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 1.762 |  Acc: 16.712,29.364,70.810,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 2.382 |  Acc: 14.060,25.220,58.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 1.768 |  Acc: 16.956,29.478,70.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 2.469 |  Acc: 14.530,24.890,56.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 1.751 |  Acc: 17.088,29.622,71.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 2.440 |  Acc: 13.690,23.640,56.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 1.739 |  Acc: 17.246,29.768,71.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 2.537 |  Acc: 12.980,24.920,55.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 1.729 |  Acc: 17.142,30.092,71.546,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 2.268 |  Acc: 14.140,26.640,60.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 1.731 |  Acc: 17.418,29.774,71.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 2.341 |  Acc: 15.080,26.220,58.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 1.731 |  Acc: 17.460,30.376,71.618,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 2.296 |  Acc: 14.410,25.260,59.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 1.726 |  Acc: 17.436,30.156,71.556,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 2.466 |  Acc: 14.450,24.840,56.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 1.709 |  Acc: 17.508,30.076,72.060,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 2.361 |  Acc: 14.080,26.450,58.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 1.717 |  Acc: 17.542,30.316,71.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 2.341 |  Acc: 15.070,25.960,59.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 1.713 |  Acc: 17.422,30.308,71.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 2.374 |  Acc: 14.530,26.910,59.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 1.702 |  Acc: 17.606,30.452,72.056,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 2.331 |  Acc: 13.570,26.460,59.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 1.698 |  Acc: 17.532,30.446,72.194,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 2.285 |  Acc: 16.030,26.370,60.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 1.685 |  Acc: 17.652,30.866,72.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 2.288 |  Acc: 15.400,26.610,59.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 1.685 |  Acc: 17.832,30.734,72.566,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 2.430 |  Acc: 14.300,25.120,57.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 1.673 |  Acc: 17.862,30.906,73.016,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 2.287 |  Acc: 15.350,28.200,60.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 1.679 |  Acc: 17.978,31.194,72.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 2.372 |  Acc: 15.920,26.660,58.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 1.679 |  Acc: 17.840,31.136,72.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 2.318 |  Acc: 15.610,25.840,59.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 1.670 |  Acc: 17.918,31.080,72.882,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 2.352 |  Acc: 15.110,27.260,58.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 1.664 |  Acc: 18.074,31.144,73.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 2.897 |  Acc: 14.270,22.340,49.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 1.655 |  Acc: 18.016,31.398,73.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 2.398 |  Acc: 16.200,28.710,58.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 1.650 |  Acc: 18.156,31.400,73.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 2.307 |  Acc: 16.580,28.800,59.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 1.652 |  Acc: 18.182,31.590,73.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 2.432 |  Acc: 15.560,25.140,58.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 1.645 |  Acc: 18.054,31.362,73.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 2.243 |  Acc: 15.470,26.800,61.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 1.635 |  Acc: 18.192,31.658,73.890,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 2.300 |  Acc: 15.930,28.270,60.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 1.631 |  Acc: 18.342,31.530,73.772,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 2.317 |  Acc: 14.920,25.840,59.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 1.638 |  Acc: 18.198,31.800,73.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 2.442 |  Acc: 14.900,26.260,57.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 1.635 |  Acc: 18.422,32.090,73.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 2.182 |  Acc: 16.570,28.830,62.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 1.629 |  Acc: 18.530,32.142,73.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 2.354 |  Acc: 16.970,28.620,58.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 1.624 |  Acc: 18.396,31.888,73.990,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 2.352 |  Acc: 16.270,27.990,59.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 1.618 |  Acc: 18.516,32.368,74.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 2.293 |  Acc: 15.560,28.340,59.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 1.626 |  Acc: 18.444,32.206,73.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 2.378 |  Acc: 14.540,28.200,58.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 1.610 |  Acc: 18.552,32.290,74.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 2.364 |  Acc: 15.020,26.030,59.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 1.615 |  Acc: 18.416,32.086,74.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 2.360 |  Acc: 16.760,28.670,60.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 1.604 |  Acc: 18.746,32.538,74.582,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 2.232 |  Acc: 16.600,26.980,61.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 1.598 |  Acc: 18.660,32.596,74.682,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 2.253 |  Acc: 14.320,28.390,61.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 1.610 |  Acc: 18.478,32.316,74.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 2.500 |  Acc: 14.960,26.250,56.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 1.597 |  Acc: 18.694,32.756,74.848,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 2.320 |  Acc: 15.400,27.530,59.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 1.591 |  Acc: 18.584,32.516,74.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 2.325 |  Acc: 15.010,27.950,59.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 1.599 |  Acc: 18.534,32.750,74.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 2.367 |  Acc: 15.550,28.550,59.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 1.590 |  Acc: 18.614,33.056,74.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 2.387 |  Acc: 13.590,27.240,59.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 1.587 |  Acc: 18.720,32.632,74.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 2.383 |  Acc: 16.410,29.920,59.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 1.582 |  Acc: 18.930,32.808,75.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 2.267 |  Acc: 16.790,30.340,60.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 1.591 |  Acc: 18.882,32.882,74.870,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 2.459 |  Acc: 15.970,27.960,56.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 1.572 |  Acc: 18.958,32.882,75.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 2.336 |  Acc: 15.780,28.400,59.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.577 |  Acc: 18.964,33.046,74.980,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 2.271 |  Acc: 14.920,28.740,60.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 1.567 |  Acc: 19.256,33.264,75.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 2.472 |  Acc: 14.520,26.850,57.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 1.581 |  Acc: 19.048,33.196,75.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 2.477 |  Acc: 15.390,26.480,57.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 1.567 |  Acc: 18.886,33.368,75.244,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 2.323 |  Acc: 13.740,22.180,60.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 1.565 |  Acc: 18.990,33.210,75.402,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 2.376 |  Acc: 15.080,27.470,59.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.569 |  Acc: 18.980,33.552,75.228,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 2.433 |  Acc: 16.530,26.910,57.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.578 |  Acc: 18.746,33.236,74.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 2.197 |  Acc: 15.270,29.670,62.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.562 |  Acc: 19.082,33.592,75.374,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 2.310 |  Acc: 14.620,28.980,59.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.553 |  Acc: 19.146,33.484,75.714,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 2.265 |  Acc: 17.720,30.370,62.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.549 |  Acc: 19.172,33.684,75.900,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 2.174 |  Acc: 16.710,29.850,62.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.546 |  Acc: 18.886,33.518,75.876,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 2.202 |  Acc: 16.970,29.850,62.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.557 |  Acc: 19.104,33.574,75.294,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 2.294 |  Acc: 14.400,28.700,60.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.542 |  Acc: 19.224,33.906,76.086,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 2.409 |  Acc: 14.600,25.320,58.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.550 |  Acc: 19.148,33.800,75.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 2.481 |  Acc: 16.100,28.830,57.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.549 |  Acc: 19.004,33.648,75.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 2.345 |  Acc: 16.820,28.170,59.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.539 |  Acc: 19.268,33.870,75.758,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 2.342 |  Acc: 13.440,25.580,59.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.551 |  Acc: 19.238,33.628,75.508,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 2.169 |  Acc: 17.610,31.030,63.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.547 |  Acc: 19.220,33.942,75.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 2.432 |  Acc: 17.610,28.940,58.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.525 |  Acc: 19.232,34.126,76.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 2.318 |  Acc: 15.900,28.470,60.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.545 |  Acc: 19.426,33.824,75.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 2.234 |  Acc: 17.360,29.580,61.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.536 |  Acc: 19.246,33.836,76.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 2.341 |  Acc: 17.260,30.210,59.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.530 |  Acc: 19.502,34.176,76.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 2.413 |  Acc: 15.690,26.270,59.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.528 |  Acc: 19.476,34.344,76.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 2.306 |  Acc: 16.210,30.370,60.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.522 |  Acc: 19.408,34.304,76.280,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 2.130 |  Acc: 16.240,30.930,63.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.540 |  Acc: 19.534,34.070,75.858,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 2.358 |  Acc: 15.490,28.480,59.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.523 |  Acc: 19.442,34.196,76.212,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 2.325 |  Acc: 18.700,28.330,59.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.523 |  Acc: 19.588,34.430,76.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 2.306 |  Acc: 17.600,31.250,60.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.520 |  Acc: 19.306,34.448,76.216,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 2.259 |  Acc: 15.520,29.330,61.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.527 |  Acc: 19.690,34.504,76.154,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 2.350 |  Acc: 16.690,27.190,59.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.520 |  Acc: 19.372,34.414,76.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 2.324 |  Acc: 13.470,28.040,60.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.511 |  Acc: 19.288,34.536,76.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 2.405 |  Acc: 16.640,29.660,57.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.519 |  Acc: 19.460,34.818,76.404,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 2.259 |  Acc: 16.160,29.790,61.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.512 |  Acc: 19.340,34.562,76.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 2.398 |  Acc: 15.540,27.650,58.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.512 |  Acc: 19.542,34.702,76.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 2.399 |  Acc: 15.380,26.100,58.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.513 |  Acc: 19.476,34.622,76.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 2.300 |  Acc: 15.370,28.580,60.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.513 |  Acc: 19.522,34.694,76.580,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 2.293 |  Acc: 16.540,29.240,60.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.505 |  Acc: 19.436,34.746,76.730,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 2.588 |  Acc: 13.330,24.410,56.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.514 |  Acc: 19.700,34.806,76.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 2.315 |  Acc: 15.760,30.400,60.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.505 |  Acc: 19.576,34.976,76.930,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 2.313 |  Acc: 15.360,27.970,60.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.236 |  Acc: 20.186,37.150,84.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 1.778 |  Acc: 18.940,36.490,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.125 |  Acc: 20.284,38.100,87.926,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 1.775 |  Acc: 19.130,37.280,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.096 |  Acc: 20.698,38.410,88.818,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 1.763 |  Acc: 19.010,37.480,72.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.072 |  Acc: 20.478,38.804,89.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 1.778 |  Acc: 19.240,37.610,72.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.054 |  Acc: 20.744,38.938,89.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 1.766 |  Acc: 19.400,37.870,72.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.039 |  Acc: 20.710,39.030,90.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 1.781 |  Acc: 19.770,37.900,72.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.028 |  Acc: 20.680,39.020,90.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 1.777 |  Acc: 19.530,37.980,72.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.009 |  Acc: 20.866,39.270,91.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 1.794 |  Acc: 19.630,38.190,72.400,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.001 |  Acc: 20.754,39.428,91.532,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 1.798 |  Acc: 19.770,38.380,72.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 0.996 |  Acc: 20.838,39.656,91.716,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 1.807 |  Acc: 19.700,38.380,72.140,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 0.986 |  Acc: 21.006,39.734,92.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 1.815 |  Acc: 19.740,38.450,72.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 0.978 |  Acc: 20.960,39.814,92.232,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 1.813 |  Acc: 19.540,38.530,72.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 0.971 |  Acc: 21.050,39.710,92.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 1.821 |  Acc: 19.360,38.690,72.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 0.957 |  Acc: 21.052,40.232,92.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 1.836 |  Acc: 19.700,38.760,72.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 0.959 |  Acc: 20.964,39.838,92.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 1.820 |  Acc: 20.000,39.110,72.390,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 0.951 |  Acc: 21.054,40.060,92.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 1.832 |  Acc: 19.960,38.760,72.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 0.945 |  Acc: 21.112,40.282,93.178,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 1.834 |  Acc: 20.220,39.310,72.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 0.939 |  Acc: 21.234,40.470,93.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 1.838 |  Acc: 19.910,39.140,72.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 0.931 |  Acc: 21.174,40.430,93.642,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 1.850 |  Acc: 19.910,38.880,72.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 0.931 |  Acc: 21.162,40.486,93.598,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 1.851 |  Acc: 19.430,39.270,72.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 0.927 |  Acc: 21.294,40.448,93.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 1.858 |  Acc: 20.020,39.480,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 0.919 |  Acc: 21.228,40.322,93.948,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 1.880 |  Acc: 20.290,39.650,71.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 0.919 |  Acc: 21.212,40.438,93.852,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 1.880 |  Acc: 20.090,39.570,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 0.915 |  Acc: 21.328,40.522,94.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 1.877 |  Acc: 20.160,39.780,72.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 0.911 |  Acc: 21.360,40.848,94.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 1.885 |  Acc: 19.890,39.430,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 0.904 |  Acc: 21.396,40.742,94.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 1.891 |  Acc: 20.040,39.840,71.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 0.903 |  Acc: 21.590,40.842,94.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 1.884 |  Acc: 19.860,39.650,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 0.898 |  Acc: 21.490,40.750,94.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 1.884 |  Acc: 20.360,39.670,71.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 0.897 |  Acc: 21.468,40.918,94.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 1.886 |  Acc: 20.620,40.290,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 0.897 |  Acc: 21.466,40.860,94.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 1.920 |  Acc: 20.100,39.680,71.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 0.893 |  Acc: 21.458,40.870,94.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 1.915 |  Acc: 20.390,39.400,71.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 0.885 |  Acc: 21.474,41.208,94.866,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 1.897 |  Acc: 20.550,39.790,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 0.882 |  Acc: 21.362,41.050,95.026,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 1.918 |  Acc: 20.510,40.210,71.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 0.883 |  Acc: 21.504,40.896,94.920,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 1.924 |  Acc: 20.560,39.750,70.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 0.881 |  Acc: 21.520,41.018,95.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 1.913 |  Acc: 20.230,39.780,71.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 0.877 |  Acc: 21.542,41.178,95.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 1.919 |  Acc: 20.150,39.850,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 0.874 |  Acc: 21.642,41.196,95.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 1.918 |  Acc: 20.450,39.600,71.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 0.871 |  Acc: 21.670,41.284,95.162,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 1.914 |  Acc: 20.650,40.110,71.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 0.867 |  Acc: 21.666,41.506,95.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 1.945 |  Acc: 20.790,40.270,71.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.872 |  Acc: 21.724,41.342,95.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 1.926 |  Acc: 20.680,40.390,71.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.865 |  Acc: 21.822,41.400,95.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 1.961 |  Acc: 20.720,40.400,71.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.864 |  Acc: 21.752,41.478,95.424,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 1.941 |  Acc: 20.570,40.280,71.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.866 |  Acc: 21.892,41.348,95.354,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 1.943 |  Acc: 20.840,40.370,71.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.862 |  Acc: 21.834,41.294,95.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 1.940 |  Acc: 20.610,40.190,71.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.857 |  Acc: 21.782,41.674,95.700,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 1.931 |  Acc: 20.590,40.390,71.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.858 |  Acc: 21.948,41.368,95.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 1.953 |  Acc: 20.480,40.510,70.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.854 |  Acc: 21.722,41.790,95.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 1.957 |  Acc: 20.740,40.330,71.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.853 |  Acc: 21.880,41.840,95.690,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 1.958 |  Acc: 20.790,40.810,71.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.858 |  Acc: 21.790,41.876,95.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 1.947 |  Acc: 20.740,40.610,71.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.852 |  Acc: 22.016,41.764,95.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 1.953 |  Acc: 20.830,40.510,71.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.848 |  Acc: 22.008,41.830,95.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 1.979 |  Acc: 20.690,40.750,70.650,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.845 |  Acc: 21.794,41.802,95.836,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 1.949 |  Acc: 20.870,40.520,71.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.847 |  Acc: 21.976,41.998,95.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 1.971 |  Acc: 20.460,40.830,71.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.846 |  Acc: 21.858,41.844,95.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 1.982 |  Acc: 20.930,40.800,70.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.845 |  Acc: 21.936,41.872,95.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 1.940 |  Acc: 21.150,40.810,71.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.844 |  Acc: 21.872,41.858,95.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 1.959 |  Acc: 20.890,41.180,70.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.841 |  Acc: 21.974,42.132,95.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 1.974 |  Acc: 20.840,40.420,71.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.842 |  Acc: 22.012,42.012,95.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 2.020 |  Acc: 21.010,40.960,70.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.844 |  Acc: 22.004,41.986,95.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 2.009 |  Acc: 20.800,40.950,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.844 |  Acc: 22.098,41.920,95.800,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 1.966 |  Acc: 20.760,41.120,70.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.836 |  Acc: 21.992,42.094,96.092,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 1.986 |  Acc: 21.130,41.350,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.833 |  Acc: 22.278,42.248,96.168,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 1.980 |  Acc: 20.820,40.770,70.970,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.834 |  Acc: 21.904,42.210,96.272,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 1.981 |  Acc: 20.950,40.930,70.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.835 |  Acc: 22.072,42.260,96.068,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 1.978 |  Acc: 21.240,40.600,71.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.832 |  Acc: 21.984,42.298,96.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 2.016 |  Acc: 20.630,40.980,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.829 |  Acc: 22.136,42.338,96.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 2.025 |  Acc: 20.510,40.110,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.833 |  Acc: 22.062,42.388,96.094,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 1.996 |  Acc: 20.780,41.000,70.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.829 |  Acc: 22.178,42.440,96.188,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 1.994 |  Acc: 21.050,41.110,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.831 |  Acc: 22.242,42.178,96.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 1.978 |  Acc: 21.300,41.130,71.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.831 |  Acc: 22.200,42.334,96.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 2.007 |  Acc: 21.290,40.790,70.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.828 |  Acc: 22.140,42.496,96.152,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 1.988 |  Acc: 21.040,40.900,70.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.826 |  Acc: 22.086,42.534,96.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 2.011 |  Acc: 21.340,41.410,70.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.828 |  Acc: 22.188,42.642,96.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 1.985 |  Acc: 21.070,41.500,70.340,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.826 |  Acc: 22.172,42.378,96.248,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 1.991 |  Acc: 21.030,41.140,70.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.830 |  Acc: 22.094,42.290,96.046,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 1.981 |  Acc: 20.910,41.560,70.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.801 |  Acc: 22.398,43.076,96.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 1.935 |  Acc: 21.310,42.220,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.791 |  Acc: 22.230,42.856,97.358,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 1.942 |  Acc: 21.250,42.030,71.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.786 |  Acc: 22.322,42.956,97.502,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 1.934 |  Acc: 21.480,41.930,71.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.779 |  Acc: 22.406,43.150,97.726,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 1.936 |  Acc: 21.550,42.090,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.780 |  Acc: 22.476,42.900,97.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 1.935 |  Acc: 21.350,41.920,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.780 |  Acc: 22.364,43.018,97.738,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 1.937 |  Acc: 21.000,41.950,71.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.777 |  Acc: 22.474,42.950,97.814,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 1.940 |  Acc: 21.440,42.330,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.771 |  Acc: 22.472,43.346,97.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 1.939 |  Acc: 21.400,42.030,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.772 |  Acc: 22.410,43.302,97.994,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 1.948 |  Acc: 21.490,42.320,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.771 |  Acc: 22.292,43.388,97.958,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 1.937 |  Acc: 21.330,41.990,71.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.772 |  Acc: 22.492,43.276,97.916,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 1.954 |  Acc: 21.620,42.160,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.770 |  Acc: 22.502,43.382,98.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 1.942 |  Acc: 21.730,42.030,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.769 |  Acc: 22.384,43.202,98.062,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 1.946 |  Acc: 21.820,41.980,71.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.766 |  Acc: 22.604,43.418,98.238,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 1.949 |  Acc: 21.770,42.100,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.767 |  Acc: 22.592,43.410,98.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 1.964 |  Acc: 21.190,42.310,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.766 |  Acc: 22.612,43.616,98.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 1.946 |  Acc: 21.580,42.290,71.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.768 |  Acc: 22.400,43.448,98.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 1.946 |  Acc: 21.320,42.250,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.768 |  Acc: 22.540,43.110,98.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 1.955 |  Acc: 21.780,42.120,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.766 |  Acc: 22.438,43.210,98.170,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 1.955 |  Acc: 21.670,42.050,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.764 |  Acc: 22.460,43.264,98.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 1.956 |  Acc: 21.670,42.060,71.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.765 |  Acc: 22.444,43.266,98.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 1.958 |  Acc: 21.560,42.280,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.765 |  Acc: 22.462,43.394,98.196,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 1.956 |  Acc: 21.700,42.360,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.766 |  Acc: 22.404,43.356,98.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 1.959 |  Acc: 21.990,42.500,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.764 |  Acc: 22.426,43.506,98.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 1.952 |  Acc: 21.710,42.560,71.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.764 |  Acc: 22.524,43.680,98.182,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 1.965 |  Acc: 21.830,42.370,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.764 |  Acc: 22.478,43.508,98.180,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 1.950 |  Acc: 21.850,42.560,71.380,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.761 |  Acc: 22.686,43.686,98.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 1.967 |  Acc: 21.720,42.250,71.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.760 |  Acc: 22.610,43.630,98.332,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 1.963 |  Acc: 21.570,42.270,71.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.760 |  Acc: 22.600,43.426,98.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 1.957 |  Acc: 21.560,42.370,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.761 |  Acc: 22.608,43.464,98.268,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 1.955 |  Acc: 21.840,42.230,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.761 |  Acc: 22.522,43.530,98.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 1.962 |  Acc: 21.630,42.240,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.760 |  Acc: 22.334,43.548,98.344,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 1.961 |  Acc: 22.070,42.450,71.630,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.758 |  Acc: 22.638,43.598,98.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 1.956 |  Acc: 21.470,42.460,71.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.757 |  Acc: 22.390,43.454,98.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 1.968 |  Acc: 21.620,42.500,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.760 |  Acc: 22.546,43.524,98.340,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 1.965 |  Acc: 21.650,42.430,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.762 |  Acc: 22.562,43.476,98.284,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 1.970 |  Acc: 21.870,42.650,71.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.760 |  Acc: 22.418,43.672,98.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 1.967 |  Acc: 22.000,42.530,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.758 |  Acc: 22.676,43.760,98.256,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 1.964 |  Acc: 21.710,42.570,71.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.759 |  Acc: 22.504,43.504,98.350,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 1.979 |  Acc: 21.710,42.520,71.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.759 |  Acc: 22.550,43.472,98.288,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 1.965 |  Acc: 21.830,42.620,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.758 |  Acc: 22.704,43.660,98.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 1.965 |  Acc: 22.050,42.420,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.758 |  Acc: 22.578,43.612,98.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 1.954 |  Acc: 21.680,42.350,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.756 |  Acc: 22.538,43.532,98.442,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 1.962 |  Acc: 21.660,42.660,71.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.758 |  Acc: 22.446,43.716,98.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 1.972 |  Acc: 21.620,42.340,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.757 |  Acc: 22.538,43.514,98.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 1.962 |  Acc: 21.680,42.430,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.758 |  Acc: 22.514,43.458,98.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 1.966 |  Acc: 21.710,42.540,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.757 |  Acc: 22.632,43.688,98.376,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 1.957 |  Acc: 21.780,42.820,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.754 |  Acc: 22.686,43.698,98.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 1.963 |  Acc: 21.910,42.650,71.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.755 |  Acc: 22.832,43.666,98.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 1.962 |  Acc: 21.480,42.540,71.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.756 |  Acc: 22.452,43.710,98.466,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 1.962 |  Acc: 21.540,42.400,71.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.755 |  Acc: 22.570,43.560,98.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 1.955 |  Acc: 21.690,42.470,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.755 |  Acc: 22.532,43.678,98.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 1.958 |  Acc: 21.640,42.450,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.755 |  Acc: 22.652,43.920,98.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 1.963 |  Acc: 21.700,42.250,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.755 |  Acc: 22.634,43.552,98.474,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 1.954 |  Acc: 21.650,42.400,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.755 |  Acc: 22.570,43.642,98.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 1.961 |  Acc: 21.850,42.400,71.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.758 |  Acc: 22.564,43.624,98.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 1.965 |  Acc: 21.820,42.410,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.757 |  Acc: 22.678,43.610,98.362,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 1.968 |  Acc: 21.840,42.420,71.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.757 |  Acc: 22.622,43.528,98.396,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 1.973 |  Acc: 21.740,42.320,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.756 |  Acc: 22.438,43.530,98.398,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 1.960 |  Acc: 21.790,42.560,71.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.757 |  Acc: 22.560,43.610,98.456,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 1.960 |  Acc: 21.980,42.540,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.756 |  Acc: 22.538,43.600,98.390,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 1.961 |  Acc: 21.460,42.660,71.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.757 |  Acc: 22.612,43.540,98.430,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 1.961 |  Acc: 21.590,42.560,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.754 |  Acc: 22.404,43.740,98.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 1.964 |  Acc: 21.820,42.650,71.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.756 |  Acc: 22.674,43.782,98.392,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 1.957 |  Acc: 21.710,42.460,71.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.753 |  Acc: 22.586,43.524,98.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 1.960 |  Acc: 21.630,42.630,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.756 |  Acc: 22.718,43.738,98.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 1.967 |  Acc: 21.540,42.470,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.757 |  Acc: 22.672,43.550,98.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 1.957 |  Acc: 21.700,42.480,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.757 |  Acc: 22.526,43.520,98.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 1.965 |  Acc: 21.510,42.320,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.755 |  Acc: 22.734,43.556,98.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 1.956 |  Acc: 21.940,42.610,71.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.754 |  Acc: 22.554,43.584,98.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 1.962 |  Acc: 21.560,42.690,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.754 |  Acc: 22.814,43.706,98.510,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 1.964 |  Acc: 21.830,42.570,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.756 |  Acc: 22.640,43.708,98.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 1.959 |  Acc: 21.540,42.760,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.755 |  Acc: 22.510,43.720,98.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 1.957 |  Acc: 21.590,42.620,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.757 |  Acc: 22.650,43.740,98.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 1.967 |  Acc: 21.630,42.600,71.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=5, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.752 |  Acc: 22.518,43.528,98.576,% | Adaptive Acc:97.510% | clf_exit: 0.005 0.090 0.905
Testing: Epoch=299 | Loss: 1.963 |  Acc: 21.900,42.630,71.570,% | Adaptive Acc:70.270% | clf_exit: 0.015 0.163 0.822

circles: 0
Testing: Epoch=299 | Loss: 5.042 |  Acc: 1.470,1.000,11.880,% | Adaptive Acc:11.880% | clf_exit: 0.000 0.000 1.000
circles: 1
Testing: Epoch=299 | Loss: 3.974 |  Acc: 2.990,4.950,35.830,% | Adaptive Acc:35.870% | clf_exit: 0.001 0.000 1.000
circles: 2
Testing: Epoch=299 | Loss: 3.180 |  Acc: 3.790,6.430,52.270,% | Adaptive Acc:52.280% | clf_exit: 0.000 0.001 0.999
circles: 3
Testing: Epoch=299 | Loss: 2.537 |  Acc: 4.880,11.980,62.960,% | Adaptive Acc:63.000% | clf_exit: 0.001 0.003 0.997
circles: 4
Testing: Epoch=299 | Loss: 2.070 |  Acc: 11.740,32.020,69.710,% | Adaptive Acc:69.670% | clf_exit: 0.004 0.019 0.976
circles: 5
Testing: Epoch=299 | Loss: 1.963 |  Acc: 21.900,42.630,71.570,% | Adaptive Acc:70.270% | clf_exit: 0.015 0.163 0.822
