==> Preparing data..
Dataset: CIFAR100
Files already downloaded and verified
Files already downloaded and verified
==> Building model..
ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): ModuleList(
    (0): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (5): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (6): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (7): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (8): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
  )
  (classifiers): ModuleList(
    (0): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=16, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=16, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=132, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=132, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ClassifierModule(
      (relu): ReLU(inplace=True)
      (linear): Linear(in_features=164, out_features=100, bias=True)
      (b0): ParameterList(  (0): Parameter containing: [torch.FloatTensor of size 1x100])
      (linear_bw): Linear(in_features=100, out_features=164, bias=True)
      (BN1d): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)

Epoch: 0
Batch: 0 | Loss: 6.018 | Acc: 2.344,0.000,0.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.762 | Acc: 0.930,1.190,1.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.709 | Acc: 1.048,1.277,1.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.691 | Acc: 1.127,1.332,1.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.669 | Acc: 1.196,1.312,1.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.650 | Acc: 1.214,1.385,1.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.636 | Acc: 1.201,1.420,1.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.624 | Acc: 1.208,1.435,1.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.613 | Acc: 1.208,1.446,1.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.602 | Acc: 1.226,1.506,1.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.593 | Acc: 1.244,1.543,1.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.584 | Acc: 1.276,1.598,1.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.574 | Acc: 1.297,1.595,1.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.565 | Acc: 1.299,1.598,1.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.557 | Acc: 1.321,1.568,2.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.547 | Acc: 1.329,1.578,2.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.533 | Acc: 1.348,1.645,2.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.520 | Acc: 1.340,1.709,2.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.506 | Acc: 1.374,1.788,2.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.493 | Acc: 1.374,1.848,2.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.233 | Acc: 2.344,4.688,3.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.311 | Acc: 1.153,3.609,4.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.308 | Acc: 1.181,3.220,4.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.311 | Acc: 1.281,3.291,4.060,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 1
Batch: 0 | Loss: 5.180 | Acc: 3.125,4.688,6.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.203 | Acc: 1.079,2.865,4.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.185 | Acc: 1.181,3.258,4.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.176 | Acc: 1.281,3.291,4.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 5.169 | Acc: 1.341,3.463,4.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 5.160 | Acc: 1.269,3.527,4.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 5.157 | Acc: 1.291,3.422,4.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 5.149 | Acc: 1.341,3.336,4.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 5.141 | Acc: 1.393,3.319,4.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 5.138 | Acc: 1.515,3.289,4.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 5.130 | Acc: 1.594,3.370,5.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 5.123 | Acc: 1.623,3.408,5.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 5.121 | Acc: 1.627,3.433,5.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 5.113 | Acc: 1.661,3.472,5.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 5.104 | Acc: 1.688,3.528,5.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 5.098 | Acc: 1.703,3.579,5.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 5.091 | Acc: 1.738,3.614,5.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 5.083 | Acc: 1.766,3.661,5.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 5.075 | Acc: 1.781,3.722,5.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 5.068 | Acc: 1.780,3.732,5.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 5.136 | Acc: 1.562,3.906,4.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 5.105 | Acc: 1.749,3.683,6.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 5.096 | Acc: 1.524,3.449,6.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 5.101 | Acc: 1.524,3.599,6.429,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 2
Batch: 0 | Loss: 4.973 | Acc: 3.906,2.344,7.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.907 | Acc: 1.897,4.501,7.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.892 | Acc: 1.886,4.573,8.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.880 | Acc: 1.831,4.329,8.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.872 | Acc: 1.833,4.321,8.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.867 | Acc: 1.849,4.301,8.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.865 | Acc: 1.756,4.410,8.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.867 | Acc: 1.718,4.388,8.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.864 | Acc: 1.727,4.450,8.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.859 | Acc: 1.722,4.588,8.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.855 | Acc: 1.714,4.559,8.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.849 | Acc: 1.743,4.606,8.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.843 | Acc: 1.767,4.629,9.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.837 | Acc: 1.760,4.619,9.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.827 | Acc: 1.771,4.643,9.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.820 | Acc: 1.778,4.662,9.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.815 | Acc: 1.760,4.702,9.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.808 | Acc: 1.780,4.699,9.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.802 | Acc: 1.807,4.746,9.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.797 | Acc: 1.811,4.806,9.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.764 | Acc: 3.125,4.688,10.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.908 | Acc: 2.083,4.725,7.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.894 | Acc: 2.058,4.383,8.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.901 | Acc: 2.088,4.342,7.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 3
Batch: 0 | Loss: 4.747 | Acc: 0.781,6.250,8.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.698 | Acc: 1.786,4.799,10.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.677 | Acc: 1.867,5.297,11.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.693 | Acc: 1.934,5.264,10.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.684 | Acc: 2.006,5.430,11.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.669 | Acc: 2.073,5.654,11.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.666 | Acc: 2.169,5.746,11.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.663 | Acc: 2.266,5.768,11.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.654 | Acc: 2.407,5.896,11.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.647 | Acc: 2.421,5.931,11.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.642 | Acc: 2.488,5.912,11.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.641 | Acc: 2.496,5.946,11.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.633 | Acc: 2.496,6.013,11.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.625 | Acc: 2.493,6.061,12.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.619 | Acc: 2.497,6.114,12.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.610 | Acc: 2.536,6.227,12.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.608 | Acc: 2.563,6.204,12.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.605 | Acc: 2.593,6.227,12.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.601 | Acc: 2.632,6.246,12.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.598 | Acc: 2.647,6.262,12.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.549 | Acc: 1.562,7.031,14.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.600 | Acc: 1.079,7.887,13.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.574 | Acc: 1.239,7.031,13.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.582 | Acc: 1.153,6.967,13.243,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 4
Batch: 0 | Loss: 4.481 | Acc: 1.562,5.469,16.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.505 | Acc: 3.348,7.999,14.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.506 | Acc: 2.839,7.927,14.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.502 | Acc: 2.779,7.697,14.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.501 | Acc: 2.855,7.571,14.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.494 | Acc: 2.963,7.519,14.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.494 | Acc: 3.009,7.386,14.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.493 | Acc: 3.025,7.391,14.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.494 | Acc: 3.115,7.381,14.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.495 | Acc: 3.065,7.446,14.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.492 | Acc: 2.938,7.408,14.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.485 | Acc: 2.881,7.392,14.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.483 | Acc: 2.934,7.391,14.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.474 | Acc: 2.957,7.441,14.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.471 | Acc: 2.997,7.459,14.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.470 | Acc: 3.000,7.421,14.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.469 | Acc: 2.974,7.401,14.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.464 | Acc: 2.955,7.416,14.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.463 | Acc: 2.997,7.440,14.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.461 | Acc: 2.986,7.523,14.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.317 | Acc: 3.125,7.031,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.397 | Acc: 2.083,7.850,17.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.375 | Acc: 1.963,7.565,17.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.383 | Acc: 1.985,7.672,17.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 5
Batch: 0 | Loss: 4.309 | Acc: 3.906,3.125,18.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.437 | Acc: 3.534,6.585,15.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.408 | Acc: 3.582,7.146,15.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.389 | Acc: 3.522,7.403,15.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.374 | Acc: 3.530,7.668,16.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.374 | Acc: 3.643,8.060,16.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.368 | Acc: 3.603,8.284,16.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.364 | Acc: 3.546,8.245,16.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.359 | Acc: 3.576,8.303,16.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.354 | Acc: 3.604,8.292,16.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.351 | Acc: 3.623,8.155,16.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.349 | Acc: 3.662,8.180,16.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.347 | Acc: 3.650,8.211,16.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.343 | Acc: 3.679,8.282,16.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.338 | Acc: 3.703,8.324,16.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.338 | Acc: 3.693,8.280,16.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.336 | Acc: 3.721,8.277,16.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.328 | Acc: 3.714,8.349,16.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.326 | Acc: 3.703,8.347,16.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.323 | Acc: 3.707,8.352,17.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.278 | Acc: 3.906,10.156,15.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.455 | Acc: 2.641,6.548,16.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.419 | Acc: 2.744,6.517,16.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.434 | Acc: 2.574,6.468,16.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 6
Batch: 0 | Loss: 4.092 | Acc: 3.906,9.375,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.248 | Acc: 3.125,9.896,18.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.260 | Acc: 3.601,9.546,18.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.254 | Acc: 3.599,9.311,18.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.242 | Acc: 3.636,9.674,18.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.246 | Acc: 3.775,9.561,18.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.247 | Acc: 3.732,9.394,18.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.245 | Acc: 3.851,9.392,18.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.239 | Acc: 3.916,9.545,18.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.234 | Acc: 3.988,9.535,18.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.230 | Acc: 4.015,9.562,18.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.224 | Acc: 4.062,9.700,18.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.223 | Acc: 4.039,9.689,18.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.221 | Acc: 4.032,9.629,18.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.220 | Acc: 4.084,9.681,18.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.217 | Acc: 4.140,9.754,18.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.210 | Acc: 4.196,9.845,18.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.209 | Acc: 4.200,9.794,18.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.204 | Acc: 4.201,9.799,18.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.201 | Acc: 4.177,9.861,18.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.110 | Acc: 3.906,7.812,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.234 | Acc: 2.716,8.817,18.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.225 | Acc: 2.572,8.880,18.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.233 | Acc: 2.497,8.914,18.302,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 7
Batch: 0 | Loss: 4.290 | Acc: 3.125,4.688,13.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.148 | Acc: 5.208,10.454,19.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.143 | Acc: 4.745,9.566,19.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.136 | Acc: 4.508,9.964,19.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 4.133 | Acc: 4.591,9.973,19.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 4.118 | Acc: 4.587,10.156,20.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 4.111 | Acc: 4.552,10.395,20.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 4.114 | Acc: 4.449,10.322,20.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 4.111 | Acc: 4.503,10.350,20.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 4.106 | Acc: 4.584,10.350,20.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 4.104 | Acc: 4.614,10.467,20.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 4.099 | Acc: 4.589,10.527,20.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 4.096 | Acc: 4.568,10.655,20.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 4.093 | Acc: 4.616,10.680,20.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 4.093 | Acc: 4.632,10.648,20.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 4.091 | Acc: 4.576,10.696,20.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 4.090 | Acc: 4.576,10.699,20.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 4.085 | Acc: 4.559,10.782,20.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 4.086 | Acc: 4.560,10.769,20.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 4.083 | Acc: 4.567,10.780,20.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 4.165 | Acc: 1.562,9.375,20.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.215 | Acc: 3.348,10.305,18.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 4.174 | Acc: 3.201,10.232,19.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.175 | Acc: 3.227,9.939,19.647,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 8
Batch: 0 | Loss: 4.026 | Acc: 1.562,14.062,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.952 | Acc: 5.246,11.124,22.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.996 | Acc: 4.897,10.957,21.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.003 | Acc: 4.944,10.963,22.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.989 | Acc: 4.938,11.256,22.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.989 | Acc: 4.749,11.092,22.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.977 | Acc: 4.842,11.267,22.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.980 | Acc: 4.881,11.464,22.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.970 | Acc: 4.833,11.481,22.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.971 | Acc: 4.787,11.369,22.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.974 | Acc: 4.695,11.291,22.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.971 | Acc: 4.716,11.355,22.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.972 | Acc: 4.684,11.378,22.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.971 | Acc: 4.664,11.375,22.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.972 | Acc: 4.671,11.271,22.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.966 | Acc: 4.672,11.316,22.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.967 | Acc: 4.634,11.286,22.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.966 | Acc: 4.591,11.277,22.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.959 | Acc: 4.623,11.416,22.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.953 | Acc: 4.622,11.473,23.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.762 | Acc: 4.688,11.719,25.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.937 | Acc: 3.348,9.561,24.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.924 | Acc: 3.468,9.489,24.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.942 | Acc: 3.381,9.477,23.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 9
Batch: 0 | Loss: 3.999 | Acc: 3.906,10.156,24.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.865 | Acc: 4.613,11.161,23.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.854 | Acc: 4.707,11.928,24.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.855 | Acc: 4.649,11.744,24.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.851 | Acc: 4.659,11.709,25.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.857 | Acc: 4.626,11.796,25.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.844 | Acc: 4.616,11.887,25.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.848 | Acc: 4.521,11.885,25.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.849 | Acc: 4.576,12.054,25.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.842 | Acc: 4.545,12.133,25.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.843 | Acc: 4.602,12.298,25.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.844 | Acc: 4.589,12.334,25.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.841 | Acc: 4.720,12.400,25.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.836 | Acc: 4.759,12.488,25.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.829 | Acc: 4.793,12.439,25.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.828 | Acc: 4.755,12.404,25.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.825 | Acc: 4.785,12.444,25.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.823 | Acc: 4.770,12.456,25.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.817 | Acc: 4.802,12.511,25.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.815 | Acc: 4.819,12.549,25.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.895 | Acc: 7.031,14.062,22.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 4.010 | Acc: 3.013,11.049,22.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.995 | Acc: 3.258,10.461,23.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 4.005 | Acc: 3.151,10.118,22.631,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 10
Batch: 0 | Loss: 3.586 | Acc: 1.562,12.500,28.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.748 | Acc: 4.055,12.686,26.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.757 | Acc: 4.497,12.367,26.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.763 | Acc: 4.649,12.257,26.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.751 | Acc: 4.745,12.423,26.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.736 | Acc: 4.881,12.809,27.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.732 | Acc: 4.765,12.616,27.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.727 | Acc: 4.721,12.738,27.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.728 | Acc: 4.707,12.723,27.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.721 | Acc: 4.726,12.841,27.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.712 | Acc: 4.792,13.021,27.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.711 | Acc: 4.783,12.960,27.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.708 | Acc: 4.811,13.025,27.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.703 | Acc: 4.819,13.060,28.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.706 | Acc: 4.888,13.006,27.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.702 | Acc: 4.874,12.996,28.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.697 | Acc: 4.868,13.048,28.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.695 | Acc: 4.820,13.073,28.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.693 | Acc: 4.852,13.160,28.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.685 | Acc: 4.866,13.232,28.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.606 | Acc: 4.688,14.844,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.725 | Acc: 3.795,10.789,28.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.721 | Acc: 3.639,10.995,27.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.732 | Acc: 3.740,10.566,27.677,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 11
Batch: 0 | Loss: 3.482 | Acc: 3.906,15.625,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.548 | Acc: 5.097,12.686,30.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.555 | Acc: 5.259,13.377,29.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.564 | Acc: 5.033,13.499,30.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.562 | Acc: 5.112,13.503,30.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.558 | Acc: 5.074,13.521,29.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.557 | Acc: 5.114,13.772,30.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.555 | Acc: 5.147,13.785,30.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.560 | Acc: 5.119,13.859,30.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.557 | Acc: 5.188,14.002,30.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.550 | Acc: 5.189,13.989,30.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.549 | Acc: 5.207,13.960,30.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.553 | Acc: 5.248,13.968,30.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.549 | Acc: 5.256,14.062,30.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.547 | Acc: 5.277,14.115,30.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.546 | Acc: 5.259,14.174,30.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.546 | Acc: 5.218,14.209,30.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.545 | Acc: 5.187,14.198,30.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.546 | Acc: 5.187,14.188,30.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.545 | Acc: 5.171,14.167,30.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.546 | Acc: 5.469,7.031,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.679 | Acc: 5.022,11.347,29.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.677 | Acc: 4.726,11.414,29.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.698 | Acc: 4.764,11.258,28.701,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 12
Batch: 0 | Loss: 3.215 | Acc: 6.250,13.281,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.428 | Acc: 5.506,15.104,32.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.426 | Acc: 5.069,14.444,33.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.429 | Acc: 5.328,14.677,33.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.425 | Acc: 5.295,14.786,33.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.429 | Acc: 5.391,14.751,33.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.440 | Acc: 5.301,14.534,33.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.443 | Acc: 5.303,14.545,32.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.440 | Acc: 5.275,14.591,32.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.445 | Acc: 5.188,14.533,32.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.447 | Acc: 5.173,14.521,32.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.442 | Acc: 5.140,14.543,32.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.439 | Acc: 5.294,14.578,32.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.441 | Acc: 5.283,14.631,32.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.440 | Acc: 5.232,14.719,32.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.439 | Acc: 5.282,14.732,32.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.438 | Acc: 5.281,14.742,32.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.436 | Acc: 5.260,14.835,32.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.433 | Acc: 5.265,14.887,32.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.430 | Acc: 5.284,14.940,32.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.573 | Acc: 11.719,17.969,32.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.576 | Acc: 5.469,14.583,30.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.576 | Acc: 5.431,14.844,30.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.590 | Acc: 5.174,14.472,29.700,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 13
Batch: 0 | Loss: 3.156 | Acc: 7.031,20.312,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.372 | Acc: 5.915,14.955,34.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.349 | Acc: 5.850,16.159,35.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.346 | Acc: 5.443,15.907,35.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.361 | Acc: 5.334,15.480,34.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.352 | Acc: 5.469,15.486,34.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.348 | Acc: 5.546,15.470,34.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.354 | Acc: 5.591,15.475,34.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.355 | Acc: 5.634,15.407,34.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.353 | Acc: 5.611,15.349,34.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.350 | Acc: 5.558,15.267,34.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.346 | Acc: 5.501,15.254,34.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.345 | Acc: 5.482,15.217,34.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.341 | Acc: 5.526,15.314,34.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.337 | Acc: 5.533,15.414,34.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.335 | Acc: 5.528,15.368,34.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.335 | Acc: 5.571,15.401,34.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.332 | Acc: 5.570,15.400,34.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.329 | Acc: 5.575,15.441,34.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.328 | Acc: 5.577,15.453,34.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.526 | Acc: 5.469,13.281,30.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.455 | Acc: 4.688,12.165,31.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.482 | Acc: 4.497,12.462,30.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.485 | Acc: 4.547,12.282,31.186,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 14
Batch: 0 | Loss: 3.357 | Acc: 7.812,9.375,35.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.263 | Acc: 5.952,15.290,36.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.250 | Acc: 5.831,16.082,36.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.235 | Acc: 5.751,16.393,36.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.228 | Acc: 5.556,16.618,36.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.225 | Acc: 5.500,16.507,36.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.236 | Acc: 5.430,16.284,36.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.235 | Acc: 5.397,16.124,36.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.244 | Acc: 5.406,16.008,36.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.243 | Acc: 5.430,15.901,36.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.247 | Acc: 5.383,15.788,36.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.244 | Acc: 5.440,15.823,36.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.241 | Acc: 5.517,15.855,36.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.237 | Acc: 5.541,15.802,36.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.239 | Acc: 5.541,15.808,36.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.237 | Acc: 5.523,15.835,36.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.232 | Acc: 5.551,15.932,36.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.230 | Acc: 5.576,16.040,37.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.227 | Acc: 5.607,16.071,37.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.225 | Acc: 5.633,16.035,37.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.603 | Acc: 5.469,14.844,35.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.670 | Acc: 4.799,12.984,27.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.655 | Acc: 4.745,13.205,28.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.655 | Acc: 4.688,13.268,29.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 15
Batch: 0 | Loss: 3.250 | Acc: 3.906,13.281,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.208 | Acc: 6.138,16.555,36.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.187 | Acc: 6.136,17.435,38.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.166 | Acc: 6.071,17.226,38.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.177 | Acc: 6.125,17.101,38.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.171 | Acc: 6.026,16.886,38.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.162 | Acc: 5.927,16.813,38.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.145 | Acc: 5.829,16.988,38.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.146 | Acc: 5.876,16.974,38.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.140 | Acc: 5.900,17.123,38.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.138 | Acc: 5.966,17.016,38.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.141 | Acc: 5.957,17.018,38.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.143 | Acc: 5.903,17.003,38.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.146 | Acc: 5.882,16.972,38.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.146 | Acc: 5.919,16.985,38.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.144 | Acc: 5.931,17.024,38.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.140 | Acc: 5.912,17.022,38.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.139 | Acc: 5.888,16.995,38.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.136 | Acc: 5.837,17.032,38.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.135 | Acc: 5.844,17.046,38.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.304 | Acc: 8.594,14.062,36.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.397 | Acc: 4.799,15.551,34.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.389 | Acc: 5.240,15.511,34.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.395 | Acc: 5.251,15.702,34.810,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 16
Batch: 0 | Loss: 3.206 | Acc: 3.125,12.500,37.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.109 | Acc: 6.027,16.257,39.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.095 | Acc: 6.250,16.825,39.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.073 | Acc: 6.237,16.944,39.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 3.059 | Acc: 6.086,17.062,40.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 3.057 | Acc: 5.979,16.909,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 3.058 | Acc: 5.908,16.845,40.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 3.056 | Acc: 5.862,16.888,40.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 3.051 | Acc: 5.901,17.027,40.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 3.051 | Acc: 5.931,16.976,40.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 3.058 | Acc: 5.951,16.931,40.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 3.055 | Acc: 5.981,17.191,40.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 3.053 | Acc: 5.994,17.353,40.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 3.053 | Acc: 6.028,17.382,40.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 3.056 | Acc: 6.003,17.399,40.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 3.057 | Acc: 5.954,17.429,40.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 3.057 | Acc: 5.977,17.428,40.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 3.056 | Acc: 5.982,17.460,40.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 3.054 | Acc: 5.966,17.471,40.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 3.052 | Acc: 5.981,17.485,40.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.006 | Acc: 7.031,17.188,38.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.172 | Acc: 5.543,16.555,38.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.164 | Acc: 5.716,16.825,38.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.173 | Acc: 5.840,16.522,38.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 17
Batch: 0 | Loss: 2.965 | Acc: 8.594,16.406,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.961 | Acc: 5.915,17.262,41.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.960 | Acc: 5.507,17.111,42.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.956 | Acc: 5.379,17.559,42.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.958 | Acc: 5.517,17.544,42.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.955 | Acc: 5.623,17.512,42.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.954 | Acc: 5.740,17.510,42.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.955 | Acc: 5.785,17.675,42.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.949 | Acc: 5.799,17.716,42.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.954 | Acc: 5.797,17.511,42.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.951 | Acc: 5.846,17.541,42.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.957 | Acc: 5.847,17.520,42.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.957 | Acc: 5.932,17.619,42.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.961 | Acc: 5.996,17.657,42.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.958 | Acc: 6.028,17.755,42.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.961 | Acc: 6.022,17.748,42.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.964 | Acc: 6.046,17.740,42.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.965 | Acc: 6.062,17.710,42.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.967 | Acc: 6.018,17.651,42.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.966 | Acc: 6.024,17.696,42.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.007 | Acc: 8.594,16.406,43.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.052 | Acc: 5.766,15.290,40.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.046 | Acc: 5.945,15.758,40.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.054 | Acc: 6.019,15.676,40.881,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 18
Batch: 0 | Loss: 3.055 | Acc: 5.469,17.188,39.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.889 | Acc: 6.473,18.787,44.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.875 | Acc: 6.079,18.712,44.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.881 | Acc: 5.968,18.481,44.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.893 | Acc: 5.835,18.084,44.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.897 | Acc: 6.119,18.348,44.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.898 | Acc: 6.089,18.091,44.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.898 | Acc: 6.206,18.368,44.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.896 | Acc: 6.187,18.328,44.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.894 | Acc: 6.228,18.284,44.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.896 | Acc: 6.273,18.326,44.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.895 | Acc: 6.239,18.319,44.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.895 | Acc: 6.234,18.329,44.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.894 | Acc: 6.214,18.298,44.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.896 | Acc: 6.192,18.280,44.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.897 | Acc: 6.170,18.322,44.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.898 | Acc: 6.131,18.273,44.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.897 | Acc: 6.156,18.296,44.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.899 | Acc: 6.159,18.302,44.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.900 | Acc: 6.150,18.332,44.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.060 | Acc: 6.250,17.969,40.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.176 | Acc: 4.501,15.960,38.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.174 | Acc: 4.916,15.930,38.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.165 | Acc: 4.841,16.048,38.845,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 19
Batch: 0 | Loss: 2.576 | Acc: 7.031,18.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.852 | Acc: 7.106,18.155,44.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.826 | Acc: 6.726,18.445,45.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.819 | Acc: 6.493,18.519,46.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.827 | Acc: 6.356,18.364,45.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.823 | Acc: 6.498,18.402,45.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.819 | Acc: 6.476,18.376,45.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.811 | Acc: 6.582,18.534,46.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.810 | Acc: 6.595,18.731,46.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.812 | Acc: 6.518,18.797,46.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.812 | Acc: 6.534,18.979,46.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.812 | Acc: 6.480,19.022,46.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.814 | Acc: 6.445,18.980,46.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.815 | Acc: 6.486,18.966,45.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.815 | Acc: 6.422,19.086,45.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.818 | Acc: 6.429,19.010,45.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.817 | Acc: 6.450,19.066,45.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.817 | Acc: 6.413,19.073,45.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.817 | Acc: 6.404,19.090,45.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.819 | Acc: 6.418,19.035,45.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.027 | Acc: 7.812,22.656,46.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.066 | Acc: 5.097,16.257,41.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.071 | Acc: 5.316,16.425,40.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.085 | Acc: 5.161,16.317,40.241,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 20
Batch: 0 | Loss: 2.766 | Acc: 6.250,20.312,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.694 | Acc: 6.399,19.903,48.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.718 | Acc: 6.441,19.074,48.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.718 | Acc: 6.160,19.352,48.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.735 | Acc: 6.047,19.030,47.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.748 | Acc: 6.080,18.742,47.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.754 | Acc: 5.998,18.802,47.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.757 | Acc: 5.984,18.872,47.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.766 | Acc: 5.896,18.823,47.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.765 | Acc: 6.069,19.044,47.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.767 | Acc: 6.056,19.065,47.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.770 | Acc: 6.041,19.001,47.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.768 | Acc: 6.166,19.107,46.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.766 | Acc: 6.208,19.085,47.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.761 | Acc: 6.197,19.125,47.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.762 | Acc: 6.203,19.048,47.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.761 | Acc: 6.199,19.069,47.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.759 | Acc: 6.277,19.139,47.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.761 | Acc: 6.278,19.170,47.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.762 | Acc: 6.299,19.174,47.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 3.024 | Acc: 7.031,19.531,45.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 5.469,17.597,42.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.020 | Acc: 5.583,17.816,42.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.029 | Acc: 5.622,17.943,42.597,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 21
Batch: 0 | Loss: 2.694 | Acc: 4.688,21.094,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.669 | Acc: 6.473,19.531,47.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.702 | Acc: 6.631,19.245,47.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.685 | Acc: 6.660,19.429,48.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.694 | Acc: 6.761,19.522,48.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.691 | Acc: 6.660,19.175,48.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.694 | Acc: 6.676,19.092,48.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.702 | Acc: 6.483,18.988,48.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.697 | Acc: 6.400,19.114,48.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.697 | Acc: 6.341,19.203,48.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.700 | Acc: 6.289,19.244,48.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.700 | Acc: 6.328,19.344,48.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.702 | Acc: 6.273,19.363,48.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.704 | Acc: 6.220,19.420,48.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.699 | Acc: 6.219,19.453,48.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.699 | Acc: 6.198,19.485,48.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.701 | Acc: 6.228,19.616,48.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.700 | Acc: 6.252,19.680,48.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.701 | Acc: 6.235,19.590,48.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.699 | Acc: 6.246,19.570,48.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.960 | Acc: 7.812,16.406,42.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.124 | Acc: 5.506,16.369,40.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.146 | Acc: 5.488,16.616,39.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.132 | Acc: 5.725,16.662,40.151,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 22
Batch: 0 | Loss: 2.431 | Acc: 4.688,23.438,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.629 | Acc: 6.213,19.717,50.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.589 | Acc: 6.669,19.950,51.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.606 | Acc: 6.545,19.813,50.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.626 | Acc: 6.626,19.666,50.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.637 | Acc: 6.583,19.547,50.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.637 | Acc: 6.541,19.596,50.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.630 | Acc: 6.605,19.758,50.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.635 | Acc: 6.672,19.852,50.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.638 | Acc: 6.677,19.928,50.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.646 | Acc: 6.654,19.764,50.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.648 | Acc: 6.710,19.814,49.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.648 | Acc: 6.707,19.894,50.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.644 | Acc: 6.651,20.028,50.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.645 | Acc: 6.712,20.023,50.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.646 | Acc: 6.691,19.996,49.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.649 | Acc: 6.659,19.982,49.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.649 | Acc: 6.672,19.971,49.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.650 | Acc: 6.672,19.984,49.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.653 | Acc: 6.664,19.939,49.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.740 | Acc: 8.594,19.531,49.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 5.580,18.452,46.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.876 | Acc: 5.716,17.778,45.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.878 | Acc: 5.661,17.725,45.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 23
Batch: 0 | Loss: 2.453 | Acc: 8.594,25.781,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.599 | Acc: 6.808,20.833,52.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.585 | Acc: 6.612,20.389,51.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.584 | Acc: 6.814,20.441,51.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.584 | Acc: 7.060,20.583,51.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.589 | Acc: 6.900,20.258,51.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.587 | Acc: 6.838,20.287,51.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.589 | Acc: 6.810,20.373,51.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.594 | Acc: 6.750,20.332,51.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.597 | Acc: 6.755,20.395,50.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.602 | Acc: 6.751,20.363,50.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.599 | Acc: 6.745,20.404,50.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.599 | Acc: 6.772,20.484,50.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.600 | Acc: 6.771,20.516,50.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.601 | Acc: 6.828,20.568,50.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.601 | Acc: 6.834,20.533,50.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.606 | Acc: 6.866,20.515,50.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.603 | Acc: 6.910,20.532,50.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.602 | Acc: 6.917,20.602,51.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.604 | Acc: 6.916,20.602,50.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.649 | Acc: 8.594,18.750,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.892 | Acc: 6.696,18.713,46.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.880 | Acc: 6.764,19.055,46.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.884 | Acc: 6.609,18.981,45.889,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 24
Batch: 0 | Loss: 2.500 | Acc: 3.906,14.844,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.428 | Acc: 6.994,21.354,55.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.491 | Acc: 6.688,20.903,53.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.496 | Acc: 7.326,21.299,53.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.514 | Acc: 7.417,21.258,53.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.520 | Acc: 7.341,20.792,52.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.538 | Acc: 7.115,20.603,52.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.544 | Acc: 7.103,20.434,52.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.541 | Acc: 6.949,20.400,52.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.541 | Acc: 6.971,20.511,52.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.543 | Acc: 6.973,20.577,52.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.550 | Acc: 7.021,20.574,52.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.549 | Acc: 7.038,20.666,52.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.552 | Acc: 7.049,20.782,52.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.553 | Acc: 7.145,20.735,51.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.553 | Acc: 7.130,20.715,52.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.555 | Acc: 7.126,20.736,52.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.552 | Acc: 7.118,20.723,52.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.552 | Acc: 7.116,20.739,52.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.549 | Acc: 7.162,20.839,52.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.813 | Acc: 8.594,21.875,44.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.805 | Acc: 6.548,19.085,46.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.825 | Acc: 6.974,19.207,46.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.817 | Acc: 7.095,19.634,46.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 25
Batch: 0 | Loss: 2.514 | Acc: 7.031,16.406,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.487 | Acc: 6.808,21.243,53.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.496 | Acc: 6.784,20.884,53.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.496 | Acc: 6.980,20.953,53.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.496 | Acc: 7.147,20.833,53.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.504 | Acc: 7.263,20.924,53.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.509 | Acc: 7.373,20.848,53.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.507 | Acc: 7.380,20.889,53.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.511 | Acc: 7.400,21.026,53.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.511 | Acc: 7.437,21.003,53.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.516 | Acc: 7.443,20.845,53.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.514 | Acc: 7.530,20.747,53.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.514 | Acc: 7.469,20.770,53.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.516 | Acc: 7.528,20.905,53.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.517 | Acc: 7.534,20.930,53.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.517 | Acc: 7.504,20.946,53.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.520 | Acc: 7.501,20.916,53.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.520 | Acc: 7.508,20.940,53.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.522 | Acc: 7.486,20.875,53.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.518 | Acc: 7.507,20.946,53.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.636 | Acc: 9.375,17.188,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.743 | Acc: 6.659,18.713,49.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.762 | Acc: 7.203,19.055,48.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.766 | Acc: 7.134,18.955,48.348,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 26
Batch: 0 | Loss: 2.580 | Acc: 4.688,19.531,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.493 | Acc: 7.961,21.466,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 7.679,21.341,54.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.460 | Acc: 7.877,21.452,54.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.452 | Acc: 7.697,21.431,54.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.456 | Acc: 7.604,21.380,54.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.464 | Acc: 7.457,21.475,54.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.471 | Acc: 7.452,21.465,53.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.482 | Acc: 7.526,21.385,53.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.475 | Acc: 7.554,21.400,53.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.477 | Acc: 7.478,21.311,53.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.478 | Acc: 7.565,21.490,53.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.477 | Acc: 7.540,21.561,53.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.478 | Acc: 7.642,21.594,53.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.476 | Acc: 7.654,21.569,53.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.476 | Acc: 7.626,21.566,53.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.476 | Acc: 7.610,21.576,53.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.477 | Acc: 7.643,21.579,53.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.478 | Acc: 7.668,21.531,53.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.478 | Acc: 7.685,21.596,53.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.864 | Acc: 5.469,19.531,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.010 | Acc: 6.213,17.448,44.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.997 | Acc: 6.383,17.702,44.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.985 | Acc: 6.404,17.585,44.416,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 27
Batch: 0 | Loss: 2.340 | Acc: 10.156,23.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.328 | Acc: 7.961,22.731,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.366 | Acc: 7.965,22.370,56.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.390 | Acc: 7.800,22.426,55.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.405 | Acc: 7.735,21.962,55.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.422 | Acc: 7.758,21.867,55.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.423 | Acc: 7.832,21.798,55.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.423 | Acc: 7.790,21.836,55.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.427 | Acc: 7.832,21.924,55.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.430 | Acc: 7.804,21.866,55.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.430 | Acc: 7.847,21.937,55.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.429 | Acc: 7.904,21.833,55.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.433 | Acc: 7.942,21.719,55.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.434 | Acc: 7.830,21.656,55.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.434 | Acc: 7.818,21.692,55.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.432 | Acc: 7.836,21.680,55.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.434 | Acc: 7.803,21.680,55.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.432 | Acc: 7.810,21.781,55.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.431 | Acc: 7.823,21.851,55.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.432 | Acc: 7.880,21.820,54.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.819 | Acc: 7.031,21.875,48.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.815 | Acc: 6.808,16.369,47.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.816 | Acc: 7.546,16.654,47.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.812 | Acc: 7.492,16.726,47.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 28
Batch: 0 | Loss: 2.359 | Acc: 3.906,21.094,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.392 | Acc: 7.515,21.801,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.386 | Acc: 8.155,21.627,55.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.390 | Acc: 8.043,21.644,55.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.382 | Acc: 7.909,21.644,56.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.398 | Acc: 7.843,21.658,55.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.396 | Acc: 7.748,21.604,55.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.389 | Acc: 7.840,21.748,56.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.387 | Acc: 7.919,21.899,55.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.390 | Acc: 7.925,21.996,55.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.391 | Acc: 7.898,21.976,55.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.391 | Acc: 7.837,22.041,55.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.396 | Acc: 7.890,21.988,55.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.396 | Acc: 7.836,21.887,55.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.399 | Acc: 7.874,21.814,55.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.399 | Acc: 7.870,21.836,55.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.401 | Acc: 7.878,21.821,55.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.402 | Acc: 7.881,21.809,55.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.404 | Acc: 7.890,21.821,55.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.402 | Acc: 7.936,21.791,55.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.665 | Acc: 7.812,21.094,50.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.711 | Acc: 6.808,19.829,50.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.725 | Acc: 7.241,20.141,49.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.731 | Acc: 7.134,20.069,49.347,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 29
Batch: 0 | Loss: 2.421 | Acc: 7.812,25.000,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.305 | Acc: 8.036,22.061,56.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.304 | Acc: 7.851,22.294,58.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.330 | Acc: 7.684,21.990,57.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.342 | Acc: 7.880,22.058,57.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.349 | Acc: 7.882,21.999,57.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.359 | Acc: 8.051,22.133,56.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.360 | Acc: 8.001,22.036,56.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.357 | Acc: 8.118,22.064,56.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.361 | Acc: 8.041,22.086,56.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.365 | Acc: 8.073,22.116,56.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.363 | Acc: 8.109,22.218,56.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.364 | Acc: 8.120,22.361,56.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.366 | Acc: 8.088,22.336,56.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.365 | Acc: 8.102,22.320,56.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.366 | Acc: 8.038,22.282,56.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.368 | Acc: 8.070,22.233,56.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.368 | Acc: 8.092,22.239,56.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.365 | Acc: 8.122,22.234,56.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.364 | Acc: 8.163,22.267,56.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.676 | Acc: 8.594,18.750,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.850 | Acc: 6.436,16.369,47.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.856 | Acc: 6.612,16.997,47.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.850 | Acc: 6.647,17.072,47.503,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 30
Batch: 0 | Loss: 2.270 | Acc: 12.500,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.272 | Acc: 9.747,23.326,58.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.325 | Acc: 8.975,22.580,57.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.343 | Acc: 8.940,22.554,56.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.335 | Acc: 8.999,22.849,57.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.318 | Acc: 8.810,23.043,57.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.323 | Acc: 8.781,22.747,57.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.325 | Acc: 8.699,22.645,57.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.325 | Acc: 8.613,22.647,57.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.327 | Acc: 8.594,22.574,57.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.329 | Acc: 8.773,22.586,57.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.333 | Acc: 8.778,22.663,57.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.333 | Acc: 8.749,22.569,57.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.334 | Acc: 8.740,22.551,57.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.339 | Acc: 8.763,22.489,56.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.341 | Acc: 8.773,22.480,56.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.342 | Acc: 8.798,22.476,56.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.343 | Acc: 8.791,22.530,56.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.343 | Acc: 8.784,22.535,56.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.341 | Acc: 8.756,22.574,57.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.666 | Acc: 7.812,25.000,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.700 | Acc: 7.292,21.801,50.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.749 | Acc: 7.965,21.780,49.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.751 | Acc: 7.941,21.606,49.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 31
Batch: 0 | Loss: 2.078 | Acc: 11.719,25.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.270 | Acc: 9.115,22.991,57.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.287 | Acc: 9.013,22.485,58.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.276 | Acc: 9.503,22.823,58.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.270 | Acc: 9.568,22.733,58.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.276 | Acc: 9.228,22.672,58.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.271 | Acc: 9.013,22.689,58.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.276 | Acc: 8.987,22.579,58.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.281 | Acc: 8.997,22.608,58.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.285 | Acc: 8.939,22.768,58.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.285 | Acc: 8.955,22.940,58.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.287 | Acc: 8.944,22.865,58.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.289 | Acc: 8.944,22.903,58.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.292 | Acc: 9.064,22.959,58.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.294 | Acc: 9.125,23.032,58.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.298 | Acc: 9.095,22.913,58.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.299 | Acc: 9.117,22.868,58.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.302 | Acc: 9.107,22.904,58.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.301 | Acc: 9.148,22.938,58.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.301 | Acc: 9.166,22.915,58.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.619 | Acc: 11.719,21.875,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.584 | Acc: 7.440,21.466,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.616 | Acc: 7.489,21.113,52.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.620 | Acc: 7.403,21.081,51.870,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 32
Batch: 0 | Loss: 2.430 | Acc: 5.469,24.219,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.199 | Acc: 8.966,24.219,60.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.218 | Acc: 8.822,23.857,59.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.221 | Acc: 8.824,23.770,60.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.224 | Acc: 8.816,23.765,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.225 | Acc: 8.950,23.778,60.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.236 | Acc: 9.052,23.644,59.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.237 | Acc: 9.131,23.559,59.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.239 | Acc: 9.273,23.510,59.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.249 | Acc: 9.336,23.653,59.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.249 | Acc: 9.394,23.624,59.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.250 | Acc: 9.439,23.618,59.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.255 | Acc: 9.394,23.457,59.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.257 | Acc: 9.480,23.494,59.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.260 | Acc: 9.419,23.524,59.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.262 | Acc: 9.471,23.513,59.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.262 | Acc: 9.499,23.513,59.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.268 | Acc: 9.506,23.467,59.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.270 | Acc: 9.488,23.357,59.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.269 | Acc: 9.529,23.433,59.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.901 | Acc: 7.812,21.094,42.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.836 | Acc: 6.771,19.010,47.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.842 | Acc: 6.993,19.379,47.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.835 | Acc: 6.942,19.390,47.515,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 33
Batch: 0 | Loss: 2.176 | Acc: 10.938,27.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.193 | Acc: 9.524,23.103,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.210 | Acc: 9.546,22.885,60.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.188 | Acc: 9.734,23.309,60.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.194 | Acc: 9.616,23.206,60.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.188 | Acc: 9.561,23.337,60.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.193 | Acc: 9.666,23.379,60.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.200 | Acc: 9.840,23.504,60.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.204 | Acc: 9.904,23.549,60.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.209 | Acc: 9.958,23.450,60.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.214 | Acc: 9.931,23.434,60.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.217 | Acc: 9.895,23.388,60.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.219 | Acc: 9.907,23.418,59.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.222 | Acc: 9.884,23.270,59.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.226 | Acc: 9.900,23.235,59.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.231 | Acc: 9.886,23.175,59.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.232 | Acc: 9.854,23.133,59.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.235 | Acc: 9.824,23.121,59.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.239 | Acc: 9.860,23.139,59.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.239 | Acc: 9.857,23.150,59.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.876 | Acc: 4.688,18.750,50.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.945 | Acc: 5.543,16.778,45.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.970 | Acc: 5.583,16.616,45.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.965 | Acc: 5.635,16.752,45.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 34
Batch: 0 | Loss: 2.139 | Acc: 10.156,19.531,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.178 | Acc: 11.868,25.446,60.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.169 | Acc: 11.585,24.733,61.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.173 | Acc: 11.066,24.232,61.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.170 | Acc: 10.822,24.113,61.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.175 | Acc: 10.574,23.971,61.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.181 | Acc: 10.518,23.754,61.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.197 | Acc: 10.361,23.620,60.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.204 | Acc: 10.302,23.384,60.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.207 | Acc: 10.350,23.291,60.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.210 | Acc: 10.234,23.259,60.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.214 | Acc: 10.223,23.300,60.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.212 | Acc: 10.182,23.392,60.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.207 | Acc: 10.279,23.548,60.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.209 | Acc: 10.251,23.549,60.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.214 | Acc: 10.187,23.572,60.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.217 | Acc: 10.193,23.627,60.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.217 | Acc: 10.186,23.607,60.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.216 | Acc: 10.193,23.641,60.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.218 | Acc: 10.236,23.675,60.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.598 | Acc: 14.062,25.000,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.647 | Acc: 9.635,21.652,52.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.660 | Acc: 9.527,21.799,51.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.676 | Acc: 9.541,21.952,51.255,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 35
Batch: 0 | Loss: 2.220 | Acc: 8.594,17.188,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.198 | Acc: 10.379,23.103,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.183 | Acc: 10.442,23.190,61.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.176 | Acc: 10.284,23.297,61.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.162 | Acc: 10.571,23.553,61.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.161 | Acc: 10.907,23.747,61.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.168 | Acc: 10.892,23.889,61.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.176 | Acc: 10.893,23.637,61.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.179 | Acc: 10.748,23.700,61.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.172 | Acc: 10.812,23.852,61.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.169 | Acc: 10.899,24.094,61.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.169 | Acc: 10.856,24.106,61.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.174 | Acc: 10.899,23.930,61.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.175 | Acc: 10.923,24.054,61.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.178 | Acc: 10.926,24.032,61.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.183 | Acc: 10.927,23.977,61.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.188 | Acc: 10.884,24.017,60.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.190 | Acc: 10.880,23.997,60.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.195 | Acc: 10.868,23.942,60.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.197 | Acc: 10.853,23.915,60.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.891 | Acc: 6.250,12.500,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 3.025 | Acc: 6.324,14.918,44.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 3.022 | Acc: 6.307,14.539,44.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 3.035 | Acc: 6.391,14.306,44.518,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 36
Batch: 0 | Loss: 2.156 | Acc: 9.375,20.312,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.120 | Acc: 10.900,23.363,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.122 | Acc: 10.175,23.514,62.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.133 | Acc: 10.476,23.899,62.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.142 | Acc: 10.783,23.929,62.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.144 | Acc: 11.123,24.219,62.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.149 | Acc: 11.241,24.232,61.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.149 | Acc: 11.309,24.291,61.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.148 | Acc: 11.423,24.466,61.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.152 | Acc: 11.356,24.171,61.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.150 | Acc: 11.384,24.176,61.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.145 | Acc: 11.408,24.282,61.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.144 | Acc: 11.395,24.335,61.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.147 | Acc: 11.351,24.207,61.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.151 | Acc: 11.368,24.194,61.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.155 | Acc: 11.363,24.240,61.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.158 | Acc: 11.380,24.199,61.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.162 | Acc: 11.409,24.221,61.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.163 | Acc: 11.407,24.247,61.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.167 | Acc: 11.405,24.245,61.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.555 | Acc: 8.594,21.094,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.704 | Acc: 8.668,19.234,50.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.708 | Acc: 8.346,19.284,50.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.715 | Acc: 8.325,19.326,50.615,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 37
Batch: 0 | Loss: 2.112 | Acc: 8.594,24.219,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.139 | Acc: 11.830,25.521,61.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.124 | Acc: 11.986,24.486,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.121 | Acc: 11.834,24.526,61.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.130 | Acc: 11.748,24.470,61.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.132 | Acc: 11.556,24.466,61.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.139 | Acc: 11.628,24.387,61.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.142 | Acc: 11.591,24.346,61.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.141 | Acc: 11.665,24.389,61.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.141 | Acc: 11.481,24.322,61.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.143 | Acc: 11.478,24.242,61.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.147 | Acc: 11.447,24.201,61.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.147 | Acc: 11.411,24.228,61.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.144 | Acc: 11.479,24.312,61.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.143 | Acc: 11.505,24.327,61.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.144 | Acc: 11.537,24.349,61.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.144 | Acc: 11.582,24.377,61.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.150 | Acc: 11.606,24.375,61.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.151 | Acc: 11.624,24.450,61.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.151 | Acc: 11.684,24.471,61.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.432 | Acc: 10.938,23.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.500 | Acc: 10.938,21.763,55.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.507 | Acc: 10.861,21.932,54.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.541 | Acc: 10.822,21.696,53.753,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 38
Batch: 0 | Loss: 2.047 | Acc: 9.375,25.000,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.037 | Acc: 11.942,24.330,64.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.054 | Acc: 12.329,25.038,63.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.071 | Acc: 12.065,24.808,63.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.075 | Acc: 12.336,24.778,63.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.088 | Acc: 12.291,24.714,63.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.094 | Acc: 12.423,24.567,63.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.101 | Acc: 12.478,24.440,62.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.098 | Acc: 12.388,24.500,63.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.104 | Acc: 12.418,24.448,62.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.111 | Acc: 12.442,24.378,62.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.114 | Acc: 12.260,24.293,62.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.115 | Acc: 12.114,24.251,62.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.117 | Acc: 12.090,24.240,62.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.118 | Acc: 12.091,24.135,62.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.120 | Acc: 12.173,24.201,62.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.125 | Acc: 12.120,24.124,62.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.126 | Acc: 12.051,24.123,62.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.130 | Acc: 12.046,24.100,62.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.132 | Acc: 12.061,24.159,62.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.712 | Acc: 13.281,20.312,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.773 | Acc: 10.603,21.466,49.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.813 | Acc: 10.385,21.494,48.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.811 | Acc: 10.617,21.158,48.937,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 39
Batch: 0 | Loss: 2.244 | Acc: 6.250,27.344,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.055 | Acc: 11.905,24.107,64.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.069 | Acc: 11.623,24.085,64.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.062 | Acc: 11.911,24.462,64.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.059 | Acc: 12.230,24.556,64.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.079 | Acc: 12.214,24.505,63.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.076 | Acc: 12.035,24.677,63.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.084 | Acc: 12.090,24.895,63.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.082 | Acc: 12.214,24.908,63.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.081 | Acc: 12.241,25.009,63.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.082 | Acc: 12.205,24.860,63.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.083 | Acc: 12.217,24.968,63.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.091 | Acc: 12.276,24.942,63.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.097 | Acc: 12.410,24.967,63.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.101 | Acc: 12.397,24.981,63.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.104 | Acc: 12.381,24.865,63.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.107 | Acc: 12.332,24.861,63.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.108 | Acc: 12.317,24.879,63.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.106 | Acc: 12.372,24.877,63.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.106 | Acc: 12.354,24.826,62.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.584 | Acc: 10.156,25.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.513 | Acc: 10.342,23.512,55.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.544 | Acc: 10.442,22.847,53.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.560 | Acc: 10.105,22.656,53.548,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 40
Batch: 0 | Loss: 2.392 | Acc: 14.062,26.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.999 | Acc: 13.021,26.004,64.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.033 | Acc: 12.405,26.410,64.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.035 | Acc: 12.564,25.743,64.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.034 | Acc: 12.240,25.386,64.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.047 | Acc: 12.384,25.348,63.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.053 | Acc: 12.448,25.142,63.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.054 | Acc: 12.361,25.066,63.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.053 | Acc: 12.534,25.267,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.061 | Acc: 12.478,25.229,63.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.060 | Acc: 12.504,25.222,63.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.062 | Acc: 12.504,25.237,63.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.062 | Acc: 12.558,25.250,63.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.064 | Acc: 12.596,25.245,63.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.069 | Acc: 12.650,25.306,63.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.070 | Acc: 12.689,25.384,63.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.075 | Acc: 12.668,25.226,63.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.081 | Acc: 12.683,25.213,63.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.084 | Acc: 12.613,25.141,63.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.089 | Acc: 12.625,25.123,63.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.441 | Acc: 14.062,22.656,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.561 | Acc: 10.528,22.024,53.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.566 | Acc: 10.499,21.475,53.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.577 | Acc: 10.656,21.747,53.304,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 41
Batch: 0 | Loss: 1.987 | Acc: 10.156,27.344,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.057 | Acc: 12.760,25.000,64.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 12.900,24.962,65.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.033 | Acc: 12.884,24.462,64.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.028 | Acc: 13.050,24.836,64.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.033 | Acc: 12.910,24.722,64.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.027 | Acc: 12.874,24.748,64.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.032 | Acc: 12.783,24.895,64.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.040 | Acc: 12.903,25.049,64.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.052 | Acc: 12.906,25.004,64.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.055 | Acc: 12.951,24.984,63.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.056 | Acc: 13.044,25.074,63.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.057 | Acc: 13.071,25.117,63.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.058 | Acc: 13.090,25.180,63.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.061 | Acc: 13.064,25.158,63.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.063 | Acc: 13.055,25.169,63.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.066 | Acc: 13.043,25.046,63.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.069 | Acc: 13.027,24.929,63.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.072 | Acc: 13.143,25.024,63.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.076 | Acc: 13.150,24.959,63.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.377 | Acc: 10.938,28.125,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.468 | Acc: 10.156,21.429,54.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.481 | Acc: 10.880,21.399,54.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.489 | Acc: 10.925,21.798,54.521,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 42
Batch: 0 | Loss: 1.890 | Acc: 14.062,31.250,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.020 | Acc: 13.393,26.562,65.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.044 | Acc: 12.976,25.476,64.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.028 | Acc: 13.051,25.909,64.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 2.015 | Acc: 13.339,26.157,65.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 2.014 | Acc: 13.475,25.704,65.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 2.012 | Acc: 13.223,25.665,65.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.021 | Acc: 13.154,25.609,64.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.024 | Acc: 13.170,25.772,64.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.028 | Acc: 13.238,25.799,64.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.032 | Acc: 13.258,25.777,64.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.038 | Acc: 13.295,25.827,64.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.040 | Acc: 13.320,25.856,64.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.046 | Acc: 13.194,25.679,64.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.049 | Acc: 13.228,25.562,64.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.053 | Acc: 13.276,25.517,63.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.053 | Acc: 13.345,25.484,63.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.056 | Acc: 13.306,25.376,63.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.058 | Acc: 13.314,25.346,63.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.058 | Acc: 13.347,25.365,63.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.389 | Acc: 14.844,27.344,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.466 | Acc: 12.351,23.661,55.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.488 | Acc: 12.500,23.380,54.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.490 | Acc: 12.602,23.476,54.905,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 43
Batch: 0 | Loss: 1.953 | Acc: 6.250,17.969,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.001 | Acc: 13.951,25.967,64.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 14.120,26.524,65.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.980 | Acc: 13.870,26.921,65.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.975 | Acc: 13.513,26.427,66.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.981 | Acc: 13.513,26.346,66.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.990 | Acc: 13.636,26.065,65.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.002 | Acc: 13.597,26.020,65.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.000 | Acc: 13.514,26.072,65.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.005 | Acc: 13.622,26.083,65.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.009 | Acc: 13.717,26.294,65.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.018 | Acc: 13.663,26.138,65.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.022 | Acc: 13.615,25.995,65.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.024 | Acc: 13.563,25.841,64.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.029 | Acc: 13.468,25.676,64.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.029 | Acc: 13.554,25.685,64.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.030 | Acc: 13.632,25.774,64.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.036 | Acc: 13.623,25.671,64.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.039 | Acc: 13.545,25.563,64.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.040 | Acc: 13.533,25.498,64.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.359 | Acc: 10.156,25.000,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.442 | Acc: 10.417,22.210,56.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.458 | Acc: 10.766,22.332,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.456 | Acc: 10.912,22.272,55.213,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 44
Batch: 0 | Loss: 1.859 | Acc: 14.844,25.781,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 12.946,24.702,66.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.979 | Acc: 13.643,25.610,66.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.978 | Acc: 13.499,25.704,66.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.980 | Acc: 13.783,25.945,65.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.987 | Acc: 13.753,25.804,65.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.982 | Acc: 13.953,26.007,65.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.985 | Acc: 13.930,26.141,65.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.989 | Acc: 13.931,26.034,65.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.994 | Acc: 13.929,26.023,65.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.000 | Acc: 13.787,25.991,65.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.003 | Acc: 13.783,26.057,65.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.002 | Acc: 13.716,25.947,65.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.005 | Acc: 13.799,25.949,65.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.010 | Acc: 13.779,25.884,65.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.013 | Acc: 13.816,25.794,65.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.017 | Acc: 13.834,25.691,65.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.021 | Acc: 13.888,25.742,64.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.024 | Acc: 13.911,25.714,64.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.028 | Acc: 13.886,25.736,64.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.118 | Acc: 14.844,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.353 | Acc: 12.314,23.810,58.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.383 | Acc: 12.576,23.971,57.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.382 | Acc: 12.372,23.937,57.351,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 45
Batch: 0 | Loss: 2.122 | Acc: 17.188,30.469,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.979 | Acc: 13.467,25.074,66.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.958 | Acc: 14.139,25.915,66.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.960 | Acc: 14.434,26.153,66.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.983 | Acc: 14.323,26.032,66.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.997 | Acc: 14.062,25.982,65.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.997 | Acc: 13.966,25.788,65.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 2.005 | Acc: 13.891,25.526,65.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 2.005 | Acc: 13.873,25.495,65.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 2.004 | Acc: 13.920,25.488,65.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 2.001 | Acc: 13.923,25.575,65.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 2.004 | Acc: 13.865,25.491,65.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 2.008 | Acc: 13.845,25.477,65.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 2.008 | Acc: 13.865,25.515,65.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 2.006 | Acc: 13.937,25.637,65.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 2.008 | Acc: 14.091,25.737,65.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 2.009 | Acc: 14.145,25.776,65.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 2.008 | Acc: 14.134,25.829,65.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 2.010 | Acc: 14.130,25.816,65.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 2.010 | Acc: 14.136,25.839,65.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.168 | Acc: 14.062,27.344,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.352 | Acc: 12.165,24.554,57.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.396 | Acc: 12.252,24.219,56.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.406 | Acc: 12.295,23.988,56.288,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 46
Batch: 0 | Loss: 1.887 | Acc: 13.281,25.781,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 13.876,25.446,65.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.995 | Acc: 13.700,25.210,65.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.972 | Acc: 14.421,26.255,65.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.972 | Acc: 14.487,26.167,65.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.968 | Acc: 14.712,26.300,66.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.974 | Acc: 14.708,26.169,65.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.981 | Acc: 14.678,26.075,65.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.983 | Acc: 14.460,25.970,65.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.977 | Acc: 14.602,26.165,65.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.983 | Acc: 14.576,26.026,65.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.982 | Acc: 14.543,25.916,65.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.980 | Acc: 14.568,26.161,65.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.983 | Acc: 14.559,26.114,65.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.982 | Acc: 14.518,26.162,65.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.988 | Acc: 14.537,26.171,65.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.989 | Acc: 14.574,26.180,65.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.990 | Acc: 14.507,26.113,65.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.994 | Acc: 14.437,26.047,65.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.995 | Acc: 14.413,25.992,65.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.363 | Acc: 11.719,25.000,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.445 | Acc: 13.132,21.280,56.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.480 | Acc: 12.691,20.751,55.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.484 | Acc: 12.718,20.658,55.328,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 47
Batch: 0 | Loss: 1.913 | Acc: 18.750,30.469,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.927 | Acc: 14.695,25.335,68.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.944 | Acc: 14.062,24.943,67.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.946 | Acc: 14.549,25.564,67.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.957 | Acc: 14.265,25.502,67.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.968 | Acc: 13.954,25.232,66.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.961 | Acc: 14.179,25.542,66.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.966 | Acc: 14.229,25.626,66.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.965 | Acc: 14.378,25.752,66.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.959 | Acc: 14.542,25.967,66.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.963 | Acc: 14.572,25.902,66.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.962 | Acc: 14.589,25.848,66.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.963 | Acc: 14.571,25.843,66.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.965 | Acc: 14.643,25.910,66.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.968 | Acc: 14.588,25.917,66.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.966 | Acc: 14.613,25.945,66.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.966 | Acc: 14.654,25.947,66.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.969 | Acc: 14.635,25.960,66.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.968 | Acc: 14.677,26.039,66.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.970 | Acc: 14.653,26.062,66.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.427 | Acc: 11.719,27.344,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.494 | Acc: 11.793,23.958,54.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.497 | Acc: 11.928,24.219,54.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.500 | Acc: 11.744,24.296,54.790,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 48
Batch: 0 | Loss: 1.795 | Acc: 14.062,29.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.935 | Acc: 15.290,25.595,66.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.901 | Acc: 15.301,26.543,67.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.914 | Acc: 14.882,26.422,67.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.923 | Acc: 15.104,26.649,67.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.933 | Acc: 14.859,26.183,66.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.939 | Acc: 14.747,26.188,66.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.944 | Acc: 14.772,26.152,66.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.949 | Acc: 14.727,26.004,66.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.955 | Acc: 14.852,26.045,66.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.955 | Acc: 14.890,26.135,66.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.955 | Acc: 14.837,26.160,66.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.955 | Acc: 14.873,26.118,66.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.958 | Acc: 14.844,26.009,66.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.959 | Acc: 14.816,25.954,66.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.959 | Acc: 14.719,26.023,66.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.960 | Acc: 14.780,26.120,66.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.964 | Acc: 14.784,26.113,66.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.967 | Acc: 14.809,26.130,65.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.968 | Acc: 14.805,26.146,65.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.516 | Acc: 10.938,26.562,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.498 | Acc: 12.686,23.735,55.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.502 | Acc: 12.671,23.571,55.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.506 | Acc: 12.961,23.527,55.110,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 49
Batch: 0 | Loss: 2.284 | Acc: 13.281,17.969,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.903 | Acc: 14.323,25.707,68.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.902 | Acc: 14.520,26.524,68.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.900 | Acc: 14.434,26.050,67.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.897 | Acc: 14.583,26.215,67.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.897 | Acc: 14.612,26.230,68.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.918 | Acc: 14.489,26.046,67.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.917 | Acc: 14.583,26.097,67.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.918 | Acc: 14.504,26.058,67.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.919 | Acc: 14.632,26.101,67.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.925 | Acc: 14.692,26.112,67.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.934 | Acc: 14.667,26.022,66.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.934 | Acc: 14.837,26.047,66.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.935 | Acc: 14.916,26.170,66.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.935 | Acc: 14.847,26.093,66.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.935 | Acc: 14.890,26.095,66.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.939 | Acc: 14.851,26.105,66.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.944 | Acc: 14.812,26.127,66.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.946 | Acc: 14.764,26.128,66.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.950 | Acc: 14.836,26.128,66.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.229 | Acc: 13.281,21.875,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.397 | Acc: 13.021,20.796,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.418 | Acc: 12.671,20.713,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.427 | Acc: 12.859,20.530,56.698,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 50
Batch: 0 | Loss: 1.899 | Acc: 14.844,28.906,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.847 | Acc: 14.695,25.335,69.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.841 | Acc: 14.996,26.524,69.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.849 | Acc: 15.138,27.049,68.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.882 | Acc: 15.181,26.437,68.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.887 | Acc: 15.138,26.292,68.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.904 | Acc: 14.928,26.175,67.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.899 | Acc: 14.921,26.191,67.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.908 | Acc: 14.980,26.150,67.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.920 | Acc: 14.995,25.958,67.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.923 | Acc: 14.945,26.042,67.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.927 | Acc: 15.024,26.163,66.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.932 | Acc: 15.035,26.167,66.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.939 | Acc: 14.934,26.102,66.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.942 | Acc: 14.883,26.070,66.576,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.944 | Acc: 14.898,26.124,66.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.944 | Acc: 14.878,26.047,66.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.943 | Acc: 15.032,26.203,66.606,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.943 | Acc: 15.047,26.125,66.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.946 | Acc: 15.018,26.099,66.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.279 | Acc: 11.719,24.219,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.369 | Acc: 12.798,22.098,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.375 | Acc: 12.900,22.370,58.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.385 | Acc: 12.897,22.246,58.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 51
Batch: 0 | Loss: 1.849 | Acc: 13.281,28.906,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.888 | Acc: 14.397,25.930,66.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.880 | Acc: 14.729,26.639,67.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.892 | Acc: 14.754,26.742,67.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.892 | Acc: 14.680,26.948,67.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.891 | Acc: 14.983,27.251,67.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.897 | Acc: 15.057,27.157,67.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.903 | Acc: 15.148,26.867,67.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.902 | Acc: 15.193,26.902,67.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.901 | Acc: 15.159,26.809,67.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.903 | Acc: 15.139,26.718,67.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.908 | Acc: 15.201,26.711,67.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.914 | Acc: 15.116,26.585,67.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.922 | Acc: 15.170,26.515,67.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.923 | Acc: 15.208,26.510,67.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.924 | Acc: 15.212,26.526,67.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.928 | Acc: 15.236,26.516,67.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.933 | Acc: 15.194,26.457,67.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.939 | Acc: 15.162,26.392,66.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.940 | Acc: 15.188,26.333,66.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.598 | Acc: 14.844,25.000,47.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.592 | Acc: 12.798,20.164,54.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.621 | Acc: 12.595,19.627,53.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.631 | Acc: 12.961,19.659,53.471,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 52
Batch: 0 | Loss: 1.946 | Acc: 21.875,32.812,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.886 | Acc: 14.137,25.298,68.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 14.596,26.105,67.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.873 | Acc: 15.394,26.281,68.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.878 | Acc: 15.249,26.215,68.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.884 | Acc: 15.401,25.998,68.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.884 | Acc: 15.593,26.027,68.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.894 | Acc: 15.570,25.964,68.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.897 | Acc: 15.625,26.082,67.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.896 | Acc: 15.677,26.265,67.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.898 | Acc: 15.765,26.322,67.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.905 | Acc: 15.731,26.354,67.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.910 | Acc: 15.771,26.481,67.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.910 | Acc: 15.760,26.488,67.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.916 | Acc: 15.714,26.379,67.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.921 | Acc: 15.742,26.402,67.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.920 | Acc: 15.766,26.558,67.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.922 | Acc: 15.767,26.583,67.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.925 | Acc: 15.709,26.547,66.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.926 | Acc: 15.752,26.534,66.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.500 | Acc: 14.062,20.312,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.517 | Acc: 12.426,22.359,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.554 | Acc: 12.005,22.180,55.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.579 | Acc: 12.193,21.747,54.739,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 53
Batch: 0 | Loss: 1.907 | Acc: 10.938,23.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.810 | Acc: 16.146,26.637,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.821 | Acc: 15.873,27.153,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.827 | Acc: 15.881,27.216,69.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 15.972,27.228,69.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.836 | Acc: 16.081,26.942,69.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.845 | Acc: 15.993,26.976,69.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.859 | Acc: 15.769,26.718,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.864 | Acc: 15.771,26.805,68.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.872 | Acc: 16.013,26.878,68.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.879 | Acc: 15.971,26.951,68.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.878 | Acc: 15.947,27.047,68.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.883 | Acc: 15.985,27.104,67.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.887 | Acc: 15.939,26.958,67.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.892 | Acc: 15.870,26.866,67.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.896 | Acc: 15.900,26.915,67.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.899 | Acc: 15.924,26.908,67.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.899 | Acc: 15.914,26.851,67.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.904 | Acc: 15.928,26.783,67.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.907 | Acc: 15.916,26.776,67.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.422 | Acc: 13.281,25.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.540 | Acc: 15.104,23.289,55.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.516 | Acc: 14.920,23.457,55.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.538 | Acc: 14.908,23.361,54.867,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 54
Batch: 0 | Loss: 1.946 | Acc: 22.656,24.219,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.871 | Acc: 17.225,26.823,68.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.849 | Acc: 16.292,26.601,69.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 16.086,26.306,69.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.848 | Acc: 15.799,26.601,69.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.849 | Acc: 15.903,26.702,69.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.863 | Acc: 15.786,26.362,68.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.870 | Acc: 15.891,26.441,68.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.872 | Acc: 15.829,26.407,68.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.878 | Acc: 15.742,26.325,68.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.884 | Acc: 15.777,26.314,68.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.886 | Acc: 15.848,26.449,68.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.887 | Acc: 15.816,26.446,68.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.887 | Acc: 15.861,26.586,68.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.894 | Acc: 15.903,26.618,67.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.899 | Acc: 15.929,26.537,67.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.903 | Acc: 15.954,26.594,67.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.900 | Acc: 15.948,26.705,67.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.901 | Acc: 15.943,26.647,67.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.902 | Acc: 15.931,26.727,67.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.383 | Acc: 13.281,26.562,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.447 | Acc: 12.760,25.000,56.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.446 | Acc: 12.995,25.419,56.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.439 | Acc: 13.076,25.359,56.890,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 55
Batch: 0 | Loss: 1.753 | Acc: 17.969,32.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.804 | Acc: 16.034,26.972,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.825 | Acc: 15.949,27.363,69.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.849 | Acc: 16.073,26.960,69.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.845 | Acc: 16.165,26.804,69.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.842 | Acc: 16.058,26.702,69.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.853 | Acc: 15.967,26.646,68.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.857 | Acc: 15.913,26.635,68.733,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.861 | Acc: 15.814,26.737,68.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.867 | Acc: 15.854,26.821,68.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.869 | Acc: 15.928,26.741,68.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.867 | Acc: 15.989,26.891,68.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.868 | Acc: 16.011,26.909,68.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.874 | Acc: 15.936,26.838,68.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.878 | Acc: 15.914,26.857,68.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.884 | Acc: 15.877,26.866,68.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.885 | Acc: 15.932,26.872,68.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.887 | Acc: 15.953,26.833,68.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.886 | Acc: 15.932,26.840,68.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.891 | Acc: 15.928,26.868,67.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.357 | Acc: 14.844,26.562,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.516 | Acc: 14.435,22.954,55.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.513 | Acc: 14.215,22.447,55.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.519 | Acc: 14.229,22.208,55.482,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 56
Batch: 0 | Loss: 1.988 | Acc: 10.156,28.906,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.809 | Acc: 15.737,26.749,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.813 | Acc: 15.511,26.963,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.821 | Acc: 15.497,26.601,70.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.823 | Acc: 15.500,26.640,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.823 | Acc: 15.687,26.686,70.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.823 | Acc: 15.903,27.060,69.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.832 | Acc: 15.963,27.205,69.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.839 | Acc: 15.897,26.980,69.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.845 | Acc: 15.893,27.007,69.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.846 | Acc: 15.777,26.842,69.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.850 | Acc: 15.773,26.796,69.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.854 | Acc: 15.761,26.705,68.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.857 | Acc: 15.820,26.769,68.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.865 | Acc: 15.772,26.585,68.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.868 | Acc: 15.711,26.570,68.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.871 | Acc: 15.771,26.601,68.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.874 | Acc: 15.859,26.652,68.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.878 | Acc: 15.898,26.697,68.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.884 | Acc: 15.914,26.712,68.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.360 | Acc: 12.500,26.562,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.448 | Acc: 12.612,24.628,57.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.449 | Acc: 12.595,24.466,57.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.450 | Acc: 12.218,24.347,56.481,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 57
Batch: 0 | Loss: 1.836 | Acc: 17.188,21.875,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.825 | Acc: 16.629,26.860,69.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.821 | Acc: 15.796,26.963,69.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.825 | Acc: 16.163,27.241,69.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.824 | Acc: 16.339,27.151,69.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.818 | Acc: 16.337,27.150,70.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.825 | Acc: 16.451,27.273,70.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.833 | Acc: 16.290,27.067,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.842 | Acc: 16.110,26.907,69.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.848 | Acc: 16.160,26.973,69.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.853 | Acc: 16.080,26.908,69.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.854 | Acc: 16.145,26.799,69.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.858 | Acc: 16.215,26.841,68.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.859 | Acc: 16.170,26.814,68.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.858 | Acc: 16.264,26.904,68.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.861 | Acc: 16.248,26.778,68.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.862 | Acc: 16.233,26.772,68.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.865 | Acc: 16.225,26.776,68.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.868 | Acc: 16.253,26.794,68.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.873 | Acc: 16.263,26.813,68.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.550 | Acc: 16.406,25.781,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.477 | Acc: 15.141,24.405,57.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.527 | Acc: 15.682,24.104,55.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.555 | Acc: 15.958,24.142,55.520,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 58
Batch: 0 | Loss: 1.649 | Acc: 20.312,31.250,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.793 | Acc: 17.299,27.493,69.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.772 | Acc: 17.149,27.553,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.779 | Acc: 16.970,27.830,70.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.793 | Acc: 16.917,27.691,70.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.802 | Acc: 16.901,27.560,69.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.814 | Acc: 16.697,27.660,69.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.820 | Acc: 16.561,27.554,69.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.823 | Acc: 16.532,27.387,69.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.829 | Acc: 16.350,27.262,69.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.834 | Acc: 16.278,27.165,69.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.838 | Acc: 16.297,27.178,69.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.841 | Acc: 16.199,27.140,69.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.849 | Acc: 16.212,27.053,68.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.850 | Acc: 16.206,27.138,68.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.852 | Acc: 16.225,27.097,68.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.850 | Acc: 16.197,27.086,68.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.854 | Acc: 16.140,27.055,68.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.853 | Acc: 16.131,27.006,68.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.858 | Acc: 16.142,26.905,68.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.298 | Acc: 14.844,28.125,54.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.461 | Acc: 14.881,26.600,55.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.485 | Acc: 15.053,26.277,55.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.494 | Acc: 15.100,25.871,55.200,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 59
Batch: 0 | Loss: 1.898 | Acc: 17.969,26.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.806 | Acc: 18.192,26.897,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.787 | Acc: 17.511,27.611,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 16.995,27.587,70.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.801 | Acc: 16.995,28.000,70.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.804 | Acc: 16.925,28.024,70.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.807 | Acc: 17.078,27.918,69.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.816 | Acc: 16.772,27.610,69.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.820 | Acc: 16.697,27.417,69.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.831 | Acc: 16.613,27.314,69.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.830 | Acc: 16.636,27.270,69.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.831 | Acc: 16.463,27.238,69.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.834 | Acc: 16.377,27.298,69.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.835 | Acc: 16.442,27.230,69.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.841 | Acc: 16.420,27.166,68.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.843 | Acc: 16.385,27.196,68.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.846 | Acc: 16.389,27.242,68.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.848 | Acc: 16.349,27.206,68.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.853 | Acc: 16.298,27.238,68.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.855 | Acc: 16.246,27.184,68.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.265 | Acc: 11.719,28.125,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.291 | Acc: 13.802,23.996,59.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.283 | Acc: 13.396,24.181,59.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.310 | Acc: 13.525,24.270,59.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 60
Batch: 0 | Loss: 1.754 | Acc: 15.625,25.000,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.729 | Acc: 16.071,27.195,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.760 | Acc: 16.254,27.954,71.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.767 | Acc: 16.842,28.253,71.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.777 | Acc: 16.725,27.701,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.780 | Acc: 16.615,27.707,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.783 | Acc: 16.794,28.041,70.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.790 | Acc: 16.628,27.937,70.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.800 | Acc: 16.460,27.737,70.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.804 | Acc: 16.376,27.788,69.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.805 | Acc: 16.465,27.748,69.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.804 | Acc: 16.562,27.694,69.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.809 | Acc: 16.513,27.587,69.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.812 | Acc: 16.505,27.643,69.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.811 | Acc: 16.490,27.725,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.813 | Acc: 16.531,27.806,69.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.817 | Acc: 16.547,27.753,69.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.820 | Acc: 16.548,27.749,69.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.824 | Acc: 16.458,27.582,69.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.828 | Acc: 16.423,27.553,69.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.418 | Acc: 11.719,29.688,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.511 | Acc: 12.314,23.214,56.101,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.499 | Acc: 12.576,23.247,55.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.505 | Acc: 12.820,23.233,55.418,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 61
Batch: 0 | Loss: 1.765 | Acc: 20.312,38.281,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.795 | Acc: 16.927,28.720,69.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.808 | Acc: 16.902,27.801,69.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.792 | Acc: 17.111,27.894,69.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.798 | Acc: 16.917,27.749,69.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.799 | Acc: 17.102,27.808,69.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.802 | Acc: 16.761,27.731,69.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.807 | Acc: 16.783,27.615,69.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.808 | Acc: 16.693,27.562,69.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.806 | Acc: 16.812,27.706,69.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.808 | Acc: 16.857,27.612,69.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.810 | Acc: 16.876,27.556,69.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.813 | Acc: 16.808,27.587,69.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.816 | Acc: 16.762,27.526,69.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.820 | Acc: 16.743,27.474,69.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.822 | Acc: 16.731,27.479,69.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.826 | Acc: 16.742,27.521,69.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.833 | Acc: 16.642,27.431,69.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.836 | Acc: 16.644,27.400,69.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.839 | Acc: 16.667,27.465,69.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.350 | Acc: 14.844,29.688,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.322 | Acc: 15.923,25.967,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.324 | Acc: 15.396,25.838,59.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.355 | Acc: 15.471,25.307,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 62
Batch: 0 | Loss: 1.692 | Acc: 17.188,25.000,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.762 | Acc: 17.746,27.455,71.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.764 | Acc: 17.111,27.839,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.753 | Acc: 16.970,27.792,71.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.761 | Acc: 16.705,27.691,70.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.772 | Acc: 16.399,27.251,70.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.775 | Acc: 16.303,27.247,70.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.786 | Acc: 16.384,27.250,70.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.791 | Acc: 16.518,27.281,70.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.791 | Acc: 16.674,27.456,70.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.799 | Acc: 16.671,27.515,70.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.800 | Acc: 16.735,27.499,69.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.801 | Acc: 16.643,27.435,70.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.811 | Acc: 16.628,27.323,69.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.816 | Acc: 16.548,27.252,69.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.819 | Acc: 16.549,27.204,69.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.817 | Acc: 16.623,27.246,69.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.819 | Acc: 16.626,27.321,69.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.823 | Acc: 16.595,27.348,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.825 | Acc: 16.581,27.377,69.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.644 | Acc: 14.062,25.781,55.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.626 | Acc: 13.876,21.391,54.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.611 | Acc: 13.929,22.046,54.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.610 | Acc: 14.191,21.875,53.919,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 63
Batch: 0 | Loss: 1.838 | Acc: 15.625,26.562,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.781 | Acc: 16.481,26.935,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.772 | Acc: 17.035,27.210,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.765 | Acc: 17.239,27.830,71.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.772 | Acc: 17.052,27.730,70.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.782 | Acc: 16.785,27.630,70.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.782 | Acc: 16.826,27.783,70.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.788 | Acc: 16.744,27.665,70.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.797 | Acc: 16.591,27.446,70.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.799 | Acc: 16.752,27.573,70.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.800 | Acc: 16.682,27.600,70.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.800 | Acc: 16.647,27.521,70.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.800 | Acc: 16.620,27.541,70.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.802 | Acc: 16.478,27.520,69.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.806 | Acc: 16.545,27.630,69.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.810 | Acc: 16.567,27.590,69.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.813 | Acc: 16.530,27.551,69.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.818 | Acc: 16.539,27.653,69.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.819 | Acc: 16.610,27.735,69.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.820 | Acc: 16.632,27.619,69.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.187 | Acc: 15.625,28.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.387 | Acc: 12.798,22.879,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.366 | Acc: 12.652,22.580,58.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.361 | Acc: 12.666,22.221,58.760,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 64
Batch: 0 | Loss: 1.518 | Acc: 15.625,28.125,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.792 | Acc: 15.774,27.827,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.743 | Acc: 16.101,28.963,72.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.747 | Acc: 16.637,29.419,71.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.761 | Acc: 16.696,28.742,70.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.759 | Acc: 16.955,28.744,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.763 | Acc: 16.968,28.590,70.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.772 | Acc: 16.899,28.502,70.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.774 | Acc: 16.838,28.465,70.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.773 | Acc: 16.890,28.319,70.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.774 | Acc: 16.908,28.366,70.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.779 | Acc: 16.813,28.334,70.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.786 | Acc: 16.766,28.131,70.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.790 | Acc: 16.750,28.212,70.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.792 | Acc: 16.795,28.144,70.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.794 | Acc: 16.809,28.143,70.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.795 | Acc: 16.842,28.154,69.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.799 | Acc: 16.796,28.026,69.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.806 | Acc: 16.783,27.965,69.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.808 | Acc: 16.730,27.934,69.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.382 | Acc: 14.062,23.438,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.372 | Acc: 10.975,24.554,58.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.405 | Acc: 10.842,23.857,58.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.416 | Acc: 10.861,23.694,57.902,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 65
Batch: 0 | Loss: 1.658 | Acc: 15.625,25.000,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.746 | Acc: 17.522,27.790,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.730 | Acc: 17.969,28.011,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.736 | Acc: 17.982,28.099,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.751 | Acc: 17.747,28.135,71.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.764 | Acc: 17.350,27.684,70.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.773 | Acc: 17.536,27.705,70.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.777 | Acc: 17.664,27.787,70.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.784 | Acc: 17.547,27.766,70.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.785 | Acc: 17.477,27.754,70.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.787 | Acc: 17.370,27.740,70.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.791 | Acc: 17.403,27.782,70.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.794 | Acc: 17.369,27.736,70.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.791 | Acc: 17.358,27.769,70.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.791 | Acc: 17.335,27.683,70.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.792 | Acc: 17.221,27.705,69.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.795 | Acc: 17.136,27.689,69.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.796 | Acc: 17.098,27.660,69.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.797 | Acc: 17.064,27.632,69.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.799 | Acc: 17.042,27.590,69.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.213 | Acc: 18.750,27.344,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.363 | Acc: 14.100,26.302,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.363 | Acc: 14.520,25.743,58.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.361 | Acc: 14.229,25.679,58.274,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 66
Batch: 0 | Loss: 1.630 | Acc: 17.969,31.250,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.773 | Acc: 15.513,26.265,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.746 | Acc: 15.930,27.096,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.744 | Acc: 16.278,27.574,71.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.740 | Acc: 16.358,27.971,71.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.748 | Acc: 16.515,28.349,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.752 | Acc: 16.761,28.454,71.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.751 | Acc: 16.905,28.585,71.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.757 | Acc: 16.921,28.392,71.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.762 | Acc: 16.859,28.233,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.767 | Acc: 16.849,28.350,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.774 | Acc: 16.823,28.210,70.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.779 | Acc: 16.815,28.174,70.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.778 | Acc: 16.924,28.257,70.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.776 | Acc: 16.848,28.278,70.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.781 | Acc: 16.757,28.208,70.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.781 | Acc: 16.813,28.213,70.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.788 | Acc: 16.832,28.214,70.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.790 | Acc: 16.872,28.305,70.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.793 | Acc: 16.859,28.281,70.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.345 | Acc: 16.406,23.438,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.429 | Acc: 15.253,24.107,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.466 | Acc: 15.339,23.952,56.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.488 | Acc: 14.933,23.373,56.314,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 67
Batch: 0 | Loss: 1.835 | Acc: 14.062,22.656,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.698 | Acc: 16.406,27.604,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.707 | Acc: 17.168,28.544,72.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.718 | Acc: 16.778,28.279,72.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.729 | Acc: 17.062,28.356,71.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.734 | Acc: 17.273,28.357,71.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.748 | Acc: 17.091,28.286,71.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.754 | Acc: 17.138,28.103,71.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.757 | Acc: 16.979,28.067,71.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.764 | Acc: 16.963,27.901,70.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.765 | Acc: 16.978,27.989,70.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.768 | Acc: 16.951,28.037,70.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.774 | Acc: 16.948,28.025,70.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.777 | Acc: 16.921,27.990,70.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.780 | Acc: 16.998,28.011,70.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.782 | Acc: 17.107,28.039,70.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.784 | Acc: 17.083,28.086,70.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.787 | Acc: 16.997,28.049,70.216,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.788 | Acc: 17.049,28.097,70.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.788 | Acc: 17.021,28.164,70.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.360 | Acc: 14.844,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.417 | Acc: 14.286,22.731,57.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.434 | Acc: 14.120,22.828,56.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.448 | Acc: 14.306,23.169,56.442,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 68
Batch: 0 | Loss: 1.754 | Acc: 12.500,29.688,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.756 | Acc: 17.076,28.571,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.750 | Acc: 16.940,28.277,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.740 | Acc: 17.136,28.368,71.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.745 | Acc: 16.898,28.202,71.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.751 | Acc: 17.010,28.241,71.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.749 | Acc: 17.129,28.409,71.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.746 | Acc: 17.237,28.446,71.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.754 | Acc: 17.163,28.440,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.760 | Acc: 17.265,28.453,71.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.768 | Acc: 17.222,28.277,70.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.768 | Acc: 17.233,28.252,70.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.777 | Acc: 17.097,28.102,70.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.778 | Acc: 17.161,28.134,70.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.779 | Acc: 17.196,28.253,70.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.776 | Acc: 17.149,28.242,70.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.773 | Acc: 17.202,28.259,70.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.775 | Acc: 17.137,28.224,70.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.777 | Acc: 17.203,28.244,70.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.780 | Acc: 17.208,28.275,70.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.307 | Acc: 15.625,26.562,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.287 | Acc: 16.146,26.637,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.294 | Acc: 15.758,26.258,58.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.320 | Acc: 15.779,26.434,58.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 69
Batch: 0 | Loss: 1.669 | Acc: 16.406,30.469,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.718 | Acc: 17.150,28.943,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.718 | Acc: 17.188,28.963,72.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 17.111,28.753,71.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.743 | Acc: 17.101,28.414,71.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.738 | Acc: 16.940,28.481,71.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.735 | Acc: 16.936,28.280,71.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.745 | Acc: 16.766,28.053,71.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.751 | Acc: 16.760,28.106,71.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.757 | Acc: 16.795,28.112,70.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.760 | Acc: 16.884,28.172,70.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.756 | Acc: 16.954,28.242,70.974,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.757 | Acc: 16.964,28.294,70.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.756 | Acc: 16.999,28.134,71.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.758 | Acc: 16.998,28.103,71.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.762 | Acc: 17.019,28.081,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.764 | Acc: 17.032,28.106,70.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.766 | Acc: 17.110,28.127,70.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.770 | Acc: 17.049,28.123,70.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.773 | Acc: 17.058,28.109,70.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.504 | Acc: 8.594,20.312,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.559 | Acc: 9.784,18.118,54.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.598 | Acc: 9.566,17.511,53.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.584 | Acc: 9.721,17.802,54.047,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 70
Batch: 0 | Loss: 1.457 | Acc: 19.531,30.469,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.700 | Acc: 17.113,29.167,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.730 | Acc: 17.130,28.068,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.738 | Acc: 16.944,27.882,71.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.738 | Acc: 16.860,28.096,71.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.738 | Acc: 16.770,28.164,71.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.745 | Acc: 16.710,27.899,71.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.743 | Acc: 16.899,28.014,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.746 | Acc: 16.906,27.936,71.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.750 | Acc: 16.954,27.896,71.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.755 | Acc: 17.055,27.861,71.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.755 | Acc: 17.163,28.022,71.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.758 | Acc: 17.194,28.044,71.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.764 | Acc: 17.089,27.945,70.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.767 | Acc: 17.165,28.017,70.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.772 | Acc: 17.239,27.972,70.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.773 | Acc: 17.312,28.076,70.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.776 | Acc: 17.272,28.088,70.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.774 | Acc: 17.335,28.175,70.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.778 | Acc: 17.358,28.164,70.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.275 | Acc: 14.062,27.344,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.356 | Acc: 14.323,24.591,58.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.370 | Acc: 14.425,24.409,58.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.381 | Acc: 14.319,24.552,58.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 71
Batch: 0 | Loss: 1.469 | Acc: 17.969,36.719,82.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.690 | Acc: 17.597,28.162,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.686 | Acc: 17.207,28.182,72.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.680 | Acc: 17.687,28.765,73.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.690 | Acc: 17.612,28.627,72.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.713 | Acc: 17.373,28.473,72.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.723 | Acc: 17.239,28.190,71.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.724 | Acc: 17.332,28.369,71.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.729 | Acc: 17.440,28.503,71.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.730 | Acc: 17.412,28.552,71.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.733 | Acc: 17.502,28.595,71.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.738 | Acc: 17.463,28.602,71.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.738 | Acc: 17.470,28.543,71.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.742 | Acc: 17.553,28.640,71.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.744 | Acc: 17.516,28.567,71.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.745 | Acc: 17.569,28.590,71.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.747 | Acc: 17.613,28.614,71.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.750 | Acc: 17.600,28.611,71.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.752 | Acc: 17.597,28.558,71.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.754 | Acc: 17.573,28.549,71.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.169 | Acc: 18.750,23.438,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.364 | Acc: 15.774,26.265,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.390 | Acc: 15.587,26.105,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.406 | Acc: 15.702,25.615,58.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 72
Batch: 0 | Loss: 1.746 | Acc: 21.094,32.812,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.724 | Acc: 17.932,28.125,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.739 | Acc: 17.264,27.630,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.734 | Acc: 17.469,28.445,71.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.736 | Acc: 16.995,27.836,70.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.742 | Acc: 17.017,27.870,71.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.741 | Acc: 17.045,27.957,71.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.738 | Acc: 17.038,28.009,71.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.742 | Acc: 17.013,28.023,71.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.742 | Acc: 17.205,28.034,71.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.749 | Acc: 17.203,28.117,70.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.751 | Acc: 17.325,28.220,70.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.752 | Acc: 17.337,28.206,70.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.751 | Acc: 17.406,28.341,70.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.753 | Acc: 17.479,28.342,70.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.754 | Acc: 17.509,28.320,70.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.754 | Acc: 17.521,28.378,70.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.756 | Acc: 17.598,28.462,70.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.757 | Acc: 17.616,28.450,70.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.759 | Acc: 17.608,28.424,70.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.274 | Acc: 21.875,27.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.385 | Acc: 14.769,25.744,58.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.407 | Acc: 14.539,25.267,57.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.430 | Acc: 14.677,25.461,57.147,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 73
Batch: 0 | Loss: 1.569 | Acc: 10.938,25.000,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.638 | Acc: 16.964,28.348,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.663 | Acc: 16.768,28.544,73.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.688 | Acc: 17.264,28.791,72.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.701 | Acc: 17.342,28.665,72.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.711 | Acc: 17.489,28.713,72.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.717 | Acc: 17.549,28.680,71.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.724 | Acc: 17.675,28.602,71.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.728 | Acc: 17.833,28.702,71.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.728 | Acc: 17.736,28.673,71.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.731 | Acc: 17.879,28.817,71.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.735 | Acc: 17.993,28.786,71.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.737 | Acc: 17.884,28.764,71.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.740 | Acc: 17.897,28.772,71.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.745 | Acc: 17.883,28.717,71.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.745 | Acc: 17.834,28.712,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.745 | Acc: 17.920,28.806,71.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.747 | Acc: 17.831,28.718,71.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.748 | Acc: 17.811,28.718,71.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.748 | Acc: 17.827,28.738,71.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.126 | Acc: 13.281,28.125,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.318 | Acc: 14.807,25.149,59.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.342 | Acc: 15.072,24.695,58.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.357 | Acc: 15.177,24.347,59.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 74
Batch: 0 | Loss: 1.699 | Acc: 14.844,25.000,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.669 | Acc: 18.713,29.501,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 18.350,28.925,72.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.697 | Acc: 18.417,28.919,72.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.702 | Acc: 18.181,28.646,72.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.699 | Acc: 18.077,28.837,71.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.706 | Acc: 17.975,28.842,71.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.712 | Acc: 17.852,28.807,71.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.712 | Acc: 17.794,28.727,71.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.724 | Acc: 17.857,28.565,71.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.729 | Acc: 17.743,28.556,71.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.737 | Acc: 17.679,28.447,71.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.740 | Acc: 17.758,28.465,71.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.743 | Acc: 17.729,28.358,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.746 | Acc: 17.719,28.392,70.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.748 | Acc: 17.727,28.413,70.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.751 | Acc: 17.665,28.334,70.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.752 | Acc: 17.671,28.322,70.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.752 | Acc: 17.709,28.380,70.758,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.754 | Acc: 17.755,28.437,70.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.268 | Acc: 17.188,25.781,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.414 | Acc: 16.034,26.190,56.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.448 | Acc: 15.663,25.457,56.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.447 | Acc: 15.996,25.768,56.327,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 75
Batch: 0 | Loss: 1.954 | Acc: 14.062,21.094,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.681 | Acc: 17.746,29.241,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.683 | Acc: 17.854,29.002,72.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.672 | Acc: 18.007,29.265,72.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.684 | Acc: 17.901,29.012,72.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.687 | Acc: 17.961,28.837,72.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.693 | Acc: 17.807,28.816,72.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.692 | Acc: 17.852,28.989,72.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.692 | Acc: 17.663,28.858,72.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.702 | Acc: 17.615,28.729,72.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.701 | Acc: 17.751,28.829,72.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.711 | Acc: 17.633,28.715,72.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.712 | Acc: 17.709,28.744,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.715 | Acc: 17.690,28.691,71.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.717 | Acc: 17.668,28.675,71.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.722 | Acc: 17.577,28.613,71.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.725 | Acc: 17.628,28.653,71.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.730 | Acc: 17.600,28.542,71.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.731 | Acc: 17.644,28.601,71.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.733 | Acc: 17.762,28.677,71.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.458 | Acc: 14.844,28.906,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.390 | Acc: 15.402,27.976,57.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.372 | Acc: 15.015,27.477,57.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.377 | Acc: 14.985,27.216,57.838,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 76
Batch: 0 | Loss: 1.753 | Acc: 18.750,21.875,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.652 | Acc: 17.671,28.609,74.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.653 | Acc: 18.102,28.716,73.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 18.251,29.547,73.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.660 | Acc: 18.248,29.147,73.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.675 | Acc: 18.294,28.976,72.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.682 | Acc: 18.279,28.984,72.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.686 | Acc: 18.318,29.150,72.634,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.691 | Acc: 18.119,29.100,72.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.695 | Acc: 18.223,29.066,72.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.696 | Acc: 18.140,29.120,72.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.696 | Acc: 18.160,29.249,72.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.702 | Acc: 18.085,29.110,72.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.705 | Acc: 18.097,29.179,72.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.710 | Acc: 17.997,29.095,72.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.714 | Acc: 18.005,29.109,71.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.717 | Acc: 17.988,29.081,71.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.718 | Acc: 18.005,29.090,71.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.721 | Acc: 17.995,29.172,71.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.725 | Acc: 17.967,29.197,71.662,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.333 | Acc: 12.500,30.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.401 | Acc: 11.533,22.768,58.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.423 | Acc: 11.814,22.732,57.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.447 | Acc: 11.591,22.951,57.236,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 77
Batch: 0 | Loss: 2.096 | Acc: 11.719,21.094,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.712 | Acc: 16.667,27.158,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.711 | Acc: 16.978,27.801,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.696 | Acc: 17.636,28.266,72.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.699 | Acc: 17.593,28.250,72.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.694 | Acc: 17.520,28.373,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.694 | Acc: 17.627,28.532,72.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.695 | Acc: 17.586,28.563,72.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.693 | Acc: 17.663,28.722,72.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.698 | Acc: 17.598,28.626,72.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.705 | Acc: 17.553,28.572,72.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.708 | Acc: 17.605,28.652,72.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.711 | Acc: 17.538,28.702,72.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.715 | Acc: 17.645,28.691,71.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.717 | Acc: 17.721,28.751,71.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.721 | Acc: 17.662,28.763,71.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.724 | Acc: 17.699,28.746,71.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.726 | Acc: 17.747,28.750,71.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.725 | Acc: 17.793,28.789,71.680,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.727 | Acc: 17.850,28.871,71.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.303 | Acc: 17.969,29.688,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.483 | Acc: 15.513,25.818,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.474 | Acc: 15.625,25.553,56.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.479 | Acc: 15.587,25.794,56.301,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 78
Batch: 0 | Loss: 1.690 | Acc: 17.969,32.812,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.636 | Acc: 19.308,29.911,73.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.631 | Acc: 19.207,30.240,73.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.641 | Acc: 18.007,29.470,73.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.649 | Acc: 17.747,29.417,73.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.660 | Acc: 17.683,29.308,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 17.782,29.642,73.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.672 | Acc: 17.780,29.621,72.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.673 | Acc: 17.969,29.518,72.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.677 | Acc: 17.891,29.316,72.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.679 | Acc: 17.872,29.318,72.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.687 | Acc: 17.856,29.235,72.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.689 | Acc: 17.846,29.192,72.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.691 | Acc: 17.915,29.209,72.333,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.698 | Acc: 17.849,29.131,72.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 17.792,29.062,71.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.705 | Acc: 17.779,29.154,71.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.707 | Acc: 17.907,29.197,71.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.708 | Acc: 17.951,29.259,71.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.711 | Acc: 17.917,29.179,71.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.267 | Acc: 17.969,31.250,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.423 | Acc: 16.257,27.530,58.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.412 | Acc: 16.197,27.020,57.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.431 | Acc: 16.304,27.203,57.249,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 79
Batch: 0 | Loss: 1.643 | Acc: 16.406,29.688,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.667 | Acc: 18.118,30.432,73.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.662 | Acc: 18.655,30.126,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.663 | Acc: 18.519,29.688,73.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.674 | Acc: 18.432,29.678,73.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.678 | Acc: 18.178,29.641,73.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.676 | Acc: 18.175,29.436,73.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.683 | Acc: 18.157,29.233,72.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.685 | Acc: 18.134,29.227,72.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.691 | Acc: 17.951,29.148,72.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.694 | Acc: 17.996,29.345,72.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.701 | Acc: 17.866,29.256,72.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.703 | Acc: 17.839,29.269,72.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.709 | Acc: 17.765,29.218,72.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.709 | Acc: 17.766,29.218,72.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.712 | Acc: 17.746,29.168,71.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.714 | Acc: 17.706,29.023,71.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.719 | Acc: 17.669,29.039,71.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.720 | Acc: 17.694,29.049,71.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.723 | Acc: 17.758,29.060,71.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.114 | Acc: 16.406,34.375,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.259 | Acc: 15.513,26.897,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.287 | Acc: 15.587,26.353,59.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.309 | Acc: 15.574,26.498,59.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 80
Batch: 0 | Loss: 1.694 | Acc: 11.719,27.344,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.669 | Acc: 17.522,27.679,73.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.675 | Acc: 18.083,28.792,73.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.679 | Acc: 17.713,28.496,73.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.676 | Acc: 17.901,29.022,73.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.676 | Acc: 17.992,29.401,73.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.674 | Acc: 17.885,29.474,73.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.681 | Acc: 17.863,29.255,73.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.685 | Acc: 17.857,29.076,73.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.686 | Acc: 17.835,28.997,73.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.693 | Acc: 17.875,29.019,72.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.694 | Acc: 17.976,29.055,72.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.695 | Acc: 18.001,29.107,72.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.702 | Acc: 17.933,29.083,72.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.704 | Acc: 18.010,29.148,72.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.706 | Acc: 18.060,29.114,72.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.706 | Acc: 18.064,29.062,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.709 | Acc: 18.065,29.083,72.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.711 | Acc: 18.060,29.073,72.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 18.055,29.060,72.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.348 | Acc: 19.531,28.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.373 | Acc: 15.774,27.083,58.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.386 | Acc: 15.415,26.696,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.410 | Acc: 15.420,26.588,57.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 81
Batch: 0 | Loss: 1.922 | Acc: 16.406,30.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.685 | Acc: 17.634,28.757,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.679 | Acc: 17.359,28.754,73.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.678 | Acc: 17.802,29.265,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.681 | Acc: 17.940,29.244,72.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.680 | Acc: 17.768,29.007,72.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.687 | Acc: 17.982,29.165,72.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.688 | Acc: 18.207,29.388,72.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.689 | Acc: 18.265,29.576,72.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.688 | Acc: 18.202,29.502,72.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.697 | Acc: 18.097,29.338,72.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.700 | Acc: 18.004,29.249,72.419,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.699 | Acc: 17.933,29.250,72.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.701 | Acc: 17.909,29.227,72.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.702 | Acc: 18.044,29.384,72.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 17.961,29.358,72.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.705 | Acc: 17.978,29.313,72.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.707 | Acc: 18.024,29.452,72.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.707 | Acc: 17.993,29.469,72.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.710 | Acc: 17.987,29.423,72.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.205 | Acc: 11.719,31.250,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.447 | Acc: 13.132,25.595,57.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.437 | Acc: 13.014,25.171,57.336,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.438 | Acc: 13.076,25.205,57.198,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 82
Batch: 0 | Loss: 1.399 | Acc: 14.844,33.594,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.644 | Acc: 18.564,30.022,73.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.629 | Acc: 18.426,30.107,74.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.636 | Acc: 18.391,29.649,74.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.630 | Acc: 18.856,29.880,74.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.639 | Acc: 18.843,30.183,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.650 | Acc: 18.582,30.056,74.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.658 | Acc: 18.595,30.153,73.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 18.638,30.148,73.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.673 | Acc: 18.711,30.214,73.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.681 | Acc: 18.595,29.995,73.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.690 | Acc: 18.506,29.871,72.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.694 | Acc: 18.380,29.642,72.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.700 | Acc: 18.304,29.475,72.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.701 | Acc: 18.358,29.346,72.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.705 | Acc: 18.311,29.322,72.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.707 | Acc: 18.244,29.313,72.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.706 | Acc: 18.228,29.289,72.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.707 | Acc: 18.237,29.350,72.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.713 | Acc: 18.213,29.329,72.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.576 | Acc: 19.531,26.562,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.574 | Acc: 15.737,25.074,54.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.597 | Acc: 15.320,24.314,54.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.614 | Acc: 15.625,24.168,53.970,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 83
Batch: 0 | Loss: 1.900 | Acc: 16.406,28.125,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.648 | Acc: 18.341,30.655,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.640 | Acc: 18.312,30.297,74.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.641 | Acc: 17.879,29.867,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.635 | Acc: 18.171,29.784,74.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.641 | Acc: 18.417,29.889,73.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.645 | Acc: 18.414,29.823,73.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.648 | Acc: 18.445,29.887,73.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.652 | Acc: 18.255,30.008,73.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.658 | Acc: 18.154,30.067,73.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.661 | Acc: 18.148,30.014,73.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.665 | Acc: 18.174,30.115,73.176,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.672 | Acc: 18.215,30.112,73.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.675 | Acc: 18.097,30.029,72.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.677 | Acc: 18.066,29.902,72.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.678 | Acc: 18.093,29.947,72.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.681 | Acc: 18.049,29.938,72.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.685 | Acc: 18.058,29.960,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.687 | Acc: 18.105,29.936,72.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.690 | Acc: 18.094,29.907,72.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.605 | Acc: 13.281,22.656,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.615 | Acc: 12.202,22.135,53.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.633 | Acc: 11.890,21.322,52.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.658 | Acc: 12.103,21.235,52.997,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 84
Batch: 0 | Loss: 1.677 | Acc: 20.312,29.688,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.663 | Acc: 18.750,30.320,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.652 | Acc: 18.426,30.278,72.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.661 | Acc: 18.033,29.675,72.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.648 | Acc: 18.239,29.890,73.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.655 | Acc: 18.410,29.950,73.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.660 | Acc: 18.162,29.707,73.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.660 | Acc: 18.323,29.804,73.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.669 | Acc: 18.328,29.785,73.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.669 | Acc: 18.379,29.877,73.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.673 | Acc: 18.451,29.761,72.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.673 | Acc: 18.365,29.822,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.678 | Acc: 18.299,29.772,72.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.684 | Acc: 18.256,29.750,72.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.685 | Acc: 18.213,29.704,72.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.687 | Acc: 18.246,29.745,72.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.692 | Acc: 18.168,29.629,72.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.690 | Acc: 18.200,29.589,72.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.692 | Acc: 18.287,29.631,72.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.698 | Acc: 18.231,29.581,72.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.530 | Acc: 18.750,31.250,53.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.466 | Acc: 14.546,26.153,57.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.537 | Acc: 14.501,25.000,55.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.542 | Acc: 14.857,24.808,55.827,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 85
Batch: 0 | Loss: 1.481 | Acc: 18.750,35.156,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.582 | Acc: 19.494,31.138,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.606 | Acc: 18.559,30.621,74.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.608 | Acc: 18.391,30.456,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.612 | Acc: 18.326,30.449,74.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.633 | Acc: 18.069,30.291,73.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.644 | Acc: 18.253,30.307,73.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.646 | Acc: 18.290,30.352,73.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.651 | Acc: 18.211,30.115,73.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.655 | Acc: 18.223,30.188,73.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.656 | Acc: 18.210,30.068,73.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.660 | Acc: 18.110,30.037,73.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.664 | Acc: 18.021,30.047,73.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.665 | Acc: 18.154,30.145,72.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.672 | Acc: 18.227,30.063,72.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.674 | Acc: 18.296,30.009,72.755,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.675 | Acc: 18.288,30.004,72.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.677 | Acc: 18.278,30.022,72.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.681 | Acc: 18.291,29.982,72.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.685 | Acc: 18.282,29.956,72.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.179 | Acc: 16.406,29.688,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.290 | Acc: 14.918,27.641,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.301 | Acc: 14.844,27.058,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.306 | Acc: 14.754,26.703,59.618,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 86
Batch: 0 | Loss: 1.776 | Acc: 16.406,26.562,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.633 | Acc: 18.304,30.320,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.624 | Acc: 18.369,30.583,73.895,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.629 | Acc: 18.417,30.584,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.642 | Acc: 18.538,30.633,73.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.634 | Acc: 18.518,30.894,73.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 18.369,30.443,73.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.635 | Acc: 18.772,30.735,73.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.638 | Acc: 18.745,30.643,73.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.642 | Acc: 18.638,30.564,73.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.648 | Acc: 18.703,30.473,73.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.657 | Acc: 18.492,30.352,73.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.662 | Acc: 18.555,30.294,72.971,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.662 | Acc: 18.454,30.232,72.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.663 | Acc: 18.358,30.202,72.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.670 | Acc: 18.319,30.186,72.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.671 | Acc: 18.331,30.077,72.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.679 | Acc: 18.317,30.056,72.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.679 | Acc: 18.373,30.051,72.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.683 | Acc: 18.360,29.975,72.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.040 | Acc: 15.625,28.906,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.259 | Acc: 15.997,25.632,61.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.267 | Acc: 16.006,26.010,60.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.275 | Acc: 16.393,25.909,60.553,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 87
Batch: 0 | Loss: 1.456 | Acc: 26.562,39.844,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.600 | Acc: 18.266,32.292,75.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.594 | Acc: 18.483,30.926,75.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.602 | Acc: 18.519,30.789,75.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.620 | Acc: 18.316,30.565,74.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.630 | Acc: 18.348,30.337,74.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.638 | Acc: 18.434,30.546,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.638 | Acc: 18.373,30.236,74.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.647 | Acc: 18.274,30.153,73.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.649 | Acc: 18.297,30.028,73.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.651 | Acc: 18.241,29.960,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.655 | Acc: 18.273,29.794,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.657 | Acc: 18.322,29.681,73.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.654 | Acc: 18.385,29.795,73.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.653 | Acc: 18.330,29.827,73.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.658 | Acc: 18.306,29.882,73.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.662 | Acc: 18.375,29.924,73.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.666 | Acc: 18.388,29.933,73.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.668 | Acc: 18.417,29.945,73.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.671 | Acc: 18.504,29.987,73.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.500 | Acc: 18.750,33.594,52.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.647 | Acc: 15.402,27.083,53.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.710 | Acc: 14.710,26.658,52.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.712 | Acc: 14.780,26.767,52.382,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 88
Batch: 0 | Loss: 1.693 | Acc: 22.656,37.500,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.605 | Acc: 19.010,30.432,75.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 18.750,30.793,74.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.597 | Acc: 19.083,31.084,75.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.606 | Acc: 19.213,31.231,74.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.606 | Acc: 19.353,31.273,74.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.621 | Acc: 19.221,30.998,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.627 | Acc: 18.972,30.707,74.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.631 | Acc: 18.842,30.527,74.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.637 | Acc: 18.823,30.374,73.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.639 | Acc: 18.762,30.453,73.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.647 | Acc: 18.934,30.501,73.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.653 | Acc: 18.792,30.423,73.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.655 | Acc: 18.795,30.355,73.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 18.683,30.202,73.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.664 | Acc: 18.667,30.150,73.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.669 | Acc: 18.721,30.101,73.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.674 | Acc: 18.752,30.047,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.676 | Acc: 18.653,29.995,72.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.680 | Acc: 18.604,30.040,72.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.243 | Acc: 18.750,24.219,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.444 | Acc: 16.629,24.256,57.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.483 | Acc: 16.673,23.628,56.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.509 | Acc: 16.675,23.425,56.135,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 89
Batch: 0 | Loss: 1.477 | Acc: 17.969,32.031,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.658 | Acc: 20.126,30.618,73.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.652 | Acc: 19.245,30.164,73.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.649 | Acc: 18.878,29.444,73.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.643 | Acc: 18.702,29.707,73.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.642 | Acc: 18.773,29.865,73.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.647 | Acc: 18.608,29.849,73.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.645 | Acc: 18.390,29.926,73.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.643 | Acc: 18.464,30.173,73.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.644 | Acc: 18.413,30.167,73.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.646 | Acc: 18.447,30.131,73.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.651 | Acc: 18.435,30.154,73.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.649 | Acc: 18.504,30.242,73.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.656 | Acc: 18.379,30.136,73.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.661 | Acc: 18.372,30.046,73.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.662 | Acc: 18.353,30.048,73.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.665 | Acc: 18.283,30.016,73.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.667 | Acc: 18.315,29.967,73.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.669 | Acc: 18.404,30.058,73.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.674 | Acc: 18.403,30.018,72.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.083 | Acc: 15.625,31.250,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.265 | Acc: 15.848,26.711,61.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.270 | Acc: 15.816,26.124,61.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.277 | Acc: 15.766,26.127,60.873,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 90
Batch: 0 | Loss: 1.741 | Acc: 11.719,22.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 17.336,29.129,74.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.614 | Acc: 17.797,28.868,74.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.622 | Acc: 17.930,28.906,73.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.621 | Acc: 18.181,29.601,73.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.623 | Acc: 18.224,29.796,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.626 | Acc: 18.350,29.817,73.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.628 | Acc: 18.329,29.915,73.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.632 | Acc: 18.347,29.925,73.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.635 | Acc: 18.400,30.033,73.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.643 | Acc: 18.373,29.839,73.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.644 | Acc: 18.471,29.864,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.645 | Acc: 18.452,29.892,73.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 18.487,29.897,73.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.653 | Acc: 18.569,29.882,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.656 | Acc: 18.605,29.794,73.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 18.609,29.785,73.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 18.626,29.742,73.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.662 | Acc: 18.696,29.748,72.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.665 | Acc: 18.697,29.743,72.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.099 | Acc: 17.969,28.125,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.417 | Acc: 14.583,24.330,57.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.420 | Acc: 14.463,24.066,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.433 | Acc: 14.216,23.899,57.211,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 91
Batch: 0 | Loss: 1.590 | Acc: 19.531,35.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.613 | Acc: 17.076,30.171,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.615 | Acc: 17.168,28.601,74.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.614 | Acc: 18.289,29.406,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.615 | Acc: 18.355,29.524,74.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.606 | Acc: 18.588,30.167,74.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.612 | Acc: 18.304,30.088,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.619 | Acc: 18.440,30.147,74.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.622 | Acc: 18.304,30.148,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.627 | Acc: 18.374,30.175,74.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.634 | Acc: 18.412,30.115,73.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.639 | Acc: 18.421,30.154,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.642 | Acc: 18.374,30.151,73.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.646 | Acc: 18.478,30.163,73.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.649 | Acc: 18.528,30.166,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.652 | Acc: 18.584,30.238,73.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 18.516,30.140,73.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.660 | Acc: 18.480,30.088,73.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.664 | Acc: 18.438,30.094,73.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.668 | Acc: 18.449,30.067,73.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.042 | Acc: 14.062,28.906,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.365 | Acc: 14.174,25.521,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.405 | Acc: 13.720,25.229,59.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.422 | Acc: 13.653,25.320,58.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 92
Batch: 0 | Loss: 1.694 | Acc: 18.750,33.594,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.603 | Acc: 18.936,30.618,74.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.610 | Acc: 18.617,29.878,74.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.610 | Acc: 18.660,29.777,74.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.611 | Acc: 18.576,29.697,74.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.622 | Acc: 18.417,29.780,73.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.627 | Acc: 18.156,29.920,73.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.633 | Acc: 18.201,29.771,73.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.640 | Acc: 18.197,29.819,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.642 | Acc: 18.055,29.839,73.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.642 | Acc: 18.183,30.092,73.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.638 | Acc: 18.174,30.211,73.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.639 | Acc: 18.196,30.203,73.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.640 | Acc: 18.256,30.262,73.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.643 | Acc: 18.233,30.199,73.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.651 | Acc: 18.137,30.144,73.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.655 | Acc: 18.159,30.184,73.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.656 | Acc: 18.200,30.263,73.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.660 | Acc: 18.272,30.213,73.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.661 | Acc: 18.367,30.311,73.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.945 | Acc: 17.969,33.594,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.141 | Acc: 17.522,28.609,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.149 | Acc: 17.797,28.506,62.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.164 | Acc: 17.930,28.484,62.167,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 93
Batch: 0 | Loss: 1.566 | Acc: 17.188,30.469,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.590 | Acc: 17.894,29.948,75.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.606 | Acc: 18.598,30.107,74.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.607 | Acc: 18.507,29.892,74.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.614 | Acc: 18.403,29.967,74.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.615 | Acc: 18.379,29.618,74.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.624 | Acc: 18.511,29.649,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.631 | Acc: 18.711,29.848,73.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.638 | Acc: 18.551,29.780,73.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.636 | Acc: 18.685,30.231,73.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.638 | Acc: 18.711,30.197,73.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.640 | Acc: 18.746,30.200,73.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.644 | Acc: 18.601,30.070,73.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.648 | Acc: 18.567,30.041,73.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.652 | Acc: 18.544,30.035,73.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.657 | Acc: 18.615,30.012,73.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.658 | Acc: 18.516,29.980,73.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.659 | Acc: 18.585,29.953,73.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.661 | Acc: 18.575,29.884,73.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.664 | Acc: 18.586,29.874,73.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.102 | Acc: 21.094,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.361 | Acc: 17.932,28.274,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 17.207,27.287,58.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.407 | Acc: 17.431,27.305,58.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 94
Batch: 0 | Loss: 1.426 | Acc: 21.094,30.469,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.625 | Acc: 18.713,29.799,74.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.633 | Acc: 18.941,30.354,74.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.625 | Acc: 18.801,30.392,74.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.626 | Acc: 18.490,30.575,74.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.619 | Acc: 18.502,30.801,74.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.616 | Acc: 18.343,30.895,74.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.622 | Acc: 18.362,30.884,74.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.626 | Acc: 18.444,30.993,74.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.627 | Acc: 18.508,30.840,74.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.630 | Acc: 18.482,30.791,73.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.634 | Acc: 18.531,30.720,74.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.641 | Acc: 18.478,30.725,73.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.642 | Acc: 18.436,30.666,73.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.644 | Acc: 18.400,30.672,73.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.644 | Acc: 18.436,30.674,73.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.647 | Acc: 18.441,30.712,73.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.646 | Acc: 18.516,30.691,73.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.648 | Acc: 18.525,30.564,73.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.651 | Acc: 18.529,30.483,73.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.986 | Acc: 15.625,32.812,65.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.209 | Acc: 16.443,28.274,61.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.244 | Acc: 16.101,28.296,60.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.247 | Acc: 16.073,28.394,60.310,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 95
Batch: 0 | Loss: 1.673 | Acc: 15.625,28.906,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.564 | Acc: 18.043,30.618,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.581 | Acc: 18.007,30.297,75.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.593 | Acc: 17.982,30.213,75.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.592 | Acc: 18.220,30.276,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.599 | Acc: 18.232,30.183,75.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.603 | Acc: 18.479,30.398,74.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.612 | Acc: 18.562,30.386,74.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.613 | Acc: 18.624,30.508,74.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.619 | Acc: 18.603,30.495,74.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.623 | Acc: 18.699,30.465,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.626 | Acc: 18.598,30.483,74.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.631 | Acc: 18.659,30.420,74.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.638 | Acc: 18.672,30.397,74.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.642 | Acc: 18.647,30.410,73.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.644 | Acc: 18.695,30.432,73.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.644 | Acc: 18.684,30.481,73.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.646 | Acc: 18.677,30.489,73.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.648 | Acc: 18.681,30.480,73.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.652 | Acc: 18.680,30.471,73.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.963 | Acc: 14.844,32.812,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.321 | Acc: 15.030,25.930,59.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.347 | Acc: 15.168,25.991,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.356 | Acc: 15.561,26.178,58.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 96
Batch: 0 | Loss: 1.556 | Acc: 17.969,28.125,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.628 | Acc: 20.647,31.473,74.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.602 | Acc: 19.684,31.460,74.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.603 | Acc: 18.942,31.391,74.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.613 | Acc: 18.306,30.720,74.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.621 | Acc: 18.332,30.569,74.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.620 | Acc: 18.201,30.391,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.618 | Acc: 18.229,30.413,74.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.621 | Acc: 18.143,30.221,74.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.622 | Acc: 18.202,30.266,74.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.623 | Acc: 18.167,30.274,74.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.625 | Acc: 18.266,30.267,74.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.629 | Acc: 18.355,30.333,74.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.630 | Acc: 18.478,30.388,74.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.628 | Acc: 18.653,30.388,74.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.629 | Acc: 18.763,30.474,74.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.633 | Acc: 18.706,30.376,74.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.636 | Acc: 18.757,30.437,74.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.641 | Acc: 18.774,30.412,73.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.645 | Acc: 18.746,30.376,73.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.354 | Acc: 15.625,28.125,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.459 | Acc: 15.253,24.926,56.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.471 | Acc: 15.053,24.486,56.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.488 | Acc: 15.215,24.424,56.775,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 97
Batch: 0 | Loss: 1.533 | Acc: 17.969,30.469,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.570 | Acc: 18.750,28.534,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.582 | Acc: 18.731,30.202,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.577 | Acc: 18.468,30.289,75.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.589 | Acc: 18.403,30.295,75.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.597 | Acc: 18.495,30.476,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.606 | Acc: 18.601,30.262,74.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.605 | Acc: 18.528,30.413,74.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.607 | Acc: 18.668,30.716,74.631,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.615 | Acc: 18.564,30.598,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.616 | Acc: 18.595,30.640,74.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.620 | Acc: 18.644,30.713,74.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.623 | Acc: 18.724,30.699,74.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.624 | Acc: 18.693,30.750,74.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.628 | Acc: 18.603,30.647,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.629 | Acc: 18.737,30.622,73.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.630 | Acc: 18.721,30.673,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.633 | Acc: 18.716,30.615,73.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.638 | Acc: 18.683,30.605,73.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.642 | Acc: 18.672,30.543,73.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.127 | Acc: 17.969,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.328 | Acc: 16.183,28.051,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.290 | Acc: 16.444,28.220,60.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.311 | Acc: 16.522,27.984,59.913,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 98
Batch: 0 | Loss: 1.775 | Acc: 18.750,28.125,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.546 | Acc: 19.159,32.850,76.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.572 | Acc: 18.769,31.669,75.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.571 | Acc: 18.558,31.621,75.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.582 | Acc: 18.528,31.250,75.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.594 | Acc: 18.239,31.088,74.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.599 | Acc: 18.337,31.069,74.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.606 | Acc: 18.279,30.962,74.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.608 | Acc: 18.410,31.046,74.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.606 | Acc: 18.508,31.103,74.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.608 | Acc: 18.630,31.017,74.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.613 | Acc: 18.531,30.914,74.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.616 | Acc: 18.598,30.851,74.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.622 | Acc: 18.534,30.816,74.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.627 | Acc: 18.516,30.802,74.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.629 | Acc: 18.566,30.819,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.631 | Acc: 18.602,30.802,73.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.633 | Acc: 18.505,30.787,73.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.637 | Acc: 18.484,30.735,73.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.639 | Acc: 18.498,30.700,73.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.025 | Acc: 17.969,38.281,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.175 | Acc: 15.811,29.836,62.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.186 | Acc: 15.892,28.697,62.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.207 | Acc: 15.971,28.778,61.847,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 99
Batch: 0 | Loss: 1.666 | Acc: 17.969,35.156,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.549 | Acc: 18.638,31.287,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.567 | Acc: 18.712,30.640,76.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.566 | Acc: 18.891,30.879,75.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.571 | Acc: 18.846,30.729,75.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.574 | Acc: 18.858,30.809,75.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.581 | Acc: 18.685,30.753,75.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.593 | Acc: 18.467,30.452,75.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.596 | Acc: 18.595,30.745,75.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.603 | Acc: 18.642,30.775,74.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.607 | Acc: 18.668,30.854,74.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.614 | Acc: 18.609,30.822,74.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.616 | Acc: 18.653,30.761,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.621 | Acc: 18.738,30.813,74.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.625 | Acc: 18.636,30.719,74.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.628 | Acc: 18.747,30.752,74.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.630 | Acc: 18.706,30.722,74.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.632 | Acc: 18.713,30.668,74.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.634 | Acc: 18.674,30.622,73.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.638 | Acc: 18.672,30.655,73.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.146 | Acc: 17.188,25.000,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.296 | Acc: 14.472,24.665,58.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.334 | Acc: 14.043,23.723,58.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.340 | Acc: 14.485,23.425,58.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 100
Batch: 0 | Loss: 1.693 | Acc: 18.750,30.469,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.567 | Acc: 18.862,29.799,76.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.584 | Acc: 18.674,30.488,75.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.582 | Acc: 18.289,30.123,75.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.591 | Acc: 18.393,30.517,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.595 | Acc: 18.425,30.306,74.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.593 | Acc: 18.550,30.333,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.599 | Acc: 18.528,30.629,74.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.605 | Acc: 18.532,30.707,74.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.608 | Acc: 18.547,30.719,74.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.611 | Acc: 18.606,30.628,74.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.612 | Acc: 18.655,30.550,74.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.615 | Acc: 18.727,30.686,74.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.620 | Acc: 18.759,30.693,74.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.622 | Acc: 18.786,30.611,74.030,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.625 | Acc: 18.708,30.562,73.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.625 | Acc: 18.748,30.693,73.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.629 | Acc: 18.672,30.588,73.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.633 | Acc: 18.700,30.614,73.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.634 | Acc: 18.717,30.631,73.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.090 | Acc: 21.875,33.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.263 | Acc: 17.522,27.753,60.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.274 | Acc: 17.416,27.420,59.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.292 | Acc: 17.303,27.318,59.477,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 101
Batch: 0 | Loss: 1.620 | Acc: 18.750,31.250,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.577 | Acc: 18.229,31.510,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.589 | Acc: 18.388,30.469,75.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.582 | Acc: 18.545,30.802,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.587 | Acc: 18.596,30.729,74.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.590 | Acc: 18.827,31.026,74.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.596 | Acc: 18.860,31.185,74.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.602 | Acc: 18.744,31.017,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.600 | Acc: 18.794,31.129,74.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.603 | Acc: 18.733,30.982,74.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.609 | Acc: 18.688,30.916,74.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 18.743,30.992,74.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.614 | Acc: 18.692,30.897,74.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.619 | Acc: 18.696,30.843,74.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.619 | Acc: 18.625,30.805,74.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.623 | Acc: 18.522,30.715,74.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.624 | Acc: 18.575,30.754,74.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.626 | Acc: 18.640,30.792,74.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.628 | Acc: 18.685,30.806,74.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.632 | Acc: 18.766,30.776,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.234 | Acc: 21.094,34.375,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.390 | Acc: 17.597,26.004,58.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.388 | Acc: 17.435,26.848,58.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.405 | Acc: 17.431,26.639,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 102
Batch: 0 | Loss: 1.419 | Acc: 18.750,31.250,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.592 | Acc: 17.820,29.129,74.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.595 | Acc: 18.426,30.697,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.586 | Acc: 18.712,30.904,74.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.576 | Acc: 19.059,31.395,74.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.576 | Acc: 18.889,31.420,75.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.589 | Acc: 18.899,31.347,74.819,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.593 | Acc: 18.706,31.233,74.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.590 | Acc: 18.677,31.075,74.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.602 | Acc: 18.659,31.004,74.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.605 | Acc: 18.851,31.028,74.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.608 | Acc: 18.927,31.049,74.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.612 | Acc: 18.909,31.140,74.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.617 | Acc: 18.852,31.145,74.150,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.621 | Acc: 18.895,31.125,74.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.628 | Acc: 18.854,31.079,73.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.627 | Acc: 18.908,31.158,73.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.628 | Acc: 18.855,31.174,73.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.631 | Acc: 18.826,31.096,73.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.635 | Acc: 18.842,31.068,73.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.187 | Acc: 20.312,27.344,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.289 | Acc: 16.443,28.497,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.291 | Acc: 16.482,28.449,61.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.284 | Acc: 16.547,28.240,60.912,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 103
Batch: 0 | Loss: 1.562 | Acc: 20.312,28.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.556 | Acc: 20.015,31.808,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.534 | Acc: 19.226,31.764,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.560 | Acc: 18.929,31.365,75.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.572 | Acc: 18.895,31.346,75.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.573 | Acc: 19.005,31.683,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.576 | Acc: 19.112,31.650,75.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.587 | Acc: 18.994,31.350,75.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.594 | Acc: 18.905,31.260,74.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.597 | Acc: 19.013,31.155,74.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.594 | Acc: 19.034,31.071,74.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.595 | Acc: 18.973,30.974,74.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.595 | Acc: 19.035,31.166,74.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.601 | Acc: 19.043,31.043,74.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.601 | Acc: 19.100,31.150,74.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.604 | Acc: 19.038,31.084,74.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.605 | Acc: 19.040,31.133,74.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.606 | Acc: 19.052,31.145,74.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.609 | Acc: 19.051,31.049,74.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.611 | Acc: 19.017,31.061,74.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.269 | Acc: 12.500,28.125,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.340 | Acc: 14.174,27.679,60.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.346 | Acc: 13.129,26.677,59.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.361 | Acc: 13.179,26.127,59.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 104
Batch: 0 | Loss: 1.703 | Acc: 16.406,27.344,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 18.973,30.915,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.552 | Acc: 18.369,30.755,76.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.563 | Acc: 18.417,30.558,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.567 | Acc: 18.798,30.845,75.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.578 | Acc: 18.851,31.026,75.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.572 | Acc: 18.950,31.005,75.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.578 | Acc: 18.872,31.089,75.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.584 | Acc: 18.808,30.939,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.585 | Acc: 18.996,31.013,75.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.589 | Acc: 19.007,31.071,75.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.595 | Acc: 19.015,31.080,74.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.602 | Acc: 18.970,31.017,74.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.605 | Acc: 19.016,31.103,74.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.606 | Acc: 18.947,31.128,74.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.610 | Acc: 18.978,31.203,74.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.612 | Acc: 18.971,31.213,74.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.615 | Acc: 18.963,31.190,74.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.616 | Acc: 19.008,31.205,74.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.619 | Acc: 19.012,31.180,74.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.148 | Acc: 14.062,33.594,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.306 | Acc: 17.076,27.046,60.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.321 | Acc: 17.168,26.848,60.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.333 | Acc: 17.444,26.767,59.759,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 105
Batch: 0 | Loss: 1.609 | Acc: 17.969,29.688,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.569 | Acc: 18.676,30.208,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.593 | Acc: 19.207,30.259,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.592 | Acc: 18.763,30.635,74.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.582 | Acc: 19.223,30.951,75.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.579 | Acc: 19.261,31.165,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.582 | Acc: 19.015,31.050,74.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.594 | Acc: 18.966,31.134,74.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.598 | Acc: 19.090,31.143,74.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.602 | Acc: 18.871,31.129,74.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.607 | Acc: 18.742,31.141,74.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.607 | Acc: 18.838,31.328,74.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.611 | Acc: 18.782,31.308,74.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.613 | Acc: 18.684,31.277,74.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.619 | Acc: 18.703,31.236,74.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.622 | Acc: 18.592,31.102,73.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.621 | Acc: 18.701,31.155,74.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.624 | Acc: 18.773,31.016,73.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.628 | Acc: 18.666,30.930,73.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.630 | Acc: 18.744,30.961,73.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.056 | Acc: 21.875,30.469,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.245 | Acc: 18.118,29.315,60.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.239 | Acc: 17.645,29.173,60.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.249 | Acc: 17.853,28.791,60.489,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 106
Batch: 0 | Loss: 1.514 | Acc: 22.656,36.719,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.594 | Acc: 18.229,32.143,75.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.586 | Acc: 17.569,31.326,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.563 | Acc: 17.905,31.506,76.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.549 | Acc: 18.393,31.771,76.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.552 | Acc: 18.920,32.170,76.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.549 | Acc: 18.970,32.212,76.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.556 | Acc: 18.927,31.904,75.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.563 | Acc: 19.114,31.891,75.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.572 | Acc: 19.048,31.764,75.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 19.108,31.779,75.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.576 | Acc: 19.036,31.628,75.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.576 | Acc: 18.957,31.551,75.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.581 | Acc: 18.974,31.474,75.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.587 | Acc: 18.814,31.356,74.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.592 | Acc: 18.862,31.377,74.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.597 | Acc: 18.933,31.369,74.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.600 | Acc: 18.844,31.282,74.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.604 | Acc: 18.843,31.228,74.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.606 | Acc: 18.859,31.199,74.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.062 | Acc: 22.656,32.031,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.217 | Acc: 17.262,28.720,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.259 | Acc: 17.511,28.087,61.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.274 | Acc: 17.354,27.677,61.091,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 107
Batch: 0 | Loss: 1.569 | Acc: 11.719,23.438,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.529 | Acc: 18.378,30.060,77.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.512 | Acc: 19.303,30.964,77.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.520 | Acc: 19.160,31.481,77.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.527 | Acc: 19.396,31.424,76.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.536 | Acc: 19.400,31.451,76.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.541 | Acc: 19.441,31.541,76.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.545 | Acc: 19.182,31.244,76.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.554 | Acc: 19.187,31.284,75.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.562 | Acc: 19.294,31.349,75.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.570 | Acc: 19.201,31.336,75.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.579 | Acc: 19.199,31.391,75.148,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.582 | Acc: 19.103,31.370,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.588 | Acc: 19.043,31.361,74.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.593 | Acc: 19.011,31.286,74.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.597 | Acc: 19.028,31.284,74.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.600 | Acc: 19.025,31.238,74.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.606 | Acc: 18.952,31.174,74.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.609 | Acc: 18.930,31.122,74.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.611 | Acc: 18.906,31.111,74.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.247 | Acc: 17.969,32.031,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.348 | Acc: 15.885,27.716,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.374 | Acc: 16.216,27.858,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.371 | Acc: 16.189,27.805,59.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 108
Batch: 0 | Loss: 1.508 | Acc: 14.844,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.615 | Acc: 17.894,32.329,74.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.611 | Acc: 19.055,31.803,74.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.597 | Acc: 18.788,31.967,74.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.574 | Acc: 18.991,32.012,75.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.572 | Acc: 19.230,32.116,75.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.570 | Acc: 19.305,32.251,75.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.573 | Acc: 19.282,32.048,75.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.576 | Acc: 19.260,31.944,75.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.581 | Acc: 19.190,31.850,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.584 | Acc: 19.092,31.775,74.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.586 | Acc: 19.054,31.826,74.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.586 | Acc: 18.996,31.798,74.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.589 | Acc: 18.969,31.696,74.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.591 | Acc: 18.881,31.636,74.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.592 | Acc: 18.880,31.567,74.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.593 | Acc: 18.920,31.527,74.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.600 | Acc: 18.842,31.497,74.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.605 | Acc: 18.910,31.512,74.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.610 | Acc: 18.881,31.435,74.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.223 | Acc: 15.625,25.781,66.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.525 | Acc: 15.997,26.042,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.523 | Acc: 15.873,25.934,56.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.545 | Acc: 15.625,25.999,56.365,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 109
Batch: 0 | Loss: 1.597 | Acc: 16.406,31.250,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.558 | Acc: 18.415,31.585,76.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.549 | Acc: 19.036,32.336,76.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.558 | Acc: 18.891,31.557,75.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.571 | Acc: 19.001,31.809,75.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.567 | Acc: 18.943,31.822,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.568 | Acc: 18.827,31.844,75.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.576 | Acc: 18.866,31.821,75.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.571 | Acc: 18.959,31.760,75.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.570 | Acc: 19.052,31.897,75.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 18.940,31.751,75.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.574 | Acc: 19.026,31.720,75.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.580 | Acc: 18.987,31.652,75.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.588 | Acc: 19.043,31.534,75.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.592 | Acc: 19.086,31.617,74.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.595 | Acc: 19.017,31.525,74.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.601 | Acc: 19.049,31.501,74.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.604 | Acc: 18.970,31.481,74.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.607 | Acc: 19.021,31.499,74.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.609 | Acc: 19.051,31.498,74.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.049 | Acc: 15.625,31.250,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.263 | Acc: 15.327,29.241,59.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.291 | Acc: 15.511,28.963,59.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.289 | Acc: 15.279,28.765,59.759,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 110
Batch: 0 | Loss: 1.366 | Acc: 15.625,32.812,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.554 | Acc: 19.122,31.399,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.521 | Acc: 19.360,31.860,77.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.521 | Acc: 19.249,31.814,76.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.530 | Acc: 19.155,31.617,76.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.554 | Acc: 19.044,31.381,75.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.554 | Acc: 18.911,31.276,75.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.555 | Acc: 18.900,31.361,75.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.559 | Acc: 18.857,31.221,75.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.563 | Acc: 18.983,31.371,75.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.573 | Acc: 18.960,31.370,75.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.580 | Acc: 19.086,31.299,75.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.584 | Acc: 19.100,31.380,75.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.587 | Acc: 19.205,31.483,75.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.591 | Acc: 19.098,31.395,74.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.590 | Acc: 19.163,31.408,74.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.595 | Acc: 19.074,31.265,74.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.597 | Acc: 19.075,31.298,74.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.599 | Acc: 19.088,31.269,74.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.601 | Acc: 19.082,31.211,74.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.498 | Acc: 16.406,24.219,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.481 | Acc: 14.993,25.149,58.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.538 | Acc: 14.482,25.019,56.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.567 | Acc: 14.447,25.051,56.109,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 111
Batch: 0 | Loss: 1.581 | Acc: 14.844,35.156,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.595 | Acc: 19.048,32.106,74.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.572 | Acc: 19.474,32.241,75.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.557 | Acc: 19.595,31.903,76.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.566 | Acc: 19.743,31.906,75.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.571 | Acc: 19.593,31.869,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.570 | Acc: 19.531,31.954,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.578 | Acc: 19.315,31.848,75.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.580 | Acc: 19.002,31.638,75.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.582 | Acc: 18.992,31.595,75.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.587 | Acc: 18.839,31.328,75.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.587 | Acc: 19.089,31.476,75.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.588 | Acc: 19.100,31.652,75.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 19.064,31.525,75.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.590 | Acc: 19.056,31.547,75.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.589 | Acc: 19.025,31.548,74.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.590 | Acc: 19.076,31.574,74.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.594 | Acc: 19.119,31.566,74.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.600 | Acc: 19.092,31.473,74.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.602 | Acc: 19.111,31.414,74.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.022 | Acc: 12.500,27.344,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.323 | Acc: 14.695,26.079,60.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.297 | Acc: 13.948,26.181,60.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.298 | Acc: 14.101,26.255,60.669,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 112
Batch: 0 | Loss: 1.483 | Acc: 21.875,35.938,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.538 | Acc: 18.824,31.399,75.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.531 | Acc: 19.017,31.155,75.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.526 | Acc: 19.121,31.481,76.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.528 | Acc: 19.483,31.867,76.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.533 | Acc: 19.647,32.124,76.199,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.538 | Acc: 19.544,31.947,76.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.550 | Acc: 19.465,31.660,75.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.561 | Acc: 19.361,31.667,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.566 | Acc: 19.445,31.725,75.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.573 | Acc: 19.294,31.483,75.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.573 | Acc: 19.344,31.596,75.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.576 | Acc: 19.421,31.723,74.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.579 | Acc: 19.322,31.633,74.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.582 | Acc: 19.295,31.503,74.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 19.334,31.486,74.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.588 | Acc: 19.261,31.428,74.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.589 | Acc: 19.238,31.461,74.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.593 | Acc: 19.202,31.391,74.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.594 | Acc: 19.183,31.355,74.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.190 | Acc: 13.281,31.250,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.296 | Acc: 16.518,26.228,59.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.358 | Acc: 15.796,25.229,58.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.381 | Acc: 15.753,25.154,58.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 113
Batch: 0 | Loss: 1.454 | Acc: 21.875,37.500,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.521 | Acc: 18.452,31.473,77.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.557 | Acc: 18.502,31.574,75.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.546 | Acc: 18.724,31.468,76.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.547 | Acc: 18.634,31.713,76.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 18.758,32.024,76.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.560 | Acc: 18.634,31.831,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.562 | Acc: 18.794,31.887,75.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.569 | Acc: 18.842,31.764,75.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.572 | Acc: 18.970,31.850,75.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.570 | Acc: 19.042,31.903,75.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.574 | Acc: 18.959,31.745,75.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.578 | Acc: 18.970,31.694,75.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.580 | Acc: 18.924,31.723,75.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.584 | Acc: 18.903,31.714,75.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.588 | Acc: 18.989,31.790,74.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.587 | Acc: 19.030,31.768,74.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.589 | Acc: 18.984,31.617,74.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.591 | Acc: 19.023,31.581,74.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.597 | Acc: 19.058,31.568,74.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.348 | Acc: 17.969,30.469,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.268 | Acc: 15.662,28.795,60.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.312 | Acc: 15.911,27.820,59.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.330 | Acc: 15.651,27.946,59.541,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 114
Batch: 0 | Loss: 1.619 | Acc: 17.188,29.688,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.540 | Acc: 18.638,30.357,76.674,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.536 | Acc: 19.093,31.136,76.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.554 | Acc: 18.955,31.237,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.547 | Acc: 19.010,31.231,76.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 19.144,31.289,76.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.561 | Acc: 19.112,31.360,75.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.566 | Acc: 19.132,31.333,75.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.568 | Acc: 19.211,31.609,75.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.571 | Acc: 19.177,31.548,75.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.574 | Acc: 19.069,31.483,75.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.576 | Acc: 19.015,31.338,75.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.577 | Acc: 19.116,31.448,75.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.581 | Acc: 19.175,31.454,75.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.583 | Acc: 19.175,31.467,75.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.587 | Acc: 19.181,31.455,75.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.592 | Acc: 19.100,31.338,74.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.592 | Acc: 19.158,31.337,74.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.592 | Acc: 19.135,31.352,74.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.595 | Acc: 19.148,31.367,74.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.063 | Acc: 16.406,30.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.305 | Acc: 16.481,29.427,59.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.342 | Acc: 15.644,29.116,59.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.371 | Acc: 15.625,29.034,59.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 115
Batch: 0 | Loss: 1.262 | Acc: 23.438,36.719,81.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.511 | Acc: 20.201,31.994,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.518 | Acc: 20.008,31.822,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.517 | Acc: 19.915,32.044,76.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.503 | Acc: 20.042,32.253,77.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 19.531,31.962,76.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 19.583,32.031,76.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.535 | Acc: 19.581,31.987,76.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.545 | Acc: 19.502,31.905,76.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.556 | Acc: 19.302,31.790,75.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.557 | Acc: 19.419,31.849,75.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.562 | Acc: 19.344,31.727,75.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 19.330,31.798,75.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.569 | Acc: 19.256,31.771,75.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.574 | Acc: 19.223,31.695,75.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.576 | Acc: 19.241,31.647,75.223,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.583 | Acc: 19.268,31.591,75.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.585 | Acc: 19.254,31.541,74.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.591 | Acc: 19.239,31.609,74.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.593 | Acc: 19.215,31.547,74.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.189 | Acc: 13.281,25.000,57.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.227 | Acc: 14.397,25.707,62.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.229 | Acc: 14.425,25.877,62.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.247 | Acc: 14.344,25.743,62.065,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 116
Batch: 0 | Loss: 1.471 | Acc: 10.938,24.219,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.541 | Acc: 18.638,30.878,75.967,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 19.169,31.383,76.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.536 | Acc: 19.672,32.018,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.537 | Acc: 19.155,31.742,76.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.541 | Acc: 19.106,31.598,76.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.540 | Acc: 19.163,31.618,76.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.550 | Acc: 19.066,31.654,75.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.555 | Acc: 18.968,31.541,75.854,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.561 | Acc: 18.974,31.621,75.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.564 | Acc: 19.034,31.534,75.622,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.570 | Acc: 18.930,31.423,75.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.573 | Acc: 19.029,31.577,75.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.574 | Acc: 19.046,31.528,75.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.574 | Acc: 19.111,31.603,75.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.581 | Acc: 19.106,31.554,75.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.581 | Acc: 19.044,31.603,75.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.586 | Acc: 19.094,31.603,74.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.588 | Acc: 19.116,31.546,74.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.592 | Acc: 19.103,31.553,74.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.172 | Acc: 16.406,31.250,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.239 | Acc: 16.220,29.725,62.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.282 | Acc: 16.330,29.268,61.242,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.301 | Acc: 16.534,28.970,60.925,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 117
Batch: 0 | Loss: 1.520 | Acc: 20.312,39.062,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 19.606,33.371,76.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.516 | Acc: 19.950,33.213,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.526 | Acc: 19.493,32.774,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.532 | Acc: 19.792,32.697,76.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.546 | Acc: 19.647,32.325,76.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.553 | Acc: 19.299,32.251,75.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.550 | Acc: 19.548,32.441,75.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.560 | Acc: 19.483,32.250,75.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.559 | Acc: 19.497,32.286,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.564 | Acc: 19.430,32.109,75.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.566 | Acc: 19.457,32.105,75.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.567 | Acc: 19.376,32.090,75.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.568 | Acc: 19.426,32.070,75.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.575 | Acc: 19.351,31.945,75.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.578 | Acc: 19.352,31.870,74.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.580 | Acc: 19.322,31.888,74.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.582 | Acc: 19.327,31.894,74.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.583 | Acc: 19.278,31.947,74.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.584 | Acc: 19.248,31.951,74.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.274 | Acc: 15.625,28.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.250 | Acc: 14.881,27.195,61.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.266 | Acc: 14.844,26.734,60.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.270 | Acc: 14.805,26.793,60.745,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 118
Batch: 0 | Loss: 1.558 | Acc: 18.750,32.031,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.462 | Acc: 20.201,33.110,77.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.500 | Acc: 19.588,32.260,77.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.520 | Acc: 19.467,32.134,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 19.338,32.137,76.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 19.446,32.387,76.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.537 | Acc: 19.350,32.225,75.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.542 | Acc: 19.365,32.353,75.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.547 | Acc: 19.371,32.419,75.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.548 | Acc: 19.324,32.277,75.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.548 | Acc: 19.337,32.331,75.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.551 | Acc: 19.397,32.438,75.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.550 | Acc: 19.415,32.524,75.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.552 | Acc: 19.304,32.474,75.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.558 | Acc: 19.264,32.306,75.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.563 | Acc: 19.194,32.239,75.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.567 | Acc: 19.232,32.194,75.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.572 | Acc: 19.121,32.111,75.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.574 | Acc: 19.083,32.072,75.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 19.088,32.058,75.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.206 | Acc: 17.188,27.344,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.317 | Acc: 15.848,25.856,59.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.341 | Acc: 15.225,25.400,59.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.369 | Acc: 15.061,25.282,59.080,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 119
Batch: 0 | Loss: 1.639 | Acc: 22.656,33.594,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.521 | Acc: 19.010,32.515,76.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.543 | Acc: 19.417,31.803,76.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.542 | Acc: 19.352,31.647,76.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.536 | Acc: 19.300,32.012,76.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.538 | Acc: 19.175,31.737,76.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.548 | Acc: 18.995,31.708,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.553 | Acc: 19.033,31.909,75.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.558 | Acc: 18.954,31.847,75.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.564 | Acc: 19.044,31.932,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.572 | Acc: 19.022,31.829,75.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.578 | Acc: 18.976,31.823,74.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.586 | Acc: 18.880,31.658,74.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.591 | Acc: 18.846,31.612,74.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.592 | Acc: 18.914,31.623,74.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.591 | Acc: 18.903,31.629,74.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.592 | Acc: 19.010,31.800,74.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.592 | Acc: 19.080,31.811,74.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.594 | Acc: 19.046,31.741,74.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.595 | Acc: 19.049,31.750,74.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.229 | Acc: 14.844,30.469,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.268 | Acc: 15.997,29.464,61.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.286 | Acc: 15.796,28.754,61.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.303 | Acc: 15.727,28.676,60.656,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 120
Batch: 0 | Loss: 1.550 | Acc: 13.281,25.781,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.490 | Acc: 17.746,31.287,77.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.480 | Acc: 18.902,31.726,78.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 18.635,31.545,77.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.516 | Acc: 18.731,31.819,77.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 18.951,31.938,77.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.529 | Acc: 18.931,31.812,76.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.535 | Acc: 19.021,32.004,76.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.534 | Acc: 19.240,32.099,76.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.532 | Acc: 19.307,32.295,76.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.540 | Acc: 19.263,32.284,76.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 19.174,32.120,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.552 | Acc: 19.184,32.031,76.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.555 | Acc: 19.277,32.055,75.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.560 | Acc: 19.320,31.956,75.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.566 | Acc: 19.277,31.857,75.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.569 | Acc: 19.300,31.849,75.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.567 | Acc: 19.341,31.791,75.603,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.568 | Acc: 19.356,31.785,75.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.572 | Acc: 19.248,31.594,75.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.138 | Acc: 16.406,27.344,64.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.289 | Acc: 18.415,27.493,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.338 | Acc: 17.854,26.905,59.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.343 | Acc: 17.879,26.742,60.105,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 121
Batch: 0 | Loss: 1.387 | Acc: 24.219,37.500,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 19.048,32.254,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.525 | Acc: 19.665,32.393,76.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.531 | Acc: 20.441,32.518,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 20.332,32.523,76.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.532 | Acc: 20.080,32.140,76.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.533 | Acc: 20.267,32.270,76.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.541 | Acc: 20.107,32.242,76.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.544 | Acc: 19.953,32.080,76.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.548 | Acc: 19.890,32.109,76.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 19.842,32.148,76.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 19.856,32.289,75.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.553 | Acc: 19.687,32.193,75.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.559 | Acc: 19.594,32.124,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.566 | Acc: 19.520,32.042,75.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.569 | Acc: 19.560,32.057,75.358,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.572 | Acc: 19.480,32.034,75.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.574 | Acc: 19.442,31.912,75.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.573 | Acc: 19.479,31.893,75.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.575 | Acc: 19.503,31.937,75.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.196 | Acc: 20.312,28.906,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.368 | Acc: 16.146,25.930,60.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.394 | Acc: 15.739,25.896,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 15.881,26.255,59.285,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 122
Batch: 0 | Loss: 1.448 | Acc: 19.531,32.031,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.544 | Acc: 18.936,31.994,76.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.525 | Acc: 19.836,32.812,76.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.531 | Acc: 19.365,32.185,76.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.533 | Acc: 19.406,32.186,76.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.540 | Acc: 19.346,32.124,75.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.538 | Acc: 19.196,32.064,76.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.533 | Acc: 19.232,32.319,76.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.534 | Acc: 19.211,32.400,76.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.540 | Acc: 19.307,32.411,76.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.548 | Acc: 19.298,32.237,75.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.554 | Acc: 19.263,32.335,75.767,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.561 | Acc: 19.265,32.229,75.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.563 | Acc: 19.340,32.238,75.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.566 | Acc: 19.323,32.229,75.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.567 | Acc: 19.357,32.231,75.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.568 | Acc: 19.405,32.253,75.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.570 | Acc: 19.490,32.281,75.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.570 | Acc: 19.410,32.211,75.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.573 | Acc: 19.357,32.154,75.203,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.290 | Acc: 20.312,31.250,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.349 | Acc: 16.629,27.827,58.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.379 | Acc: 16.044,27.344,58.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.393 | Acc: 15.945,27.331,58.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 123
Batch: 0 | Loss: 1.634 | Acc: 20.312,30.469,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.552 | Acc: 19.680,33.296,75.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 19.779,32.107,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.549 | Acc: 19.083,31.429,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.554 | Acc: 18.962,31.250,75.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.549 | Acc: 19.005,31.366,75.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.547 | Acc: 19.021,31.424,75.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.554 | Acc: 19.088,31.394,75.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.553 | Acc: 19.075,31.405,75.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.548 | Acc: 19.203,31.617,75.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.552 | Acc: 19.248,31.666,75.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.556 | Acc: 19.287,31.784,75.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.559 | Acc: 19.321,31.834,75.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.564 | Acc: 19.376,31.714,75.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.567 | Acc: 19.473,31.798,75.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.570 | Acc: 19.479,31.837,75.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.572 | Acc: 19.495,31.822,75.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.573 | Acc: 19.463,31.768,75.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.574 | Acc: 19.484,31.854,75.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.578 | Acc: 19.484,31.882,74.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.429 | Acc: 15.625,26.562,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.389 | Acc: 15.699,27.121,59.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.404 | Acc: 15.358,26.562,59.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.414 | Acc: 15.228,26.460,59.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 124
Batch: 0 | Loss: 1.650 | Acc: 19.531,30.469,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.531 | Acc: 19.196,30.990,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.513 | Acc: 19.150,31.307,77.058,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.523 | Acc: 19.326,31.698,76.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.525 | Acc: 19.145,31.858,76.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.527 | Acc: 19.214,32.031,76.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.530 | Acc: 19.183,31.934,76.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.527 | Acc: 19.188,31.981,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.530 | Acc: 19.400,32.216,76.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.539 | Acc: 19.298,32.014,76.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.544 | Acc: 19.154,31.802,76.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.547 | Acc: 19.206,31.812,76.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.547 | Acc: 19.246,31.915,76.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.554 | Acc: 19.358,31.962,75.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.555 | Acc: 19.337,32.081,75.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.561 | Acc: 19.282,32.018,75.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.564 | Acc: 19.302,32.068,75.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.566 | Acc: 19.330,32.047,75.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.567 | Acc: 19.395,32.062,75.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.569 | Acc: 19.451,32.119,75.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.115 | Acc: 17.969,33.594,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.254 | Acc: 18.229,30.060,61.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.242 | Acc: 17.912,29.935,61.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.259 | Acc: 17.994,29.623,61.040,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 125
Batch: 0 | Loss: 1.312 | Acc: 17.969,32.031,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.521 | Acc: 19.903,32.664,75.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.514 | Acc: 19.779,32.470,76.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 19.403,32.108,76.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 19.300,32.099,76.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 19.454,32.140,76.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.519 | Acc: 19.706,32.419,76.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.515 | Acc: 19.731,32.547,76.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.519 | Acc: 19.895,32.546,76.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 20.028,32.700,76.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.536 | Acc: 19.939,32.700,76.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.541 | Acc: 19.871,32.653,76.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.547 | Acc: 19.784,32.508,75.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.554 | Acc: 19.744,32.561,75.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.562 | Acc: 19.698,32.412,75.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.565 | Acc: 19.627,32.309,75.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.567 | Acc: 19.592,32.275,75.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.570 | Acc: 19.563,32.265,75.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.573 | Acc: 19.505,32.282,75.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.576 | Acc: 19.462,32.251,75.086,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.120 | Acc: 13.281,30.469,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.349 | Acc: 14.732,28.162,60.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.390 | Acc: 14.139,27.096,59.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.425 | Acc: 14.216,27.113,58.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 126
Batch: 0 | Loss: 1.604 | Acc: 19.531,40.625,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.546 | Acc: 19.122,32.478,76.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.552 | Acc: 19.188,32.203,76.315,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.549 | Acc: 19.070,32.147,76.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.546 | Acc: 19.319,32.147,76.167,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.540 | Acc: 19.423,32.109,76.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.543 | Acc: 19.647,32.464,76.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.546 | Acc: 19.553,32.270,76.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.549 | Acc: 19.405,32.172,76.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.552 | Acc: 19.402,32.234,75.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.557 | Acc: 19.271,32.156,75.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.560 | Acc: 19.305,32.070,75.629,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.565 | Acc: 19.308,32.012,75.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.567 | Acc: 19.226,32.031,75.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.570 | Acc: 19.200,32.137,75.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.569 | Acc: 19.233,32.158,75.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.570 | Acc: 19.288,32.133,75.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.572 | Acc: 19.293,32.148,75.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.573 | Acc: 19.209,32.107,75.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.574 | Acc: 19.201,32.107,75.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.313 | Acc: 17.188,29.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.304 | Acc: 15.699,29.204,60.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.370 | Acc: 15.777,28.620,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.388 | Acc: 16.099,28.509,59.119,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 127
Batch: 0 | Loss: 1.232 | Acc: 23.438,39.062,84.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.474 | Acc: 20.238,33.929,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.483 | Acc: 20.141,33.937,77.687,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.481 | Acc: 20.082,33.517,77.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.486 | Acc: 19.994,33.517,77.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.493 | Acc: 19.964,33.377,77.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 19.925,33.232,76.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.506 | Acc: 19.963,32.979,76.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.517 | Acc: 19.900,32.846,76.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.521 | Acc: 19.868,32.821,76.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.527 | Acc: 19.850,32.855,76.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.534 | Acc: 19.842,32.812,75.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.535 | Acc: 19.794,32.793,75.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.541 | Acc: 19.792,32.762,75.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.550 | Acc: 19.662,32.668,75.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.553 | Acc: 19.607,32.652,75.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.560 | Acc: 19.490,32.542,75.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.563 | Acc: 19.419,32.464,75.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.565 | Acc: 19.362,32.436,75.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.563 | Acc: 19.336,32.421,75.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.239 | Acc: 21.875,31.250,64.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.274 | Acc: 16.778,28.646,62.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.271 | Acc: 16.864,28.125,61.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.264 | Acc: 16.650,28.407,61.706,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 128
Batch: 0 | Loss: 1.521 | Acc: 20.312,32.031,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.467 | Acc: 20.647,34.189,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 19.855,33.175,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 19.365,32.915,77.395,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 19.695,32.880,77.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.508 | Acc: 19.284,32.550,76.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.513 | Acc: 19.370,32.632,76.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.517 | Acc: 19.387,32.419,76.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 19.308,32.361,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.525 | Acc: 19.393,32.385,76.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.527 | Acc: 19.543,32.610,76.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.530 | Acc: 19.648,32.636,76.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.533 | Acc: 19.687,32.628,76.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.541 | Acc: 19.630,32.603,76.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.544 | Acc: 19.631,32.657,75.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.548 | Acc: 19.586,32.742,75.831,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.551 | Acc: 19.492,32.720,75.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.556 | Acc: 19.495,32.712,75.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.559 | Acc: 19.520,32.637,75.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.563 | Acc: 19.486,32.548,75.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.207 | Acc: 18.750,35.156,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.222 | Acc: 16.369,30.208,61.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.214 | Acc: 16.311,29.802,62.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.217 | Acc: 16.342,29.636,62.244,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 129
Batch: 0 | Loss: 1.359 | Acc: 16.406,35.938,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.518 | Acc: 20.164,32.999,76.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 19.970,32.832,76.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.524 | Acc: 20.133,33.325,76.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.523 | Acc: 19.705,32.890,76.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.518 | Acc: 19.872,33.014,76.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.512 | Acc: 19.828,33.013,77.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.516 | Acc: 19.930,32.923,76.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 19.691,32.677,76.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.524 | Acc: 19.669,32.562,76.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.530 | Acc: 19.551,32.432,76.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.537 | Acc: 19.570,32.307,76.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.544 | Acc: 19.583,32.268,76.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.545 | Acc: 19.678,32.390,76.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.547 | Acc: 19.640,32.432,76.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.549 | Acc: 19.619,32.449,76.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.551 | Acc: 19.643,32.511,75.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.553 | Acc: 19.598,32.510,75.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.555 | Acc: 19.616,32.464,75.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.558 | Acc: 19.570,32.427,75.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.186 | Acc: 18.750,33.594,61.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.403 | Acc: 17.634,30.506,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.385 | Acc: 17.835,30.088,58.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.384 | Acc: 17.789,30.187,58.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 130
Batch: 0 | Loss: 1.474 | Acc: 18.750,35.156,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.489 | Acc: 19.382,33.333,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.482 | Acc: 19.893,32.946,77.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.507 | Acc: 19.442,32.697,76.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.513 | Acc: 19.261,32.407,76.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 19.183,32.534,76.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.533 | Acc: 19.228,32.451,75.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.537 | Acc: 19.182,32.430,75.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.538 | Acc: 19.284,32.444,75.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.540 | Acc: 19.324,32.592,75.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.546 | Acc: 19.321,32.568,75.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.548 | Acc: 19.287,32.579,75.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.547 | Acc: 19.343,32.592,75.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.545 | Acc: 19.283,32.597,75.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.549 | Acc: 19.289,32.679,75.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.549 | Acc: 19.391,32.675,75.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.550 | Acc: 19.393,32.696,75.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.552 | Acc: 19.479,32.819,75.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.553 | Acc: 19.430,32.771,75.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.551 | Acc: 19.425,32.829,75.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.977 | Acc: 19.531,31.250,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.196 | Acc: 16.592,30.506,62.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.206 | Acc: 16.978,29.535,61.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.209 | Acc: 17.059,29.380,62.001,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 131
Batch: 0 | Loss: 1.560 | Acc: 20.312,28.906,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 19.345,31.138,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.492 | Acc: 19.836,31.955,77.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.504 | Acc: 20.146,32.454,76.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.511 | Acc: 19.878,32.224,76.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.517 | Acc: 20.003,32.387,76.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.516 | Acc: 19.983,32.354,76.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 19.919,32.242,76.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.525 | Acc: 19.813,32.405,76.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.535 | Acc: 19.656,32.264,76.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.541 | Acc: 19.729,32.342,75.964,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.546 | Acc: 19.818,32.328,75.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.546 | Acc: 19.842,32.355,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.550 | Acc: 19.777,32.271,75.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.552 | Acc: 19.634,32.309,75.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.557 | Acc: 19.677,32.267,75.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.558 | Acc: 19.680,32.233,75.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.559 | Acc: 19.703,32.244,75.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.558 | Acc: 19.672,32.339,75.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.561 | Acc: 19.632,32.396,75.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.049 | Acc: 18.750,36.719,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.231 | Acc: 17.113,29.650,61.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.264 | Acc: 17.359,28.830,60.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.276 | Acc: 17.354,28.637,60.848,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 132
Batch: 0 | Loss: 1.578 | Acc: 17.188,32.031,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.534 | Acc: 19.271,32.254,77.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.526 | Acc: 19.112,32.279,77.039,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.522 | Acc: 19.608,32.480,77.011,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.524 | Acc: 19.348,32.282,76.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 19.524,32.542,76.872,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 19.454,32.580,76.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.526 | Acc: 19.459,32.463,76.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.524 | Acc: 19.439,32.400,76.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.528 | Acc: 19.337,32.411,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.535 | Acc: 19.391,32.478,76.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.540 | Acc: 19.358,32.565,76.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.542 | Acc: 19.327,32.576,75.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.545 | Acc: 19.415,32.606,75.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.547 | Acc: 19.403,32.604,75.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.550 | Acc: 19.321,32.501,75.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.553 | Acc: 19.317,32.486,75.557,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.555 | Acc: 19.362,32.522,75.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.560 | Acc: 19.336,32.507,75.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.562 | Acc: 19.363,32.491,75.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.161 | Acc: 19.531,31.250,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.315 | Acc: 18.006,29.129,59.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.335 | Acc: 17.759,28.373,58.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.328 | Acc: 18.148,28.753,59.209,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 133
Batch: 0 | Loss: 1.486 | Acc: 21.875,31.250,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.505 | Acc: 20.350,32.924,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.525 | Acc: 20.332,32.870,76.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.524 | Acc: 19.698,33.017,76.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.526 | Acc: 19.850,33.054,76.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.524 | Acc: 19.554,32.851,76.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.526 | Acc: 19.699,32.864,76.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.527 | Acc: 19.720,32.752,76.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.531 | Acc: 19.818,32.730,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.528 | Acc: 19.717,32.895,76.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.529 | Acc: 19.601,32.723,76.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.536 | Acc: 19.659,32.802,76.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.542 | Acc: 19.616,32.731,75.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.543 | Acc: 19.534,32.705,75.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.546 | Acc: 19.537,32.704,75.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.550 | Acc: 19.510,32.732,75.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.551 | Acc: 19.468,32.793,75.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.556 | Acc: 19.467,32.728,75.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.557 | Acc: 19.421,32.717,75.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.557 | Acc: 19.386,32.804,75.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.156 | Acc: 15.625,29.688,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.205 | Acc: 16.592,29.353,62.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.209 | Acc: 16.635,28.277,61.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.218 | Acc: 16.509,28.253,62.013,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 134
Batch: 0 | Loss: 1.447 | Acc: 17.969,34.375,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.497 | Acc: 20.387,33.519,77.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.493 | Acc: 19.836,33.689,77.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.490 | Acc: 20.441,33.478,77.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.490 | Acc: 20.361,33.555,77.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.483 | Acc: 20.065,33.393,77.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.491 | Acc: 19.932,33.316,77.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.501 | Acc: 19.681,33.084,77.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 19.589,33.075,77.014,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.512 | Acc: 19.523,33.106,76.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 19.531,33.053,76.803,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.520 | Acc: 19.591,33.148,76.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.523 | Acc: 19.648,33.202,76.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.528 | Acc: 19.603,33.163,76.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.529 | Acc: 19.553,33.132,76.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.532 | Acc: 19.534,33.114,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.534 | Acc: 19.522,33.136,76.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.537 | Acc: 19.531,33.090,76.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.541 | Acc: 19.637,33.137,76.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.541 | Acc: 19.624,33.073,76.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.322 | Acc: 17.188,30.469,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.423 | Acc: 14.844,26.116,59.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.428 | Acc: 15.625,25.972,58.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.428 | Acc: 15.740,25.499,58.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 135
Batch: 0 | Loss: 1.655 | Acc: 21.875,40.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 20.499,34.375,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.519 | Acc: 19.703,33.708,76.296,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.515 | Acc: 19.442,32.723,76.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.517 | Acc: 18.981,32.620,76.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.509 | Acc: 19.361,32.975,77.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.513 | Acc: 19.396,32.877,76.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 19.343,32.835,76.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.532 | Acc: 19.357,32.973,76.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.535 | Acc: 19.609,33.054,76.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.540 | Acc: 19.434,32.886,76.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.546 | Acc: 19.365,32.752,75.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.549 | Acc: 19.243,32.624,75.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.552 | Acc: 19.247,32.615,75.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.553 | Acc: 19.256,32.615,75.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.555 | Acc: 19.220,32.605,75.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.556 | Acc: 19.225,32.615,75.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.557 | Acc: 19.206,32.657,75.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.558 | Acc: 19.323,32.795,75.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.559 | Acc: 19.402,32.870,75.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.056 | Acc: 21.094,33.594,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.117 | Acc: 17.857,31.510,64.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.156 | Acc: 17.816,29.935,62.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.161 | Acc: 18.071,30.341,62.846,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 136
Batch: 0 | Loss: 1.421 | Acc: 23.438,35.156,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.526 | Acc: 18.936,32.552,76.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.514 | Acc: 19.760,33.175,76.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.525 | Acc: 19.595,33.197,76.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.520 | Acc: 19.821,32.996,76.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.521 | Acc: 19.469,32.944,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.525 | Acc: 19.628,33.019,76.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.533 | Acc: 19.681,32.918,76.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.539 | Acc: 19.604,32.905,76.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.537 | Acc: 19.488,32.912,76.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.542 | Acc: 19.508,32.867,76.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.540 | Acc: 19.503,33.021,76.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.542 | Acc: 19.460,32.900,76.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.543 | Acc: 19.480,32.920,75.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.544 | Acc: 19.573,32.918,75.859,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.546 | Acc: 19.607,32.836,75.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.549 | Acc: 19.487,32.859,75.703,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.549 | Acc: 19.524,32.826,75.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.550 | Acc: 19.542,32.806,75.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.551 | Acc: 19.572,32.796,75.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.243 | Acc: 18.750,35.938,57.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.292 | Acc: 17.225,29.650,61.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.333 | Acc: 16.921,28.659,59.909,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.330 | Acc: 17.034,28.804,59.900,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 137
Batch: 0 | Loss: 1.457 | Acc: 16.406,33.594,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.426 | Acc: 20.759,33.891,79.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.451 | Acc: 20.675,33.994,78.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.462 | Acc: 20.786,33.683,78.112,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 20.399,33.218,77.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.490 | Acc: 20.181,33.037,77.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.500 | Acc: 20.106,33.103,77.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 20.047,32.968,76.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 19.856,32.759,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.521 | Acc: 19.894,32.877,76.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.526 | Acc: 19.776,32.785,76.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 19.825,32.678,76.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.536 | Acc: 19.829,32.589,76.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.542 | Acc: 19.792,32.501,75.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.545 | Acc: 19.798,32.448,75.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.547 | Acc: 19.780,32.325,75.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.550 | Acc: 19.750,32.377,75.567,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.550 | Acc: 19.728,32.418,75.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.554 | Acc: 19.694,32.403,75.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.554 | Acc: 19.677,32.327,75.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.082 | Acc: 16.406,35.938,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.240 | Acc: 15.662,28.125,62.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.234 | Acc: 15.892,27.687,61.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.214 | Acc: 15.881,27.741,62.641,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 138
Batch: 0 | Loss: 1.456 | Acc: 19.531,28.906,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.476 | Acc: 19.010,33.073,77.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.479 | Acc: 18.407,32.984,77.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.491 | Acc: 18.673,32.928,77.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.498 | Acc: 18.731,33.131,76.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.500 | Acc: 18.619,32.952,77.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.505 | Acc: 18.776,32.625,76.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.509 | Acc: 18.977,32.735,76.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.507 | Acc: 18.997,32.740,76.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.511 | Acc: 19.100,32.847,76.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 19.146,32.914,76.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.518 | Acc: 19.270,33.053,76.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.524 | Acc: 19.243,32.975,76.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.527 | Acc: 19.346,33.079,76.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 19.209,32.985,76.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.536 | Acc: 19.225,33.002,76.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.536 | Acc: 19.315,33.015,76.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.537 | Acc: 19.332,32.987,76.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.540 | Acc: 19.427,33.007,76.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.543 | Acc: 19.453,33.069,75.927,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.273 | Acc: 16.406,30.469,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.363 | Acc: 16.555,27.827,58.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.374 | Acc: 16.273,27.553,57.832,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.381 | Acc: 16.060,27.856,57.966,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 139
Batch: 0 | Loss: 1.415 | Acc: 19.531,33.594,80.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.516 | Acc: 18.155,32.106,75.893,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.508 | Acc: 19.226,32.927,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.516 | Acc: 19.352,32.582,76.550,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.514 | Acc: 19.425,32.562,76.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.522 | Acc: 19.469,32.557,76.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.524 | Acc: 19.454,32.741,76.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.524 | Acc: 19.459,32.707,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.533 | Acc: 19.293,32.648,76.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.535 | Acc: 19.315,32.838,76.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.542 | Acc: 19.317,32.914,76.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.541 | Acc: 19.436,32.890,76.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.541 | Acc: 19.492,32.984,76.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.545 | Acc: 19.570,32.938,76.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.547 | Acc: 19.612,32.957,75.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.552 | Acc: 19.643,32.937,75.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.553 | Acc: 19.573,32.949,75.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.555 | Acc: 19.550,32.904,75.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.554 | Acc: 19.581,32.901,75.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.553 | Acc: 19.597,32.903,75.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.147 | Acc: 17.188,29.688,60.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.344 | Acc: 12.872,23.103,59.635,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.364 | Acc: 13.643,23.514,59.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.365 | Acc: 13.781,23.630,59.375,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 140
Batch: 0 | Loss: 1.485 | Acc: 21.094,34.375,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.514 | Acc: 18.750,31.548,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.490 | Acc: 18.388,32.050,77.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.496 | Acc: 19.019,32.159,77.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.502 | Acc: 19.280,32.610,76.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.507 | Acc: 19.291,32.735,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.507 | Acc: 19.447,33.168,76.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.513 | Acc: 19.470,33.178,76.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 19.488,32.987,76.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.519 | Acc: 19.363,32.730,76.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.516 | Acc: 19.450,32.785,76.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.524 | Acc: 19.499,32.738,76.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.527 | Acc: 19.551,32.777,76.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.530 | Acc: 19.585,32.884,76.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.534 | Acc: 19.651,32.918,76.076,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.538 | Acc: 19.560,32.934,75.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.539 | Acc: 19.587,32.959,75.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.541 | Acc: 19.529,32.936,75.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.544 | Acc: 19.538,32.923,75.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.550 | Acc: 19.542,32.948,75.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.002 | Acc: 17.188,28.906,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.232 | Acc: 14.993,26.935,61.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.252 | Acc: 14.958,26.543,61.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.272 | Acc: 14.844,26.588,60.861,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 141
Batch: 0 | Loss: 1.599 | Acc: 17.969,35.938,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.485 | Acc: 19.866,34.375,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.483 | Acc: 19.970,33.441,77.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.480 | Acc: 20.312,33.504,77.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.482 | Acc: 20.544,33.661,77.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.500 | Acc: 20.096,33.192,76.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.504 | Acc: 20.093,33.187,76.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.512 | Acc: 19.963,33.001,76.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.516 | Acc: 19.968,33.094,76.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.518 | Acc: 20.054,33.115,76.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.518 | Acc: 20.052,33.166,76.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 19.938,33.074,76.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.525 | Acc: 20.011,33.159,76.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.529 | Acc: 19.956,33.136,76.212,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.531 | Acc: 19.990,33.093,76.134,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.533 | Acc: 19.980,33.054,76.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.535 | Acc: 20.001,32.966,75.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.536 | Acc: 19.985,32.856,75.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.538 | Acc: 19.960,32.743,75.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.541 | Acc: 19.876,32.718,75.814,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.145 | Acc: 16.406,28.906,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.361 | Acc: 16.034,27.753,59.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.382 | Acc: 15.949,27.058,59.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.399 | Acc: 15.663,26.883,58.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 142
Batch: 0 | Loss: 1.512 | Acc: 18.750,35.938,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.466 | Acc: 20.833,34.673,77.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.461 | Acc: 20.408,34.070,77.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.459 | Acc: 20.492,34.055,77.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.469 | Acc: 20.399,33.931,77.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.471 | Acc: 20.243,33.872,77.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.485 | Acc: 20.254,33.839,77.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.497 | Acc: 20.030,33.400,76.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.495 | Acc: 20.152,33.555,77.038,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.500 | Acc: 20.066,33.261,76.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.502 | Acc: 20.153,33.326,76.920,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.505 | Acc: 20.065,33.272,76.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.512 | Acc: 20.092,33.286,76.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.518 | Acc: 20.022,33.145,76.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.524 | Acc: 19.962,33.118,76.398,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.523 | Acc: 19.988,33.116,76.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.526 | Acc: 19.994,33.187,76.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.528 | Acc: 20.074,33.202,76.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.533 | Acc: 19.988,33.124,76.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.537 | Acc: 19.904,32.999,76.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.054 | Acc: 15.625,29.688,63.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.253 | Acc: 15.588,27.939,61.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.282 | Acc: 16.063,27.039,60.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.306 | Acc: 16.112,26.921,60.118,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 143
Batch: 0 | Loss: 1.492 | Acc: 23.438,32.031,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.496 | Acc: 19.382,32.254,77.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 20.217,32.527,77.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.487 | Acc: 20.005,32.672,77.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.496 | Acc: 20.004,32.851,77.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.504 | Acc: 19.941,32.983,77.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.514 | Acc: 20.132,32.793,76.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.521 | Acc: 20.074,32.862,76.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.521 | Acc: 20.065,33.031,76.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.524 | Acc: 19.984,33.002,76.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.526 | Acc: 19.889,33.069,76.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.529 | Acc: 19.807,33.138,76.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.530 | Acc: 19.820,33.218,76.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.532 | Acc: 19.807,33.232,76.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.535 | Acc: 19.681,33.277,76.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.539 | Acc: 19.700,33.287,76.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.545 | Acc: 19.731,33.234,75.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.547 | Acc: 19.728,33.163,75.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.548 | Acc: 19.720,33.111,75.870,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.551 | Acc: 19.636,33.079,75.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.555 | Acc: 14.062,33.594,60.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.403 | Acc: 16.518,29.725,58.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.445 | Acc: 16.482,29.668,57.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.444 | Acc: 16.509,29.995,57.313,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 144
Batch: 0 | Loss: 1.480 | Acc: 18.750,30.469,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.454 | Acc: 19.531,33.557,78.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.495 | Acc: 19.569,33.098,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.492 | Acc: 19.736,33.210,77.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 19.743,33.285,77.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.506 | Acc: 19.802,33.632,76.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.501 | Acc: 19.841,33.536,76.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.512 | Acc: 19.792,33.577,76.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.518 | Acc: 19.769,33.502,76.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.513 | Acc: 19.786,33.512,76.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.517 | Acc: 19.831,33.469,76.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.521 | Acc: 19.736,33.307,76.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.518 | Acc: 19.888,33.318,76.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.521 | Acc: 19.917,33.321,76.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.522 | Acc: 19.907,33.377,76.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.527 | Acc: 19.897,33.360,76.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.530 | Acc: 19.862,33.421,76.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.531 | Acc: 19.875,33.433,76.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.536 | Acc: 19.897,33.358,75.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.539 | Acc: 19.896,33.303,75.787,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.326 | Acc: 14.062,28.125,56.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.396 | Acc: 15.402,24.665,58.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.400 | Acc: 15.358,24.295,57.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.389 | Acc: 15.241,24.308,58.184,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 145
Batch: 0 | Loss: 1.601 | Acc: 17.969,27.344,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.452 | Acc: 19.308,33.222,78.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.459 | Acc: 20.084,33.479,78.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.456 | Acc: 19.980,33.568,78.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.457 | Acc: 19.859,33.632,78.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.456 | Acc: 19.756,33.516,78.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.463 | Acc: 19.919,33.587,78.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.469 | Acc: 19.842,33.688,77.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.475 | Acc: 19.910,33.909,77.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.479 | Acc: 19.812,33.658,77.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.486 | Acc: 19.873,33.714,77.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.492 | Acc: 19.892,33.512,77.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.498 | Acc: 20.005,33.574,77.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.504 | Acc: 19.983,33.471,76.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.509 | Acc: 19.934,33.452,76.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 19.915,33.443,76.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.517 | Acc: 19.938,33.501,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.522 | Acc: 19.850,33.564,76.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.526 | Acc: 19.813,33.477,76.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 19.755,33.405,76.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.393 | Acc: 18.750,28.906,51.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.306 | Acc: 16.853,28.423,59.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.357 | Acc: 16.406,27.706,59.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.378 | Acc: 16.457,27.638,59.042,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 146
Batch: 0 | Loss: 1.393 | Acc: 20.312,35.938,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.477 | Acc: 20.312,33.147,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 19.074,32.489,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.470 | Acc: 19.339,33.210,77.779,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.479 | Acc: 19.213,33.227,77.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.482 | Acc: 19.678,33.509,77.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.484 | Acc: 19.415,33.484,77.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.489 | Acc: 19.703,33.760,77.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.491 | Acc: 19.740,33.773,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.492 | Acc: 19.730,33.702,77.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.496 | Acc: 19.858,33.784,77.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.500 | Acc: 19.853,33.654,76.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.502 | Acc: 19.833,33.704,76.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.507 | Acc: 19.690,33.618,76.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.511 | Acc: 19.779,33.624,76.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.512 | Acc: 19.947,33.661,76.614,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.516 | Acc: 19.867,33.633,76.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.518 | Acc: 19.930,33.656,76.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.521 | Acc: 19.938,33.607,76.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.523 | Acc: 19.964,33.602,76.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.273 | Acc: 12.500,31.250,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.260 | Acc: 15.030,30.469,61.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.305 | Acc: 14.272,29.345,59.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.313 | Acc: 14.357,28.855,60.041,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 147
Batch: 0 | Loss: 1.484 | Acc: 18.750,28.125,79.688,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.506 | Acc: 19.345,31.585,77.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.488 | Acc: 19.569,32.317,77.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.472 | Acc: 19.160,32.300,78.125,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.480 | Acc: 19.126,32.321,77.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.480 | Acc: 19.183,32.782,77.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.483 | Acc: 19.363,33.006,77.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.484 | Acc: 19.188,33.189,77.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.488 | Acc: 19.556,33.346,77.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.490 | Acc: 19.639,33.581,77.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.492 | Acc: 19.582,33.660,77.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 19.666,33.583,77.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.506 | Acc: 19.641,33.516,76.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.510 | Acc: 19.681,33.549,76.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.513 | Acc: 19.773,33.585,76.668,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.516 | Acc: 19.806,33.617,76.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.521 | Acc: 19.901,33.579,76.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 19.918,33.525,76.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.530 | Acc: 19.873,33.483,76.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.532 | Acc: 19.872,33.510,76.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.970 | Acc: 18.750,39.062,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.183 | Acc: 15.104,28.385,63.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.215 | Acc: 15.244,27.934,62.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.221 | Acc: 15.113,27.779,62.257,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 148
Batch: 0 | Loss: 1.321 | Acc: 15.625,27.344,78.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.470 | Acc: 18.080,30.952,77.716,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.492 | Acc: 18.312,31.612,77.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.492 | Acc: 18.788,32.364,77.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.492 | Acc: 19.126,32.649,77.257,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.486 | Acc: 18.905,32.743,77.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 19.092,32.890,77.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.485 | Acc: 19.143,33.134,77.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.487 | Acc: 19.143,33.152,77.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.485 | Acc: 19.294,33.326,77.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.492 | Acc: 19.333,33.337,77.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.498 | Acc: 19.362,33.396,77.252,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.499 | Acc: 19.512,33.471,77.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.502 | Acc: 19.564,33.474,77.149,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.503 | Acc: 19.553,33.524,77.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.509 | Acc: 19.625,33.612,76.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.513 | Acc: 19.638,33.557,76.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.513 | Acc: 19.630,33.585,76.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.515 | Acc: 19.657,33.613,76.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.516 | Acc: 19.660,33.637,76.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.119 | Acc: 16.406,34.375,62.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.212 | Acc: 16.220,29.948,62.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.233 | Acc: 16.082,29.688,61.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.244 | Acc: 16.163,29.585,61.655,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 149
Batch: 0 | Loss: 1.375 | Acc: 19.531,28.125,77.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.483 | Acc: 19.643,34.524,76.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.496 | Acc: 20.008,33.803,76.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.493 | Acc: 19.685,33.863,76.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.495 | Acc: 19.927,33.941,76.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.489 | Acc: 19.957,33.810,77.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.488 | Acc: 20.235,33.910,77.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.488 | Acc: 20.047,33.771,77.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.490 | Acc: 20.065,33.851,76.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.500 | Acc: 19.902,33.702,76.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.505 | Acc: 19.982,33.675,76.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.508 | Acc: 20.058,33.795,76.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.510 | Acc: 19.998,33.662,76.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.513 | Acc: 19.950,33.582,76.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.516 | Acc: 19.948,33.521,76.329,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.518 | Acc: 19.996,33.547,76.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.521 | Acc: 19.996,33.567,76.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.524 | Acc: 19.960,33.479,76.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.525 | Acc: 19.966,33.509,76.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.527 | Acc: 19.898,33.493,75.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.422 | Acc: 15.625,33.594,58.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.378 | Acc: 17.932,29.129,60.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.393 | Acc: 17.111,29.040,59.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.376 | Acc: 16.906,29.098,59.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 150
Batch: 0 | Loss: 1.569 | Acc: 17.969,35.938,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.536 | Acc: 19.531,31.622,76.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.452 | Acc: 19.550,32.965,78.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.406 | Acc: 20.005,33.491,79.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.378 | Acc: 20.129,34.327,80.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.359 | Acc: 20.235,34.746,80.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.344 | Acc: 20.293,34.879,81.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.332 | Acc: 20.263,34.984,81.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.323 | Acc: 20.269,35.079,81.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.313 | Acc: 20.321,35.143,82.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.306 | Acc: 20.386,35.218,82.451,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.298 | Acc: 20.472,35.358,82.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.292 | Acc: 20.410,35.383,82.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.282 | Acc: 20.432,35.506,83.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.277 | Acc: 20.343,35.573,83.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.273 | Acc: 20.411,35.717,83.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.269 | Acc: 20.451,35.699,83.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.264 | Acc: 20.459,35.782,83.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.260 | Acc: 20.503,35.918,83.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.254 | Acc: 20.522,36.001,83.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.739 | Acc: 21.875,40.625,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.747 | Acc: 20.052,38.356,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.752 | Acc: 20.160,37.309,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.758 | Acc: 20.338,37.346,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 151
Batch: 0 | Loss: 1.040 | Acc: 24.219,45.312,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.151 | Acc: 19.271,36.421,87.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.142 | Acc: 20.522,37.252,87.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.148 | Acc: 21.145,37.449,87.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.148 | Acc: 21.393,37.365,87.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.149 | Acc: 21.272,37.608,87.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.150 | Acc: 21.016,37.558,86.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.151 | Acc: 20.944,37.345,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.151 | Acc: 20.856,37.262,86.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.149 | Acc: 20.882,37.366,86.913,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.148 | Acc: 20.903,37.267,86.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.148 | Acc: 20.906,37.256,86.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.148 | Acc: 20.938,37.224,86.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.147 | Acc: 20.983,37.192,86.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.146 | Acc: 21.172,37.166,86.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.146 | Acc: 21.195,37.067,86.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.146 | Acc: 21.152,37.057,86.948,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.147 | Acc: 21.142,37.049,86.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.145 | Acc: 21.035,37.037,87.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.144 | Acc: 20.999,37.071,87.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.708 | Acc: 22.656,40.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.742 | Acc: 20.201,37.277,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.744 | Acc: 20.084,36.623,71.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.755 | Acc: 20.120,36.757,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 152
Batch: 0 | Loss: 1.155 | Acc: 17.188,34.375,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.101 | Acc: 20.759,36.533,88.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.099 | Acc: 21.189,36.414,88.605,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.098 | Acc: 21.055,36.898,88.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.103 | Acc: 20.824,37.027,88.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.101 | Acc: 20.831,37.183,88.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.099 | Acc: 21.120,37.268,88.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.099 | Acc: 20.966,37.073,88.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.098 | Acc: 20.900,37.126,88.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.099 | Acc: 20.917,37.267,88.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.100 | Acc: 21.090,37.457,88.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.102 | Acc: 21.133,37.436,88.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.105 | Acc: 20.971,37.335,88.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.105 | Acc: 21.055,37.353,88.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.105 | Acc: 20.983,37.361,88.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.105 | Acc: 20.980,37.383,88.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.105 | Acc: 21.001,37.446,88.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.106 | Acc: 21.030,37.440,88.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.105 | Acc: 21.042,37.426,88.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.105 | Acc: 21.051,37.471,88.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.692 | Acc: 22.656,44.531,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.738 | Acc: 19.978,39.025,72.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.747 | Acc: 20.122,37.595,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.754 | Acc: 20.056,37.513,72.029,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 153
Batch: 0 | Loss: 0.960 | Acc: 25.000,45.312,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.069 | Acc: 20.833,38.058,90.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.070 | Acc: 21.094,37.100,89.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.072 | Acc: 20.825,36.872,89.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.074 | Acc: 20.669,36.661,89.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.074 | Acc: 20.583,36.765,89.155,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.076 | Acc: 20.571,36.861,89.153,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.075 | Acc: 20.772,37.273,89.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.075 | Acc: 20.909,37.384,89.116,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.078 | Acc: 20.969,37.366,88.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.079 | Acc: 21.016,37.473,88.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.080 | Acc: 21.055,37.408,88.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.080 | Acc: 21.048,37.351,88.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.080 | Acc: 21.145,37.362,88.793,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.079 | Acc: 21.066,37.478,88.821,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.078 | Acc: 21.120,37.521,88.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.078 | Acc: 21.128,37.568,88.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.078 | Acc: 21.149,37.495,88.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.077 | Acc: 21.131,37.550,88.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.078 | Acc: 21.204,37.551,88.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.738 | Acc: 21.094,40.625,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.753 | Acc: 20.610,38.393,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.763 | Acc: 20.351,37.195,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.770 | Acc: 20.287,37.462,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 154
Batch: 0 | Loss: 0.983 | Acc: 22.656,36.719,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.038 | Acc: 21.801,38.356,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.055 | Acc: 21.723,38.453,89.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.050 | Acc: 21.824,38.320,90.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.059 | Acc: 21.316,37.818,89.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.057 | Acc: 21.457,38.374,89.712,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.055 | Acc: 21.262,38.165,89.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.055 | Acc: 21.254,38.004,89.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.054 | Acc: 21.283,37.961,89.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.052 | Acc: 21.357,38.096,89.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.054 | Acc: 21.362,38.095,89.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.055 | Acc: 21.345,37.942,89.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.055 | Acc: 21.259,37.873,89.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.055 | Acc: 21.205,37.925,89.727,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.056 | Acc: 21.183,37.906,89.696,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.056 | Acc: 21.205,37.874,89.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.056 | Acc: 21.206,37.931,89.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.058 | Acc: 21.117,37.901,89.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.058 | Acc: 21.180,37.903,89.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.059 | Acc: 21.118,37.957,89.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.717 | Acc: 21.875,42.969,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.764 | Acc: 20.647,38.988,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.767 | Acc: 20.484,37.843,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.772 | Acc: 20.607,37.782,71.734,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 155
Batch: 0 | Loss: 1.053 | Acc: 14.844,33.594,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.054 | Acc: 22.359,37.835,90.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.042 | Acc: 21.780,38.567,90.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.041 | Acc: 21.478,38.717,90.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.041 | Acc: 21.373,38.831,90.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.038 | Acc: 21.372,38.892,90.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.036 | Acc: 21.313,38.804,90.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.038 | Acc: 21.376,38.808,90.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.037 | Acc: 21.453,38.830,90.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.039 | Acc: 21.314,38.734,90.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.040 | Acc: 21.319,38.616,90.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.040 | Acc: 21.433,38.649,90.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.042 | Acc: 21.334,38.609,90.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.042 | Acc: 21.270,38.476,90.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.042 | Acc: 21.327,38.451,90.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.042 | Acc: 21.361,38.468,90.059,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.042 | Acc: 21.374,38.393,89.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.042 | Acc: 21.364,38.366,90.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.043 | Acc: 21.334,38.415,90.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.043 | Acc: 21.295,38.449,90.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.702 | Acc: 21.875,44.531,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.754 | Acc: 19.792,38.839,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.765 | Acc: 20.084,37.824,71.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.771 | Acc: 20.325,37.884,71.901,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 156
Batch: 0 | Loss: 1.087 | Acc: 20.312,36.719,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.020 | Acc: 21.429,38.095,90.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.024 | Acc: 21.322,38.110,90.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.031 | Acc: 21.068,37.987,90.318,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.035 | Acc: 21.094,38.117,90.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.031 | Acc: 21.094,38.227,90.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.029 | Acc: 21.197,38.268,90.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.032 | Acc: 21.288,38.237,90.281,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.033 | Acc: 21.463,38.087,90.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.034 | Acc: 21.305,37.841,90.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.033 | Acc: 21.311,37.889,90.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.032 | Acc: 21.309,37.878,90.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.032 | Acc: 21.431,38.022,90.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.033 | Acc: 21.474,38.114,90.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.033 | Acc: 21.561,38.103,90.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.034 | Acc: 21.634,38.185,90.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.034 | Acc: 21.624,38.206,90.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.033 | Acc: 21.660,38.201,90.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.035 | Acc: 21.563,38.052,90.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.035 | Acc: 21.528,38.119,90.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.750 | Acc: 21.875,41.406,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.769 | Acc: 20.685,39.993,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.782 | Acc: 20.617,38.472,71.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.785 | Acc: 20.581,38.448,71.619,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 157
Batch: 0 | Loss: 1.038 | Acc: 22.656,38.281,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.040 | Acc: 21.317,39.025,89.918,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.022 | Acc: 21.570,38.967,90.587,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.023 | Acc: 21.952,39.216,90.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.019 | Acc: 22.068,39.169,90.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.022 | Acc: 22.200,38.939,90.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.021 | Acc: 22.166,39.017,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.019 | Acc: 22.069,39.062,90.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.022 | Acc: 21.928,39.048,90.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.021 | Acc: 21.931,39.101,90.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.023 | Acc: 21.859,38.993,90.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.023 | Acc: 21.857,38.932,90.664,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.024 | Acc: 21.856,38.878,90.657,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.022 | Acc: 21.749,38.784,90.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.023 | Acc: 21.789,38.776,90.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.024 | Acc: 21.802,38.720,90.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.024 | Acc: 21.714,38.700,90.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.023 | Acc: 21.703,38.673,90.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.022 | Acc: 21.708,38.690,90.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.024 | Acc: 21.635,38.556,90.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.719 | Acc: 21.875,43.750,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.757 | Acc: 20.796,39.546,72.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.780 | Acc: 20.598,38.224,72.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.787 | Acc: 20.876,38.230,72.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 158
Batch: 0 | Loss: 1.122 | Acc: 18.750,33.594,86.719,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.018 | Acc: 20.796,36.756,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.016 | Acc: 20.713,37.862,91.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.010 | Acc: 21.068,37.987,91.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 1.011 | Acc: 21.113,37.722,91.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 1.007 | Acc: 21.148,38.011,91.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 1.004 | Acc: 21.087,38.094,91.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 1.004 | Acc: 21.094,38.265,91.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 1.003 | Acc: 21.283,38.306,91.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 1.002 | Acc: 21.387,38.480,91.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 1.004 | Acc: 21.397,38.487,91.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 1.004 | Acc: 21.391,38.462,91.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 1.004 | Acc: 21.434,38.615,91.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 1.006 | Acc: 21.423,38.476,91.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 1.006 | Acc: 21.452,38.423,91.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 1.007 | Acc: 21.527,38.489,91.191,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 1.008 | Acc: 21.408,38.381,91.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.010 | Acc: 21.437,38.400,91.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 1.010 | Acc: 21.405,38.413,91.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.011 | Acc: 21.457,38.423,91.052,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.755 | Acc: 20.312,43.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.762 | Acc: 20.499,39.435,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.788 | Acc: 20.465,38.072,71.437,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.797 | Acc: 20.505,38.076,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 159
Batch: 0 | Loss: 0.960 | Acc: 17.969,32.031,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.992 | Acc: 20.796,37.165,91.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.985 | Acc: 20.351,38.567,92.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.992 | Acc: 20.863,38.563,91.931,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.990 | Acc: 21.190,38.966,91.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.987 | Acc: 21.163,38.985,91.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.989 | Acc: 21.429,39.050,91.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.986 | Acc: 21.437,39.074,91.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.988 | Acc: 21.336,38.990,91.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.990 | Acc: 21.448,38.877,91.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.992 | Acc: 21.432,38.779,91.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.993 | Acc: 21.458,38.751,91.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.995 | Acc: 21.473,38.813,91.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.997 | Acc: 21.525,38.874,91.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.997 | Acc: 21.614,38.846,91.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.998 | Acc: 21.509,38.816,91.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.999 | Acc: 21.456,38.865,91.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 1.000 | Acc: 21.458,38.827,91.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.999 | Acc: 21.455,38.773,91.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 1.000 | Acc: 21.477,38.804,91.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.727 | Acc: 22.656,43.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.785 | Acc: 20.573,40.141,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.798 | Acc: 20.655,39.043,71.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.803 | Acc: 21.145,38.947,71.824,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 160
Batch: 0 | Loss: 0.939 | Acc: 24.219,42.188,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.987 | Acc: 19.792,38.095,91.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.981 | Acc: 20.484,38.662,91.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.982 | Acc: 21.171,39.267,91.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.982 | Acc: 21.017,38.609,91.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.987 | Acc: 21.009,38.761,91.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.992 | Acc: 20.848,38.494,91.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.991 | Acc: 21.055,38.531,91.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.988 | Acc: 21.118,38.684,91.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.987 | Acc: 21.292,38.670,91.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.988 | Acc: 21.335,38.584,91.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.987 | Acc: 21.490,38.642,91.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.988 | Acc: 21.424,38.602,91.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.986 | Acc: 21.510,38.631,91.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.987 | Acc: 21.578,38.634,91.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.988 | Acc: 21.579,38.634,91.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.988 | Acc: 21.512,38.627,91.552,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.989 | Acc: 21.534,38.629,91.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.990 | Acc: 21.507,38.677,91.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.990 | Acc: 21.604,38.730,91.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.742 | Acc: 21.875,45.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.777 | Acc: 20.908,40.662,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.801 | Acc: 20.732,39.082,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.803 | Acc: 20.940,39.037,72.067,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 161
Batch: 0 | Loss: 0.931 | Acc: 23.438,41.406,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.997 | Acc: 22.321,37.984,91.667,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.979 | Acc: 22.332,38.586,92.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.981 | Acc: 21.926,38.640,91.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.976 | Acc: 22.184,38.918,92.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.975 | Acc: 22.223,38.846,92.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.973 | Acc: 22.191,38.753,92.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.972 | Acc: 22.069,38.957,92.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.972 | Acc: 21.933,39.048,92.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.975 | Acc: 21.771,38.855,92.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.977 | Acc: 21.723,38.860,92.067,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.975 | Acc: 21.744,39.020,92.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.977 | Acc: 21.645,38.913,92.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.978 | Acc: 21.642,38.850,92.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.979 | Acc: 21.611,38.935,91.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.980 | Acc: 21.670,38.909,91.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.980 | Acc: 21.753,38.870,91.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.980 | Acc: 21.703,38.845,91.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.981 | Acc: 21.641,38.777,91.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.980 | Acc: 21.688,38.849,91.946,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.685 | Acc: 21.094,43.750,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 20.759,40.216,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.814 | Acc: 20.732,38.700,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.818 | Acc: 20.876,38.422,71.696,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 162
Batch: 0 | Loss: 0.980 | Acc: 20.312,36.719,89.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.990 | Acc: 22.061,38.690,91.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.974 | Acc: 21.894,38.567,92.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.974 | Acc: 21.926,38.909,92.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.969 | Acc: 21.885,38.956,92.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.970 | Acc: 21.906,38.854,92.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.968 | Acc: 21.843,38.979,92.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.967 | Acc: 21.648,39.184,92.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.968 | Acc: 21.574,39.160,92.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.968 | Acc: 21.599,39.088,92.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.968 | Acc: 21.685,39.195,92.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.972 | Acc: 21.575,39.119,92.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.971 | Acc: 21.629,39.212,92.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.972 | Acc: 21.686,39.128,92.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.972 | Acc: 21.703,39.151,92.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.971 | Acc: 21.665,39.148,92.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.972 | Acc: 21.714,39.084,92.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.972 | Acc: 21.687,39.042,92.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.973 | Acc: 21.724,39.065,92.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.973 | Acc: 21.748,38.980,92.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.770 | Acc: 22.656,46.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.784 | Acc: 20.871,40.439,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.807 | Acc: 20.922,39.082,71.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.809 | Acc: 20.914,39.024,72.170,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 163
Batch: 0 | Loss: 0.917 | Acc: 19.531,37.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.948 | Acc: 22.024,39.881,92.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.968 | Acc: 21.532,38.453,92.397,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.971 | Acc: 21.183,38.665,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.967 | Acc: 21.152,38.561,92.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.965 | Acc: 21.604,38.815,92.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.967 | Acc: 21.462,38.901,92.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.967 | Acc: 21.459,38.941,92.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.966 | Acc: 21.598,38.999,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.967 | Acc: 21.551,39.002,92.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.967 | Acc: 21.661,39.055,92.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.968 | Acc: 21.681,38.946,92.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.967 | Acc: 21.680,38.988,92.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.967 | Acc: 21.785,39.003,92.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.966 | Acc: 21.803,39.032,92.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.967 | Acc: 21.724,39.062,92.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.968 | Acc: 21.753,39.075,92.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.968 | Acc: 21.715,39.040,92.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.968 | Acc: 21.741,39.069,92.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.969 | Acc: 21.746,39.056,92.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.843 | Acc: 22.656,46.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.800 | Acc: 20.871,40.551,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.818 | Acc: 20.979,39.215,71.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.826 | Acc: 21.081,39.203,71.837,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 164
Batch: 0 | Loss: 0.862 | Acc: 17.969,38.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.919 | Acc: 21.652,39.658,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.924 | Acc: 22.027,39.844,93.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.940 | Acc: 21.619,39.088,93.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.953 | Acc: 21.441,38.927,93.007,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.957 | Acc: 21.403,38.722,92.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.959 | Acc: 21.539,38.843,92.639,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.961 | Acc: 21.731,38.996,92.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.964 | Acc: 21.763,38.970,92.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.965 | Acc: 21.728,38.864,92.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.964 | Acc: 21.688,39.109,92.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.967 | Acc: 21.688,39.140,92.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.966 | Acc: 21.697,39.072,92.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.967 | Acc: 21.698,39.048,92.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.967 | Acc: 21.730,39.107,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.966 | Acc: 21.792,39.239,92.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.964 | Acc: 21.751,39.306,92.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.966 | Acc: 21.781,39.353,92.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.966 | Acc: 21.775,39.344,92.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.965 | Acc: 21.789,39.350,92.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.799 | Acc: 21.875,46.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.788 | Acc: 21.391,40.588,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.814 | Acc: 21.151,39.367,71.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.820 | Acc: 21.247,39.472,71.990,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 165
Batch: 0 | Loss: 0.940 | Acc: 18.750,41.406,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.954 | Acc: 21.354,39.286,92.783,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 21.094,39.539,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.955 | Acc: 21.555,39.600,92.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.955 | Acc: 21.856,39.342,92.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.952 | Acc: 21.983,39.295,92.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.953 | Acc: 21.720,39.088,92.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.954 | Acc: 21.531,39.190,92.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.954 | Acc: 21.530,39.446,92.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.951 | Acc: 21.638,39.524,92.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.949 | Acc: 21.583,39.482,92.914,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.950 | Acc: 21.592,39.483,92.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.950 | Acc: 21.651,39.542,92.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.953 | Acc: 21.612,39.401,92.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.953 | Acc: 21.628,39.527,92.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.953 | Acc: 21.628,39.465,92.746,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.953 | Acc: 21.680,39.510,92.742,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.953 | Acc: 21.795,39.567,92.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.953 | Acc: 21.808,39.634,92.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.954 | Acc: 21.781,39.592,92.665,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.736 | Acc: 22.656,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.798 | Acc: 20.982,40.290,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.823 | Acc: 21.037,39.272,71.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.826 | Acc: 21.145,39.229,72.144,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 166
Batch: 0 | Loss: 0.958 | Acc: 23.438,34.375,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.941 | Acc: 21.987,39.360,93.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.949 | Acc: 22.161,39.139,92.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.947 | Acc: 22.016,39.460,93.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.945 | Acc: 21.991,40.017,93.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.946 | Acc: 21.890,39.720,93.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.948 | Acc: 21.668,39.560,93.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.946 | Acc: 21.681,39.700,93.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.947 | Acc: 21.725,39.494,93.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.944 | Acc: 21.784,39.675,93.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.945 | Acc: 21.751,39.517,93.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.945 | Acc: 21.737,39.483,93.082,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.945 | Acc: 21.638,39.468,93.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.944 | Acc: 21.728,39.511,93.139,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.945 | Acc: 21.739,39.471,93.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.945 | Acc: 21.704,39.486,93.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.945 | Acc: 21.787,39.559,93.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.946 | Acc: 21.827,39.532,93.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.947 | Acc: 21.866,39.513,92.984,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.947 | Acc: 21.863,39.522,92.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.813 | Acc: 21.875,42.969,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 20.833,40.365,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.851 | Acc: 20.598,39.043,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.851 | Acc: 20.722,38.998,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 167
Batch: 0 | Loss: 0.933 | Acc: 18.750,44.531,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.940 | Acc: 21.243,39.621,93.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.931 | Acc: 21.380,39.558,93.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.936 | Acc: 21.491,39.306,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.934 | Acc: 21.923,39.497,93.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.933 | Acc: 21.929,39.550,93.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.937 | Acc: 21.830,39.463,93.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.939 | Acc: 21.803,39.351,93.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.938 | Acc: 21.773,39.354,93.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.940 | Acc: 21.707,39.516,93.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.941 | Acc: 21.762,39.529,93.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.943 | Acc: 21.709,39.575,93.096,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.943 | Acc: 21.726,39.614,93.053,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.943 | Acc: 21.674,39.538,93.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.942 | Acc: 21.666,39.571,93.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.944 | Acc: 21.631,39.512,93.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.944 | Acc: 21.602,39.530,92.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.945 | Acc: 21.605,39.544,93.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.944 | Acc: 21.741,39.575,92.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.945 | Acc: 21.758,39.505,92.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.889 | Acc: 21.875,44.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.827 | Acc: 21.057,40.848,71.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.847 | Acc: 20.846,39.444,71.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.850 | Acc: 20.889,39.549,71.644,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 168
Batch: 0 | Loss: 0.880 | Acc: 22.656,43.750,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.922 | Acc: 22.879,40.588,93.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.929 | Acc: 22.504,40.339,93.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.933 | Acc: 22.118,39.690,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.940 | Acc: 21.769,39.612,93.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.935 | Acc: 21.945,39.921,93.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.934 | Acc: 21.901,39.824,93.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.934 | Acc: 21.803,39.689,93.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.933 | Acc: 21.851,39.786,93.517,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.935 | Acc: 21.901,39.796,93.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.936 | Acc: 21.945,39.758,93.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.934 | Acc: 21.960,39.784,93.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.936 | Acc: 21.872,39.698,93.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.936 | Acc: 21.935,39.655,93.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.937 | Acc: 21.875,39.616,93.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.937 | Acc: 21.839,39.532,93.262,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.937 | Acc: 21.863,39.503,93.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.937 | Acc: 21.831,39.406,93.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.937 | Acc: 21.888,39.506,93.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.937 | Acc: 21.877,39.483,93.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.913 | Acc: 20.312,44.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.842 | Acc: 20.796,40.699,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.855 | Acc: 20.694,39.787,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 20.774,39.677,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 169
Batch: 0 | Loss: 0.898 | Acc: 17.969,48.438,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.922 | Acc: 21.429,38.988,93.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.933 | Acc: 21.608,39.520,93.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.921 | Acc: 21.990,39.985,93.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.920 | Acc: 21.914,39.988,93.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.917 | Acc: 22.107,40.300,93.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.916 | Acc: 21.765,40.121,93.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.922 | Acc: 21.664,40.121,93.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.926 | Acc: 21.768,40.106,93.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.928 | Acc: 21.668,39.991,93.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.927 | Acc: 21.650,39.883,93.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.928 | Acc: 21.787,39.960,93.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.928 | Acc: 21.917,39.980,93.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.929 | Acc: 21.905,39.949,93.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.929 | Acc: 21.894,39.877,93.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.930 | Acc: 21.883,39.846,93.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.932 | Acc: 21.880,39.849,93.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.932 | Acc: 21.845,39.695,93.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.932 | Acc: 21.793,39.707,93.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.932 | Acc: 21.795,39.708,93.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.905 | Acc: 22.656,44.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.838 | Acc: 20.759,40.774,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 20.922,39.501,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.866 | Acc: 20.966,39.434,71.568,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 170
Batch: 0 | Loss: 0.878 | Acc: 23.438,39.844,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.934 | Acc: 22.507,39.955,93.378,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.923 | Acc: 21.894,39.310,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.919 | Acc: 21.734,39.447,93.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.917 | Acc: 21.624,39.506,93.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.921 | Acc: 21.550,39.395,93.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.922 | Acc: 21.707,39.728,93.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.923 | Acc: 21.903,39.822,93.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.923 | Acc: 21.788,39.752,93.653,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.922 | Acc: 21.910,39.826,93.677,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.924 | Acc: 21.852,39.681,93.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.924 | Acc: 21.836,39.593,93.644,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.924 | Acc: 21.732,39.623,93.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.926 | Acc: 21.710,39.631,93.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.927 | Acc: 21.725,39.746,93.497,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.928 | Acc: 21.701,39.737,93.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.927 | Acc: 21.765,39.822,93.529,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.928 | Acc: 21.793,39.860,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.929 | Acc: 21.758,39.846,93.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.929 | Acc: 21.777,39.895,93.403,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.905 | Acc: 21.875,44.531,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.820 | Acc: 21.317,41.071,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.862 | Acc: 21.037,39.520,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.867 | Acc: 21.183,39.562,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 171
Batch: 0 | Loss: 0.942 | Acc: 26.562,42.188,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.917 | Acc: 21.838,39.360,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.909 | Acc: 21.723,39.253,94.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.916 | Acc: 22.131,39.549,93.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.916 | Acc: 21.836,39.564,93.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.917 | Acc: 22.022,39.851,93.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.917 | Acc: 22.127,40.037,93.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.918 | Acc: 22.058,39.833,93.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.921 | Acc: 22.059,39.795,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.920 | Acc: 22.121,39.883,93.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.921 | Acc: 22.050,39.836,93.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.922 | Acc: 22.016,39.918,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.923 | Acc: 21.869,39.841,93.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.923 | Acc: 21.797,39.859,93.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.923 | Acc: 21.792,39.752,93.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.924 | Acc: 21.787,39.776,93.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.924 | Acc: 21.787,39.798,93.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.925 | Acc: 21.703,39.743,93.454,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.924 | Acc: 21.791,39.822,93.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.924 | Acc: 21.875,39.899,93.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.873 | Acc: 22.656,46.094,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.816 | Acc: 21.354,41.109,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.853 | Acc: 21.189,39.768,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.855 | Acc: 21.260,39.793,71.965,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 172
Batch: 0 | Loss: 0.852 | Acc: 19.531,37.500,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.939 | Acc: 21.801,39.137,93.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.925 | Acc: 21.456,39.463,93.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.921 | Acc: 21.734,39.831,93.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.919 | Acc: 21.779,39.747,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.918 | Acc: 21.782,39.998,93.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.922 | Acc: 21.869,40.057,93.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.921 | Acc: 21.897,39.977,93.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.920 | Acc: 21.933,40.028,93.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.920 | Acc: 21.875,39.913,93.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.920 | Acc: 21.914,40.034,93.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.919 | Acc: 22.006,40.119,93.725,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.919 | Acc: 21.985,40.213,93.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.920 | Acc: 21.989,40.257,93.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.919 | Acc: 21.942,40.233,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.919 | Acc: 21.966,40.147,93.714,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.919 | Acc: 21.921,40.160,93.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.918 | Acc: 21.964,40.123,93.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.918 | Acc: 22.042,40.192,93.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.919 | Acc: 22.012,40.164,93.707,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.908 | Acc: 23.438,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.847 | Acc: 21.317,41.704,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.868 | Acc: 21.189,40.111,71.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.875 | Acc: 21.273,39.921,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 173
Batch: 0 | Loss: 0.911 | Acc: 20.312,48.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.892 | Acc: 20.647,38.430,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.907 | Acc: 21.399,39.043,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.915 | Acc: 21.350,39.216,93.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.912 | Acc: 21.547,39.593,93.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.912 | Acc: 21.558,39.403,93.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.912 | Acc: 21.636,39.379,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.911 | Acc: 21.753,39.417,93.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.913 | Acc: 21.899,39.587,93.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.913 | Acc: 22.099,39.865,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.912 | Acc: 22.108,40.011,93.937,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.913 | Acc: 22.031,39.939,93.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.913 | Acc: 22.086,39.944,93.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.913 | Acc: 21.992,39.868,93.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.913 | Acc: 22.000,39.816,93.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.913 | Acc: 22.023,39.870,93.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.912 | Acc: 22.062,39.919,93.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.913 | Acc: 22.102,40.002,93.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.913 | Acc: 22.141,40.058,93.886,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.913 | Acc: 22.033,40.022,93.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.872 | Acc: 21.875,46.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.857 | Acc: 20.833,40.588,71.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.884 | Acc: 20.846,39.768,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.886 | Acc: 21.055,39.690,71.299,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 174
Batch: 0 | Loss: 0.998 | Acc: 21.094,38.281,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 21.280,40.141,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.898 | Acc: 21.322,39.787,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.897 | Acc: 21.555,39.844,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.899 | Acc: 21.856,40.297,94.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.899 | Acc: 22.192,40.463,94.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.904 | Acc: 22.153,40.083,94.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.907 | Acc: 22.036,40.004,94.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.907 | Acc: 22.098,40.072,94.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.905 | Acc: 22.117,40.353,94.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.905 | Acc: 22.093,40.291,94.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.905 | Acc: 22.225,40.300,94.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.908 | Acc: 22.089,40.187,94.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.909 | Acc: 22.073,40.179,93.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.911 | Acc: 22.056,40.100,93.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.911 | Acc: 22.057,39.999,93.942,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.911 | Acc: 21.980,40.073,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.912 | Acc: 21.962,39.951,93.936,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.911 | Acc: 21.990,40.008,93.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.911 | Acc: 22.064,40.057,93.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.926 | Acc: 22.656,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.859 | Acc: 21.354,40.737,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.886 | Acc: 21.189,39.577,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.884 | Acc: 21.286,39.741,71.862,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 175
Batch: 0 | Loss: 0.937 | Acc: 27.344,53.125,90.625,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.884 | Acc: 22.693,42.932,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.890 | Acc: 21.970,41.178,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.892 | Acc: 22.208,41.048,94.493,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.899 | Acc: 22.328,40.934,94.348,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.901 | Acc: 22.378,40.517,94.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.897 | Acc: 22.379,40.431,94.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.896 | Acc: 22.346,40.265,94.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.893 | Acc: 22.258,40.251,94.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.894 | Acc: 22.186,40.293,94.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.897 | Acc: 22.058,40.248,94.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.899 | Acc: 22.087,40.197,94.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.900 | Acc: 22.066,40.275,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.900 | Acc: 22.111,40.272,94.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.901 | Acc: 22.175,40.316,94.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.901 | Acc: 22.176,40.415,94.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.902 | Acc: 22.089,40.411,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.903 | Acc: 22.026,40.316,94.146,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.904 | Acc: 22.007,40.272,94.127,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.904 | Acc: 21.947,40.225,94.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.846 | Acc: 22.656,47.656,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.875 | Acc: 21.391,40.885,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.897 | Acc: 21.189,39.710,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.909 | Acc: 21.299,39.408,70.863,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 176
Batch: 0 | Loss: 0.891 | Acc: 19.531,35.156,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.892 | Acc: 22.805,41.109,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.897 | Acc: 22.447,40.777,94.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.900 | Acc: 22.349,40.138,94.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.897 | Acc: 22.704,40.307,94.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.895 | Acc: 22.339,40.207,94.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.897 | Acc: 21.965,39.986,94.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.896 | Acc: 21.820,40.021,94.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.895 | Acc: 21.720,39.975,94.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.897 | Acc: 21.612,39.883,94.195,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.898 | Acc: 21.603,39.871,94.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.899 | Acc: 21.596,39.858,94.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.898 | Acc: 21.661,39.892,94.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.900 | Acc: 21.842,39.937,94.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.901 | Acc: 21.842,39.986,94.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.902 | Acc: 21.878,40.093,94.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.902 | Acc: 21.875,40.160,94.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.902 | Acc: 21.912,40.208,94.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.903 | Acc: 21.923,40.171,94.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.901 | Acc: 21.963,40.172,94.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.865 | Acc: 22.656,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.863 | Acc: 21.280,40.848,72.098,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.892 | Acc: 21.151,39.577,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.901 | Acc: 21.388,39.613,70.991,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 177
Batch: 0 | Loss: 0.874 | Acc: 14.062,46.094,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.892 | Acc: 22.805,41.778,94.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.883 | Acc: 21.532,40.873,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.887 | Acc: 21.350,40.625,94.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.892 | Acc: 21.422,40.374,94.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.896 | Acc: 21.357,40.084,94.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.897 | Acc: 21.591,40.438,94.641,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.895 | Acc: 21.681,40.536,94.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.898 | Acc: 21.700,40.450,94.478,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.897 | Acc: 21.810,40.595,94.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.897 | Acc: 21.797,40.403,94.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.898 | Acc: 21.847,40.409,94.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.898 | Acc: 21.836,40.314,94.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.897 | Acc: 21.818,40.212,94.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.897 | Acc: 21.797,40.163,94.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.897 | Acc: 21.924,40.246,94.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.899 | Acc: 21.892,40.107,94.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.900 | Acc: 21.854,39.995,94.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.900 | Acc: 21.923,40.041,94.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.901 | Acc: 21.961,40.108,94.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 23.438,46.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.871 | Acc: 21.243,41.332,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.899 | Acc: 21.189,39.748,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.896 | Acc: 21.311,39.959,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 178
Batch: 0 | Loss: 0.855 | Acc: 28.125,50.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.880 | Acc: 23.214,40.737,94.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.889 | Acc: 22.809,40.244,94.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.895 | Acc: 22.285,39.664,94.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.896 | Acc: 21.991,39.776,94.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.899 | Acc: 21.697,39.527,94.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.895 | Acc: 21.623,39.728,94.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.895 | Acc: 21.692,39.827,94.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.895 | Acc: 21.885,39.897,94.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.896 | Acc: 21.914,40.038,94.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.896 | Acc: 21.906,40.003,94.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.896 | Acc: 22.048,40.144,94.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.895 | Acc: 22.134,40.194,94.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.893 | Acc: 22.210,40.272,94.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.894 | Acc: 22.192,40.241,94.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.895 | Acc: 22.184,40.147,94.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.896 | Acc: 22.238,40.236,94.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.896 | Acc: 22.228,40.210,94.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.896 | Acc: 22.267,40.322,94.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.897 | Acc: 22.219,40.285,94.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.953 | Acc: 23.438,44.531,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.901 | Acc: 20.945,40.365,70.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.920 | Acc: 21.208,39.882,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.917 | Acc: 21.388,40.036,70.748,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 179
Batch: 0 | Loss: 0.833 | Acc: 24.219,49.219,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.884 | Acc: 22.507,39.472,94.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 22.313,39.920,94.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.877 | Acc: 22.374,40.190,94.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.879 | Acc: 22.328,40.258,94.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.878 | Acc: 22.432,40.470,94.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.879 | Acc: 22.559,40.683,94.738,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.882 | Acc: 22.435,40.509,94.692,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.882 | Acc: 22.380,40.450,94.720,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.884 | Acc: 22.397,40.578,94.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.886 | Acc: 22.283,40.473,94.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.887 | Acc: 22.214,40.335,94.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.889 | Acc: 22.141,40.145,94.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.888 | Acc: 22.141,40.266,94.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.889 | Acc: 22.064,40.255,94.562,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.890 | Acc: 22.106,40.212,94.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.889 | Acc: 22.126,40.233,94.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.889 | Acc: 22.088,40.291,94.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.890 | Acc: 22.098,40.220,94.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.891 | Acc: 22.123,40.256,94.406,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.888 | Acc: 25.000,46.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.897 | Acc: 21.577,41.295,71.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.926 | Acc: 21.627,40.282,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.927 | Acc: 21.644,40.407,70.786,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 180
Batch: 0 | Loss: 0.948 | Acc: 20.312,37.500,92.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.898 | Acc: 22.135,40.662,93.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.885 | Acc: 22.599,41.463,94.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.881 | Acc: 22.567,41.829,94.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.882 | Acc: 22.386,41.175,94.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.879 | Acc: 22.269,40.973,95.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.881 | Acc: 22.282,41.006,94.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.883 | Acc: 22.235,40.896,94.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.883 | Acc: 22.200,40.800,94.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.882 | Acc: 22.181,40.698,94.760,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.883 | Acc: 22.252,40.742,94.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.883 | Acc: 22.349,40.894,94.659,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.883 | Acc: 22.400,40.897,94.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.883 | Acc: 22.381,40.817,94.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.884 | Acc: 22.348,40.775,94.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.884 | Acc: 22.368,40.770,94.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 22.350,40.781,94.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.888 | Acc: 22.290,40.740,94.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.887 | Acc: 22.260,40.694,94.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.888 | Acc: 22.265,40.693,94.441,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.880 | Acc: 24.219,46.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.882 | Acc: 21.689,41.555,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.909 | Acc: 21.437,40.149,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.919 | Acc: 21.593,40.215,71.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 181
Batch: 0 | Loss: 0.925 | Acc: 17.188,38.281,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.863 | Acc: 21.652,40.737,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.878 | Acc: 22.237,41.159,94.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.872 | Acc: 22.310,40.727,95.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.875 | Acc: 22.454,40.789,94.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.876 | Acc: 22.664,40.919,94.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.880 | Acc: 22.721,41.045,94.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.881 | Acc: 22.822,41.074,94.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.882 | Acc: 22.681,40.926,94.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.884 | Acc: 22.686,40.849,94.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.884 | Acc: 22.738,40.850,94.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.885 | Acc: 22.685,40.954,94.620,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.884 | Acc: 22.669,40.991,94.654,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.885 | Acc: 22.575,40.975,94.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.887 | Acc: 22.462,40.814,94.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.887 | Acc: 22.467,40.737,94.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.887 | Acc: 22.425,40.786,94.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.888 | Acc: 22.365,40.740,94.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.888 | Acc: 22.332,40.709,94.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.888 | Acc: 22.281,40.604,94.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.938 | Acc: 22.656,43.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.875 | Acc: 20.871,40.699,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.903 | Acc: 21.246,39.825,70.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.916 | Acc: 21.529,39.882,70.607,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 182
Batch: 0 | Loss: 0.758 | Acc: 28.906,47.656,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.860 | Acc: 23.028,41.592,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.863 | Acc: 22.828,41.425,95.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 23.015,41.176,94.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.868 | Acc: 22.637,41.049,95.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.872 | Acc: 22.594,40.958,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.870 | Acc: 22.475,41.064,95.009,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.872 | Acc: 22.279,40.913,94.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.873 | Acc: 22.118,40.785,94.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.872 | Acc: 22.298,41.018,94.972,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.872 | Acc: 22.132,40.917,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.872 | Acc: 22.098,40.940,94.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.872 | Acc: 22.125,41.059,94.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.872 | Acc: 22.138,41.053,94.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.874 | Acc: 22.236,41.092,94.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.875 | Acc: 22.233,41.020,94.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 22.211,40.924,94.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.878 | Acc: 22.106,40.829,94.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.879 | Acc: 22.120,40.740,94.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.880 | Acc: 22.125,40.754,94.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.972 | Acc: 22.656,45.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.908 | Acc: 21.503,41.109,71.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.935 | Acc: 21.265,40.111,70.636,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.939 | Acc: 21.401,40.228,70.978,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 183
Batch: 0 | Loss: 0.917 | Acc: 20.312,34.375,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.889 | Acc: 21.763,39.621,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 22.466,39.996,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.879 | Acc: 22.426,39.805,95.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.888 | Acc: 22.270,39.371,94.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.881 | Acc: 22.548,40.091,94.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.878 | Acc: 22.321,40.044,94.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.878 | Acc: 22.340,40.198,94.925,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.877 | Acc: 22.365,40.213,94.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.877 | Acc: 22.320,40.219,94.933,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.878 | Acc: 22.225,40.275,94.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.877 | Acc: 22.200,40.420,94.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.876 | Acc: 22.332,40.619,94.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.877 | Acc: 22.321,40.751,94.896,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.877 | Acc: 22.387,40.800,94.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 22.469,40.874,94.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.878 | Acc: 22.427,40.856,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.879 | Acc: 22.326,40.833,94.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.879 | Acc: 22.345,40.852,94.791,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.879 | Acc: 22.371,40.896,94.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.865 | Acc: 22.656,46.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.875 | Acc: 21.280,41.332,71.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.925 | Acc: 21.227,39.539,70.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.929 | Acc: 21.337,39.652,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 184
Batch: 0 | Loss: 0.889 | Acc: 21.094,38.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.866 | Acc: 22.321,40.625,95.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 21.608,39.806,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.874 | Acc: 21.721,40.113,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.872 | Acc: 22.068,40.085,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.870 | Acc: 22.355,40.231,95.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.869 | Acc: 22.508,40.373,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.870 | Acc: 22.451,40.254,95.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.870 | Acc: 22.365,40.237,95.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 22.251,40.422,95.226,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 22.260,40.508,95.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 22.193,40.367,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.873 | Acc: 22.238,40.414,95.073,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.874 | Acc: 22.195,40.475,94.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 22.078,40.358,94.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.876 | Acc: 22.171,40.467,94.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 22.131,40.545,94.806,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.876 | Acc: 22.184,40.600,94.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 22.169,40.629,94.815,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 22.101,40.607,94.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.887 | Acc: 22.656,45.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.887 | Acc: 21.615,41.778,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.924 | Acc: 21.837,40.492,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.934 | Acc: 21.977,40.382,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 185
Batch: 0 | Loss: 0.796 | Acc: 29.688,42.969,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.879 | Acc: 22.396,42.225,94.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.883 | Acc: 21.456,40.701,94.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.875 | Acc: 21.696,41.048,94.839,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.878 | Acc: 21.701,40.895,94.840,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.875 | Acc: 21.573,40.718,94.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.875 | Acc: 21.610,40.857,94.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.876 | Acc: 21.858,40.808,94.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.874 | Acc: 21.909,40.766,95.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.874 | Acc: 22.035,40.815,94.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.874 | Acc: 22.213,40.854,94.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.876 | Acc: 22.179,40.770,94.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.874 | Acc: 22.235,40.849,94.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.875 | Acc: 22.171,40.861,94.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.876 | Acc: 22.078,40.800,94.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.877 | Acc: 22.129,40.846,94.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.877 | Acc: 22.118,40.878,94.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.877 | Acc: 22.141,40.872,94.749,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.877 | Acc: 22.210,40.837,94.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.877 | Acc: 22.164,40.873,94.761,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.844 | Acc: 24.219,47.656,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.909 | Acc: 21.391,41.853,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 21.399,40.187,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.949 | Acc: 21.491,40.266,70.684,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 186
Batch: 0 | Loss: 0.845 | Acc: 23.438,44.531,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.874 | Acc: 22.731,40.439,95.126,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.869 | Acc: 22.294,40.320,95.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 22.208,40.894,95.184,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 22.010,41.155,95.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 21.952,41.221,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 22.153,41.193,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.863 | Acc: 22.152,41.107,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.864 | Acc: 22.171,41.033,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.865 | Acc: 22.164,40.962,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.864 | Acc: 22.167,40.936,95.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.866 | Acc: 22.091,40.728,95.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 22.053,40.894,95.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 22.126,40.876,95.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.867 | Acc: 22.070,40.867,95.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 22.153,40.957,95.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 22.138,41.039,95.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.867 | Acc: 22.157,40.957,95.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 22.176,40.984,95.081,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.866 | Acc: 22.224,41.019,95.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.942 | Acc: 23.438,42.969,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.911 | Acc: 21.131,41.667,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.948 | Acc: 21.284,40.244,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.953 | Acc: 21.529,40.305,70.953,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 187
Batch: 0 | Loss: 0.805 | Acc: 28.906,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.853 | Acc: 21.801,41.034,95.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.859 | Acc: 21.856,41.406,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 22.567,41.304,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.862 | Acc: 22.463,41.078,95.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.862 | Acc: 22.509,41.035,95.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.863 | Acc: 22.243,40.916,95.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.862 | Acc: 22.418,41.196,95.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.866 | Acc: 22.438,41.057,95.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.868 | Acc: 22.367,40.871,95.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.870 | Acc: 22.291,40.932,95.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.870 | Acc: 22.349,40.841,95.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.869 | Acc: 22.371,40.943,95.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.868 | Acc: 22.306,40.906,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.868 | Acc: 22.256,40.822,95.062,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.871 | Acc: 22.101,40.672,94.975,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.872 | Acc: 22.118,40.703,94.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.871 | Acc: 22.223,40.769,94.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.872 | Acc: 22.165,40.826,94.884,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.872 | Acc: 22.222,40.820,94.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.958 | Acc: 23.438,42.969,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.918 | Acc: 21.503,42.001,71.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.951 | Acc: 21.684,40.130,70.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.954 | Acc: 21.760,40.049,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 188
Batch: 0 | Loss: 0.838 | Acc: 24.219,39.844,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.872 | Acc: 23.140,40.141,94.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.874 | Acc: 22.370,40.454,94.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.869 | Acc: 22.528,40.407,95.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.870 | Acc: 22.512,40.336,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.868 | Acc: 22.672,40.617,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.868 | Acc: 22.275,40.631,95.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.868 | Acc: 22.291,40.719,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.869 | Acc: 22.244,40.606,95.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.867 | Acc: 22.320,40.785,95.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.868 | Acc: 22.213,40.749,95.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.867 | Acc: 22.370,40.887,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.866 | Acc: 22.491,40.881,95.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.866 | Acc: 22.432,40.894,95.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.866 | Acc: 22.389,41.039,95.201,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.867 | Acc: 22.334,41.105,95.175,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.867 | Acc: 22.264,41.017,95.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.868 | Acc: 22.315,41.079,95.129,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.867 | Acc: 22.323,41.045,95.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.868 | Acc: 22.263,41.058,95.114,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.937 | Acc: 22.656,45.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.908 | Acc: 21.615,42.001,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.942 | Acc: 21.761,40.701,70.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.943 | Acc: 21.696,40.676,71.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 189
Batch: 0 | Loss: 0.947 | Acc: 24.219,42.188,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.857 | Acc: 23.958,42.522,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.857 | Acc: 23.095,41.806,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.864 | Acc: 22.656,41.342,95.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.861 | Acc: 22.492,41.127,95.197,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.861 | Acc: 22.517,41.012,95.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.861 | Acc: 22.288,40.993,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.859 | Acc: 22.279,41.179,95.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.859 | Acc: 22.360,40.989,95.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.860 | Acc: 22.410,40.949,95.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.858 | Acc: 22.505,41.204,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.858 | Acc: 22.646,41.106,95.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 22.510,41.147,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.859 | Acc: 22.483,41.035,95.250,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.860 | Acc: 22.462,41.089,95.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.860 | Acc: 22.459,41.056,95.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.861 | Acc: 22.432,40.898,95.147,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 22.429,40.840,95.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.862 | Acc: 22.321,40.720,95.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.863 | Acc: 22.336,40.674,95.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.926 | Acc: 22.656,43.750,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.922 | Acc: 21.838,41.704,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.963 | Acc: 21.989,40.473,70.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.964 | Acc: 22.029,40.574,71.081,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 190
Batch: 0 | Loss: 0.821 | Acc: 23.438,46.094,92.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.829 | Acc: 22.507,42.299,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 21.608,41.578,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.855 | Acc: 21.568,41.445,95.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.859 | Acc: 21.566,41.223,95.023,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.856 | Acc: 21.759,41.252,95.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.857 | Acc: 21.849,41.368,95.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.860 | Acc: 21.703,41.174,95.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.861 | Acc: 21.924,41.232,94.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.859 | Acc: 22.173,41.329,95.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.859 | Acc: 22.182,41.177,95.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.860 | Acc: 22.122,41.088,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.860 | Acc: 22.232,41.179,95.124,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.863 | Acc: 22.162,41.041,95.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.864 | Acc: 22.139,40.984,95.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.865 | Acc: 22.207,40.936,95.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.865 | Acc: 22.206,40.941,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.866 | Acc: 22.122,40.893,95.033,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.866 | Acc: 22.137,40.926,95.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.867 | Acc: 22.158,40.885,94.999,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.935 | Acc: 23.438,46.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.926 | Acc: 21.577,42.336,71.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.969 | Acc: 22.046,40.987,70.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.974 | Acc: 21.939,41.009,70.722,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 191
Batch: 0 | Loss: 0.886 | Acc: 15.625,33.594,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.862 | Acc: 21.466,41.295,95.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.853 | Acc: 21.913,41.120,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.856 | Acc: 21.977,41.586,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.858 | Acc: 21.914,41.252,95.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.854 | Acc: 22.540,41.352,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.855 | Acc: 22.501,41.374,95.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.855 | Acc: 22.540,41.428,95.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.855 | Acc: 22.317,41.193,95.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.855 | Acc: 22.169,41.208,95.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.855 | Acc: 22.120,41.274,95.200,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 22.052,41.201,95.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.859 | Acc: 22.005,41.228,95.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.860 | Acc: 22.031,41.185,95.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.860 | Acc: 22.131,41.242,95.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.860 | Acc: 22.210,41.279,95.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.860 | Acc: 22.174,41.258,95.154,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.861 | Acc: 22.141,41.207,95.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.861 | Acc: 22.130,41.090,95.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.862 | Acc: 22.154,41.172,95.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 25.000,46.094,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.928 | Acc: 21.131,42.597,71.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.971 | Acc: 21.303,40.911,70.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.973 | Acc: 21.286,40.920,70.671,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 192
Batch: 0 | Loss: 0.825 | Acc: 21.094,37.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 21.875,40.774,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.850 | Acc: 21.837,40.301,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.853 | Acc: 22.029,40.215,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.854 | Acc: 22.174,40.828,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 22.509,40.981,95.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.852 | Acc: 22.585,41.122,95.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.853 | Acc: 22.606,41.157,95.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.852 | Acc: 22.579,41.295,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.854 | Acc: 22.363,41.022,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.856 | Acc: 22.299,41.025,95.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.857 | Acc: 22.303,41.116,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.858 | Acc: 22.306,41.082,95.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.857 | Acc: 22.279,40.978,95.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.857 | Acc: 22.350,41.134,95.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.857 | Acc: 22.376,41.167,95.346,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.857 | Acc: 22.325,41.170,95.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.858 | Acc: 22.251,41.163,95.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.857 | Acc: 22.295,41.192,95.295,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.858 | Acc: 22.285,41.207,95.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.810 | Acc: 22.656,46.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.904 | Acc: 21.205,42.634,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.961 | Acc: 21.284,41.101,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.969 | Acc: 21.529,40.881,70.735,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 193
Batch: 0 | Loss: 0.846 | Acc: 15.625,41.406,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.843 | Acc: 21.726,42.113,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.841 | Acc: 21.780,41.616,96.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 22.336,41.726,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.848 | Acc: 22.405,41.937,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 22.455,42.218,95.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.850 | Acc: 22.333,42.000,95.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 22.318,42.082,95.601,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.848 | Acc: 22.472,42.081,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.851 | Acc: 22.479,42.019,95.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 22.470,41.915,95.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.850 | Acc: 22.603,41.975,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 22.647,42.009,95.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 22.653,41.993,95.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 22.623,41.862,95.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 22.643,41.803,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.852 | Acc: 22.666,41.776,95.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 22.629,41.677,95.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 22.581,41.566,95.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 22.550,41.525,95.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.916 | Acc: 25.000,46.094,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.921 | Acc: 21.280,42.039,71.131,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.967 | Acc: 21.513,40.796,70.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.973 | Acc: 21.529,40.702,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 194
Batch: 0 | Loss: 0.775 | Acc: 28.125,49.219,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.834 | Acc: 23.958,41.815,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.848 | Acc: 23.056,41.120,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.853 | Acc: 22.746,40.574,95.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.853 | Acc: 22.367,40.278,95.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.852 | Acc: 22.440,40.455,95.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.853 | Acc: 22.656,40.567,95.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.850 | Acc: 22.828,40.752,95.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.851 | Acc: 22.724,40.843,95.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.852 | Acc: 22.717,40.828,95.477,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.852 | Acc: 22.559,40.792,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.852 | Acc: 22.642,40.968,95.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.851 | Acc: 22.728,41.108,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.852 | Acc: 22.620,41.155,95.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 22.648,41.137,95.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.853 | Acc: 22.706,41.162,95.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.853 | Acc: 22.642,41.190,95.320,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.853 | Acc: 22.652,41.202,95.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.854 | Acc: 22.602,41.218,95.269,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.855 | Acc: 22.543,41.150,95.251,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.812 | Acc: 24.219,47.656,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.922 | Acc: 21.354,42.374,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.964 | Acc: 21.704,41.273,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.968 | Acc: 22.003,41.419,71.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 195
Batch: 0 | Loss: 0.839 | Acc: 17.188,43.750,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 23.028,43.155,96.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.844 | Acc: 22.637,42.340,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.845 | Acc: 22.810,42.111,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.848 | Acc: 22.917,41.773,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.848 | Acc: 22.749,41.576,95.575,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.844 | Acc: 22.876,41.516,95.616,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 22.662,41.567,95.540,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.848 | Acc: 22.753,41.693,95.555,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 22.682,41.600,95.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 22.831,41.674,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 22.833,41.445,95.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.850 | Acc: 22.760,41.351,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.851 | Acc: 22.938,41.397,95.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.852 | Acc: 22.798,41.359,95.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.852 | Acc: 22.685,41.308,95.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.851 | Acc: 22.642,41.241,95.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.852 | Acc: 22.569,41.202,95.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.853 | Acc: 22.539,41.170,95.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.853 | Acc: 22.486,41.125,95.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.822 | Acc: 25.000,47.656,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 21.019,41.667,69.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.989 | Acc: 21.380,40.396,69.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.986 | Acc: 21.414,40.459,70.082,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 196
Batch: 0 | Loss: 0.828 | Acc: 23.438,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.848 | Acc: 22.321,41.704,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.839 | Acc: 22.428,42.492,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.840 | Acc: 22.567,41.842,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.843 | Acc: 22.454,41.792,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.845 | Acc: 22.424,41.399,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.846 | Acc: 22.411,41.296,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.844 | Acc: 22.496,41.473,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.843 | Acc: 22.705,41.688,95.735,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.845 | Acc: 22.643,41.726,95.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.846 | Acc: 22.687,41.709,95.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.846 | Acc: 22.716,41.632,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.845 | Acc: 22.724,41.740,95.607,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.847 | Acc: 22.620,41.733,95.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.848 | Acc: 22.492,41.698,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 22.425,41.684,95.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.848 | Acc: 22.389,41.618,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.849 | Acc: 22.347,41.514,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.849 | Acc: 22.349,41.501,95.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.850 | Acc: 22.363,41.464,95.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.934 | Acc: 24.219,49.219,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.923 | Acc: 21.019,43.080,71.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.966 | Acc: 21.341,41.521,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.971 | Acc: 21.440,41.496,71.030,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 197
Batch: 0 | Loss: 0.795 | Acc: 24.219,39.062,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.813 | Acc: 22.619,41.890,96.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.824 | Acc: 22.885,42.454,96.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 22.310,41.995,96.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 22.483,42.351,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.834 | Acc: 22.532,42.257,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 22.366,42.181,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.840 | Acc: 22.213,41.999,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 22.389,41.799,95.778,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.842 | Acc: 22.406,41.644,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.843 | Acc: 22.505,41.604,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.844 | Acc: 22.646,41.640,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.844 | Acc: 22.653,41.565,95.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.846 | Acc: 22.486,41.427,95.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 22.520,41.551,95.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.848 | Acc: 22.524,41.479,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.847 | Acc: 22.554,41.521,95.556,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 22.500,41.441,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.848 | Acc: 22.464,41.445,95.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.849 | Acc: 22.474,41.384,95.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.929 | Acc: 23.438,46.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.941 | Acc: 21.466,42.671,70.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.986 | Acc: 21.627,40.968,70.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.984 | Acc: 21.811,41.060,70.581,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 198
Batch: 0 | Loss: 0.793 | Acc: 13.281,40.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.844 | Acc: 21.875,40.774,95.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.848 | Acc: 21.951,40.758,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.849 | Acc: 22.182,40.574,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.850 | Acc: 22.126,40.500,95.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.851 | Acc: 22.308,40.695,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.849 | Acc: 22.301,40.928,95.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.849 | Acc: 22.246,41.090,95.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.850 | Acc: 22.394,41.159,95.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.849 | Acc: 22.354,41.065,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.848 | Acc: 22.353,41.018,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.849 | Acc: 22.278,41.039,95.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.849 | Acc: 22.283,41.209,95.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.847 | Acc: 22.468,41.451,95.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.847 | Acc: 22.462,41.470,95.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.847 | Acc: 22.467,41.471,95.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.846 | Acc: 22.527,41.438,95.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.847 | Acc: 22.546,41.473,95.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.847 | Acc: 22.581,41.514,95.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.847 | Acc: 22.564,41.488,95.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.884 | Acc: 21.875,46.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 21.726,43.155,70.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 21.951,41.654,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.995 | Acc: 21.965,41.598,70.633,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 199
Batch: 0 | Loss: 0.772 | Acc: 19.531,40.625,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 22.693,41.704,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.833 | Acc: 22.637,40.816,96.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.841 | Acc: 22.605,40.843,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.840 | Acc: 22.685,41.300,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.843 | Acc: 22.463,41.445,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.845 | Acc: 22.430,41.413,95.739,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.847 | Acc: 22.512,41.107,95.612,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.848 | Acc: 22.647,41.173,95.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.847 | Acc: 22.488,41.160,95.628,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.847 | Acc: 22.505,40.998,95.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.847 | Acc: 22.628,41.039,95.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.848 | Acc: 22.601,41.069,95.595,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.849 | Acc: 22.557,40.999,95.558,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.849 | Acc: 22.609,41.095,95.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.850 | Acc: 22.578,41.178,95.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.849 | Acc: 22.535,41.195,95.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.850 | Acc: 22.567,41.225,95.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.850 | Acc: 22.613,41.250,95.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.851 | Acc: 22.535,41.287,95.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.961 | Acc: 24.219,45.312,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 21.131,42.001,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 21.361,40.644,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.001 | Acc: 21.452,40.894,70.261,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 200
Batch: 0 | Loss: 0.859 | Acc: 20.312,40.625,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.833 | Acc: 21.838,41.741,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.837 | Acc: 22.504,41.387,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 22.528,41.803,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.834 | Acc: 22.840,41.840,95.795,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.838 | Acc: 22.679,41.685,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.833 | Acc: 22.682,41.677,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.835 | Acc: 22.540,41.611,95.861,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 22.394,41.416,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 22.358,41.337,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.838 | Acc: 22.334,41.344,95.802,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.839 | Acc: 22.183,41.258,95.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 22.309,41.384,95.682,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.842 | Acc: 22.246,41.322,95.642,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 22.320,41.337,95.604,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 22.360,41.336,95.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.844 | Acc: 22.423,41.377,95.583,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.844 | Acc: 22.498,41.445,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.844 | Acc: 22.615,41.582,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 22.699,41.632,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.062 | Acc: 23.438,44.531,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.969 | Acc: 21.057,42.336,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.005 | Acc: 21.494,41.425,70.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.003 | Acc: 21.465,41.445,70.466,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 201
Batch: 0 | Loss: 0.850 | Acc: 17.969,39.062,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.838 | Acc: 22.470,42.374,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.840 | Acc: 22.466,42.492,95.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.843 | Acc: 22.413,41.970,95.581,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.838 | Acc: 22.676,42.631,95.756,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.836 | Acc: 22.865,42.814,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 23.018,42.788,95.771,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 22.828,42.453,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.840 | Acc: 22.947,42.401,95.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.841 | Acc: 22.941,42.360,95.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.842 | Acc: 22.932,42.312,95.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.843 | Acc: 22.798,42.096,95.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 22.805,42.019,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 22.731,41.933,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.842 | Acc: 22.606,41.912,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.844 | Acc: 22.539,41.723,95.593,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.843 | Acc: 22.547,41.706,95.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.844 | Acc: 22.487,41.569,95.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.844 | Acc: 22.503,41.603,95.594,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.844 | Acc: 22.527,41.527,95.577,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.046 | Acc: 21.875,46.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 21.168,42.894,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 21.170,41.482,70.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 21.299,41.317,70.492,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 202
Batch: 0 | Loss: 0.835 | Acc: 24.219,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.827 | Acc: 22.545,41.592,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.829 | Acc: 22.828,41.330,96.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.829 | Acc: 22.515,41.714,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.829 | Acc: 22.463,41.917,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.833 | Acc: 22.679,42.025,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.836 | Acc: 22.669,42.188,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 22.817,42.088,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.836 | Acc: 22.991,42.124,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.837 | Acc: 22.907,41.903,95.822,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.837 | Acc: 23.025,41.908,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.837 | Acc: 22.897,41.781,95.705,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.839 | Acc: 22.757,41.743,95.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 22.743,41.765,95.669,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.840 | Acc: 22.715,41.715,95.638,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 22.630,41.713,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.842 | Acc: 22.608,41.713,95.597,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.841 | Acc: 22.597,41.658,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 22.600,41.657,95.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.843 | Acc: 22.552,41.605,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.057 | Acc: 24.219,46.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 21.763,42.113,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.018 | Acc: 21.570,40.949,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.006 | Acc: 21.529,41.227,70.645,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 203
Batch: 0 | Loss: 0.855 | Acc: 23.438,39.844,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.829 | Acc: 24.070,42.857,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.834 | Acc: 23.342,42.797,95.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.833 | Acc: 23.322,42.777,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 23.071,42.988,95.891,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.830 | Acc: 22.973,42.713,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.835 | Acc: 23.031,42.375,95.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.838 | Acc: 22.906,42.320,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 22.899,42.280,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 22.829,42.140,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 22.781,42.075,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.839 | Acc: 22.702,41.975,95.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.840 | Acc: 22.553,41.818,95.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.839 | Acc: 22.614,41.864,95.651,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.840 | Acc: 22.601,41.779,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 22.555,41.718,95.608,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 22.634,41.698,95.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.841 | Acc: 22.643,41.713,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 22.635,41.688,95.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 22.642,41.665,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.969 | Acc: 25.000,45.312,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 21.615,42.708,71.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 21.780,41.406,70.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 21.811,41.317,70.774,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 204
Batch: 0 | Loss: 0.785 | Acc: 25.781,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.824 | Acc: 21.987,40.104,96.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.814 | Acc: 22.466,41.063,96.589,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.816 | Acc: 22.362,40.958,96.504,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.817 | Acc: 22.753,41.281,96.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.822 | Acc: 22.795,41.151,96.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 22.747,41.258,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.827 | Acc: 22.689,41.201,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.564,41.101,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.830 | Acc: 22.609,41.281,95.956,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 22.676,41.336,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.831 | Acc: 22.667,41.438,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.833 | Acc: 22.611,41.312,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 22.516,41.349,95.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 22.595,41.495,95.852,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.834 | Acc: 22.693,41.546,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 22.754,41.640,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.833 | Acc: 22.782,41.803,95.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 22.769,41.787,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 22.734,41.724,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.008 | Acc: 25.781,46.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 22.061,42.150,70.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.030 | Acc: 22.085,41.235,69.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 22.118,41.317,70.377,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 205
Batch: 0 | Loss: 0.783 | Acc: 19.531,42.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.855 | Acc: 21.838,40.625,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.845 | Acc: 22.066,41.406,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.840 | Acc: 22.170,41.547,95.774,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.833 | Acc: 22.627,42.236,95.910,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.833 | Acc: 23.028,42.389,95.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.835 | Acc: 23.018,42.233,95.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.835 | Acc: 23.011,42.176,95.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.837 | Acc: 22.947,42.032,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.837 | Acc: 22.894,42.011,95.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.839 | Acc: 22.831,41.985,95.623,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.840 | Acc: 22.918,42.071,95.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.841 | Acc: 22.890,42.207,95.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.841 | Acc: 22.989,42.250,95.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.840 | Acc: 22.965,42.110,95.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.841 | Acc: 22.815,42.019,95.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.841 | Acc: 22.839,42.020,95.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.841 | Acc: 22.759,41.933,95.535,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.842 | Acc: 22.730,41.815,95.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.843 | Acc: 22.759,41.888,95.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.067 | Acc: 24.219,42.188,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.995 | Acc: 21.801,41.815,70.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.034 | Acc: 21.742,40.758,69.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 21.747,40.971,70.658,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 206
Batch: 0 | Loss: 0.808 | Acc: 22.656,39.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.834 | Acc: 22.247,41.741,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.842 | Acc: 22.752,42.092,95.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.839 | Acc: 22.541,41.598,95.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 22.386,41.590,95.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 22.424,41.553,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.837 | Acc: 22.469,41.671,95.648,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.837 | Acc: 22.684,41.462,95.678,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.838 | Acc: 22.695,41.557,95.676,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.838 | Acc: 22.686,41.441,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.840 | Acc: 22.563,41.231,95.658,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.840 | Acc: 22.600,41.226,95.670,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.842 | Acc: 22.510,41.124,95.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.840 | Acc: 22.740,41.439,95.672,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.841 | Acc: 22.656,41.381,95.660,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.840 | Acc: 22.680,41.463,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.840 | Acc: 22.656,41.577,95.643,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.840 | Acc: 22.716,41.704,95.645,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.841 | Acc: 22.726,41.685,95.602,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.841 | Acc: 22.654,41.630,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.125 | Acc: 22.656,46.094,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 21.243,42.597,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.036 | Acc: 21.341,40.968,69.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 21.363,40.971,70.095,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 207
Batch: 0 | Loss: 0.745 | Acc: 26.562,42.969,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.844 | Acc: 22.842,41.257,95.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.828 | Acc: 23.114,42.149,95.960,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 22.592,41.765,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 22.502,41.985,95.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 22.803,41.925,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 22.915,42.175,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 22.961,42.171,95.883,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.831,41.877,95.934,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.829 | Acc: 22.872,41.859,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.830 | Acc: 22.924,41.880,95.919,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.831 | Acc: 22.879,41.756,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.830 | Acc: 22.864,41.747,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.830 | Acc: 22.914,41.879,95.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.831 | Acc: 22.954,41.873,95.894,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.832 | Acc: 22.913,41.832,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.832 | Acc: 22.880,41.859,95.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.833 | Acc: 22.892,41.761,95.876,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 22.929,41.729,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 22.839,41.718,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.175 | Acc: 24.219,43.750,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 21.689,42.113,70.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.036 | Acc: 21.894,40.930,69.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.039 | Acc: 22.029,40.868,70.312,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 208
Batch: 0 | Loss: 0.784 | Acc: 26.562,41.406,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.820 | Acc: 22.173,42.113,96.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.822 | Acc: 23.018,42.226,96.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.828 | Acc: 22.285,41.688,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.830 | Acc: 22.550,41.734,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.829 | Acc: 22.679,41.948,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 22.792,42.155,96.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 22.651,42.010,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.829 | Acc: 22.632,41.945,96.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 22.665,41.993,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 22.711,41.958,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.832 | Acc: 22.716,41.944,95.818,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.831 | Acc: 22.721,42.087,95.844,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.833 | Acc: 22.701,42.014,95.788,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.835 | Acc: 22.640,41.965,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.836 | Acc: 22.610,41.801,95.743,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 22.554,41.886,95.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.836 | Acc: 22.601,41.931,95.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 22.702,41.969,95.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.835 | Acc: 22.790,41.960,95.706,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.139 | Acc: 26.562,44.531,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.984 | Acc: 21.429,42.039,70.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.026 | Acc: 21.761,40.816,69.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 21.913,40.958,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 209
Batch: 0 | Loss: 0.806 | Acc: 20.312,42.969,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.856 | Acc: 22.991,41.592,95.164,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.842 | Acc: 22.294,41.101,95.732,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.834 | Acc: 22.669,41.893,95.799,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 22.820,42.207,95.862,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.830 | Acc: 22.803,42.126,95.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.829 | Acc: 22.940,42.368,95.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.830 | Acc: 23.005,42.570,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.830 | Acc: 22.807,42.319,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.832 | Acc: 22.686,42.287,95.813,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 22.641,42.312,95.826,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.833 | Acc: 22.632,42.286,95.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.834 | Acc: 22.527,42.191,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.834 | Acc: 22.551,42.226,95.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.833 | Acc: 22.698,42.379,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.833 | Acc: 22.809,42.434,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 22.783,42.355,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 22.711,42.366,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.834 | Acc: 22.684,42.302,95.765,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 22.656,42.294,95.762,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.009 | Acc: 23.438,48.438,69.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.017 | Acc: 22.098,42.374,70.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.041 | Acc: 22.046,41.159,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.043 | Acc: 22.029,41.112,69.864,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 210
Batch: 0 | Loss: 0.826 | Acc: 30.469,47.656,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.804 | Acc: 23.624,42.634,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.814 | Acc: 23.018,41.921,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.821 | Acc: 22.733,41.983,95.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.826 | Acc: 22.955,41.946,95.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.825 | Acc: 23.028,42.056,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.827 | Acc: 23.057,42.110,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.828 | Acc: 22.939,42.304,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.879,42.071,95.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.829 | Acc: 22.889,41.907,95.887,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.830 | Acc: 22.804,41.900,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.830 | Acc: 22.833,42.032,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.828 | Acc: 22.828,42.226,95.873,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.828 | Acc: 22.830,42.253,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.829 | Acc: 22.820,42.199,95.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.830 | Acc: 22.737,42.234,95.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.830 | Acc: 22.729,42.149,95.794,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.830 | Acc: 22.720,42.091,95.796,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.830 | Acc: 22.645,41.971,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.831 | Acc: 22.646,41.960,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.016 | Acc: 24.219,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 22.024,42.560,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 22.180,41.120,70.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 22.054,41.124,70.505,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 211
Batch: 0 | Loss: 0.839 | Acc: 26.562,48.438,93.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.822 | Acc: 22.061,41.629,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.831 | Acc: 22.961,42.645,95.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.830 | Acc: 22.823,42.508,95.633,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.831 | Acc: 23.013,42.361,95.621,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.831 | Acc: 22.927,42.520,95.637,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.830 | Acc: 22.630,42.233,95.745,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.831 | Acc: 22.629,42.149,95.728,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.831 | Acc: 22.564,42.061,95.773,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.831 | Acc: 22.583,41.933,95.740,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 22.610,41.861,95.690,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.835 | Acc: 22.501,41.838,95.613,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.837 | Acc: 22.549,41.821,95.585,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.838 | Acc: 22.590,41.816,95.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.837 | Acc: 22.623,41.759,95.579,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.837 | Acc: 22.651,41.803,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.837 | Acc: 22.639,41.903,95.590,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.837 | Acc: 22.567,41.837,95.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.837 | Acc: 22.665,41.900,95.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.838 | Acc: 22.572,41.866,95.600,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.068 | Acc: 24.219,45.312,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.004 | Acc: 21.540,43.266,70.573,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.039 | Acc: 21.856,41.787,69.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.044 | Acc: 22.029,41.714,70.325,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 212
Batch: 0 | Loss: 0.841 | Acc: 20.312,42.969,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.826 | Acc: 22.693,41.667,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.827 | Acc: 22.752,41.540,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.831 | Acc: 23.181,41.829,95.786,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.835 | Acc: 23.351,41.966,95.611,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.835 | Acc: 23.028,41.839,95.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.832 | Acc: 22.876,42.097,95.681,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.832 | Acc: 23.022,42.237,95.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.831 | Acc: 22.972,42.188,95.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.832 | Acc: 22.777,42.062,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.832 | Acc: 22.738,41.888,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.833 | Acc: 22.692,41.795,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.832 | Acc: 22.754,41.883,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.832 | Acc: 22.839,41.888,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.834 | Acc: 22.876,41.832,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.834 | Acc: 22.677,41.785,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.834 | Acc: 22.576,41.740,95.777,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.834 | Acc: 22.714,41.819,95.752,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.835 | Acc: 22.669,41.789,95.747,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.834 | Acc: 22.736,41.849,95.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.029 | Acc: 24.219,46.875,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.994 | Acc: 21.987,43.490,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.031 | Acc: 21.894,41.749,69.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.039 | Acc: 21.990,41.560,70.210,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 213
Batch: 0 | Loss: 0.810 | Acc: 23.438,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.818 | Acc: 23.103,41.815,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.820 | Acc: 23.323,42.664,96.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.824 | Acc: 22.925,42.700,96.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.823 | Acc: 22.637,42.255,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.827 | Acc: 22.447,42.149,96.001,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.826 | Acc: 22.527,42.020,95.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.826 | Acc: 22.529,42.088,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.828 | Acc: 22.613,41.921,95.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.826 | Acc: 22.838,42.023,95.908,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.827 | Acc: 22.893,42.118,95.864,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.827 | Acc: 23.045,42.315,95.857,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.829 | Acc: 22.990,42.262,95.825,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.828 | Acc: 23.063,42.289,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.830 | Acc: 22.979,42.129,95.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.831 | Acc: 23.030,42.099,95.686,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.831 | Acc: 22.914,41.990,95.702,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.832 | Acc: 22.897,42.013,95.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.833 | Acc: 22.933,41.993,95.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.833 | Acc: 22.878,41.978,95.710,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.058 | Acc: 23.438,49.219,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.009 | Acc: 21.354,43.192,71.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.039 | Acc: 21.704,41.711,70.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.041 | Acc: 21.747,41.598,70.569,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 214
Batch: 0 | Loss: 0.831 | Acc: 24.219,41.406,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.839 | Acc: 22.135,42.374,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.827 | Acc: 22.332,42.226,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.827 | Acc: 22.579,42.175,95.978,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.828 | Acc: 22.213,41.937,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.826 | Acc: 22.386,41.971,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.824 | Acc: 22.450,41.923,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.824 | Acc: 22.418,41.772,95.944,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.821 | Acc: 22.603,41.906,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.825 | Acc: 22.587,41.916,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.826 | Acc: 22.606,41.981,95.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.828 | Acc: 22.564,41.894,95.853,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.828 | Acc: 22.523,41.828,95.867,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.828 | Acc: 22.477,41.834,95.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.828 | Acc: 22.551,41.968,95.880,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.828 | Acc: 22.617,41.990,95.850,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.828 | Acc: 22.632,41.971,95.848,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.828 | Acc: 22.686,41.940,95.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.828 | Acc: 22.747,42.019,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.828 | Acc: 22.783,42.089,95.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.133 | Acc: 23.438,47.656,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.993 | Acc: 21.503,43.192,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 21.723,41.749,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 21.696,41.906,70.287,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 215
Batch: 0 | Loss: 0.845 | Acc: 21.094,43.750,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.814 | Acc: 22.879,41.890,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.822 | Acc: 22.332,41.768,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.822 | Acc: 22.733,41.701,96.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.820 | Acc: 22.676,41.734,96.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.820 | Acc: 22.765,41.731,96.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.818 | Acc: 22.811,42.013,96.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.819 | Acc: 22.739,41.999,96.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.820 | Acc: 22.705,41.959,96.249,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.821 | Acc: 22.807,42.015,96.202,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.821 | Acc: 22.851,41.908,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.823 | Acc: 22.829,41.855,96.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.823 | Acc: 22.831,41.821,96.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.823 | Acc: 22.827,41.885,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.823 | Acc: 22.851,41.960,96.097,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 22.802,41.964,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.823 | Acc: 22.783,41.917,96.091,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.824 | Acc: 22.780,41.894,96.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 22.704,41.952,96.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.825 | Acc: 22.675,42.007,96.026,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.053 | Acc: 26.562,44.531,67.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.997 | Acc: 21.763,42.374,70.871,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.048 | Acc: 21.742,41.120,69.798,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.055 | Acc: 21.773,40.945,70.044,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 216
Batch: 0 | Loss: 0.837 | Acc: 21.094,40.625,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.807 | Acc: 24.888,43.750,96.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.817 | Acc: 23.285,41.997,95.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.818 | Acc: 22.925,41.880,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.812 | Acc: 23.013,42.573,96.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.814 | Acc: 23.082,42.543,96.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.816 | Acc: 22.869,42.633,96.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.818 | Acc: 22.806,42.431,96.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.818 | Acc: 22.802,42.328,96.268,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.819 | Acc: 22.639,42.308,96.241,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.819 | Acc: 22.695,42.296,96.152,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.819 | Acc: 22.699,42.495,96.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.820 | Acc: 22.812,42.534,96.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.820 | Acc: 22.818,42.523,96.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.821 | Acc: 22.792,42.482,96.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.821 | Acc: 22.796,42.486,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.822 | Acc: 22.751,42.321,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.822 | Acc: 22.725,42.291,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.822 | Acc: 22.704,42.328,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.823 | Acc: 22.662,42.282,96.016,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.039 | Acc: 24.219,47.656,67.969,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.054 | Acc: 21.019,42.671,69.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.081 | Acc: 21.608,41.082,69.436,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.081 | Acc: 21.555,40.920,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 217
Batch: 0 | Loss: 0.844 | Acc: 20.312,35.156,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.822 | Acc: 22.917,42.076,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.825 | Acc: 22.942,41.521,96.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.821 | Acc: 23.194,41.662,96.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.825 | Acc: 23.447,41.628,96.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.823 | Acc: 23.089,41.932,96.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.825 | Acc: 23.011,42.142,96.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.826 | Acc: 22.950,42.071,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.826 | Acc: 22.850,41.984,96.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.827 | Acc: 22.967,41.967,95.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.826 | Acc: 22.940,41.954,96.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.826 | Acc: 22.981,42.219,96.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.829 | Acc: 22.899,42.249,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.828 | Acc: 22.917,42.214,95.959,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.829 | Acc: 22.884,42.238,95.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.828 | Acc: 22.895,42.255,95.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.828 | Acc: 22.861,42.309,95.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.828 | Acc: 22.842,42.373,95.915,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.828 | Acc: 22.853,42.365,95.901,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.829 | Acc: 22.882,42.384,95.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.987 | Acc: 24.219,48.438,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.012 | Acc: 21.875,43.155,70.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.062 | Acc: 21.780,41.463,69.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.073 | Acc: 21.901,41.496,69.659,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 218
Batch: 0 | Loss: 0.825 | Acc: 25.000,39.062,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.831 | Acc: 22.098,41.443,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 22.161,41.616,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.822 | Acc: 22.298,41.726,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.821 | Acc: 22.425,41.831,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.821 | Acc: 22.765,42.025,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.823 | Acc: 22.508,41.832,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.824 | Acc: 22.545,41.982,96.083,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.825 | Acc: 22.676,42.221,95.977,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.824 | Acc: 22.656,42.140,95.943,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.825 | Acc: 22.730,42.250,95.892,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.825 | Acc: 22.755,42.269,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.825 | Acc: 22.809,42.388,95.838,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.825 | Acc: 22.878,42.292,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.826 | Acc: 22.876,42.374,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.826 | Acc: 22.822,42.338,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.827 | Acc: 22.797,42.273,95.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.827 | Acc: 22.823,42.316,95.817,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.827 | Acc: 22.806,42.281,95.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.827 | Acc: 22.808,42.280,95.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.073 | Acc: 25.000,50.781,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.011 | Acc: 21.429,42.188,70.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.063 | Acc: 21.627,40.682,69.588,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.064 | Acc: 21.580,40.740,69.839,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 219
Batch: 0 | Loss: 0.799 | Acc: 25.781,42.969,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 24.665,44.606,95.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.823 | Acc: 23.723,43.216,95.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.822 | Acc: 23.053,43.084,95.966,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.828 | Acc: 23.235,42.785,95.833,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.827 | Acc: 22.857,42.853,95.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.826 | Acc: 22.676,42.911,95.952,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.827 | Acc: 22.706,42.819,95.961,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.826 | Acc: 22.729,42.838,96.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.824 | Acc: 22.764,42.787,96.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.824 | Acc: 22.785,42.844,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.825 | Acc: 22.808,42.834,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.827 | Acc: 22.779,42.813,95.899,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.827 | Acc: 22.701,42.666,95.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.828 | Acc: 22.692,42.524,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.828 | Acc: 22.742,42.496,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.827 | Acc: 22.739,42.514,95.858,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.828 | Acc: 22.739,42.543,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.828 | Acc: 22.684,42.536,95.830,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.829 | Acc: 22.677,42.421,95.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.071 | Acc: 25.000,46.094,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.977 | Acc: 21.689,43.341,71.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 21.761,41.959,70.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 21.619,41.983,70.428,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 220
Batch: 0 | Loss: 0.827 | Acc: 25.781,46.875,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.828 | Acc: 23.475,42.597,95.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.825 | Acc: 23.247,41.864,95.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.817 | Acc: 22.797,41.778,96.017,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.815 | Acc: 22.801,42.014,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.817 | Acc: 22.850,42.064,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.818 | Acc: 22.856,42.375,95.907,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.820 | Acc: 23.016,42.409,95.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.822 | Acc: 22.938,42.391,95.715,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.823 | Acc: 22.932,42.490,95.718,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.823 | Acc: 22.967,42.436,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.822 | Acc: 23.031,42.502,95.769,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.823 | Acc: 22.977,42.301,95.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.823 | Acc: 22.968,42.283,95.785,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.823 | Acc: 22.898,42.352,95.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.824 | Acc: 22.905,42.380,95.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.825 | Acc: 22.793,42.268,95.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.824 | Acc: 22.796,42.316,95.789,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 22.767,42.311,95.784,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.825 | Acc: 22.790,42.364,95.801,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.976 | Acc: 23.438,43.750,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 21.763,43.452,71.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 21.913,41.749,70.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.033 | Acc: 21.862,41.829,70.338,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 221
Batch: 0 | Loss: 0.796 | Acc: 24.219,45.312,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.821 | Acc: 22.396,42.560,96.280,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.825 | Acc: 22.561,41.940,96.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.818 | Acc: 22.772,42.828,96.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.816 | Acc: 23.071,42.853,96.161,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.818 | Acc: 22.942,42.667,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.820 | Acc: 22.992,42.594,96.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.821 | Acc: 22.756,42.453,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.820 | Acc: 22.913,42.508,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.822 | Acc: 22.743,42.377,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.824 | Acc: 22.699,42.359,95.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.824 | Acc: 22.798,42.354,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.822 | Acc: 22.737,42.411,95.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.822 | Acc: 22.824,42.457,96.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.823 | Acc: 22.806,42.499,95.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 22.833,42.468,96.008,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.824 | Acc: 22.926,42.523,95.957,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.824 | Acc: 23.034,42.627,95.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 23.005,42.538,95.916,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.824 | Acc: 22.945,42.509,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 24.219,46.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.988 | Acc: 21.689,42.969,70.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.037 | Acc: 21.704,42.054,69.722,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 21.747,41.944,70.133,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 222
Batch: 0 | Loss: 0.831 | Acc: 26.562,46.094,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.816 | Acc: 21.949,43.787,96.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.815 | Acc: 22.409,43.159,96.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.809 | Acc: 22.477,43.148,96.401,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.813 | Acc: 22.830,42.959,96.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.815 | Acc: 23.004,42.915,96.156,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.815 | Acc: 23.031,42.936,96.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.816 | Acc: 23.077,42.963,96.099,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.817 | Acc: 22.943,43.027,95.982,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.819 | Acc: 22.894,42.861,95.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.819 | Acc: 22.901,42.813,95.973,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.818 | Acc: 22.967,42.948,95.995,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.819 | Acc: 22.993,43.014,95.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.819 | Acc: 23.018,42.930,95.968,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.821 | Acc: 22.984,42.805,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.820 | Acc: 23.017,42.834,95.938,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.820 | Acc: 22.980,42.755,95.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.820 | Acc: 22.927,42.705,95.986,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.820 | Acc: 22.834,42.627,96.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.821 | Acc: 22.837,42.596,95.965,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.138 | Acc: 23.438,44.531,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.031 | Acc: 21.503,42.597,69.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.093 | Acc: 21.799,41.578,68.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.103 | Acc: 21.760,41.393,69.339,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 223
Batch: 0 | Loss: 0.771 | Acc: 26.562,42.188,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.818 | Acc: 22.098,41.481,96.019,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.817 | Acc: 22.713,42.092,95.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.816 | Acc: 22.989,42.802,95.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.813 | Acc: 23.119,43.258,96.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.817 | Acc: 23.012,42.953,95.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.818 | Acc: 23.037,42.859,96.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.819 | Acc: 23.016,42.592,96.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.818 | Acc: 23.069,42.527,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.820 | Acc: 23.002,42.231,95.990,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.821 | Acc: 22.959,42.281,95.981,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.823 | Acc: 22.914,42.233,95.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.822 | Acc: 22.796,42.126,95.993,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.822 | Acc: 22.728,42.047,95.992,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.823 | Acc: 22.790,42.090,95.930,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 22.890,42.200,95.928,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.824 | Acc: 22.892,42.205,95.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.825 | Acc: 22.849,42.275,95.890,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.826 | Acc: 22.801,42.205,95.882,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.827 | Acc: 22.820,42.237,95.860,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.959 | Acc: 25.000,46.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.019 | Acc: 22.396,43.304,70.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.066 | Acc: 22.485,41.883,69.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.061 | Acc: 22.515,41.688,70.146,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 224
Batch: 0 | Loss: 0.794 | Acc: 22.656,42.188,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.811 | Acc: 23.214,43.899,95.945,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.809 | Acc: 23.723,43.845,96.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.811 | Acc: 23.169,43.507,96.311,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.814 | Acc: 23.139,42.901,96.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.814 | Acc: 23.453,43.046,96.047,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.814 | Acc: 23.509,42.962,96.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.814 | Acc: 23.582,43.096,96.055,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.815 | Acc: 23.467,42.901,96.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.815 | Acc: 23.433,42.934,96.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.816 | Acc: 23.379,42.899,96.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.820 | Acc: 23.201,42.647,95.963,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.821 | Acc: 23.165,42.671,95.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.822 | Acc: 23.147,42.654,95.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.822 | Acc: 23.171,42.635,95.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.823 | Acc: 23.066,42.561,95.855,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.825 | Acc: 23.016,42.550,95.816,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.825 | Acc: 23.030,42.616,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.825 | Acc: 23.007,42.657,95.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.826 | Acc: 23.036,42.657,95.766,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.011 | Acc: 25.000,46.094,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 2.002 | Acc: 21.391,42.597,71.652,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.039 | Acc: 21.799,41.406,70.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.048 | Acc: 21.824,41.496,70.402,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 225
Batch: 0 | Loss: 0.808 | Acc: 28.906,38.281,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.793 | Acc: 24.963,42.932,96.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.809 | Acc: 24.505,42.492,96.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.816 | Acc: 23.617,42.572,96.145,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.810 | Acc: 23.428,42.872,96.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.809 | Acc: 23.058,42.505,96.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.809 | Acc: 23.005,42.536,96.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.808 | Acc: 23.055,42.592,96.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.806 | Acc: 23.161,42.750,96.516,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.805 | Acc: 23.075,42.451,96.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.805 | Acc: 22.948,42.452,96.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.805 | Acc: 22.875,42.527,96.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.803 | Acc: 22.831,42.586,96.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.801 | Acc: 22.932,42.651,96.671,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.800 | Acc: 22.954,42.782,96.683,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.798 | Acc: 22.895,42.870,96.730,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.797 | Acc: 22.956,43.003,96.748,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.796 | Acc: 22.956,43.070,96.804,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.796 | Acc: 22.920,42.993,96.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.795 | Acc: 22.966,42.954,96.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.992 | Acc: 25.000,46.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.946 | Acc: 21.689,43.118,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 21.970,42.340,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.994 | Acc: 21.939,42.444,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 226
Batch: 0 | Loss: 0.837 | Acc: 18.750,32.812,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.788 | Acc: 22.061,42.262,97.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.785 | Acc: 22.199,42.054,97.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.783 | Acc: 22.912,42.597,97.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.779 | Acc: 23.032,42.853,97.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.775 | Acc: 23.291,42.992,97.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.283,42.988,97.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.327,43.030,97.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.777 | Acc: 23.195,43.279,97.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.131,43.267,97.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.777 | Acc: 23.197,43.326,97.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.176,43.322,97.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.777 | Acc: 23.091,43.351,97.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.138,43.400,97.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.776 | Acc: 23.207,43.422,97.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.777 | Acc: 23.199,43.324,97.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.776 | Acc: 23.214,43.368,97.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.776 | Acc: 23.156,43.267,97.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.777 | Acc: 23.132,43.246,97.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.777 | Acc: 23.083,43.207,97.439,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 23.438,45.312,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.925 | Acc: 22.098,43.378,72.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.971 | Acc: 22.313,42.359,71.684,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.977 | Acc: 22.323,42.520,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 227
Batch: 0 | Loss: 0.774 | Acc: 25.781,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.783 | Acc: 24.219,44.085,97.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.771 | Acc: 23.285,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.771 | Acc: 23.143,43.302,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.771 | Acc: 22.994,43.490,97.685,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.774 | Acc: 22.981,43.441,97.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.773 | Acc: 22.915,43.453,97.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.774 | Acc: 22.728,43.201,97.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.774 | Acc: 22.748,43.139,97.525,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.775 | Acc: 22.794,42.960,97.548,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.774 | Acc: 22.901,43.000,97.598,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.775 | Acc: 22.953,42.951,97.564,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.774 | Acc: 23.006,43.105,97.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.774 | Acc: 23.081,43.127,97.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.774 | Acc: 23.179,43.133,97.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.183,43.104,97.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.775 | Acc: 23.126,43.032,97.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.775 | Acc: 23.096,43.026,97.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.776 | Acc: 23.005,42.923,97.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.776 | Acc: 22.980,42.897,97.511,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.991 | Acc: 24.219,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.942 | Acc: 22.135,43.378,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 22.294,42.302,71.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.992 | Acc: 22.285,42.431,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 228
Batch: 0 | Loss: 0.763 | Acc: 17.188,50.000,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.778 | Acc: 24.107,43.676,97.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.780 | Acc: 23.780,43.388,97.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.776 | Acc: 23.591,43.955,97.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.774 | Acc: 23.148,43.721,97.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.777 | Acc: 23.267,43.572,97.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.776 | Acc: 23.386,43.640,97.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.776 | Acc: 23.454,43.484,97.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.776 | Acc: 23.418,43.566,97.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.777 | Acc: 23.256,43.461,97.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.776 | Acc: 23.395,43.552,97.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.777 | Acc: 23.363,43.446,97.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.776 | Acc: 23.311,43.406,97.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.776 | Acc: 23.225,43.259,97.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.775 | Acc: 23.190,43.305,97.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.775 | Acc: 23.157,43.192,97.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.774 | Acc: 23.172,43.202,97.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.774 | Acc: 23.103,43.113,97.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.774 | Acc: 23.093,43.157,97.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.773 | Acc: 23.120,43.178,97.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.999 | Acc: 25.000,46.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 22.135,43.527,72.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.990 | Acc: 22.351,42.435,71.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 22.272,42.456,71.580,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 229
Batch: 0 | Loss: 0.747 | Acc: 25.781,46.094,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.760 | Acc: 22.359,43.899,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 22.885,43.102,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.765 | Acc: 22.823,42.802,97.823,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.763 | Acc: 22.772,43.046,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.762 | Acc: 23.082,43.193,97.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 22.973,43.246,97.869,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.762 | Acc: 23.210,43.318,97.834,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.764 | Acc: 23.234,43.255,97.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 23.269,43.202,97.764,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.765 | Acc: 23.333,43.136,97.753,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.766 | Acc: 23.300,43.107,97.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.767 | Acc: 23.321,43.111,97.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.767 | Acc: 23.189,43.115,97.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.767 | Acc: 23.204,43.169,97.729,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.766 | Acc: 23.248,43.293,97.700,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.182,43.278,97.673,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.153,43.262,97.679,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.119,43.177,97.697,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.019,43.170,97.695,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.000 | Acc: 24.219,48.438,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.946 | Acc: 21.875,44.122,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 22.180,42.702,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.994 | Acc: 22.259,42.674,71.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 230
Batch: 0 | Loss: 0.759 | Acc: 25.000,45.312,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 24.368,43.043,97.879,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.762 | Acc: 24.276,43.655,97.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.761 | Acc: 23.975,43.481,97.900,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.762 | Acc: 23.659,43.509,97.820,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.766 | Acc: 23.175,43.263,97.741,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.768 | Acc: 23.069,43.027,97.708,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.767 | Acc: 22.955,42.825,97.717,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.765 | Acc: 23.258,43.260,97.744,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.765 | Acc: 23.261,43.206,97.699,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.766 | Acc: 23.255,43.105,97.691,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.767 | Acc: 23.077,43.036,97.709,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.211,43.108,97.711,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.766 | Acc: 23.249,43.077,97.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.765 | Acc: 23.298,43.088,97.734,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.765 | Acc: 23.274,43.065,97.724,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.764 | Acc: 23.284,43.173,97.737,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.764 | Acc: 23.293,43.173,97.736,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.765 | Acc: 23.217,43.159,97.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.765 | Acc: 23.148,43.104,97.775,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.972 | Acc: 24.219,46.094,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.932 | Acc: 21.615,43.601,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.987 | Acc: 21.951,42.492,70.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.993 | Acc: 22.054,42.354,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 231
Batch: 0 | Loss: 0.750 | Acc: 21.094,42.188,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.764 | Acc: 23.363,43.341,97.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.767 | Acc: 23.380,43.293,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.768 | Acc: 23.015,43.238,97.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.764 | Acc: 23.447,43.981,97.782,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.765 | Acc: 23.105,43.688,97.811,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.763 | Acc: 23.179,43.776,97.856,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.763 | Acc: 23.305,43.634,97.878,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.763 | Acc: 23.360,43.536,97.841,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.763 | Acc: 23.273,43.465,97.863,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.764 | Acc: 23.197,43.365,97.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.764 | Acc: 23.141,43.294,97.829,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.766 | Acc: 23.071,43.179,97.812,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 23.102,43.172,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 22.998,43.063,97.790,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.767 | Acc: 23.040,43.106,97.776,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.767 | Acc: 23.082,43.198,97.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.767 | Acc: 23.059,43.154,97.757,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.767 | Acc: 23.070,43.198,97.754,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.767 | Acc: 23.044,43.231,97.759,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.983 | Acc: 24.219,47.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.920 | Acc: 21.838,43.750,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.981 | Acc: 22.199,42.588,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.987 | Acc: 22.195,42.520,71.491,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 232
Batch: 0 | Loss: 0.769 | Acc: 29.688,43.750,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 23.624,44.940,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 22.885,43.731,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 23.207,44.109,97.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.761 | Acc: 22.878,43.972,97.868,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.761 | Acc: 22.919,43.665,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.761 | Acc: 23.031,43.705,97.843,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.762 | Acc: 23.077,43.711,97.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.762 | Acc: 23.044,43.857,97.797,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.764 | Acc: 22.967,43.595,97.807,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.763 | Acc: 23.002,43.630,97.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.763 | Acc: 22.971,43.503,97.837,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.764 | Acc: 22.958,43.358,97.835,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.765 | Acc: 22.989,43.355,97.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.766 | Acc: 23.043,43.411,97.792,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.765 | Acc: 23.056,43.446,97.809,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.764 | Acc: 23.197,43.499,97.824,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.763 | Acc: 23.206,43.457,97.849,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.763 | Acc: 23.141,43.423,97.845,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.764 | Acc: 23.155,43.395,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.001 | Acc: 24.219,46.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.933 | Acc: 22.135,44.568,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.992 | Acc: 22.104,43.159,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.996 | Acc: 22.144,42.828,71.427,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 233
Batch: 0 | Loss: 0.767 | Acc: 24.219,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 22.954,43.266,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 23.399,43.769,97.923,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 23.706,43.366,98.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 23.601,43.547,97.994,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 23.445,43.472,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.757 | Acc: 23.095,43.201,98.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 23.299,43.124,98.050,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.757 | Acc: 23.248,43.119,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.759 | Acc: 23.299,43.055,97.980,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.760 | Acc: 23.173,43.120,97.979,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 23.225,43.156,97.985,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.760 | Acc: 23.288,43.108,97.997,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 23.195,43.190,98.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.759 | Acc: 23.246,43.314,98.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.759 | Acc: 23.321,43.426,98.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 23.265,43.417,98.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.759 | Acc: 23.364,43.475,97.988,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 23.295,43.514,97.970,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 23.296,43.533,97.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.948 | Acc: 24.219,46.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 21.949,43.638,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.998 | Acc: 22.409,42.759,71.227,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.999 | Acc: 22.413,42.559,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 234
Batch: 0 | Loss: 0.781 | Acc: 16.406,43.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 22.210,43.006,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.763 | Acc: 22.466,43.540,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.764 | Acc: 22.605,43.404,97.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 22.618,43.557,98.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.764 | Acc: 22.873,43.704,98.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.764 | Acc: 22.882,43.744,97.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.765 | Acc: 22.734,43.562,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.763 | Acc: 22.884,43.604,97.947,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.764 | Acc: 22.846,43.478,97.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.764 | Acc: 22.913,43.474,97.932,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.764 | Acc: 22.999,43.492,97.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.764 | Acc: 22.903,43.410,97.954,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.764 | Acc: 23.012,43.343,97.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.764 | Acc: 22.887,43.216,97.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.764 | Acc: 22.898,43.218,97.926,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.764 | Acc: 23.041,43.312,97.929,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.763 | Acc: 23.124,43.322,97.950,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.763 | Acc: 23.139,43.228,97.953,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.763 | Acc: 23.126,43.235,97.962,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.014 | Acc: 24.219,46.875,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.934 | Acc: 22.024,43.862,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 22.275,42.778,71.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 1.997 | Acc: 22.170,42.661,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 235
Batch: 0 | Loss: 0.805 | Acc: 24.219,45.312,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 22.173,43.304,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 23.495,43.979,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.757 | Acc: 23.886,43.712,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.759 | Acc: 24.180,43.731,97.897,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.758 | Acc: 24.049,43.688,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 23.973,43.873,97.902,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.758 | Acc: 23.825,43.789,97.939,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.760 | Acc: 23.884,43.692,97.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.760 | Acc: 23.796,43.590,97.889,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.761 | Acc: 23.706,43.676,97.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.761 | Acc: 23.607,43.612,97.851,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.761 | Acc: 23.476,43.594,97.877,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.761 | Acc: 23.440,43.561,97.881,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 23.385,43.469,97.898,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.760 | Acc: 23.323,43.446,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.760 | Acc: 23.369,43.594,97.924,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.760 | Acc: 23.435,43.553,97.906,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.760 | Acc: 23.394,43.531,97.905,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.760 | Acc: 23.337,43.442,97.911,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.994 | Acc: 23.438,49.219,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.943 | Acc: 21.838,43.638,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.998 | Acc: 22.256,42.492,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 22.400,42.661,71.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 236
Batch: 0 | Loss: 0.772 | Acc: 19.531,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.775 | Acc: 22.879,41.295,97.693,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.764 | Acc: 23.247,42.702,97.866,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.760 | Acc: 23.117,43.340,97.989,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.762 | Acc: 23.341,43.355,97.888,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.764 | Acc: 22.788,43.031,97.935,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.762 | Acc: 23.005,43.246,98.005,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 23.155,43.218,98.022,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.759 | Acc: 23.302,43.435,98.010,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 23.355,43.569,98.045,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.759 | Acc: 23.092,43.346,98.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 23.197,43.396,98.063,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 23.207,43.374,98.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 23.243,43.412,98.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 23.201,43.444,98.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 23.277,43.472,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.757 | Acc: 23.253,43.400,98.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 23.257,43.351,98.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 23.267,43.322,98.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 23.261,43.321,98.070,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.054 | Acc: 24.219,48.438,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.941 | Acc: 22.321,43.973,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.993 | Acc: 22.389,42.588,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.002 | Acc: 22.349,42.751,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 237
Batch: 0 | Loss: 0.794 | Acc: 19.531,41.406,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.767 | Acc: 22.470,41.406,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.766 | Acc: 23.171,42.092,97.828,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.769 | Acc: 23.181,41.842,97.874,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.765 | Acc: 22.782,41.686,98.042,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.764 | Acc: 22.981,42.025,98.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.763 | Acc: 23.089,42.323,98.031,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.761 | Acc: 23.349,42.736,98.027,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.761 | Acc: 23.263,42.784,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.761 | Acc: 23.213,42.861,98.006,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.761 | Acc: 23.169,42.980,98.029,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.762 | Acc: 23.109,43.036,97.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.761 | Acc: 23.013,42.995,98.013,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.760 | Acc: 23.072,43.017,98.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.760 | Acc: 23.159,43.060,98.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.760 | Acc: 23.139,43.145,98.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.759 | Acc: 23.211,43.122,98.041,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.758 | Acc: 23.195,43.232,98.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 23.178,43.254,98.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.759 | Acc: 23.204,43.289,98.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.001 | Acc: 25.000,46.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 21.801,44.085,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.004 | Acc: 22.085,43.045,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 22.182,42.892,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 238
Batch: 0 | Loss: 0.748 | Acc: 17.188,46.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 23.549,45.350,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.761 | Acc: 23.114,43.693,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.758 | Acc: 23.220,44.249,97.951,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.758 | Acc: 23.139,44.203,98.003,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.757 | Acc: 23.012,43.827,98.020,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.757 | Acc: 22.921,43.899,98.069,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.756 | Acc: 22.817,43.872,98.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.758 | Acc: 22.899,43.697,98.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.757 | Acc: 23.071,43.931,98.040,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 23.064,43.758,98.037,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.758 | Acc: 23.123,43.633,98.035,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.758 | Acc: 23.159,43.662,98.036,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.758 | Acc: 23.237,43.675,98.021,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 23.260,43.639,98.012,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 23.232,43.633,98.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 23.114,43.546,98.046,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.758 | Acc: 23.041,43.477,98.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.758 | Acc: 22.955,43.293,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.758 | Acc: 23.036,43.389,98.066,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.041 | Acc: 24.219,46.875,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.953 | Acc: 22.098,43.936,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.007 | Acc: 22.237,42.740,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.009 | Acc: 22.323,42.713,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 239
Batch: 0 | Loss: 0.730 | Acc: 31.250,52.344,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.757 | Acc: 24.256,44.048,97.917,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.756 | Acc: 23.990,44.379,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.755 | Acc: 24.206,44.109,97.976,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 23.891,43.953,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 23.994,44.346,98.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.753 | Acc: 23.618,43.970,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.754 | Acc: 23.537,44.027,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.754 | Acc: 23.510,44.036,98.141,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.755 | Acc: 23.416,44.005,98.122,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 23.348,43.956,98.142,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.755 | Acc: 23.321,43.835,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 23.262,43.679,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 23.261,43.594,98.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 23.246,43.564,98.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.756 | Acc: 23.248,43.490,98.090,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.756 | Acc: 23.357,43.509,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.756 | Acc: 23.408,43.516,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.756 | Acc: 23.353,43.423,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.757 | Acc: 23.267,43.455,98.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.010 | Acc: 25.781,46.875,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.946 | Acc: 21.875,43.713,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.002 | Acc: 22.218,42.873,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.008 | Acc: 22.413,42.930,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 240
Batch: 0 | Loss: 0.754 | Acc: 23.438,46.875,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.747 | Acc: 23.958,45.164,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 23.609,44.474,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 23.194,43.776,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.749 | Acc: 22.984,44.030,98.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 22.896,43.750,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.750 | Acc: 23.205,43.705,98.179,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 23.061,43.384,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.753 | Acc: 23.088,43.391,98.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 23.213,43.435,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 23.325,43.462,98.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 23.285,43.375,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 23.279,43.432,98.087,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 23.276,43.481,98.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 23.212,43.389,98.079,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 23.240,43.475,98.074,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 23.360,43.567,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 23.337,43.569,98.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 23.301,43.594,98.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 23.249,43.541,98.107,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.035 | Acc: 25.000,48.438,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.958 | Acc: 22.173,43.824,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.332,42.835,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.374,42.918,71.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 241
Batch: 0 | Loss: 0.718 | Acc: 20.312,38.281,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.761 | Acc: 22.954,42.932,97.805,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 22.428,42.569,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.759 | Acc: 22.964,43.007,97.836,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.757 | Acc: 23.187,43.007,97.955,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 23.236,43.000,98.004,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 23.050,43.104,98.044,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.756 | Acc: 23.000,43.057,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.757 | Acc: 23.074,43.109,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.758 | Acc: 22.889,43.068,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.758 | Acc: 22.788,42.938,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.759 | Acc: 22.826,43.068,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.759 | Acc: 22.890,43.043,98.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.759 | Acc: 22.920,43.038,98.051,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.758 | Acc: 22.995,43.113,98.068,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.758 | Acc: 23.043,43.189,98.064,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.758 | Acc: 23.107,43.278,98.060,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.757 | Acc: 23.119,43.310,98.043,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.757 | Acc: 23.132,43.278,98.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.756 | Acc: 23.214,43.418,98.077,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.029 | Acc: 24.219,47.656,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 21.875,43.936,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.017 | Acc: 22.199,42.988,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 22.221,43.084,71.158,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 242
Batch: 0 | Loss: 0.792 | Acc: 20.312,41.406,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.749 | Acc: 23.772,44.345,97.991,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 23.552,44.284,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.749 | Acc: 23.399,43.865,98.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.751 | Acc: 22.965,43.605,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.749 | Acc: 23.043,43.564,98.275,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.748 | Acc: 23.121,43.795,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.748 | Acc: 23.277,43.839,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.749 | Acc: 23.277,43.745,98.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.748 | Acc: 23.321,43.836,98.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.749 | Acc: 23.251,43.804,98.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.750 | Acc: 23.324,43.824,98.211,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.750 | Acc: 23.266,43.786,98.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.749 | Acc: 23.345,43.717,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.750 | Acc: 23.307,43.608,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.751 | Acc: 23.326,43.555,98.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.751 | Acc: 23.309,43.516,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.751 | Acc: 23.279,43.519,98.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.751 | Acc: 23.273,43.514,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.751 | Acc: 23.269,43.570,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.014 | Acc: 23.438,50.781,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 22.173,44.420,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.018 | Acc: 22.294,42.912,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 22.362,42.853,71.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 243
Batch: 0 | Loss: 0.777 | Acc: 26.562,47.656,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.745 | Acc: 23.921,44.531,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 23.266,43.845,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 23.642,43.763,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 23.389,43.769,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.748 | Acc: 23.229,43.843,98.267,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.750 | Acc: 23.212,43.731,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.751 | Acc: 23.066,43.606,98.232,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.752 | Acc: 23.078,43.488,98.253,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.752 | Acc: 23.097,43.409,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.752 | Acc: 23.130,43.237,98.255,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.752 | Acc: 23.144,43.255,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 23.165,43.280,98.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 23.123,43.277,98.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 23.162,43.308,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 23.238,43.340,98.183,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.754 | Acc: 23.228,43.424,98.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 23.254,43.473,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 23.238,43.421,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 23.228,43.426,98.169,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.945 | Acc: 24.219,48.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.942 | Acc: 21.987,43.936,72.619,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 22.332,43.045,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.014 | Acc: 22.362,42.930,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 244
Batch: 0 | Loss: 0.724 | Acc: 28.125,45.312,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.744 | Acc: 24.182,44.866,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.758 | Acc: 23.171,42.778,97.885,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.757 | Acc: 23.015,42.969,98.002,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.758 | Acc: 22.965,43.181,98.032,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.759 | Acc: 23.151,43.317,97.904,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.759 | Acc: 23.089,43.221,97.940,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.757 | Acc: 23.105,43.041,97.983,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 23.195,43.250,98.025,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.755 | Acc: 23.097,43.215,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 23.010,43.260,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.754 | Acc: 22.974,43.188,98.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.754 | Acc: 23.010,43.134,98.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.754 | Acc: 23.120,43.250,98.084,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.753 | Acc: 23.173,43.347,98.118,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.754 | Acc: 23.157,43.368,98.108,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.753 | Acc: 23.182,43.426,98.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.753 | Acc: 23.183,43.351,98.105,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 23.165,43.339,98.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.754 | Acc: 23.234,43.375,98.085,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.026 | Acc: 22.656,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.950 | Acc: 21.838,44.159,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.006 | Acc: 22.066,42.969,71.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 22.195,42.853,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 245
Batch: 0 | Loss: 0.767 | Acc: 22.656,43.750,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.746 | Acc: 24.702,43.638,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 23.609,43.312,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.756 | Acc: 23.284,43.084,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.755 | Acc: 23.322,43.519,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.756 | Acc: 23.167,43.131,98.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.758 | Acc: 22.960,43.201,98.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.758 | Acc: 22.856,43.035,98.138,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.756 | Acc: 23.025,43.270,98.137,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.756 | Acc: 23.045,43.297,98.109,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.757 | Acc: 22.987,43.218,98.123,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.756 | Acc: 23.027,43.234,98.130,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.756 | Acc: 23.104,43.393,98.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.755 | Acc: 23.222,43.343,98.186,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.755 | Acc: 23.215,43.486,98.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 23.194,43.524,98.157,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 23.214,43.516,98.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.754 | Acc: 23.293,43.571,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.754 | Acc: 23.245,43.568,98.178,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.754 | Acc: 23.161,43.539,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.992 | Acc: 24.219,46.094,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.938 | Acc: 22.284,44.308,72.842,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 1.994 | Acc: 22.485,42.950,71.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.003 | Acc: 22.451,42.853,71.709,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 246
Batch: 0 | Loss: 0.773 | Acc: 27.344,52.344,94.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.756 | Acc: 24.033,44.382,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 24.028,44.627,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.752 | Acc: 23.924,43.904,98.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.751 | Acc: 23.573,44.261,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 23.577,43.936,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.751 | Acc: 23.321,43.834,98.276,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.752 | Acc: 23.365,43.661,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 23.379,43.745,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.751 | Acc: 23.416,43.892,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.751 | Acc: 23.395,43.890,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.751 | Acc: 23.360,43.757,98.236,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.751 | Acc: 23.331,43.675,98.240,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.752 | Acc: 23.285,43.606,98.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.752 | Acc: 23.262,43.639,98.229,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.752 | Acc: 23.316,43.638,98.230,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.752 | Acc: 23.240,43.614,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.751 | Acc: 23.282,43.654,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.752 | Acc: 23.280,43.557,98.215,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.752 | Acc: 23.230,43.520,98.224,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.978 | Acc: 23.438,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.950 | Acc: 22.396,44.382,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.002 | Acc: 22.466,43.102,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.007 | Acc: 22.451,43.071,71.478,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 247
Batch: 0 | Loss: 0.777 | Acc: 18.750,39.844,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 24.554,43.973,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.751 | Acc: 23.685,43.769,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.751 | Acc: 23.399,43.635,98.194,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.753 | Acc: 23.167,43.007,98.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.752 | Acc: 23.438,43.270,98.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.754 | Acc: 23.496,43.324,98.128,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.752 | Acc: 23.332,43.418,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.755 | Acc: 23.277,43.410,98.054,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.754 | Acc: 23.235,43.521,98.071,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.755 | Acc: 23.158,43.439,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.755 | Acc: 23.049,43.481,98.049,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.755 | Acc: 23.052,43.552,98.048,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.756 | Acc: 23.060,43.370,98.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.756 | Acc: 23.073,43.369,98.034,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.755 | Acc: 23.147,43.415,98.072,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.755 | Acc: 23.109,43.387,98.089,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.755 | Acc: 23.124,43.406,98.078,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.755 | Acc: 23.152,43.415,98.106,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.755 | Acc: 23.118,43.516,98.111,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.990 | Acc: 24.219,48.438,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.953 | Acc: 22.247,44.085,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.008 | Acc: 22.351,42.873,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.016 | Acc: 22.323,42.815,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 248
Batch: 0 | Loss: 0.747 | Acc: 21.875,42.188,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.745 | Acc: 24.070,43.118,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.744 | Acc: 24.104,43.312,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 23.950,43.225,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.746 | Acc: 23.688,43.152,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.746 | Acc: 23.345,43.077,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.749 | Acc: 23.276,43.182,98.218,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.750 | Acc: 23.210,43.063,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.750 | Acc: 23.059,43.255,98.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.748 | Acc: 23.153,43.560,98.217,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.749 | Acc: 23.255,43.595,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.749 | Acc: 23.254,43.605,98.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.750 | Acc: 23.301,43.630,98.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.750 | Acc: 23.303,43.579,98.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.751 | Acc: 23.260,43.558,98.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.750 | Acc: 23.308,43.568,98.162,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.751 | Acc: 23.311,43.599,98.143,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.751 | Acc: 23.245,43.539,98.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.751 | Acc: 23.210,43.577,98.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.751 | Acc: 23.208,43.621,98.187,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.981 | Acc: 24.219,46.094,75.781,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 21.987,43.378,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.123,42.473,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.019 | Acc: 22.067,42.520,71.183,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 249
Batch: 0 | Loss: 0.792 | Acc: 20.312,38.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.760 | Acc: 22.693,43.787,97.731,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.759 | Acc: 23.190,43.712,97.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.756 | Acc: 23.117,43.443,98.015,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.750 | Acc: 23.544,43.779,98.100,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 23.190,43.897,98.136,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 22.986,43.634,98.115,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.752 | Acc: 22.767,43.495,98.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.752 | Acc: 23.006,43.532,98.088,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.752 | Acc: 23.040,43.633,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.754 | Acc: 23.022,43.563,98.057,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.753 | Acc: 23.038,43.594,98.080,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.753 | Acc: 23.087,43.426,98.110,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.753 | Acc: 23.078,43.382,98.093,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.752 | Acc: 23.168,43.430,98.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.753 | Acc: 23.001,43.485,98.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.752 | Acc: 23.150,43.533,98.104,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.752 | Acc: 23.188,43.592,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.752 | Acc: 23.219,43.560,98.117,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.753 | Acc: 23.206,43.570,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.942 | Acc: 25.000,48.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.948 | Acc: 22.433,44.494,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.001 | Acc: 22.561,43.007,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.012 | Acc: 22.567,42.943,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 250
Batch: 0 | Loss: 0.840 | Acc: 20.312,46.094,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.752 | Acc: 22.396,42.671,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.747 | Acc: 23.152,42.950,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 23.617,43.737,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.751 | Acc: 23.418,43.306,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 23.221,42.938,98.182,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 23.354,43.150,98.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 23.382,43.301,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 23.331,43.488,98.166,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.751 | Acc: 23.351,43.331,98.144,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.750 | Acc: 23.313,43.357,98.193,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.749 | Acc: 23.321,43.400,98.204,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.750 | Acc: 23.389,43.478,98.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.751 | Acc: 23.324,43.346,98.174,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.752 | Acc: 23.254,43.341,98.159,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.751 | Acc: 23.323,43.389,98.168,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.751 | Acc: 23.357,43.475,98.160,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.751 | Acc: 23.371,43.599,98.172,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.751 | Acc: 23.334,43.590,98.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.750 | Acc: 23.382,43.654,98.185,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.944 | Acc: 22.098,43.899,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.003 | Acc: 22.389,42.969,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.008 | Acc: 22.451,42.918,71.721,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 251
Batch: 0 | Loss: 0.741 | Acc: 26.562,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 22.024,42.597,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.755 | Acc: 22.771,43.007,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.754 | Acc: 22.989,42.495,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 22.859,43.036,98.225,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.755 | Acc: 22.826,43.062,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.755 | Acc: 22.986,43.175,98.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.755 | Acc: 23.288,43.124,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.752 | Acc: 23.394,43.444,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.752 | Acc: 23.325,43.452,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.752 | Acc: 23.189,43.381,98.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.751 | Acc: 23.349,43.556,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.751 | Acc: 23.421,43.442,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.751 | Acc: 23.393,43.454,98.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.751 | Acc: 23.390,43.469,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.752 | Acc: 23.349,43.485,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.752 | Acc: 23.326,43.370,98.272,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.751 | Acc: 23.330,43.402,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.751 | Acc: 23.357,43.451,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.751 | Acc: 23.343,43.461,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.989 | Acc: 24.219,47.656,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 22.098,43.638,72.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.009 | Acc: 22.294,42.816,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.013 | Acc: 22.323,42.866,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 252
Batch: 0 | Loss: 0.746 | Acc: 22.656,46.875,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 21.726,42.857,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.752 | Acc: 21.913,43.483,98.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 22.618,43.238,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.748 | Acc: 23.158,43.769,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.747 | Acc: 23.128,43.742,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.399,44.163,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.745 | Acc: 23.199,43.949,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.745 | Acc: 23.243,43.852,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.744 | Acc: 23.416,43.944,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 23.414,43.917,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.746 | Acc: 23.300,43.775,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 23.269,43.799,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 23.312,43.819,98.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.746 | Acc: 23.332,43.850,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.746 | Acc: 23.445,43.802,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.746 | Acc: 23.403,43.823,98.372,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.746 | Acc: 23.346,43.796,98.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.747 | Acc: 23.379,43.802,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.747 | Acc: 23.386,43.826,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.051 | Acc: 24.219,47.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.960 | Acc: 22.173,44.494,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.014 | Acc: 22.275,43.197,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 22.387,43.251,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 253
Batch: 0 | Loss: 0.690 | Acc: 26.562,49.219,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 23.586,44.159,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.750 | Acc: 23.438,44.036,98.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 23.361,44.134,98.245,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.751 | Acc: 23.129,43.895,98.235,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 23.167,43.773,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.754 | Acc: 23.005,43.421,98.102,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.753 | Acc: 23.205,43.573,98.188,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 23.389,43.774,98.234,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.749 | Acc: 23.360,43.905,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.747 | Acc: 23.368,44.042,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.748 | Acc: 23.293,43.930,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.748 | Acc: 23.243,43.672,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.749 | Acc: 23.195,43.526,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.749 | Acc: 23.223,43.553,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.750 | Acc: 23.206,43.576,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.749 | Acc: 23.175,43.514,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.749 | Acc: 23.250,43.564,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.749 | Acc: 23.225,43.583,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.749 | Acc: 23.319,43.580,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.003 | Acc: 25.000,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.952 | Acc: 22.210,44.271,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.409,43.140,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.464,43.020,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 254
Batch: 0 | Loss: 0.729 | Acc: 22.656,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 23.698,43.527,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.747 | Acc: 23.095,43.255,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.749 | Acc: 23.322,43.110,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.750 | Acc: 23.071,43.065,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 22.997,42.984,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.751 | Acc: 23.179,43.046,98.237,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.750 | Acc: 23.133,42.880,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 23.171,43.022,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.752 | Acc: 23.010,42.960,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.751 | Acc: 23.060,43.046,98.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.750 | Acc: 23.066,43.276,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.750 | Acc: 23.078,43.235,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.749 | Acc: 23.213,43.439,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.749 | Acc: 23.193,43.503,98.287,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.749 | Acc: 23.129,43.452,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.750 | Acc: 23.133,43.453,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.749 | Acc: 23.190,43.454,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.749 | Acc: 23.223,43.486,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.749 | Acc: 23.245,43.584,98.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.972 | Acc: 23.438,49.219,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.950 | Acc: 22.061,44.606,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.010 | Acc: 22.237,43.216,71.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.298,43.122,71.593,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 255
Batch: 0 | Loss: 0.722 | Acc: 17.188,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.736 | Acc: 24.070,43.378,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.747 | Acc: 23.399,42.778,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 23.412,42.905,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.744 | Acc: 23.187,42.940,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.745 | Acc: 23.337,43.178,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.745 | Acc: 23.250,43.233,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.745 | Acc: 23.371,43.406,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.745 | Acc: 23.486,43.435,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.746 | Acc: 23.528,43.297,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 23.476,43.447,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.745 | Acc: 23.339,43.347,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 23.272,43.452,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.746 | Acc: 23.282,43.418,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.747 | Acc: 23.243,43.380,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.746 | Acc: 23.308,43.446,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.748 | Acc: 23.364,43.451,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.748 | Acc: 23.311,43.461,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.748 | Acc: 23.353,43.560,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.748 | Acc: 23.257,43.526,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 25.000,48.438,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 22.545,44.271,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.561,43.140,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.592,43.238,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 256
Batch: 0 | Loss: 0.729 | Acc: 21.094,48.438,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.754 | Acc: 23.586,44.940,98.028,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.754 | Acc: 23.685,43.979,98.095,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.756 | Acc: 23.194,43.814,98.092,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.754 | Acc: 23.399,43.856,98.119,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.753 | Acc: 23.221,43.959,98.120,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.752 | Acc: 23.425,44.053,98.121,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.752 | Acc: 23.421,43.844,98.133,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.751 | Acc: 23.399,43.668,98.180,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.749 | Acc: 23.317,43.793,98.209,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.749 | Acc: 23.414,43.867,98.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.750 | Acc: 23.370,43.785,98.158,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.750 | Acc: 23.279,43.834,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.750 | Acc: 23.165,43.738,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.749 | Acc: 23.262,43.783,98.198,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.749 | Acc: 23.110,43.592,98.181,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.749 | Acc: 23.289,43.658,98.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.749 | Acc: 23.282,43.672,98.192,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.750 | Acc: 23.362,43.683,98.189,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.749 | Acc: 23.366,43.760,98.165,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.962 | Acc: 25.000,48.438,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.959 | Acc: 22.135,44.531,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.332,43.274,70.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 22.374,43.097,71.132,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 257
Batch: 0 | Loss: 0.678 | Acc: 35.156,50.781,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.741 | Acc: 24.293,43.452,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.743 | Acc: 23.838,44.741,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.742 | Acc: 23.706,44.416,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.746 | Acc: 23.225,44.117,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.745 | Acc: 23.213,44.160,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.237,44.215,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.745 | Acc: 23.172,43.916,98.316,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.746 | Acc: 23.083,43.920,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.747 | Acc: 23.036,43.616,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.747 | Acc: 23.181,43.684,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.747 | Acc: 23.165,43.623,98.282,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.747 | Acc: 23.126,43.617,98.259,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 23.123,43.582,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.746 | Acc: 23.187,43.667,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.747 | Acc: 23.082,43.553,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.747 | Acc: 23.167,43.543,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.747 | Acc: 23.208,43.548,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.747 | Acc: 23.191,43.525,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.747 | Acc: 23.239,43.551,98.339,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.027 | Acc: 24.219,50.000,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 22.396,44.122,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.020 | Acc: 22.580,43.026,71.056,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.707,43.135,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 258
Batch: 0 | Loss: 0.755 | Acc: 21.875,40.625,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 23.103,42.634,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.739 | Acc: 23.895,43.236,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.739 | Acc: 23.950,43.801,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.742 | Acc: 24.122,44.165,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 24.018,44.230,98.306,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 24.012,44.170,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.743 | Acc: 23.659,43.911,98.338,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.744 | Acc: 23.602,43.716,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.745 | Acc: 23.563,43.698,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 23.430,43.649,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.746 | Acc: 23.406,43.467,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.748 | Acc: 23.382,43.358,98.256,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.748 | Acc: 23.420,43.415,98.258,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.748 | Acc: 23.399,43.472,98.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.748 | Acc: 23.279,43.506,98.271,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.748 | Acc: 23.228,43.555,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.748 | Acc: 23.305,43.649,98.298,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.748 | Acc: 23.351,43.756,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.748 | Acc: 23.284,43.684,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.002 | Acc: 24.219,47.656,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 22.433,43.750,72.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 22.771,42.912,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 22.861,43.033,71.350,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 259
Batch: 0 | Loss: 0.711 | Acc: 22.656,49.219,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.744 | Acc: 23.214,43.899,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.751 | Acc: 22.809,43.426,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 23.271,43.609,98.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.748 | Acc: 23.447,43.721,98.196,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 23.538,43.619,98.205,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.749 | Acc: 23.250,43.634,98.270,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.749 | Acc: 23.299,43.484,98.327,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.748 | Acc: 23.209,43.401,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.747 | Acc: 23.312,43.362,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.748 | Acc: 23.251,43.284,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.747 | Acc: 23.151,43.354,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.747 | Acc: 23.188,43.461,98.324,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 23.192,43.424,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.748 | Acc: 23.184,43.377,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.747 | Acc: 23.284,43.405,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.747 | Acc: 23.262,43.480,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.748 | Acc: 23.199,43.432,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.747 | Acc: 23.264,43.488,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.747 | Acc: 23.193,43.504,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.023 | Acc: 24.219,48.438,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.098,44.345,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.022 | Acc: 22.256,43.083,71.265,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.023 | Acc: 22.234,43.033,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 260
Batch: 0 | Loss: 0.693 | Acc: 24.219,42.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.746 | Acc: 23.177,44.457,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.745 | Acc: 22.542,43.197,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.745 | Acc: 22.810,43.481,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.745 | Acc: 22.849,43.692,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.743 | Acc: 23.314,44.330,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 23.392,44.196,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 23.432,44.304,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.394,44.230,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.381,44.160,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.744 | Acc: 23.356,44.193,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.744 | Acc: 23.413,44.142,98.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.745 | Acc: 23.343,44.048,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.745 | Acc: 23.366,43.966,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.746 | Acc: 23.390,44.025,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.746 | Acc: 23.435,43.950,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.746 | Acc: 23.435,43.976,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.747 | Acc: 23.344,44.000,98.332,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.747 | Acc: 23.390,43.938,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.748 | Acc: 23.372,43.916,98.302,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.995 | Acc: 24.219,48.438,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.956 | Acc: 21.987,44.606,72.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.275,43.140,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.426,43.174,71.273,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 261
Batch: 0 | Loss: 0.700 | Acc: 14.844,42.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.758 | Acc: 22.619,43.378,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.752 | Acc: 23.380,43.941,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.748 | Acc: 23.271,43.494,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.742 | Acc: 23.254,43.644,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 23.198,43.851,98.546,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 23.250,43.944,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.743 | Acc: 23.365,43.999,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.744 | Acc: 23.345,43.794,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.745 | Acc: 23.390,43.754,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 23.282,43.738,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.746 | Acc: 23.190,43.761,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 23.055,43.607,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 22.989,43.573,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.747 | Acc: 23.165,43.722,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.748 | Acc: 23.181,43.776,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.748 | Acc: 23.187,43.748,98.260,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.747 | Acc: 23.204,43.794,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.748 | Acc: 23.219,43.741,98.286,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.748 | Acc: 23.228,43.734,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 25.000,50.000,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.961 | Acc: 22.247,44.048,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.389,42.969,71.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.023 | Acc: 22.541,43.007,71.414,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 262
Batch: 0 | Loss: 0.742 | Acc: 21.875,45.312,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.740 | Acc: 25.037,45.461,98.214,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.744 | Acc: 24.009,44.284,98.342,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.745 | Acc: 23.591,43.814,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.745 | Acc: 23.659,43.779,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.744 | Acc: 23.708,43.773,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 23.541,43.873,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.743 | Acc: 23.548,43.966,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.743 | Acc: 23.438,43.789,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.550,43.733,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.601,43.874,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.744 | Acc: 23.367,43.679,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.744 | Acc: 23.412,43.789,98.415,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.443,43.753,98.411,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.745 | Acc: 23.379,43.714,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.745 | Acc: 23.393,43.677,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.374,43.689,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.396,43.720,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.446,43.800,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.745 | Acc: 23.358,43.748,98.427,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.022 | Acc: 25.781,50.000,70.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.986 | Acc: 22.247,44.680,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.038 | Acc: 22.561,43.559,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.042 | Acc: 22.528,43.199,71.107,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 263
Batch: 0 | Loss: 0.753 | Acc: 22.656,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.748 | Acc: 22.210,42.039,98.512,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.746 | Acc: 22.752,42.588,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.749 | Acc: 22.848,43.097,98.233,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 23.553,43.355,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.748 | Acc: 23.546,43.448,98.190,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.747 | Acc: 23.450,43.292,98.263,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.747 | Acc: 23.271,43.262,98.238,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.746 | Acc: 23.141,43.381,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.745 | Acc: 23.135,43.448,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.744 | Acc: 23.022,43.470,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.743 | Acc: 23.088,43.541,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.071,43.617,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.042,43.570,98.393,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.744 | Acc: 22.993,43.569,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.744 | Acc: 22.968,43.589,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 22.929,43.653,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 22.950,43.619,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.015,43.715,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.060,43.678,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.017 | Acc: 25.000,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.978 | Acc: 22.842,44.420,72.061,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.041 | Acc: 22.866,43.197,70.675,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.040 | Acc: 22.682,42.943,71.017,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 264
Batch: 0 | Loss: 0.733 | Acc: 23.438,43.750,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 23.772,45.722,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.742 | Acc: 23.133,44.588,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.739 | Acc: 23.079,44.698,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.743 | Acc: 22.704,43.933,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.744 | Acc: 22.966,43.959,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.250,44.060,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.746 | Acc: 23.321,43.833,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.747 | Acc: 23.224,43.832,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.746 | Acc: 23.213,44.061,98.317,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.747 | Acc: 23.197,43.972,98.274,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.746 | Acc: 23.204,43.906,98.314,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.745 | Acc: 23.194,43.919,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.746 | Acc: 23.159,43.774,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.746 | Acc: 23.148,43.786,98.340,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.746 | Acc: 23.173,43.846,98.334,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.745 | Acc: 23.170,43.906,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.240,43.892,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.336,43.975,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.314,43.935,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.033 | Acc: 24.219,48.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.024,44.643,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 22.294,43.369,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.400,43.251,71.260,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 265
Batch: 0 | Loss: 0.673 | Acc: 28.906,57.812,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.742 | Acc: 25.298,45.275,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 24.390,44.017,98.304,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.744 | Acc: 23.873,43.750,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.744 | Acc: 23.515,43.605,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.743 | Acc: 23.600,43.425,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 23.580,43.634,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 23.582,43.889,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.501,43.760,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.741 | Acc: 23.593,43.871,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.507,43.762,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.743 | Acc: 23.544,43.870,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.438,43.948,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.518,43.992,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.449,43.911,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.417,43.846,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.428,43.879,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.421,43.819,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.489,43.865,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.458,43.791,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.006 | Acc: 25.781,48.438,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.024,43.936,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 22.123,42.835,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.285,42.969,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 266
Batch: 0 | Loss: 0.705 | Acc: 28.125,47.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.730 | Acc: 24.368,45.387,98.921,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.740 | Acc: 23.533,43.941,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.741 | Acc: 23.194,43.801,98.527,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.740 | Acc: 23.544,44.300,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.738 | Acc: 23.685,44.493,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.738 | Acc: 23.657,44.460,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.739 | Acc: 23.631,44.443,98.565,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.739 | Acc: 23.632,44.318,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 23.610,44.255,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.742 | Acc: 23.686,44.279,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.604,44.256,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.567,44.359,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.518,44.280,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.362,44.167,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.316,44.082,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.282,44.020,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.309,44.016,98.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.297,43.999,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.269,43.937,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.028 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 22.359,44.643,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.024 | Acc: 22.504,43.483,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.023 | Acc: 22.528,43.340,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 267
Batch: 0 | Loss: 0.690 | Acc: 28.125,42.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.737 | Acc: 22.619,43.973,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.741 | Acc: 22.313,43.693,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.741 | Acc: 22.682,43.750,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.741 | Acc: 22.820,43.335,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 22.896,43.162,98.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 22.863,43.233,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.741 | Acc: 23.044,43.528,98.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.010,43.498,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 22.958,43.413,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.742 | Acc: 22.932,43.427,98.480,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 22.950,43.503,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 22.993,43.575,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.033,43.561,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.057,43.605,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.110,43.628,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.121,43.701,98.423,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.124,43.624,98.424,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.115,43.646,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.116,43.635,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.011 | Acc: 23.438,48.438,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.951 | Acc: 22.284,44.420,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.012 | Acc: 22.370,43.121,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.310,43.020,71.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 268
Batch: 0 | Loss: 0.782 | Acc: 13.281,39.844,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.745 | Acc: 24.219,44.792,98.140,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.750 | Acc: 23.571,44.303,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.747 | Acc: 23.373,43.916,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.748 | Acc: 23.129,43.297,98.264,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.749 | Acc: 23.291,43.433,98.213,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.748 | Acc: 23.502,43.563,98.231,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.747 | Acc: 23.543,43.623,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.748 | Acc: 23.438,43.566,98.248,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.748 | Acc: 23.273,43.526,98.222,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.748 | Acc: 23.278,43.509,98.228,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.748 | Acc: 23.328,43.619,98.243,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.747 | Acc: 23.266,43.578,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 23.333,43.720,98.261,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.747 | Acc: 23.343,43.600,98.279,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.747 | Acc: 23.323,43.581,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.746 | Acc: 23.360,43.550,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.746 | Acc: 23.348,43.587,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.746 | Acc: 23.357,43.629,98.344,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.745 | Acc: 23.507,43.699,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.006 | Acc: 23.438,49.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 21.875,44.271,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 22.180,43.121,71.151,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 22.234,42.918,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 269
Batch: 0 | Loss: 0.784 | Acc: 22.656,42.188,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 22.619,42.783,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.750 | Acc: 23.533,43.236,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 23.322,43.852,98.284,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 23.283,43.933,98.331,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.751 | Acc: 23.345,43.564,98.244,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.748 | Acc: 23.444,43.711,98.283,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.751 | Acc: 23.432,43.672,98.221,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.750 | Acc: 23.433,43.706,98.239,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.749 | Acc: 23.235,43.573,98.299,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.749 | Acc: 23.239,43.528,98.313,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.749 | Acc: 23.222,43.647,98.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.748 | Acc: 23.188,43.727,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.748 | Acc: 23.225,43.738,98.330,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.747 | Acc: 23.184,43.603,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.747 | Acc: 23.194,43.612,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.747 | Acc: 23.182,43.667,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.746 | Acc: 23.263,43.706,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.746 | Acc: 23.254,43.702,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.745 | Acc: 23.181,43.686,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.038 | Acc: 24.219,50.000,75.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.978 | Acc: 21.912,44.159,71.987,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 21.951,43.102,70.827,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 22.131,42.969,71.196,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 270
Batch: 0 | Loss: 0.728 | Acc: 23.438,44.531,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.735 | Acc: 23.214,45.089,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.736 | Acc: 24.238,44.531,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.740 | Acc: 23.604,43.942,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.742 | Acc: 23.621,44.010,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 23.360,43.928,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 23.257,43.769,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.743 | Acc: 23.316,43.889,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.745 | Acc: 23.137,43.624,98.292,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.744 | Acc: 23.282,43.724,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.744 | Acc: 23.162,43.758,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.744 | Acc: 23.095,43.605,98.381,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.744 | Acc: 23.159,43.630,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.153,43.618,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.190,43.711,98.365,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.240,43.786,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.291,43.787,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.355,43.775,98.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.405,43.789,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.421,43.795,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.010 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.970 | Acc: 22.135,44.457,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.026 | Acc: 22.351,43.274,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 22.477,43.302,71.324,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 271
Batch: 0 | Loss: 0.702 | Acc: 24.219,50.781,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.730 | Acc: 24.628,45.275,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.733 | Acc: 23.952,45.160,98.723,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.735 | Acc: 23.988,44.864,98.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.741 | Acc: 23.727,44.676,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 23.708,44.315,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 23.728,44.286,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 23.587,44.099,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.593,44.022,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.498,44.048,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.426,44.092,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.743 | Acc: 23.459,44.079,98.356,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.522,44.035,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.399,43.807,98.354,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.744 | Acc: 23.326,43.775,98.368,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.744 | Acc: 23.284,43.695,98.388,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.272,43.679,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.745 | Acc: 23.218,43.711,98.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.745 | Acc: 23.180,43.750,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.745 | Acc: 23.234,43.758,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.995 | Acc: 24.219,49.219,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.965 | Acc: 22.061,44.234,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.020 | Acc: 22.218,43.140,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 22.336,43.186,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 272
Batch: 0 | Loss: 0.749 | Acc: 21.094,42.969,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.747 | Acc: 23.363,43.750,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.738 | Acc: 24.123,44.245,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.740 | Acc: 23.911,44.121,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.741 | Acc: 24.035,43.914,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 24.226,43.858,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.740 | Acc: 23.728,43.666,98.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.741 | Acc: 23.748,43.429,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.777,43.536,98.549,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.741 | Acc: 23.813,43.616,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.742 | Acc: 23.671,43.501,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.600,43.464,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.596,43.471,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.740 | Acc: 23.620,43.454,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.741 | Acc: 23.513,43.469,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.741 | Acc: 23.526,43.516,98.456,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.741 | Acc: 23.530,43.514,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.481,43.464,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.476,43.501,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.458,43.584,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.979 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.507,44.903,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.021 | Acc: 22.599,43.655,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 22.592,43.481,71.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 273
Batch: 0 | Loss: 0.734 | Acc: 16.406,41.406,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 22.247,42.708,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.751 | Acc: 22.942,42.664,98.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.752 | Acc: 22.503,42.354,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.749 | Acc: 22.560,42.602,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.748 | Acc: 22.556,42.644,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.746 | Acc: 22.843,42.969,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.746 | Acc: 23.027,42.952,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.745 | Acc: 23.214,43.202,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.746 | Acc: 23.191,43.137,98.416,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 23.414,43.311,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.747 | Acc: 23.190,43.248,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 23.240,43.380,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.745 | Acc: 23.291,43.505,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.745 | Acc: 23.368,43.630,98.385,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.745 | Acc: 23.336,43.615,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.745 | Acc: 23.408,43.723,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.745 | Acc: 23.394,43.631,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.745 | Acc: 23.483,43.744,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.745 | Acc: 23.499,43.762,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.024 | Acc: 25.000,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.433,44.717,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.022 | Acc: 22.561,43.598,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.028 | Acc: 22.567,43.430,71.401,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 274
Batch: 0 | Loss: 0.741 | Acc: 22.656,44.531,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.749 | Acc: 22.731,43.638,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.738 | Acc: 23.514,44.550,98.800,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.739 | Acc: 23.578,44.147,98.770,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.739 | Acc: 23.235,43.731,98.630,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 22.942,43.649,98.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.739 | Acc: 23.341,43.911,98.663,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.741 | Acc: 23.343,43.717,98.626,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.740 | Acc: 23.282,43.760,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.740 | Acc: 23.200,43.694,98.649,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.146,43.595,98.632,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.077,43.609,98.618,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 23.094,43.669,98.596,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.054,43.720,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.196,43.900,98.560,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.178,43.859,98.534,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.160,43.974,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.165,43.908,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.184,43.884,98.524,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.224,43.832,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.034 | Acc: 24.219,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.962 | Acc: 22.321,44.717,71.912,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.018 | Acc: 22.485,43.617,70.808,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.503,43.404,71.388,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 275
Batch: 0 | Loss: 0.771 | Acc: 16.406,38.281,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.748 | Acc: 22.024,41.927,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.747 | Acc: 22.790,43.026,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.748 | Acc: 23.040,42.828,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.744 | Acc: 23.100,43.374,98.582,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.744 | Acc: 22.942,43.216,98.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 22.921,43.737,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 23.072,43.706,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.243,43.915,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 23.200,43.849,98.584,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.742 | Acc: 23.255,43.913,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.314,43.853,98.568,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 23.353,43.945,98.532,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.743 | Acc: 23.384,43.951,98.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.379,43.933,98.490,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.331,43.926,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.260,43.886,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.254,43.816,98.488,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.273,43.839,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.327,43.853,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.989 | Acc: 24.219,46.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.962 | Acc: 22.210,43.899,72.768,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.018 | Acc: 22.580,42.797,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.023 | Acc: 22.592,42.918,71.542,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 276
Batch: 0 | Loss: 0.745 | Acc: 24.219,46.875,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.748 | Acc: 23.698,44.903,98.289,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 22.389,43.617,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.745 | Acc: 22.759,43.404,98.514,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.743 | Acc: 23.235,43.615,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.740 | Acc: 23.275,43.758,98.561,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.741 | Acc: 23.179,43.834,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.740 | Acc: 23.133,43.844,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.064,43.784,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.740 | Acc: 23.161,43.944,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.740 | Acc: 23.072,43.933,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.190,43.845,98.522,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.168,43.808,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.096,43.687,98.503,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.157,43.639,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.214,43.711,98.458,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.153,43.704,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.163,43.688,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.163,43.653,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.118,43.586,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.016 | Acc: 25.000,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 22.396,44.568,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.022 | Acc: 22.389,43.178,71.170,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 22.426,43.199,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 277
Batch: 0 | Loss: 0.730 | Acc: 23.438,38.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.751 | Acc: 23.251,40.923,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 22.637,41.730,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.750 | Acc: 22.823,42.367,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 23.235,42.969,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.746 | Acc: 23.314,43.054,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.747 | Acc: 23.528,43.117,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.748 | Acc: 23.332,42.985,98.343,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.746 | Acc: 23.268,42.949,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.747 | Acc: 23.157,43.111,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.747 | Acc: 23.212,43.105,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.747 | Acc: 23.296,43.128,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 23.486,43.228,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.746 | Acc: 23.443,43.364,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.745 | Acc: 23.490,43.511,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.744 | Acc: 23.510,43.636,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.474,43.631,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.421,43.651,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.390,43.711,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.403,43.684,98.440,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.020 | Acc: 23.438,47.656,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.968 | Acc: 22.098,44.345,71.726,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.021 | Acc: 22.199,43.216,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.021 | Acc: 22.285,43.161,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 278
Batch: 0 | Loss: 0.732 | Acc: 21.875,46.875,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 24.033,44.420,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.739 | Acc: 24.181,44.607,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.740 | Acc: 23.566,44.237,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.741 | Acc: 23.196,44.001,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 23.530,44.392,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.250,44.344,98.392,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.745 | Acc: 23.083,44.188,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.745 | Acc: 23.258,44.260,98.350,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.317,44.324,98.373,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.744 | Acc: 23.375,44.329,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.743 | Acc: 23.409,44.344,98.353,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.744 | Acc: 23.227,44.126,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.743 | Acc: 23.294,44.208,98.384,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.293,44.092,98.390,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.341,44.087,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.430,44.147,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.318,44.137,98.366,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.303,44.068,98.362,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.321,44.072,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.005 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.971 | Acc: 22.098,44.122,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 22.256,42.950,70.846,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.031 | Acc: 22.349,42.969,71.171,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 279
Batch: 0 | Loss: 0.756 | Acc: 24.219,36.719,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.753 | Acc: 23.586,44.978,98.103,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.753 | Acc: 22.732,43.921,98.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.753 | Acc: 22.759,43.507,98.207,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.750 | Acc: 22.685,43.625,98.322,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.750 | Acc: 22.950,43.711,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.749 | Acc: 23.050,43.744,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.750 | Acc: 23.016,43.661,98.277,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.748 | Acc: 23.010,43.609,98.326,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.747 | Acc: 23.088,43.677,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.748 | Acc: 23.169,43.793,98.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.747 | Acc: 23.275,43.959,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.747 | Acc: 23.269,43.841,98.301,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.747 | Acc: 23.339,43.903,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.746 | Acc: 23.351,43.931,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.746 | Acc: 23.344,43.760,98.328,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.746 | Acc: 23.362,43.787,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.745 | Acc: 23.350,43.635,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.746 | Acc: 23.401,43.720,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.746 | Acc: 23.335,43.629,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.994 | Acc: 24.219,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 22.210,44.420,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.015 | Acc: 22.618,43.197,71.380,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 22.567,43.225,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 280
Batch: 0 | Loss: 0.753 | Acc: 23.438,39.062,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.740 | Acc: 23.065,45.089,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.741 | Acc: 24.695,45.179,98.266,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.739 | Acc: 24.475,44.928,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.739 | Acc: 24.219,44.223,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 24.165,43.796,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.896,43.776,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 23.742,43.800,98.382,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.744 | Acc: 23.666,43.755,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.745 | Acc: 23.528,43.819,98.278,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.744 | Acc: 23.589,43.975,98.305,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.743 | Acc: 23.639,44.036,98.303,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.744 | Acc: 23.512,43.990,98.288,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.432,44.064,98.300,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.744 | Acc: 23.418,44.092,98.273,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.745 | Acc: 23.334,44.046,98.290,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.745 | Acc: 23.316,44.001,98.294,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.421,44.117,98.307,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.474,44.111,98.325,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.745 | Acc: 23.401,44.107,98.319,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.999 | Acc: 25.000,49.219,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.963 | Acc: 22.359,44.345,71.949,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.019 | Acc: 22.409,43.216,70.903,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.020 | Acc: 22.426,43.238,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 281
Batch: 0 | Loss: 0.771 | Acc: 28.125,44.531,95.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.746 | Acc: 24.777,44.792,98.065,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.737 | Acc: 24.524,44.588,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.738 | Acc: 24.001,44.877,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.738 | Acc: 23.765,44.522,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.740 | Acc: 23.515,44.237,98.492,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 23.521,44.241,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 23.609,44.271,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.709,44.211,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 23.623,44.143,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.593,43.960,98.465,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.604,43.927,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.613,43.773,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.743 | Acc: 23.611,43.879,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.643,43.981,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.601,43.888,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.501,43.818,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.504,43.777,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.476,43.785,98.422,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.431,43.785,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.054 | Acc: 24.219,49.219,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.972 | Acc: 22.321,44.159,72.135,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 22.466,43.197,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.030 | Acc: 22.567,42.969,71.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 282
Batch: 0 | Loss: 0.758 | Acc: 21.875,40.625,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.743 | Acc: 23.028,42.150,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.742 | Acc: 23.152,42.283,98.647,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.741 | Acc: 22.810,42.802,98.655,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.740 | Acc: 23.573,43.422,98.553,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 23.298,43.363,98.538,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.740 | Acc: 23.321,43.530,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.740 | Acc: 23.293,43.517,98.559,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.229,43.527,98.462,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.295,43.482,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.216,43.466,98.426,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.169,43.439,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.237,43.429,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.180,43.355,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.744 | Acc: 23.324,43.411,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.339,43.415,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.413,43.436,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.454,43.484,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.531,43.529,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.528,43.598,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.999 | Acc: 25.000,47.656,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.972 | Acc: 22.396,44.531,71.763,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 22.580,43.312,70.922,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 22.605,43.084,71.247,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 283
Batch: 0 | Loss: 0.797 | Acc: 28.906,43.750,96.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.737 | Acc: 24.219,44.680,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.745 | Acc: 23.323,43.693,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.741 | Acc: 23.322,44.326,98.591,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.742 | Acc: 23.216,43.875,98.592,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 23.229,43.982,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.741 | Acc: 23.128,43.905,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.741 | Acc: 23.111,43.877,98.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.239,43.735,98.627,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.740 | Acc: 23.256,43.703,98.610,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.220,43.606,98.566,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.165,43.679,98.572,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 23.301,43.750,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.282,43.747,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.310,43.689,98.521,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.422,43.784,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.391,43.733,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.330,43.745,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.301,43.819,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.323,43.859,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.010 | Acc: 25.000,46.875,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.974 | Acc: 22.359,44.271,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 22.428,43.159,71.075,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.026 | Acc: 22.528,43.110,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 284
Batch: 0 | Loss: 0.748 | Acc: 28.125,49.219,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.745 | Acc: 22.842,42.039,98.958,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.741 | Acc: 23.152,43.255,98.780,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.742 | Acc: 23.399,43.622,98.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.745 | Acc: 23.447,43.441,98.650,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 23.584,43.773,98.646,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 23.496,43.582,98.580,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 23.404,43.634,98.543,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.744 | Acc: 23.549,43.891,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.623,43.914,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.742 | Acc: 23.589,43.972,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.743 | Acc: 23.554,43.782,98.505,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.463,43.782,98.496,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.743 | Acc: 23.440,43.807,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.415,43.708,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.393,43.799,98.508,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.420,43.840,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.465,43.839,98.509,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.442,43.826,98.502,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.485,43.824,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.011 | Acc: 24.219,48.438,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.973 | Acc: 22.693,44.308,72.024,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 22.675,43.388,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.033 | Acc: 22.554,43.161,71.311,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 285
Batch: 0 | Loss: 0.707 | Acc: 25.000,42.188,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.744 | Acc: 22.470,41.927,98.996,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.745 | Acc: 22.675,42.588,98.704,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.751 | Acc: 22.797,42.431,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 22.897,42.834,98.389,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.748 | Acc: 22.873,43.007,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.750 | Acc: 22.798,42.833,98.360,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.748 | Acc: 22.961,43.030,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.747 | Acc: 23.137,43.090,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.747 | Acc: 23.222,43.107,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.746 | Acc: 23.270,43.214,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.747 | Acc: 23.293,43.396,98.402,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.746 | Acc: 23.259,43.449,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.745 | Acc: 23.216,43.523,98.467,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.744 | Acc: 23.201,43.494,98.499,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.744 | Acc: 23.266,43.571,98.471,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.231,43.458,98.459,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.206,43.523,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.173,43.460,98.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.196,43.504,98.464,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.990 | Acc: 24.219,50.000,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.284,44.903,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.022 | Acc: 22.580,43.521,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.027 | Acc: 22.707,43.276,71.516,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 286
Batch: 0 | Loss: 0.740 | Acc: 21.094,37.500,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.736 | Acc: 23.661,43.676,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.746 | Acc: 23.114,43.693,98.171,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.745 | Acc: 23.117,43.660,98.220,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.744 | Acc: 23.370,43.808,98.312,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.742 | Acc: 23.291,44.044,98.345,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 23.128,43.918,98.418,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.741 | Acc: 23.094,43.916,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.132,43.813,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.741 | Acc: 23.265,43.966,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.740 | Acc: 23.333,44.049,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.236,43.856,98.409,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.233,43.714,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.741 | Acc: 23.111,43.726,98.446,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.741 | Acc: 23.193,43.858,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.741 | Acc: 23.170,43.864,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.741 | Acc: 23.233,43.881,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.259,43.764,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.238,43.806,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.278,43.785,98.444,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.990 | Acc: 25.000,50.781,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.972 | Acc: 22.173,44.903,72.545,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 22.504,43.464,71.246,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.032 | Acc: 22.439,43.430,71.606,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 287
Batch: 0 | Loss: 0.756 | Acc: 20.312,48.438,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.738 | Acc: 22.210,45.312,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.740 | Acc: 23.095,44.474,98.609,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.738 | Acc: 22.976,44.262,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.738 | Acc: 23.322,44.068,98.640,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.738 | Acc: 23.314,44.446,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.739 | Acc: 23.360,44.086,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.740 | Acc: 23.293,43.988,98.570,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.739 | Acc: 23.239,44.133,98.617,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.740 | Acc: 23.282,44.035,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.740 | Acc: 23.317,44.030,98.542,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.740 | Acc: 23.314,43.937,98.547,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.740 | Acc: 23.399,43.941,98.541,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.390,43.870,98.494,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.426,43.811,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.404,43.916,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.294,43.855,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.334,43.894,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.338,43.932,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.345,43.945,98.489,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.006 | Acc: 23.438,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.978 | Acc: 22.321,44.345,72.359,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.031 | Acc: 22.542,43.178,71.208,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.034 | Acc: 22.669,43.110,71.555,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 288
Batch: 0 | Loss: 0.742 | Acc: 25.781,48.438,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.740 | Acc: 25.037,44.494,98.177,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.746 | Acc: 24.276,43.788,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.745 | Acc: 24.116,44.237,98.309,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.747 | Acc: 23.929,43.798,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.745 | Acc: 24.242,43.974,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 24.090,44.150,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.743 | Acc: 24.036,43.911,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.957,44.085,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.744 | Acc: 23.856,43.888,98.481,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.745 | Acc: 23.678,43.863,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.744 | Acc: 23.812,43.870,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.745 | Acc: 23.768,43.831,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.745 | Acc: 23.701,43.741,98.420,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.745 | Acc: 23.643,43.825,98.429,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.745 | Acc: 23.606,43.820,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.746 | Acc: 23.547,43.745,98.391,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.747 | Acc: 23.541,43.711,98.371,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.746 | Acc: 23.550,43.806,98.364,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.746 | Acc: 23.515,43.766,98.376,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.980 | Acc: 24.219,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.958 | Acc: 22.061,44.457,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.024 | Acc: 22.085,43.293,70.865,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.028 | Acc: 22.208,43.174,71.311,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 289
Batch: 0 | Loss: 0.782 | Acc: 22.656,48.438,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.743 | Acc: 23.289,44.531,98.586,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.744 | Acc: 22.618,43.274,98.666,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.747 | Acc: 22.656,42.930,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.745 | Acc: 22.897,42.988,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.743 | Acc: 22.942,43.131,98.569,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.018,43.240,98.554,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 23.338,43.307,98.537,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.743 | Acc: 23.442,43.430,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 23.463,43.556,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.356,43.633,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.487,43.821,98.466,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.450,43.630,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.461,43.627,98.491,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.741 | Acc: 23.435,43.847,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.740 | Acc: 23.508,43.958,98.528,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.741 | Acc: 23.542,43.920,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.741 | Acc: 23.573,43.963,98.486,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.487,43.895,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.741 | Acc: 23.458,43.916,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.987 | Acc: 25.000,48.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.952 | Acc: 22.359,44.234,72.321,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.012 | Acc: 22.466,42.988,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.528,43.007,71.465,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 290
Batch: 0 | Loss: 0.703 | Acc: 27.344,47.656,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.741 | Acc: 22.210,42.336,98.847,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.743 | Acc: 23.018,43.902,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.745 | Acc: 22.989,43.942,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.746 | Acc: 23.100,43.760,98.428,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.743 | Acc: 23.468,43.974,98.484,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 23.218,43.866,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.746 | Acc: 23.022,43.611,98.482,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.744 | Acc: 23.248,43.624,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.744 | Acc: 23.252,43.482,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.325,43.521,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.392,43.651,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 23.369,43.737,98.473,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.420,43.837,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.741 | Acc: 23.407,43.914,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.316,43.841,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.253,43.772,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.229,43.789,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.269,43.780,98.407,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.292,43.723,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.983 | Acc: 25.000,48.438,74.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.961 | Acc: 22.284,44.754,72.507,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.021 | Acc: 22.389,43.312,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.024 | Acc: 22.605,43.225,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 291
Batch: 0 | Loss: 0.768 | Acc: 17.188,34.375,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.738 | Acc: 23.847,43.192,98.810,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.745 | Acc: 23.609,42.778,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 23.655,43.519,98.297,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.745 | Acc: 23.611,43.586,98.293,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.743 | Acc: 23.569,43.735,98.352,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.741 | Acc: 23.580,43.937,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 23.482,43.611,98.526,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.743 | Acc: 23.345,43.425,98.520,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.338,43.465,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.228,43.462,98.523,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.353,43.775,98.536,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.532,43.863,98.574,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.741 | Acc: 23.420,43.912,98.551,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.460,43.850,98.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.471,43.843,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.450,43.852,98.498,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.433,43.789,98.483,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.425,43.893,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.394,43.883,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.023 | Acc: 23.438,46.094,71.094,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.969 | Acc: 21.763,44.122,72.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.027 | Acc: 21.913,43.140,71.018,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 22.016,43.071,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 292
Batch: 0 | Loss: 0.738 | Acc: 22.656,39.844,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.732 | Acc: 23.438,44.457,98.772,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.735 | Acc: 23.971,44.036,98.533,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.740 | Acc: 23.719,43.699,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.738 | Acc: 23.746,43.846,98.544,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.739 | Acc: 24.033,43.781,98.468,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.740 | Acc: 23.799,43.847,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.739 | Acc: 23.820,43.905,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.741 | Acc: 23.753,43.842,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 23.558,43.629,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.507,43.633,98.453,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.604,43.810,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.574,43.873,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.515,43.861,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.443,43.822,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.422,43.807,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.438,43.735,98.469,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.387,43.670,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.407,43.629,98.472,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.427,43.691,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.007 | Acc: 24.219,48.438,71.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.173,44.606,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 22.466,43.312,70.998,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.022 | Acc: 22.528,43.212,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 293
Batch: 0 | Loss: 0.697 | Acc: 19.531,43.750,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.738 | Acc: 22.879,42.374,98.363,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.736 | Acc: 23.285,43.540,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.734 | Acc: 23.655,44.301,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.734 | Acc: 23.900,44.049,98.563,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.740 | Acc: 23.847,43.340,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.740 | Acc: 23.857,43.601,98.379,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.741 | Acc: 23.637,43.656,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.588,43.551,98.374,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.741 | Acc: 23.740,43.759,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.570,43.649,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.671,43.732,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.740 | Acc: 23.700,43.714,98.447,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.741 | Acc: 23.644,43.744,98.452,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.740 | Acc: 23.638,43.808,98.501,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.741 | Acc: 23.619,43.776,98.510,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.545,43.723,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.577,43.805,98.463,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.742 | Acc: 23.479,43.672,98.479,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.501,43.682,98.487,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.983 | Acc: 25.781,50.000,68.750,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.957 | Acc: 22.359,44.234,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.016 | Acc: 22.428,43.178,70.694,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.018 | Acc: 22.426,43.097,71.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 294
Batch: 0 | Loss: 0.733 | Acc: 29.688,46.094,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.729 | Acc: 23.735,44.680,98.698,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.737 | Acc: 23.704,44.722,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.738 | Acc: 24.039,44.467,98.361,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.742 | Acc: 23.891,44.203,98.341,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.744 | Acc: 23.855,44.299,98.291,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.744 | Acc: 23.973,44.118,98.308,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.744 | Acc: 23.903,44.293,98.310,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.894,44.405,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.742 | Acc: 23.688,44.216,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.772,44.290,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.823,44.146,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.742 | Acc: 23.697,44.061,98.408,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.742 | Acc: 23.656,43.897,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.607,43.892,98.435,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.601,43.937,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.576,43.954,98.425,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.513,43.924,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.507,43.889,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.509,44.000,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.031 | Acc: 23.438,47.656,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.966 | Acc: 22.135,44.494,71.689,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.023 | Acc: 22.409,43.236,70.713,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.025 | Acc: 22.387,43.058,71.222,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 295
Batch: 0 | Loss: 0.804 | Acc: 20.312,38.281,97.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.744 | Acc: 22.842,43.341,98.475,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.748 | Acc: 22.961,43.064,98.323,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.747 | Acc: 22.554,43.058,98.335,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.748 | Acc: 22.868,43.615,98.254,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.745 | Acc: 22.765,43.688,98.383,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 22.908,43.673,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.745 | Acc: 23.011,43.484,98.349,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.744 | Acc: 23.185,43.541,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.744 | Acc: 23.114,43.448,98.386,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.266,43.637,98.375,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.742 | Acc: 23.353,43.831,98.377,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.744 | Acc: 23.246,43.656,98.347,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.744 | Acc: 23.249,43.741,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.744 | Acc: 23.307,43.747,98.337,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.744 | Acc: 23.282,43.599,98.367,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.744 | Acc: 23.328,43.650,98.369,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.744 | Acc: 23.357,43.702,98.355,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.744 | Acc: 23.347,43.726,98.357,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.744 | Acc: 23.382,43.699,98.351,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.986 | Acc: 23.438,49.219,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.959 | Acc: 22.321,44.494,72.173,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.013 | Acc: 22.447,43.197,71.113,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.017 | Acc: 22.503,43.276,71.440,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 296
Batch: 0 | Loss: 0.745 | Acc: 19.531,42.188,99.219,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.750 | Acc: 23.214,44.420,98.400,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.746 | Acc: 23.438,43.540,98.495,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.746 | Acc: 23.271,43.353,98.399,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.744 | Acc: 23.428,43.692,98.370,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.743 | Acc: 23.646,43.928,98.430,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.743 | Acc: 23.870,44.047,98.405,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.743 | Acc: 23.720,43.905,98.460,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.743 | Acc: 23.729,44.007,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.743 | Acc: 23.701,44.074,98.455,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.743 | Acc: 23.628,43.937,98.449,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.744 | Acc: 23.618,43.962,98.445,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.743 | Acc: 23.590,43.938,98.434,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.743 | Acc: 23.635,43.870,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.743 | Acc: 23.513,43.903,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.743 | Acc: 23.559,43.981,98.448,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.743 | Acc: 23.532,44.018,98.433,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.506,44.004,98.421,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.442,43.878,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.743 | Acc: 23.466,43.883,98.417,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 2.015 | Acc: 25.000,48.438,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.975 | Acc: 22.284,44.494,71.615,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.028 | Acc: 22.447,43.369,70.751,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.029 | Acc: 22.503,43.225,71.145,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 297
Batch: 0 | Loss: 0.795 | Acc: 23.438,35.156,96.875,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.736 | Acc: 23.214,43.229,98.661,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.736 | Acc: 22.980,43.807,98.571,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.736 | Acc: 23.770,43.660,98.578,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.738 | Acc: 23.573,43.769,98.515,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.739 | Acc: 23.561,43.742,98.530,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.739 | Acc: 23.638,43.821,98.470,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.739 | Acc: 23.903,43.905,98.432,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.740 | Acc: 23.588,43.668,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.740 | Acc: 23.671,43.759,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.740 | Acc: 23.628,43.668,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.547,43.732,98.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.476,43.821,98.431,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.741 | Acc: 23.467,43.825,98.414,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.742 | Acc: 23.438,43.833,98.410,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.742 | Acc: 23.419,43.875,98.404,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.742 | Acc: 23.413,43.816,98.396,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.743 | Acc: 23.383,43.784,98.387,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.323,43.748,98.394,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.376,43.727,98.413,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.993 | Acc: 25.000,49.219,73.438,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.954 | Acc: 22.470,44.382,72.210,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.011 | Acc: 22.656,42.950,70.941,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.015 | Acc: 22.631,42.853,71.376,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 298
Batch: 0 | Loss: 0.719 | Acc: 23.438,42.969,100.000,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 0.739 | Acc: 23.475,42.597,98.624,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 0.744 | Acc: 23.819,43.674,98.285,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 0.743 | Acc: 23.399,43.660,98.412,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 80 | Loss: 0.742 | Acc: 23.534,43.740,98.457,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 100 | Loss: 0.741 | Acc: 23.654,44.237,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 120 | Loss: 0.742 | Acc: 23.412,44.137,98.450,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 140 | Loss: 0.742 | Acc: 23.360,43.894,98.443,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 160 | Loss: 0.742 | Acc: 23.370,43.876,98.442,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 180 | Loss: 0.741 | Acc: 23.256,43.914,98.485,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 200 | Loss: 0.741 | Acc: 23.274,43.801,98.500,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 220 | Loss: 0.741 | Acc: 23.328,43.874,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 240 | Loss: 0.741 | Acc: 23.337,43.967,98.519,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 260 | Loss: 0.741 | Acc: 23.264,44.022,98.506,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 280 | Loss: 0.741 | Acc: 23.404,43.997,98.518,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 300 | Loss: 0.741 | Acc: 23.510,44.004,98.531,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 320 | Loss: 0.741 | Acc: 23.513,43.942,98.513,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 340 | Loss: 0.742 | Acc: 23.483,43.931,98.474,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 360 | Loss: 0.743 | Acc: 23.425,43.908,98.461,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 380 | Loss: 0.742 | Acc: 23.452,43.941,98.476,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 0 | Loss: 1.965 | Acc: 23.438,47.656,72.656,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 20 | Loss: 1.976 | Acc: 21.912,44.308,72.247,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 40 | Loss: 2.033 | Acc: 22.104,43.121,71.132,% | Adaptive Acc: 0.000% | clf_exit: 
Batch: 60 | Loss: 2.034 | Acc: 22.195,43.110,71.337,% | Adaptive Acc: 0.000% | clf_exit: 

Epoch: 299
Batch: 0 | Loss: 0.717 | Acc: 27.344,47.656,99.219,% | Adaptive Acc: 98.438% | clf_exit: 0.000 0.141 0.859
Batch: 20 | Loss: 0.748 | Acc: 23.549,43.713,98.251,% | Adaptive Acc: 96.912% | clf_exit: 0.003 0.103 0.894
Batch: 40 | Loss: 0.745 | Acc: 23.399,43.369,98.266,% | Adaptive Acc: 97.027% | clf_exit: 0.003 0.102 0.895
Batch: 60 | Loss: 0.746 | Acc: 23.194,43.904,98.284,% | Adaptive Acc: 96.939% | clf_exit: 0.003 0.104 0.893
Batch: 80 | Loss: 0.745 | Acc: 23.119,44.059,98.264,% | Adaptive Acc: 96.875% | clf_exit: 0.003 0.107 0.890
Batch: 100 | Loss: 0.745 | Acc: 23.020,43.905,98.291,% | Adaptive Acc: 96.906% | clf_exit: 0.003 0.106 0.890
Batch: 120 | Loss: 0.746 | Acc: 23.160,44.176,98.237,% | Adaptive Acc: 96.830% | clf_exit: 0.003 0.109 0.888
Batch: 140 | Loss: 0.745 | Acc: 23.221,44.082,98.310,% | Adaptive Acc: 96.897% | clf_exit: 0.003 0.109 0.888
Batch: 160 | Loss: 0.745 | Acc: 23.263,44.002,98.340,% | Adaptive Acc: 96.924% | clf_exit: 0.003 0.109 0.888
Batch: 180 | Loss: 0.744 | Acc: 23.248,43.979,98.403,% | Adaptive Acc: 96.983% | clf_exit: 0.003 0.109 0.888
Batch: 200 | Loss: 0.743 | Acc: 23.298,43.886,98.410,% | Adaptive Acc: 96.968% | clf_exit: 0.003 0.109 0.888
Batch: 220 | Loss: 0.743 | Acc: 23.190,43.835,98.384,% | Adaptive Acc: 96.939% | clf_exit: 0.003 0.109 0.888
Batch: 240 | Loss: 0.743 | Acc: 23.143,43.906,98.415,% | Adaptive Acc: 96.979% | clf_exit: 0.003 0.109 0.888
Batch: 260 | Loss: 0.742 | Acc: 23.261,43.972,98.429,% | Adaptive Acc: 96.983% | clf_exit: 0.003 0.108 0.888
Batch: 280 | Loss: 0.743 | Acc: 23.090,43.817,98.435,% | Adaptive Acc: 96.975% | clf_exit: 0.003 0.108 0.889
Batch: 300 | Loss: 0.742 | Acc: 23.188,43.825,98.435,% | Adaptive Acc: 96.981% | clf_exit: 0.003 0.108 0.889
Batch: 320 | Loss: 0.742 | Acc: 23.248,43.840,98.438,% | Adaptive Acc: 96.989% | clf_exit: 0.003 0.108 0.889
Batch: 340 | Loss: 0.742 | Acc: 23.332,43.970,98.419,% | Adaptive Acc: 96.999% | clf_exit: 0.003 0.108 0.889
Batch: 360 | Loss: 0.742 | Acc: 23.334,43.977,98.442,% | Adaptive Acc: 97.033% | clf_exit: 0.003 0.108 0.889
Batch: 380 | Loss: 0.742 | Acc: 23.284,43.965,98.458,% | Adaptive Acc: 97.043% | clf_exit: 0.003 0.108 0.889
Batch: 0 | Loss: 2.012 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 73.438% | clf_exit: 0.023 0.211 0.766
Batch: 20 | Loss: 1.957 | Acc: 22.210,44.345,72.321,% | Adaptive Acc: 71.131% | clf_exit: 0.013 0.189 0.798
Batch: 40 | Loss: 2.017 | Acc: 22.561,43.216,71.132,% | Adaptive Acc: 69.569% | clf_exit: 0.011 0.189 0.800
Batch: 60 | Loss: 2.021 | Acc: 22.631,43.071,71.529,% | Adaptive Acc: 70.018% | clf_exit: 0.011 0.186 0.803
model is save as models/resnet56_cifar100_adaptive0_circles8_dropout1.00_all0clf0_vanilla0_ge1_fb111_lmbda0.0000.pt
Evaluate with different circles:
Batch: 0 | Loss: 5.114 | Acc: 1.562,0.781,15.625,% | Adaptive Acc: 15.625% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: 5.250 | Acc: 1.042,0.856,9.970,% | Adaptive Acc: 9.970% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: 5.222 | Acc: 0.972,0.819,10.290,% | Adaptive Acc: 10.290% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: 5.230 | Acc: 0.999,0.948,10.156,% | Adaptive Acc: 10.156% | clf_exit: 0.000 0.000 1.000
Batch: 0 | Loss: 4.146 | Acc: 1.562,0.781,43.750,% | Adaptive Acc: 43.750% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: 4.332 | Acc: 1.786,0.856,36.124,% | Adaptive Acc: 36.124% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: 4.320 | Acc: 1.639,0.819,36.871,% | Adaptive Acc: 36.871% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: 4.326 | Acc: 1.703,0.948,36.719,% | Adaptive Acc: 36.719% | clf_exit: 0.000 0.000 1.000
Batch: 0 | Loss: 3.541 | Acc: 0.000,0.781,53.125,% | Adaptive Acc: 53.125% | clf_exit: 0.000 0.000 1.000
Batch: 20 | Loss: 3.728 | Acc: 2.604,1.042,46.503,% | Adaptive Acc: 46.540% | clf_exit: 0.000 0.000 1.000
Batch: 40 | Loss: 3.729 | Acc: 2.668,1.067,47.027,% | Adaptive Acc: 47.046% | clf_exit: 0.000 0.000 1.000
Batch: 60 | Loss: 3.731 | Acc: 2.561,1.178,47.259,% | Adaptive Acc: 47.272% | clf_exit: 0.000 0.000 1.000
Batch: 0 | Loss: 3.110 | Acc: 2.344,1.562,61.719,% | Adaptive Acc: 61.719% | clf_exit: 0.008 0.000 0.992
Batch: 20 | Loss: 3.292 | Acc: 3.013,2.195,53.311,% | Adaptive Acc: 53.460% | clf_exit: 0.002 0.000 0.998
Batch: 40 | Loss: 3.304 | Acc: 3.182,2.191,52.973,% | Adaptive Acc: 53.068% | clf_exit: 0.002 0.000 0.998
Batch: 60 | Loss: 3.302 | Acc: 3.138,2.382,53.074,% | Adaptive Acc: 53.151% | clf_exit: 0.002 0.000 0.998
Batch: 0 | Loss: 2.700 | Acc: 4.688,7.031,61.719,% | Adaptive Acc: 60.938% | clf_exit: 0.008 0.016 0.977
Batch: 20 | Loss: 2.872 | Acc: 5.171,6.362,58.519,% | Adaptive Acc: 58.519% | clf_exit: 0.004 0.010 0.986
Batch: 40 | Loss: 2.894 | Acc: 5.545,6.402,58.098,% | Adaptive Acc: 57.965% | clf_exit: 0.004 0.009 0.987
Batch: 60 | Loss: 2.891 | Acc: 5.533,6.609,58.299,% | Adaptive Acc: 58.248% | clf_exit: 0.004 0.009 0.987
Batch: 0 | Loss: 2.278 | Acc: 11.719,14.062,67.188,% | Adaptive Acc: 67.188% | clf_exit: 0.008 0.016 0.977
Batch: 20 | Loss: 2.427 | Acc: 9.263,13.988,64.583,% | Adaptive Acc: 63.728% | clf_exit: 0.007 0.028 0.965
Batch: 40 | Loss: 2.458 | Acc: 9.851,14.444,64.177,% | Adaptive Acc: 63.091% | clf_exit: 0.007 0.031 0.962
Batch: 60 | Loss: 2.455 | Acc: 9.977,14.511,64.408,% | Adaptive Acc: 63.499% | clf_exit: 0.007 0.030 0.963
Batch: 0 | Loss: 1.961 | Acc: 20.312,32.031,69.531,% | Adaptive Acc: 70.312% | clf_exit: 0.008 0.039 0.953
Batch: 20 | Loss: 2.070 | Acc: 16.332,27.939,70.052,% | Adaptive Acc: 69.271% | clf_exit: 0.010 0.047 0.943
Batch: 40 | Loss: 2.106 | Acc: 16.349,28.106,69.341,% | Adaptive Acc: 68.426% | clf_exit: 0.008 0.050 0.942
Batch: 60 | Loss: 2.106 | Acc: 16.201,28.010,69.544,% | Adaptive Acc: 68.686% | clf_exit: 0.009 0.050 0.941
Batch: 0 | Loss: 1.885 | Acc: 22.656,46.094,72.656,% | Adaptive Acc: 73.438% | clf_exit: 0.016 0.133 0.852
Batch: 20 | Loss: 1.923 | Acc: 20.908,40.513,71.838,% | Adaptive Acc: 71.354% | clf_exit: 0.011 0.116 0.874
Batch: 40 | Loss: 1.969 | Acc: 21.132,39.882,71.075,% | Adaptive Acc: 70.332% | clf_exit: 0.010 0.119 0.871
Batch: 60 | Loss: 1.972 | Acc: 21.030,40.254,71.311,% | Adaptive Acc: 70.517% | clf_exit: 0.010 0.115 0.875
Batch: 0 | Loss: 2.012 | Acc: 25.000,49.219,72.656,% | Adaptive Acc: 73.438% | clf_exit: 0.023 0.211 0.766
Batch: 20 | Loss: 1.957 | Acc: 22.210,44.345,72.321,% | Adaptive Acc: 71.131% | clf_exit: 0.013 0.189 0.798
Batch: 40 | Loss: 2.017 | Acc: 22.561,43.216,71.132,% | Adaptive Acc: 69.569% | clf_exit: 0.011 0.189 0.800
Batch: 60 | Loss: 2.021 | Acc: 22.631,43.071,71.529,% | Adaptive Acc: 70.018% | clf_exit: 0.011 0.186 0.803







Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=0 | Loss: 5.487 |  Acc: 1.366,1.884,2.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=0 | Loss: 5.309 |  Acc: 1.320,3.220,4.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=1 | Loss: 5.065 |  Acc: 1.782,3.720,5.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=1 | Loss: 5.091 |  Acc: 1.580,3.590,6.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=2 | Loss: 4.797 |  Acc: 1.810,4.800,9.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=2 | Loss: 4.901 |  Acc: 2.130,4.340,8.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=3 | Loss: 4.596 |  Acc: 2.656,6.284,12.496,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=3 | Loss: 4.580 |  Acc: 1.180,6.990,13.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=4 | Loss: 4.459 |  Acc: 2.990,7.580,14.896,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=4 | Loss: 4.380 |  Acc: 2.030,7.680,17.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=5 | Loss: 4.323 |  Acc: 3.732,8.344,17.018,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=5 | Loss: 4.428 |  Acc: 2.570,6.640,16.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=6 | Loss: 4.202 |  Acc: 4.164,9.876,18.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=6 | Loss: 4.231 |  Acc: 2.580,9.050,18.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=7 | Loss: 4.082 |  Acc: 4.578,10.774,20.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=7 | Loss: 4.177 |  Acc: 3.250,9.830,19.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=8 | Loss: 3.951 |  Acc: 4.592,11.494,23.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=8 | Loss: 3.944 |  Acc: 3.430,9.490,23.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=9 | Loss: 3.814 |  Acc: 4.794,12.544,25.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=9 | Loss: 3.999 |  Acc: 3.190,10.040,22.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=10 | Loss: 3.683 |  Acc: 4.890,13.250,28.292,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=10 | Loss: 3.735 |  Acc: 3.770,10.600,27.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=11 | Loss: 3.545 |  Acc: 5.180,14.158,30.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=11 | Loss: 3.696 |  Acc: 4.770,11.360,28.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=12 | Loss: 3.428 |  Acc: 5.272,14.944,33.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=12 | Loss: 3.586 |  Acc: 5.010,14.500,30.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=13 | Loss: 3.327 |  Acc: 5.580,15.450,34.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=13 | Loss: 3.483 |  Acc: 4.640,12.220,31.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=14 | Loss: 3.226 |  Acc: 5.646,16.048,37.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=14 | Loss: 3.662 |  Acc: 4.850,13.270,28.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=15 | Loss: 3.134 |  Acc: 5.864,17.068,38.790,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=15 | Loss: 3.389 |  Acc: 5.220,15.630,35.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=16 | Loss: 3.053 |  Acc: 5.994,17.466,40.630,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=16 | Loss: 3.167 |  Acc: 5.810,16.150,39.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=17 | Loss: 2.964 |  Acc: 6.022,17.700,42.562,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=17 | Loss: 3.040 |  Acc: 6.180,15.580,41.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=18 | Loss: 2.899 |  Acc: 6.148,18.400,44.108,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=18 | Loss: 3.150 |  Acc: 4.820,15.670,39.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=19 | Loss: 2.819 |  Acc: 6.444,18.962,45.936,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=19 | Loss: 3.078 |  Acc: 5.290,16.390,40.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=20 | Loss: 2.760 |  Acc: 6.312,19.164,47.138,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=20 | Loss: 3.013 |  Acc: 5.720,17.960,42.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=21 | Loss: 2.698 |  Acc: 6.278,19.650,48.646,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=21 | Loss: 3.125 |  Acc: 5.700,16.580,40.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=22 | Loss: 2.656 |  Acc: 6.654,19.898,49.832,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=22 | Loss: 2.882 |  Acc: 5.740,17.840,45.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=23 | Loss: 2.604 |  Acc: 6.904,20.572,50.924,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=23 | Loss: 2.878 |  Acc: 6.680,18.830,46.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=24 | Loss: 2.548 |  Acc: 7.176,20.834,52.274,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=24 | Loss: 2.801 |  Acc: 7.190,19.500,47.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=25 | Loss: 2.520 |  Acc: 7.518,20.946,53.052,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=25 | Loss: 2.758 |  Acc: 7.210,19.130,48.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=26 | Loss: 2.478 |  Acc: 7.726,21.590,53.768,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=26 | Loss: 2.980 |  Acc: 6.320,17.340,44.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=27 | Loss: 2.433 |  Acc: 7.832,21.762,54.964,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=27 | Loss: 2.805 |  Acc: 7.550,16.760,47.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=28 | Loss: 2.401 |  Acc: 7.968,21.804,55.624,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=28 | Loss: 2.728 |  Acc: 7.200,19.760,49.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=29 | Loss: 2.364 |  Acc: 8.176,22.264,56.664,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=29 | Loss: 2.849 |  Acc: 6.750,17.160,47.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=30 | Loss: 2.341 |  Acc: 8.758,22.618,57.114,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=30 | Loss: 2.753 |  Acc: 7.930,21.420,49.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=31 | Loss: 2.301 |  Acc: 9.126,22.858,58.116,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=31 | Loss: 2.604 |  Acc: 7.370,21.000,52.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=32 | Loss: 2.271 |  Acc: 9.558,23.436,59.126,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=32 | Loss: 2.822 |  Acc: 6.950,19.490,48.030,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=33 | Loss: 2.241 |  Acc: 9.866,23.146,59.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=33 | Loss: 2.951 |  Acc: 5.640,16.920,45.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=34 | Loss: 2.220 |  Acc: 10.250,23.674,60.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=34 | Loss: 2.669 |  Acc: 9.570,22.030,50.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=35 | Loss: 2.198 |  Acc: 10.842,23.900,60.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=35 | Loss: 3.031 |  Acc: 6.560,14.380,44.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=36 | Loss: 2.168 |  Acc: 11.408,24.266,61.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=36 | Loss: 2.701 |  Acc: 8.440,19.500,50.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=37 | Loss: 2.152 |  Acc: 11.750,24.486,61.594,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=37 | Loss: 2.535 |  Acc: 10.580,21.720,53.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=38 | Loss: 2.131 |  Acc: 12.058,24.204,62.234,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=38 | Loss: 2.811 |  Acc: 10.630,21.180,48.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=39 | Loss: 2.109 |  Acc: 12.320,24.754,62.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=39 | Loss: 2.553 |  Acc: 10.240,22.680,53.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=40 | Loss: 2.092 |  Acc: 12.604,25.086,63.142,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=40 | Loss: 2.581 |  Acc: 10.870,21.720,53.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=41 | Loss: 2.078 |  Acc: 13.142,24.936,63.320,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=41 | Loss: 2.482 |  Acc: 10.990,21.720,54.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=42 | Loss: 2.059 |  Acc: 13.318,25.360,63.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=42 | Loss: 2.483 |  Acc: 12.610,23.580,55.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=43 | Loss: 2.040 |  Acc: 13.546,25.476,64.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=43 | Loss: 2.445 |  Acc: 11.130,22.570,55.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=44 | Loss: 2.030 |  Acc: 13.880,25.718,64.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=44 | Loss: 2.380 |  Acc: 12.300,23.870,57.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=45 | Loss: 2.009 |  Acc: 14.158,25.838,65.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=45 | Loss: 2.400 |  Acc: 12.260,24.000,56.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=46 | Loss: 1.994 |  Acc: 14.408,26.032,65.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=46 | Loss: 2.482 |  Acc: 12.730,20.830,55.370,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=47 | Loss: 1.971 |  Acc: 14.686,26.100,66.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=47 | Loss: 2.497 |  Acc: 11.600,24.320,54.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=48 | Loss: 1.970 |  Acc: 14.816,26.144,65.894,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=48 | Loss: 2.496 |  Acc: 13.080,23.590,55.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=49 | Loss: 1.952 |  Acc: 14.790,26.116,66.492,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=49 | Loss: 2.409 |  Acc: 12.810,20.920,56.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=50 | Loss: 1.949 |  Acc: 14.990,26.066,66.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=50 | Loss: 2.379 |  Acc: 12.980,22.220,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=51 | Loss: 1.941 |  Acc: 15.192,26.332,66.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=51 | Loss: 2.620 |  Acc: 12.850,20.110,53.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=52 | Loss: 1.928 |  Acc: 15.722,26.518,66.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=52 | Loss: 2.573 |  Acc: 12.170,21.630,54.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=53 | Loss: 1.908 |  Acc: 15.912,26.772,67.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=53 | Loss: 2.532 |  Acc: 14.660,23.180,55.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=54 | Loss: 1.904 |  Acc: 15.904,26.754,67.544,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=54 | Loss: 2.448 |  Acc: 13.020,25.070,56.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=55 | Loss: 1.893 |  Acc: 15.962,26.848,67.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=55 | Loss: 2.507 |  Acc: 14.080,22.250,55.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=56 | Loss: 1.884 |  Acc: 15.986,26.718,68.120,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=56 | Loss: 2.448 |  Acc: 12.070,23.830,56.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=57 | Loss: 1.875 |  Acc: 16.256,26.788,68.276,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=57 | Loss: 2.546 |  Acc: 15.810,24.060,55.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=58 | Loss: 1.861 |  Acc: 16.146,26.910,68.614,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=58 | Loss: 2.499 |  Acc: 14.790,25.790,54.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=59 | Loss: 1.856 |  Acc: 16.218,27.110,68.636,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=59 | Loss: 2.307 |  Acc: 13.610,24.180,59.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=60 | Loss: 1.831 |  Acc: 16.434,27.520,69.290,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=60 | Loss: 2.493 |  Acc: 12.910,23.160,55.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=61 | Loss: 1.840 |  Acc: 16.608,27.414,68.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=61 | Loss: 2.361 |  Acc: 15.430,25.200,58.180,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=62 | Loss: 1.827 |  Acc: 16.580,27.352,69.472,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=62 | Loss: 2.603 |  Acc: 14.080,21.850,53.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=63 | Loss: 1.821 |  Acc: 16.614,27.630,69.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=63 | Loss: 2.351 |  Acc: 12.850,22.140,59.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=64 | Loss: 1.810 |  Acc: 16.728,27.902,69.644,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=64 | Loss: 2.404 |  Acc: 10.830,23.450,57.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=65 | Loss: 1.800 |  Acc: 17.056,27.628,69.820,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=65 | Loss: 2.346 |  Acc: 14.190,25.460,58.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=66 | Loss: 1.792 |  Acc: 16.902,28.294,70.338,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=66 | Loss: 2.462 |  Acc: 14.900,23.540,56.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=67 | Loss: 1.789 |  Acc: 17.002,28.172,70.236,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=67 | Loss: 2.443 |  Acc: 14.220,22.910,56.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=68 | Loss: 1.781 |  Acc: 17.198,28.260,70.484,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=68 | Loss: 2.331 |  Acc: 15.740,26.400,58.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=69 | Loss: 1.776 |  Acc: 17.042,28.098,70.676,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=69 | Loss: 2.560 |  Acc: 9.770,17.740,54.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=70 | Loss: 1.779 |  Acc: 17.338,28.186,70.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=70 | Loss: 2.366 |  Acc: 14.280,24.620,58.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=71 | Loss: 1.756 |  Acc: 17.580,28.554,71.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=71 | Loss: 2.411 |  Acc: 15.740,25.320,57.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=72 | Loss: 1.759 |  Acc: 17.598,28.442,70.752,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=72 | Loss: 2.422 |  Acc: 14.700,25.360,57.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=73 | Loss: 1.748 |  Acc: 17.834,28.720,71.076,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=73 | Loss: 2.345 |  Acc: 14.960,24.210,59.320,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=74 | Loss: 1.755 |  Acc: 17.752,28.446,70.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=74 | Loss: 2.442 |  Acc: 15.840,25.760,56.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=75 | Loss: 1.734 |  Acc: 17.706,28.656,71.460,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=75 | Loss: 2.370 |  Acc: 15.170,27.140,58.110,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=76 | Loss: 1.728 |  Acc: 17.918,29.144,71.572,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=76 | Loss: 2.437 |  Acc: 11.750,22.760,57.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=77 | Loss: 1.730 |  Acc: 17.812,28.816,71.534,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=77 | Loss: 2.468 |  Acc: 15.510,25.820,56.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=78 | Loss: 1.715 |  Acc: 17.898,29.138,71.658,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=78 | Loss: 2.407 |  Acc: 16.350,27.020,57.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=79 | Loss: 1.725 |  Acc: 17.768,29.034,71.640,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=79 | Loss: 2.319 |  Acc: 15.640,26.300,58.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=80 | Loss: 1.713 |  Acc: 18.064,29.068,72.144,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=80 | Loss: 2.404 |  Acc: 15.310,26.490,57.930,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=81 | Loss: 1.712 |  Acc: 17.938,29.368,72.150,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=81 | Loss: 2.435 |  Acc: 13.100,25.210,57.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=82 | Loss: 1.714 |  Acc: 18.214,29.314,72.122,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=82 | Loss: 2.614 |  Acc: 15.690,24.260,53.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=83 | Loss: 1.691 |  Acc: 18.094,29.910,72.574,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=83 | Loss: 2.664 |  Acc: 12.040,21.050,53.070,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=84 | Loss: 1.699 |  Acc: 18.206,29.536,72.334,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=84 | Loss: 2.523 |  Acc: 14.940,24.650,56.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=85 | Loss: 1.686 |  Acc: 18.264,29.946,72.520,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=85 | Loss: 2.312 |  Acc: 14.830,26.350,59.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=86 | Loss: 1.684 |  Acc: 18.322,29.916,72.444,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=86 | Loss: 2.263 |  Acc: 16.260,25.740,60.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=87 | Loss: 1.673 |  Acc: 18.512,30.008,73.036,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=87 | Loss: 2.687 |  Acc: 14.800,26.570,52.490,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=88 | Loss: 1.681 |  Acc: 18.620,30.070,72.670,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=88 | Loss: 2.501 |  Acc: 16.720,23.360,56.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=89 | Loss: 1.676 |  Acc: 18.424,30.068,72.850,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=89 | Loss: 2.265 |  Acc: 15.580,25.840,60.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=90 | Loss: 1.667 |  Acc: 18.648,29.726,72.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=90 | Loss: 2.417 |  Acc: 14.120,24.100,57.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=91 | Loss: 1.668 |  Acc: 18.502,30.098,73.048,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=91 | Loss: 2.416 |  Acc: 13.600,25.090,58.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=92 | Loss: 1.662 |  Acc: 18.330,30.228,73.010,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=92 | Loss: 2.165 |  Acc: 18.060,28.190,62.410,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=93 | Loss: 1.663 |  Acc: 18.634,29.932,73.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=93 | Loss: 2.392 |  Acc: 17.260,26.880,58.160,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=94 | Loss: 1.653 |  Acc: 18.554,30.500,73.440,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=94 | Loss: 2.239 |  Acc: 16.110,28.390,60.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=95 | Loss: 1.653 |  Acc: 18.654,30.508,73.524,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=95 | Loss: 2.337 |  Acc: 15.430,25.920,58.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=96 | Loss: 1.645 |  Acc: 18.746,30.408,73.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=96 | Loss: 2.482 |  Acc: 14.980,24.360,57.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=97 | Loss: 1.643 |  Acc: 18.706,30.596,73.576,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=97 | Loss: 2.296 |  Acc: 16.460,27.730,60.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=98 | Loss: 1.638 |  Acc: 18.492,30.722,73.722,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=98 | Loss: 2.201 |  Acc: 16.080,28.430,61.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=99 | Loss: 1.640 |  Acc: 18.688,30.632,73.788,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=99 | Loss: 2.332 |  Acc: 14.430,23.210,59.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=100 | Loss: 1.636 |  Acc: 18.716,30.662,73.674,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=100 | Loss: 2.293 |  Acc: 17.100,27.290,59.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=101 | Loss: 1.634 |  Acc: 18.794,30.772,73.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=101 | Loss: 2.387 |  Acc: 17.340,26.880,58.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=102 | Loss: 1.637 |  Acc: 18.840,31.054,73.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=102 | Loss: 2.262 |  Acc: 16.400,27.970,61.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=103 | Loss: 1.612 |  Acc: 18.958,31.028,74.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=103 | Loss: 2.346 |  Acc: 13.100,25.930,59.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=104 | Loss: 1.622 |  Acc: 18.980,31.102,74.104,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=104 | Loss: 2.328 |  Acc: 17.260,26.590,60.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=105 | Loss: 1.630 |  Acc: 18.694,30.958,73.718,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=105 | Loss: 2.251 |  Acc: 17.810,28.510,60.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=106 | Loss: 1.607 |  Acc: 18.900,31.234,74.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=106 | Loss: 2.259 |  Acc: 17.230,27.580,61.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=107 | Loss: 1.613 |  Acc: 18.898,31.098,74.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=107 | Loss: 2.350 |  Acc: 16.160,27.510,59.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=108 | Loss: 1.610 |  Acc: 18.904,31.406,74.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=108 | Loss: 2.553 |  Acc: 15.540,25.840,56.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=109 | Loss: 1.610 |  Acc: 19.044,31.494,74.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=109 | Loss: 2.274 |  Acc: 15.430,28.610,60.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=110 | Loss: 1.603 |  Acc: 19.070,31.196,74.596,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=110 | Loss: 2.546 |  Acc: 14.570,25.110,56.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=111 | Loss: 1.604 |  Acc: 19.140,31.434,74.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=111 | Loss: 2.292 |  Acc: 14.130,26.220,60.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=112 | Loss: 1.597 |  Acc: 19.154,31.314,74.542,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=112 | Loss: 2.360 |  Acc: 15.650,25.120,58.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=113 | Loss: 1.597 |  Acc: 19.128,31.610,74.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=113 | Loss: 2.314 |  Acc: 15.610,27.790,59.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=114 | Loss: 1.596 |  Acc: 19.156,31.386,74.706,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=114 | Loss: 2.361 |  Acc: 15.460,28.710,59.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=115 | Loss: 1.598 |  Acc: 19.194,31.550,74.734,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=115 | Loss: 2.234 |  Acc: 14.360,25.880,62.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=116 | Loss: 1.593 |  Acc: 19.104,31.584,74.754,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=116 | Loss: 2.287 |  Acc: 16.810,28.740,61.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=117 | Loss: 1.585 |  Acc: 19.278,31.976,74.838,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=117 | Loss: 2.257 |  Acc: 14.730,26.730,60.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=118 | Loss: 1.577 |  Acc: 19.134,32.092,75.204,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=118 | Loss: 2.354 |  Acc: 15.110,25.470,59.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=119 | Loss: 1.594 |  Acc: 19.084,31.776,74.696,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=119 | Loss: 2.296 |  Acc: 15.730,28.600,60.950,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=120 | Loss: 1.574 |  Acc: 19.238,31.550,75.468,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=120 | Loss: 2.322 |  Acc: 18.000,26.460,60.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=121 | Loss: 1.577 |  Acc: 19.502,31.918,75.156,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=121 | Loss: 2.357 |  Acc: 15.880,26.140,59.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=122 | Loss: 1.576 |  Acc: 19.344,32.128,75.134,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=122 | Loss: 2.378 |  Acc: 15.820,27.030,58.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=123 | Loss: 1.578 |  Acc: 19.498,31.878,75.024,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=123 | Loss: 2.409 |  Acc: 15.260,26.490,59.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=124 | Loss: 1.571 |  Acc: 19.442,32.138,75.312,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=124 | Loss: 2.256 |  Acc: 18.170,29.580,61.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=125 | Loss: 1.578 |  Acc: 19.452,32.226,75.020,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=125 | Loss: 2.406 |  Acc: 14.270,27.140,58.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=126 | Loss: 1.574 |  Acc: 19.184,32.112,75.262,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=126 | Loss: 2.367 |  Acc: 16.000,28.950,59.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=127 | Loss: 1.564 |  Acc: 19.304,32.412,75.260,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=127 | Loss: 2.248 |  Acc: 16.630,28.210,61.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=128 | Loss: 1.564 |  Acc: 19.466,32.508,75.316,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=128 | Loss: 2.206 |  Acc: 16.230,29.510,62.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=129 | Loss: 1.563 |  Acc: 19.534,32.380,75.552,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=129 | Loss: 2.359 |  Acc: 17.530,30.260,59.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=130 | Loss: 1.553 |  Acc: 19.442,32.784,75.558,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=130 | Loss: 2.187 |  Acc: 17.000,29.360,62.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=131 | Loss: 1.562 |  Acc: 19.604,32.408,75.422,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=131 | Loss: 2.270 |  Acc: 17.240,28.260,60.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=132 | Loss: 1.564 |  Acc: 19.342,32.422,75.318,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=132 | Loss: 2.310 |  Acc: 17.980,28.640,59.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=133 | Loss: 1.558 |  Acc: 19.408,32.822,75.514,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=133 | Loss: 2.208 |  Acc: 16.560,28.370,62.310,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=134 | Loss: 1.542 |  Acc: 19.644,33.024,76.082,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=134 | Loss: 2.408 |  Acc: 15.760,25.360,59.210,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=135 | Loss: 1.559 |  Acc: 19.430,32.836,75.600,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=135 | Loss: 2.146 |  Acc: 18.020,30.230,63.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=136 | Loss: 1.551 |  Acc: 19.594,32.810,75.586,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=136 | Loss: 2.312 |  Acc: 17.080,28.720,60.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=137 | Loss: 1.557 |  Acc: 19.642,32.286,75.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=137 | Loss: 2.201 |  Acc: 16.070,27.370,62.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=138 | Loss: 1.543 |  Acc: 19.420,33.082,75.888,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=138 | Loss: 2.361 |  Acc: 16.180,27.760,58.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=139 | Loss: 1.553 |  Acc: 19.582,32.916,75.710,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=139 | Loss: 2.358 |  Acc: 13.710,23.560,59.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=140 | Loss: 1.549 |  Acc: 19.546,32.968,75.742,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=140 | Loss: 2.254 |  Acc: 14.720,26.740,61.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=141 | Loss: 1.542 |  Acc: 19.852,32.716,75.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=141 | Loss: 2.378 |  Acc: 15.580,26.650,59.300,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=142 | Loss: 1.540 |  Acc: 19.908,32.984,75.956,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=142 | Loss: 2.293 |  Acc: 16.160,26.790,60.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=143 | Loss: 1.551 |  Acc: 19.674,33.122,75.778,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=143 | Loss: 2.438 |  Acc: 16.400,29.980,57.360,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=144 | Loss: 1.540 |  Acc: 19.888,33.294,75.760,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=144 | Loss: 2.363 |  Acc: 15.180,24.610,58.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=145 | Loss: 1.533 |  Acc: 19.738,33.370,76.070,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=145 | Loss: 2.358 |  Acc: 16.320,27.620,59.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=146 | Loss: 1.524 |  Acc: 20.016,33.630,76.330,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=146 | Loss: 2.292 |  Acc: 14.390,28.720,60.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=147 | Loss: 1.534 |  Acc: 19.854,33.484,76.112,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=147 | Loss: 2.209 |  Acc: 15.240,27.550,62.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=148 | Loss: 1.518 |  Acc: 19.694,33.618,76.512,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=148 | Loss: 2.229 |  Acc: 16.130,29.820,61.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=149 | Loss: 1.530 |  Acc: 19.896,33.468,75.934,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=149 | Loss: 2.370 |  Acc: 16.850,28.900,59.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=150 | Loss: 1.251 |  Acc: 20.528,36.064,84.034,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=150 | Loss: 1.749 |  Acc: 20.410,37.250,71.710,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=151 | Loss: 1.142 |  Acc: 21.036,37.092,87.132,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=151 | Loss: 1.747 |  Acc: 20.140,36.890,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=152 | Loss: 1.105 |  Acc: 21.042,37.454,88.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=152 | Loss: 1.748 |  Acc: 20.170,37.430,72.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=153 | Loss: 1.077 |  Acc: 21.216,37.546,88.918,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=153 | Loss: 1.760 |  Acc: 20.350,37.320,72.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=154 | Loss: 1.060 |  Acc: 21.126,37.974,89.588,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=154 | Loss: 1.757 |  Acc: 20.650,37.730,72.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=155 | Loss: 1.042 |  Acc: 21.328,38.424,90.014,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=155 | Loss: 1.762 |  Acc: 20.250,37.810,72.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=156 | Loss: 1.035 |  Acc: 21.494,38.126,90.328,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=156 | Loss: 1.770 |  Acc: 20.630,38.400,72.050,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=157 | Loss: 1.024 |  Acc: 21.660,38.586,90.720,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=157 | Loss: 1.772 |  Acc: 20.860,38.100,72.440,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=158 | Loss: 1.011 |  Acc: 21.444,38.386,91.044,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=158 | Loss: 1.780 |  Acc: 20.530,38.280,72.100,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=159 | Loss: 1.001 |  Acc: 21.460,38.782,91.348,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=159 | Loss: 1.792 |  Acc: 21.170,38.930,72.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=160 | Loss: 0.991 |  Acc: 21.644,38.776,91.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=160 | Loss: 1.789 |  Acc: 20.980,39.060,72.280,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=161 | Loss: 0.980 |  Acc: 21.734,38.844,91.950,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=161 | Loss: 1.803 |  Acc: 20.870,38.520,72.240,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=162 | Loss: 0.974 |  Acc: 21.754,38.988,92.200,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=162 | Loss: 1.793 |  Acc: 20.940,38.900,72.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=163 | Loss: 0.969 |  Acc: 21.760,39.060,92.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=163 | Loss: 1.809 |  Acc: 21.090,39.200,72.170,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=164 | Loss: 0.966 |  Acc: 21.756,39.280,92.384,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=164 | Loss: 1.805 |  Acc: 21.210,39.250,72.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=165 | Loss: 0.954 |  Acc: 21.824,39.600,92.634,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=165 | Loss: 1.813 |  Acc: 21.160,39.190,72.330,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=166 | Loss: 0.948 |  Acc: 21.824,39.464,92.902,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=166 | Loss: 1.840 |  Acc: 20.670,39.040,71.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=167 | Loss: 0.945 |  Acc: 21.752,39.534,92.978,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=167 | Loss: 1.840 |  Acc: 20.910,39.550,72.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=168 | Loss: 0.937 |  Acc: 21.914,39.530,93.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=168 | Loss: 1.839 |  Acc: 20.830,39.520,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=169 | Loss: 0.933 |  Acc: 21.822,39.668,93.296,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=169 | Loss: 1.846 |  Acc: 21.060,39.360,71.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=170 | Loss: 0.929 |  Acc: 21.772,39.958,93.394,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=170 | Loss: 1.856 |  Acc: 21.290,39.460,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=171 | Loss: 0.924 |  Acc: 21.908,39.908,93.478,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=171 | Loss: 1.848 |  Acc: 21.250,39.760,72.090,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=172 | Loss: 0.919 |  Acc: 21.996,40.118,93.708,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=172 | Loss: 1.862 |  Acc: 21.170,39.840,71.610,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=173 | Loss: 0.914 |  Acc: 22.054,39.994,93.872,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=173 | Loss: 1.875 |  Acc: 20.960,39.600,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=174 | Loss: 0.911 |  Acc: 22.058,40.062,93.898,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=174 | Loss: 1.871 |  Acc: 21.460,39.820,71.990,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=175 | Loss: 0.905 |  Acc: 21.938,40.204,94.118,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=175 | Loss: 1.894 |  Acc: 21.290,39.520,71.230,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=176 | Loss: 0.902 |  Acc: 21.898,40.196,94.124,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=176 | Loss: 1.888 |  Acc: 21.440,39.670,71.190,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=177 | Loss: 0.901 |  Acc: 21.958,40.122,94.218,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=177 | Loss: 1.884 |  Acc: 21.320,39.880,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=178 | Loss: 0.898 |  Acc: 22.184,40.276,94.240,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=178 | Loss: 1.903 |  Acc: 21.430,40.150,71.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=179 | Loss: 0.892 |  Acc: 22.168,40.316,94.360,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=179 | Loss: 1.911 |  Acc: 21.640,40.510,70.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=180 | Loss: 0.889 |  Acc: 22.236,40.638,94.410,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=180 | Loss: 1.910 |  Acc: 21.650,40.260,71.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=181 | Loss: 0.889 |  Acc: 22.250,40.578,94.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=181 | Loss: 1.903 |  Acc: 21.410,39.960,70.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=182 | Loss: 0.880 |  Acc: 22.080,40.718,94.824,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=182 | Loss: 1.923 |  Acc: 21.480,40.210,71.200,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=183 | Loss: 0.880 |  Acc: 22.318,40.864,94.770,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=183 | Loss: 1.907 |  Acc: 21.300,39.760,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=184 | Loss: 0.878 |  Acc: 22.106,40.624,94.784,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=184 | Loss: 1.922 |  Acc: 21.940,40.450,71.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=185 | Loss: 0.878 |  Acc: 22.188,40.846,94.762,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=185 | Loss: 1.935 |  Acc: 21.520,40.280,70.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=186 | Loss: 0.867 |  Acc: 22.224,41.066,95.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=186 | Loss: 1.949 |  Acc: 21.590,40.270,71.010,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=187 | Loss: 0.873 |  Acc: 22.200,40.774,94.886,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=187 | Loss: 1.933 |  Acc: 21.750,40.080,71.080,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=188 | Loss: 0.868 |  Acc: 22.258,41.016,95.096,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=188 | Loss: 1.932 |  Acc: 21.820,40.840,71.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=189 | Loss: 0.863 |  Acc: 22.314,40.690,95.084,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=189 | Loss: 1.951 |  Acc: 22.040,40.730,71.250,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=190 | Loss: 0.867 |  Acc: 22.146,40.900,94.986,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=190 | Loss: 1.955 |  Acc: 21.950,41.150,71.020,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=191 | Loss: 0.862 |  Acc: 22.184,41.148,95.058,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=191 | Loss: 1.961 |  Acc: 21.350,40.940,70.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=192 | Loss: 0.858 |  Acc: 22.260,41.170,95.258,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=192 | Loss: 1.945 |  Acc: 21.650,40.850,71.120,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=193 | Loss: 0.853 |  Acc: 22.546,41.484,95.412,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=193 | Loss: 1.958 |  Acc: 21.680,40.610,70.510,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=194 | Loss: 0.856 |  Acc: 22.556,41.164,95.222,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=194 | Loss: 1.954 |  Acc: 22.230,41.300,71.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=195 | Loss: 0.854 |  Acc: 22.488,41.154,95.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=195 | Loss: 1.974 |  Acc: 21.520,40.460,70.290,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=196 | Loss: 0.850 |  Acc: 22.356,41.410,95.414,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=196 | Loss: 1.955 |  Acc: 21.670,41.350,71.220,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=197 | Loss: 0.850 |  Acc: 22.456,41.338,95.498,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=197 | Loss: 1.977 |  Acc: 21.780,40.970,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=198 | Loss: 0.848 |  Acc: 22.554,41.458,95.454,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=198 | Loss: 1.984 |  Acc: 22.100,41.600,70.870,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=199 | Loss: 0.851 |  Acc: 22.512,41.234,95.446,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=199 | Loss: 1.985 |  Acc: 21.480,40.870,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=200 | Loss: 0.844 |  Acc: 22.678,41.588,95.616,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=200 | Loss: 1.988 |  Acc: 21.590,41.270,70.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=201 | Loss: 0.844 |  Acc: 22.570,41.542,95.570,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=201 | Loss: 2.005 |  Acc: 21.400,41.220,70.560,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=202 | Loss: 0.843 |  Acc: 22.576,41.632,95.604,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=202 | Loss: 1.994 |  Acc: 21.550,41.150,70.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=203 | Loss: 0.841 |  Acc: 22.578,41.662,95.560,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=203 | Loss: 2.000 |  Acc: 21.790,41.270,70.960,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=204 | Loss: 0.835 |  Acc: 22.712,41.688,95.806,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=204 | Loss: 2.008 |  Acc: 22.080,41.220,70.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=205 | Loss: 0.843 |  Acc: 22.748,41.926,95.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=205 | Loss: 2.012 |  Acc: 21.780,41.050,70.980,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=206 | Loss: 0.842 |  Acc: 22.634,41.648,95.564,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=206 | Loss: 2.009 |  Acc: 21.270,41.080,70.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=207 | Loss: 0.835 |  Acc: 22.850,41.706,95.796,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=207 | Loss: 2.027 |  Acc: 22.010,40.800,70.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=208 | Loss: 0.836 |  Acc: 22.750,41.910,95.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=208 | Loss: 2.020 |  Acc: 22.010,41.010,70.350,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=209 | Loss: 0.834 |  Acc: 22.644,42.258,95.766,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=209 | Loss: 2.031 |  Acc: 22.030,41.180,70.150,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=210 | Loss: 0.832 |  Acc: 22.648,41.926,95.724,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=210 | Loss: 2.021 |  Acc: 22.040,41.060,70.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=211 | Loss: 0.838 |  Acc: 22.578,41.840,95.606,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=211 | Loss: 2.026 |  Acc: 22.110,41.780,70.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=212 | Loss: 0.834 |  Acc: 22.756,41.898,95.726,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=212 | Loss: 2.022 |  Acc: 22.060,41.470,70.450,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=213 | Loss: 0.834 |  Acc: 22.856,41.998,95.694,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=213 | Loss: 2.028 |  Acc: 21.740,41.610,70.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=214 | Loss: 0.829 |  Acc: 22.770,42.130,95.860,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=214 | Loss: 2.014 |  Acc: 21.790,41.930,70.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=215 | Loss: 0.825 |  Acc: 22.696,42.024,95.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=215 | Loss: 2.042 |  Acc: 21.850,40.890,70.270,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=216 | Loss: 0.824 |  Acc: 22.652,42.272,95.998,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=216 | Loss: 2.079 |  Acc: 21.650,40.910,69.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=217 | Loss: 0.829 |  Acc: 22.868,42.354,95.868,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=217 | Loss: 2.063 |  Acc: 21.910,41.410,69.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=218 | Loss: 0.827 |  Acc: 22.812,42.304,95.802,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=218 | Loss: 2.051 |  Acc: 21.560,40.830,70.060,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=219 | Loss: 0.830 |  Acc: 22.664,42.382,95.792,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=219 | Loss: 2.006 |  Acc: 21.710,41.890,70.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=220 | Loss: 0.825 |  Acc: 22.768,42.344,95.804,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=220 | Loss: 2.026 |  Acc: 21.920,41.830,70.480,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=221 | Loss: 0.825 |  Acc: 22.922,42.502,95.910,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=221 | Loss: 2.024 |  Acc: 21.770,42.020,70.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=222 | Loss: 0.821 |  Acc: 22.858,42.604,95.960,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=222 | Loss: 2.087 |  Acc: 21.870,41.550,69.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=223 | Loss: 0.827 |  Acc: 22.790,42.186,95.856,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=223 | Loss: 2.051 |  Acc: 22.410,41.900,70.260,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=224 | Loss: 0.826 |  Acc: 23.054,42.666,95.748,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=224 | Loss: 2.037 |  Acc: 21.850,41.670,70.680,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=225 | Loss: 0.796 |  Acc: 22.954,42.964,96.812,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=225 | Loss: 1.981 |  Acc: 22.050,42.490,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=226 | Loss: 0.777 |  Acc: 23.054,43.204,97.434,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=226 | Loss: 1.964 |  Acc: 22.330,42.630,72.000,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=227 | Loss: 0.775 |  Acc: 22.968,42.852,97.516,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=227 | Loss: 1.978 |  Acc: 22.300,42.570,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=228 | Loss: 0.773 |  Acc: 23.150,43.190,97.538,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=228 | Loss: 1.987 |  Acc: 22.280,42.550,71.920,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=229 | Loss: 0.767 |  Acc: 22.996,43.162,97.692,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=229 | Loss: 1.983 |  Acc: 22.310,42.660,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=230 | Loss: 0.765 |  Acc: 23.150,43.178,97.786,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=230 | Loss: 1.981 |  Acc: 22.100,42.410,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=231 | Loss: 0.767 |  Acc: 23.056,43.334,97.756,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=231 | Loss: 1.975 |  Acc: 22.180,42.670,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=232 | Loss: 0.764 |  Acc: 23.160,43.436,97.834,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=232 | Loss: 1.981 |  Acc: 22.300,42.840,71.810,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=233 | Loss: 0.760 |  Acc: 23.288,43.484,97.966,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=233 | Loss: 1.986 |  Acc: 22.580,42.630,71.890,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=234 | Loss: 0.764 |  Acc: 23.080,43.214,97.932,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=234 | Loss: 1.983 |  Acc: 22.180,42.580,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=235 | Loss: 0.760 |  Acc: 23.276,43.420,97.904,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=235 | Loss: 1.991 |  Acc: 22.480,42.640,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=236 | Loss: 0.757 |  Acc: 23.276,43.322,98.066,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=236 | Loss: 1.987 |  Acc: 22.380,42.710,71.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=237 | Loss: 0.759 |  Acc: 23.212,43.264,98.022,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=237 | Loss: 1.993 |  Acc: 22.200,42.840,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=238 | Loss: 0.759 |  Acc: 23.060,43.366,98.042,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=238 | Loss: 1.993 |  Acc: 22.380,42.690,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=239 | Loss: 0.758 |  Acc: 23.262,43.432,98.064,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=239 | Loss: 1.993 |  Acc: 22.490,42.960,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=240 | Loss: 0.755 |  Acc: 23.256,43.510,98.130,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=240 | Loss: 2.004 |  Acc: 22.520,43.020,71.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=241 | Loss: 0.756 |  Acc: 23.220,43.396,98.078,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=241 | Loss: 2.008 |  Acc: 22.400,43.090,71.420,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=242 | Loss: 0.751 |  Acc: 23.300,43.582,98.164,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=242 | Loss: 2.006 |  Acc: 22.410,42.940,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=243 | Loss: 0.754 |  Acc: 23.244,43.458,98.160,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=243 | Loss: 1.998 |  Acc: 22.400,42.910,71.840,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=244 | Loss: 0.754 |  Acc: 23.226,43.396,98.072,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=244 | Loss: 1.998 |  Acc: 22.210,43.020,71.620,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=245 | Loss: 0.754 |  Acc: 23.174,43.562,98.198,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=245 | Loss: 1.989 |  Acc: 22.550,42.910,71.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=246 | Loss: 0.752 |  Acc: 23.216,43.544,98.226,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=246 | Loss: 1.992 |  Acc: 22.410,43.060,71.850,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=247 | Loss: 0.755 |  Acc: 23.140,43.480,98.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=247 | Loss: 1.998 |  Acc: 22.340,42.870,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=248 | Loss: 0.751 |  Acc: 23.178,43.614,98.190,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=248 | Loss: 2.003 |  Acc: 22.210,42.630,71.460,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=249 | Loss: 0.752 |  Acc: 23.180,43.554,98.110,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=249 | Loss: 1.998 |  Acc: 22.630,43.010,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=250 | Loss: 0.751 |  Acc: 23.368,43.644,98.186,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=250 | Loss: 1.997 |  Acc: 22.480,42.890,72.040,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=251 | Loss: 0.751 |  Acc: 23.316,43.446,98.278,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=251 | Loss: 1.997 |  Acc: 22.310,42.860,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=252 | Loss: 0.748 |  Acc: 23.322,43.702,98.326,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=252 | Loss: 2.003 |  Acc: 22.400,43.370,71.730,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=253 | Loss: 0.749 |  Acc: 23.346,43.578,98.310,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=253 | Loss: 2.004 |  Acc: 22.520,43.090,71.740,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=254 | Loss: 0.750 |  Acc: 23.266,43.580,98.224,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=254 | Loss: 1.998 |  Acc: 22.340,43.120,71.940,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=255 | Loss: 0.748 |  Acc: 23.292,43.560,98.302,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=255 | Loss: 2.006 |  Acc: 22.580,43.270,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=256 | Loss: 0.750 |  Acc: 23.366,43.732,98.146,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=256 | Loss: 2.009 |  Acc: 22.410,43.160,71.500,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=257 | Loss: 0.747 |  Acc: 23.248,43.548,98.324,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=257 | Loss: 2.006 |  Acc: 22.700,43.150,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=258 | Loss: 0.748 |  Acc: 23.318,43.738,98.298,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=258 | Loss: 2.015 |  Acc: 22.880,43.050,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=259 | Loss: 0.747 |  Acc: 23.204,43.538,98.356,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=259 | Loss: 2.010 |  Acc: 22.240,43.030,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=260 | Loss: 0.749 |  Acc: 23.322,43.860,98.300,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=260 | Loss: 2.007 |  Acc: 22.470,43.210,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=261 | Loss: 0.748 |  Acc: 23.262,43.742,98.282,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=261 | Loss: 2.010 |  Acc: 22.610,43.150,71.690,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=262 | Loss: 0.745 |  Acc: 23.402,43.818,98.426,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=262 | Loss: 2.027 |  Acc: 22.500,43.190,71.530,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=263 | Loss: 0.744 |  Acc: 23.136,43.768,98.380,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=263 | Loss: 2.024 |  Acc: 22.720,43.000,71.430,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=264 | Loss: 0.745 |  Acc: 23.340,43.904,98.378,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=264 | Loss: 2.008 |  Acc: 22.470,43.190,71.590,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=265 | Loss: 0.743 |  Acc: 23.486,43.834,98.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=265 | Loss: 2.008 |  Acc: 22.280,42.930,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=266 | Loss: 0.744 |  Acc: 23.270,43.902,98.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=266 | Loss: 2.010 |  Acc: 22.550,43.360,71.800,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=267 | Loss: 0.743 |  Acc: 23.100,43.640,98.452,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=267 | Loss: 2.008 |  Acc: 22.310,43.080,71.470,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=268 | Loss: 0.745 |  Acc: 23.526,43.704,98.364,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=268 | Loss: 2.011 |  Acc: 22.390,43.000,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=269 | Loss: 0.745 |  Acc: 23.192,43.702,98.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=269 | Loss: 2.019 |  Acc: 22.110,42.990,71.520,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=270 | Loss: 0.743 |  Acc: 23.442,43.828,98.368,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=270 | Loss: 2.014 |  Acc: 22.570,43.440,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=271 | Loss: 0.745 |  Acc: 23.238,43.710,98.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=271 | Loss: 2.010 |  Acc: 22.310,43.190,71.770,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=272 | Loss: 0.742 |  Acc: 23.496,43.600,98.416,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=272 | Loss: 2.014 |  Acc: 22.650,43.410,71.600,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=273 | Loss: 0.745 |  Acc: 23.472,43.762,98.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=273 | Loss: 2.014 |  Acc: 22.670,43.410,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=274 | Loss: 0.743 |  Acc: 23.246,43.780,98.540,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=274 | Loss: 2.010 |  Acc: 22.570,43.470,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=275 | Loss: 0.743 |  Acc: 23.308,43.882,98.480,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=275 | Loss: 2.006 |  Acc: 22.690,42.980,71.900,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=276 | Loss: 0.744 |  Acc: 23.130,43.568,98.436,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=276 | Loss: 2.009 |  Acc: 22.400,43.270,71.860,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=277 | Loss: 0.743 |  Acc: 23.376,43.694,98.438,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=277 | Loss: 2.009 |  Acc: 22.380,43.110,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=278 | Loss: 0.744 |  Acc: 23.322,44.072,98.336,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=278 | Loss: 2.017 |  Acc: 22.400,42.990,71.570,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=279 | Loss: 0.746 |  Acc: 23.284,43.598,98.352,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=279 | Loss: 2.007 |  Acc: 22.560,43.230,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=280 | Loss: 0.745 |  Acc: 23.392,44.120,98.322,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=280 | Loss: 2.007 |  Acc: 22.570,43.310,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=281 | Loss: 0.743 |  Acc: 23.422,43.748,98.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=281 | Loss: 2.018 |  Acc: 22.620,42.990,71.670,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=282 | Loss: 0.743 |  Acc: 23.500,43.606,98.420,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=282 | Loss: 2.012 |  Acc: 22.630,43.200,71.580,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=283 | Loss: 0.742 |  Acc: 23.336,43.882,98.490,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=283 | Loss: 2.012 |  Acc: 22.570,43.100,71.820,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=284 | Loss: 0.744 |  Acc: 23.508,43.824,98.470,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=284 | Loss: 2.020 |  Acc: 22.620,43.150,71.720,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=285 | Loss: 0.744 |  Acc: 23.220,43.516,98.450,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=285 | Loss: 2.013 |  Acc: 22.720,43.400,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=286 | Loss: 0.742 |  Acc: 23.288,43.792,98.448,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=286 | Loss: 2.017 |  Acc: 22.460,43.380,71.910,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=287 | Loss: 0.742 |  Acc: 23.380,43.934,98.488,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=287 | Loss: 2.020 |  Acc: 22.750,43.140,71.880,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=288 | Loss: 0.746 |  Acc: 23.502,43.822,98.388,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=288 | Loss: 2.012 |  Acc: 22.270,43.140,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=289 | Loss: 0.742 |  Acc: 23.476,43.934,98.464,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=289 | Loss: 2.002 |  Acc: 22.560,43.060,71.790,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=290 | Loss: 0.743 |  Acc: 23.296,43.674,98.408,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=290 | Loss: 2.010 |  Acc: 22.560,43.320,71.760,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=291 | Loss: 0.743 |  Acc: 23.374,43.794,98.458,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=291 | Loss: 2.014 |  Acc: 22.090,42.940,71.830,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=292 | Loss: 0.742 |  Acc: 23.418,43.708,98.486,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=292 | Loss: 2.009 |  Acc: 22.570,43.230,71.780,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=293 | Loss: 0.742 |  Acc: 23.516,43.708,98.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=293 | Loss: 2.004 |  Acc: 22.500,43.160,71.550,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=294 | Loss: 0.743 |  Acc: 23.496,43.996,98.400,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=294 | Loss: 2.013 |  Acc: 22.380,43.210,71.640,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=295 | Loss: 0.744 |  Acc: 23.392,43.644,98.370,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=295 | Loss: 2.005 |  Acc: 22.540,43.270,71.750,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=296 | Loss: 0.743 |  Acc: 23.452,43.874,98.406,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=296 | Loss: 2.016 |  Acc: 22.480,43.190,71.540,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=297 | Loss: 0.742 |  Acc: 23.358,43.672,98.418,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=297 | Loss: 2.003 |  Acc: 22.700,42.980,71.700,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=298 | Loss: 0.742 |  Acc: 23.458,43.994,98.476,% | Adaptive Acc:0.000% | clf_exit:
Testing: Epoch=298 | Loss: 2.019 |  Acc: 22.220,43.170,71.660,% | Adaptive Acc:0.000% | clf_exit:

Training Setting: Namespace(T=3.0, adaptive=0, backend='resnet56', batch_size=128, circles=8, dataset_name='cifar100', dropout=1.0, fb='1:1:1', gamma=0.9, ge=1, kd=1, lmbda=0.0, max_epoch=300, step_all=0, step_clf=0, threshold=0.5, vanilla=0)
Training: Epoch=299 | Loss: 0.742 |  Acc: 23.316,43.992,98.450,% | Adaptive Acc:97.038% | clf_exit: 0.003 0.107 0.889
Testing: Epoch=299 | Loss: 2.011 |  Acc: 22.650,42.960,71.780,% | Adaptive Acc:70.350% | clf_exit: 0.011 0.186 0.803

circles: 0
Testing: Epoch=299 | Loss: 5.219 |  Acc: 1.000,1.000,10.150,% | Adaptive Acc:10.150% | clf_exit: 0.000 0.000 1.000
circles: 1
Testing: Epoch=299 | Loss: 4.311 |  Acc: 1.710,1.000,37.190,% | Adaptive Acc:37.190% | clf_exit: 0.000 0.000 1.000
circles: 2
Testing: Epoch=299 | Loss: 3.715 |  Acc: 2.680,1.200,47.780,% | Adaptive Acc:47.790% | clf_exit: 0.000 0.000 1.000
circles: 3
Testing: Epoch=299 | Loss: 3.286 |  Acc: 3.260,2.450,53.430,% | Adaptive Acc:53.540% | clf_exit: 0.002 0.000 0.998
circles: 4
Testing: Epoch=299 | Loss: 2.878 |  Acc: 5.680,6.800,58.700,% | Adaptive Acc:58.680% | clf_exit: 0.004 0.009 0.987
circles: 5
Testing: Epoch=299 | Loss: 2.447 |  Acc: 10.180,14.780,64.620,% | Adaptive Acc:63.680% | clf_exit: 0.008 0.030 0.962
circles: 6
Testing: Epoch=299 | Loss: 2.100 |  Acc: 16.280,28.100,69.670,% | Adaptive Acc:68.740% | clf_exit: 0.010 0.051 0.939
circles: 7
Testing: Epoch=299 | Loss: 1.965 |  Acc: 21.060,40.140,71.530,% | Adaptive Acc:70.830% | clf_exit: 0.011 0.114 0.875
circles: 8
Testing: Epoch=299 | Loss: 2.011 |  Acc: 22.650,42.960,71.780,% | Adaptive Acc:70.350% | clf_exit: 0.011 0.186 0.803
